2025-05-13 07:52:50,931 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2025-05-13 07:52:50,931 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2025-05-13 07:52:50,931 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(138)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:50,945 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is null
2025-05-13 07:52:50,945 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(166)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-05-13 07:52:50,946 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:50,947 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-13 07:52:50,947 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:52:50,947 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15264 (fallback to raft.grpc.server.port)
2025-05-13 07:52:50,947 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:52:50,948 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15264 (fallback to raft.grpc.server.port)
2025-05-13 07:52:50,948 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-13 07:52:50,948 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15264 (custom)
2025-05-13 07:52:50,950 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 5242880 (custom)
2025-05-13 07:52:50,950 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-05-13 07:52:50,950 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-05-13 07:52:50,950 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:52:50,950 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:50,951 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-13 07:52:50,951 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-13 07:52:50,952 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2025-05-13 07:52:50,952 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:52:50,952 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-13 07:52:50,952 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:52:50,952 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha] (custom)
2025-05-13 07:52:50,952 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-13 07:52:50,952 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-13 07:52:50,953 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 22a047fb-99fa-46e1-9d16-532806e028b1: addNew group-A61BB3107D3C:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264] returns group-A61BB3107D3C:java.util.concurrent.CompletableFuture@3957a2ad[Not completed]
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 22a047fb-99fa-46e1-9d16-532806e028b1: new RaftServerImpl for group-A61BB3107D3C:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264] with SCMStateMachine:uninitialized
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5000ms (custom)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: ConfigurationManager, init=conf: {index: -1, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 60s (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 60000ms (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:52:50,954 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:52:50,955 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha] (custom)
2025-05-13 07:52:50,956 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c does not exist. Creating ...
2025-05-13 07:52:50,957 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:52:50,958 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c has been successfully formatted.
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 22a047fb-99fa-46e1-9d16-532806e028b1: initialize group-A61BB3107D3C
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:52:50,959 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#7123,22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:50,960 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:52:50,961 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:52:50,961 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2025-05-13 07:52:50,961 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:52:50,961 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:52:50,964 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: start as a follower, conf=conf: {index: -1, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:50,964 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:52:50,965 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 22a047fb-99fa-46e1-9d16-532806e028b1: start 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState
2025-05-13 07:52:50,966 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A61BB3107D3C,id=22a047fb-99fa-46e1-9d16-532806e028b1
2025-05-13 07:52:50,966 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:52:50,967 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:52:50,966 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-A61BB3107D3C,id=22a047fb-99fa-46e1-9d16-532806e028b1
2025-05-13 07:52:50,967 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:52:50,967 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:52:50,967 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:52:50,968 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-05-13 07:52:50,968 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2025-05-13 07:52:50,968 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:52:50,969 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: Successfully started.
2025-05-13 07:52:50,969 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - 22a047fb-99fa-46e1-9d16-532806e028b1: start RPC server
2025-05-13 07:52:50,971 [main] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 22a047fb-99fa-46e1-9d16-532806e028b1: GrpcService started, listening on 15264
2025-05-13 07:52:50,972 [JvmPauseMonitor45] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-22a047fb-99fa-46e1-9d16-532806e028b1: Started
2025-05-13 07:52:51,923 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-13 07:52:52,043 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1078462683ns, electionTimeout:1076ms
2025-05-13 07:52:52,044 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState
2025-05-13 07:52:52,044 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:52:52,044 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:52:52,044 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 22a047fb-99fa-46e1-9d16-532806e028b1: start 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49
2025-05-13 07:52:52,044 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:52,044 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49 PRE_VOTE round 0: result PASSED (term=0)
2025-05-13 07:52:52,046 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:52,046 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49 ELECTION round 0: result PASSED (term=1)
2025-05-13 07:52:52,046 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49
2025-05-13 07:52:52,046 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-13 07:52:52,046 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:52:52,046 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-13 07:52:52,046 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5000ms (custom)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 22a047fb-99fa-46e1-9d16-532806e028b1: start 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderStateImpl
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: change Leader from null to 22a047fb-99fa-46e1-9d16-532806e028b1 at term 1 for becomeLeader, leader elected after 1093ms
2025-05-13 07:52:52,047 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:52:52,048 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:52:52,048 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection49] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: set configuration conf: {index: 0, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:52,053 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/current/log_inprogress_0
2025-05-13 07:52:52,055 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-13 07:52:52,606 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 11 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 11.
2025-05-13 07:52:52,972 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - 22a047fb-99fa-46e1-9d16-532806e028b1: close
2025-05-13 07:52:52,972 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: shutdown
2025-05-13 07:52:52,972 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown server GrpcServerProtocolService now
2025-05-13 07:52:52,972 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A61BB3107D3C,id=22a047fb-99fa-46e1-9d16-532806e028b1
2025-05-13 07:52:52,972 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderStateImpl
2025-05-13 07:52:52,972 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-PendingRequests: sendNotLeaderResponses
2025-05-13 07:52:52,973 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater: set stopIndex = 0
2025-05-13 07:52:52,973 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater: Took a snapshot at index 0
2025-05-13 07:52:52,973 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-13 07:52:52,973 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:1, i:0)
2025-05-13 07:52:52,973 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown server GrpcServerProtocolService successfully
2025-05-13 07:52:52,973 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:52:53,055 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker close()
2025-05-13 07:52:53,055 [JvmPauseMonitor45] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-22a047fb-99fa-46e1-9d16-532806e028b1: Stopped
2025-05-13 07:52:53,055 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(138)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:53,056 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is null
2025-05-13 07:52:53,056 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(166)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-05-13 07:52:53,057 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:53,057 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:53,114 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-05-13 07:52:53,114 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-05-13 07:52:53,131 [main] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:<init>(100)) - starting Raft server for scm:22a047fb-99fa-46e1-9d16-532806e028b1
2025-05-13 07:52:53,131 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:53,132 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-13 07:52:53,132 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:52:53,132 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15264 (fallback to raft.grpc.server.port)
2025-05-13 07:52:53,132 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:52:53,132 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15264 (fallback to raft.grpc.server.port)
2025-05-13 07:52:53,132 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-13 07:52:53,132 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15264 (custom)
2025-05-13 07:52:53,132 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 5242880 (custom)
2025-05-13 07:52:53,132 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-05-13 07:52:53,133 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-05-13 07:52:53,133 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:52:53,133 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:53,133 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-13 07:52:53,133 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-13 07:52:53,133 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2025-05-13 07:52:53,133 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:52:53,134 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-13 07:52:53,134 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:52:53,134 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha] (custom)
2025-05-13 07:52:53,134 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-13 07:52:53,134 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-13 07:52:53,134 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - 22a047fb-99fa-46e1-9d16-532806e028b1: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c
2025-05-13 07:52:53,135 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 22a047fb-99fa-46e1-9d16-532806e028b1: addNew group-A61BB3107D3C:[] returns group-A61BB3107D3C:java.util.concurrent.CompletableFuture@5a78b25d[Not completed]
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 22a047fb-99fa-46e1-9d16-532806e028b1: new RaftServerImpl for group-A61BB3107D3C:[] with SCMStateMachine:uninitialized
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5000ms (custom)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 60s (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 60000ms (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:52:53,135 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:52:53,136 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-05-13 07:52:53,136 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:52:53,136 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:52:53,136 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:52:53,136 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:52:53,136 [22a047fb-99fa-46e1-9d16-532806e028b1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:52:53,136 [main] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:<init>(61)) - Initializing SCM Snapshot Provider
2025-05-13 07:52:53,136 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(304)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-05-13 07:52:53,136 [main] WARN  ha.SCMHAUtils (SCMHAUtils.java:getSCMRatisSnapshotDirectory(120)) - SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2025-05-13 07:52:53,137 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-13 07:52:53,138 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(355)) - upgrade localId to 115816896921600000
2025-05-13 07:52:53,138 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(365)) - upgrade delTxnId to 0
2025-05-13 07:52:53,139 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(382)) - upgrade containerId to 0
2025-05-13 07:52:53,140 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(419)) - upgrade CertificateId to 2
2025-05-13 07:52:53,140 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-05-13 07:52:53,141 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(182)) - Entering startup safe mode.
2025-05-13 07:52:53,142 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(84)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-05-13 07:52:53,142 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(84)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-05-13 07:52:53,142 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-05-13 07:52:53,143 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(55)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-05-13 07:52:53,143 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(84)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-05-13 07:52:53,143 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2025-05-13 07:52:53,143 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting RatisPipelineUtilsThread.
2025-05-13 07:52:53,143 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(64)) - Starting BackgroundPipelineScrubber Service.
2025-05-13 07:52:53,144 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2025-05-13 07:52:53,144 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(64)) - Starting ExpiredContainerReplicaOpScrubber Service.
2025-05-13 07:52:53,145 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2025-05-13 07:52:53,146 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-05-13 07:52:53,147 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-05-13 07:52:53,148 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2025-05-13 07:52:53,149 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(285)) - Starting Replication Monitor Thread.
2025-05-13 07:52:53,150 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2025-05-13 07:52:53,150 [main] INFO  safemode.RatisContainerSafeModeRule (RatisContainerSafeModeRule.java:initializeRule(160)) - Refreshed Containers with one replica threshold count 0.
2025-05-13 07:52:53,151 [main] INFO  safemode.ECContainerSafeModeRule (ECContainerSafeModeRule.java:initializeRule(205)) - Refreshed Containers with ec n replica threshold count 0.
2025-05-13 07:52:53,151 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(177)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:52:53,151 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(190)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-05-13 07:52:53,151 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(430)) - SCM start with adminUsers: [runner]
2025-05-13 07:52:53,152 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:52:53,152 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15262
2025-05-13 07:52:53,152 [Socket Reader #1 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15262
2025-05-13 07:52:53,152 [Socket Reader #2 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15262
2025-05-13 07:52:53,153 [Socket Reader #3 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15262
2025-05-13 07:52:53,153 [Socket Reader #4 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15262
2025-05-13 07:52:53,154 [Socket Reader #5 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15262
2025-05-13 07:52:53,154 [Socket Reader #6 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15262
2025-05-13 07:52:53,154 [Socket Reader #7 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15262
2025-05-13 07:52:53,155 [Socket Reader #8 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15262
2025-05-13 07:52:53,155 [Socket Reader #9 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15262
2025-05-13 07:52:53,155 [Socket Reader #10 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15262
2025-05-13 07:52:53,156 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:52:53,156 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15261
2025-05-13 07:52:53,156 [Socket Reader #1 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15261
2025-05-13 07:52:53,157 [Socket Reader #2 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15261
2025-05-13 07:52:53,157 [Socket Reader #3 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15261
2025-05-13 07:52:53,157 [Socket Reader #4 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15261
2025-05-13 07:52:53,158 [Socket Reader #5 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15261
2025-05-13 07:52:53,158 [Socket Reader #7 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15261
2025-05-13 07:52:53,158 [Socket Reader #8 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15261
2025-05-13 07:52:53,158 [Socket Reader #9 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15261
2025-05-13 07:52:53,158 [Socket Reader #10 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15261
2025-05-13 07:52:53,158 [Socket Reader #6 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15261
2025-05-13 07:52:53,159 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:52:53,159 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15260
2025-05-13 07:52:53,159 [Socket Reader #1 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15260
2025-05-13 07:52:53,159 [Socket Reader #2 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15260
2025-05-13 07:52:53,159 [Socket Reader #3 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15260
2025-05-13 07:52:53,160 [Socket Reader #4 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15260
2025-05-13 07:52:53,160 [Socket Reader #5 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15260
2025-05-13 07:52:53,160 [Socket Reader #6 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15260
2025-05-13 07:52:53,160 [Socket Reader #7 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15260
2025-05-13 07:52:53,160 [Socket Reader #8 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15260
2025-05-13 07:52:53,160 [Socket Reader #9 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15260
2025-05-13 07:52:53,160 [Socket Reader #10 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15260
2025-05-13 07:52:53,163 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2025-05-13 07:52:53,163 [main] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-05-13 07:52:53,164 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1507)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15260
2025-05-13 07:52:53,164 [main] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:start(203)) - starting ratis server 0.0.0.0:15264
2025-05-13 07:52:53,164 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:52:53,164 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:52:53,164 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha] (custom)
2025-05-13 07:52:53,165 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:52:53,166 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:analyzeAndRecoverStorage(118)) - Read RaftStorageMetadata{term=1, votedFor=22a047fb-99fa-46e1-9d16-532806e028b1} from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/current/raft-meta
2025-05-13 07:52:53,166 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: set configuration conf: {index: 0, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:53,166 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 22a047fb-99fa-46e1-9d16-532806e028b1: initialize group-A61BB3107D3C
2025-05-13 07:52:53,166 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:52:53,166 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:52:53,166 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#7197,22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:52:53,167 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-05-13 07:52:53,168 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2025-05-13 07:52:53,168 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:53,168 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:52:53,168 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:52:53,168 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2025-05-13 07:52:53,168 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: set configuration conf: {index: 0, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:53,168 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(171)) - Successfully read 1 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/current/log_inprogress_0
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 (append) at position 82
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: start as a follower, conf=conf: {index: 0, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: changes role from      null to FOLLOWER at term 1 for startAsFollower
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 22a047fb-99fa-46e1-9d16-532806e028b1: start 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A61BB3107D3C,id=22a047fb-99fa-46e1-9d16-532806e028b1
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-A61BB3107D3C,id=22a047fb-99fa-46e1-9d16-532806e028b1
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:52:53,169 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:52:53,170 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:52:53,170 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: Successfully started.
2025-05-13 07:52:53,170 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - 22a047fb-99fa-46e1-9d16-532806e028b1: start RPC server
2025-05-13 07:52:53,171 [main] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 22a047fb-99fa-46e1-9d16-532806e028b1: GrpcService started, listening on 15264
2025-05-13 07:52:53,172 [JvmPauseMonitor46] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-22a047fb-99fa-46e1-9d16-532806e028b1: Started
2025-05-13 07:52:53,172 [main] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:start(131)) -  scm role is FOLLOWER peers [22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]
2025-05-13 07:52:53,172 [main] INFO  ha.InterSCMGrpcService (InterSCMGrpcProtocolService.java:start(98)) - Starting SCM Grpc Service at port 15265
2025-05-13 07:52:53,172 [main] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(64)) - Starting SCMHATransactionMonitor Service.
2025-05-13 07:52:53,174 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMHATransactionMonitor.
2025-05-13 07:52:53,174 [main] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(61)) - SCMHATransactionMonitor Service is already running, skip start.
2025-05-13 07:52:53,175 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(138)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2025-05-13 07:52:53,176 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2025-05-13 07:52:53,176 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2025-05-13 07:52:53,192 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2025-05-13 07:52:53,192 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2025-05-13 07:52:53,210 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(207)) - RPC server for Client  is listening at /0.0.0.0:15260
2025-05-13 07:52:53,210 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:52:53,211 [IPC Server listener on 15260] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15260: starting
2025-05-13 07:52:53,222 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1520)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15261
2025-05-13 07:52:53,222 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(166)) - RPC server for Block Protocol is listening at /0.0.0.0:15261
2025-05-13 07:52:53,222 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:52:53,223 [IPC Server listener on 15261] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15261: starting
2025-05-13 07:52:53,235 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for scm at: http://0.0.0.0:15263
2025-05-13 07:52:53,235 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-13 07:52:53,244 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-13 07:52:53,247 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-13 07:52:53,247 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2025-05-13 07:52:53,247 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-13 07:52:53,247 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-13 07:52:53,248 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/webserver
2025-05-13 07:52:53,248 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15263
2025-05-13 07:52:53,248 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-13 07:52:53,249 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-13 07:52:53,250 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-13 07:52:53,250 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-13 07:52:53,250 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@72031e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-13 07:52:53,251 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@587d34b7{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-05-13 07:52:53,255 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7ea95d85{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-05-13 07:52:53,256 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@46870b92{HTTP/1.1, (http/1.1)}{0.0.0.0:15263}
2025-05-13 07:52:53,256 [main] INFO  server.Server (Server.java:doStart(415)) - Started @259394ms
2025-05-13 07:52:53,256 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-13 07:52:53,256 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of scm listening at http://0.0.0.0:15263
2025-05-13 07:52:53,257 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:53,258 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(113)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2025-05-13 07:52:53,258 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(224)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15266
2025-05-13 07:52:53,258 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(252)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2025-05-13 07:52:53,258 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(259)) - OM Node ID is not set. Setting it to the default ID: om1
2025-05-13 07:52:53,259 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:53,260 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = DELEGATION_TOKEN_SYMMETRIC_SIGN (version = 8), software layout = DELEGATION_TOKEN_SYMMETRIC_SIGN (version = 8)
2025-05-13 07:52:53,342 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 81 ms to scan 2 urls, producing 207 keys and 618 values
2025-05-13 07:52:53,342 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(110)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2025-05-13 07:52:53,342 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(110)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2025-05-13 07:52:53,342 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:53,343 [main] INFO  om.OzoneManager (OzoneManager.java:setReplicationFromConfig(4596)) - Set default replication in OM: RATIS/3 -> RATIS/THREE
2025-05-13 07:52:53,343 [main] INFO  proxy.SCMContainerLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15260]
2025-05-13 07:52:53,343 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15261]
2025-05-13 07:52:53,345 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15261]
2025-05-13 07:52:53,924 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-13 07:52:54,255 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1085775053ns, electionTimeout:1085ms
2025-05-13 07:52:54,255 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState
2025-05-13 07:52:54,255 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2025-05-13 07:52:54,255 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:52:54,255 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 22a047fb-99fa-46e1-9d16-532806e028b1: start 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50
2025-05-13 07:52:54,255 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50 PRE_VOTE round 0: submit vote requests at term 1 for conf: {index: 0, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:54,256 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50 PRE_VOTE round 0: result PASSED (term=1)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50 ELECTION round 0: submit vote requests at term 2 for conf: {index: 0, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50 ELECTION round 0: result PASSED (term=2)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5000ms (custom)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 22a047fb-99fa-46e1-9d16-532806e028b1: start 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderStateImpl
2025-05-13 07:52:54,257 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:52:54,258 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(291)) - current SCM becomes leader of term 2.
2025-05-13 07:52:54,258 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(95)) - update <isLeader,term> from <false,0> to <true,2>
2025-05-13 07:52:54,258 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: change Leader from null to 22a047fb-99fa-46e1-9d16-532806e028b1 at term 2 for becomeLeader, leader elected after 1122ms
2025-05-13 07:52:54,258 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(443)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2025-05-13 07:52:54,258 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderElection50] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: set configuration conf: {index: 1, cur=peers:[22a047fb-99fa-46e1-9d16-532806e028b1|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-13 07:52:54,258 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(601)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/current/log_inprogress_0 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/current/log_0-0
2025-05-13 07:52:54,259 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_1 at position 0
2025-05-13 07:52:54,264 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/scm-ha/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/current/log_inprogress_1
2025-05-13 07:52:54,266 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderStateImpl is ready since appliedIndex == startIndex == 1
2025-05-13 07:52:54,266 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  ha.SCMContext (SCMContext.java:setLeaderReady(122)) - update <isLeaderReady> from <false> to <true>
2025-05-13 07:52:54,266 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(268)) - Service BackgroundPipelineCreator transitions to RUNNING.
2025-05-13 07:52:54,266 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.RatisContainerSafeModeRule (RatisContainerSafeModeRule.java:initializeRule(160)) - Refreshed Containers with one replica threshold count 0.
2025-05-13 07:52:54,266 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:52:54,266 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.ECContainerSafeModeRule (ECContainerSafeModeRule.java:initializeRule(205)) - Refreshed Containers with ec n replica threshold count 0.
2025-05-13 07:52:54,266 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(186)) - Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-05-13 07:52:54,267 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15262
2025-05-13 07:52:54,267 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:52:54,267 [IPC Server listener on 15262] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15262: starting
2025-05-13 07:52:54,607 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 12 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 12.
2025-05-13 07:52:55,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:52:55,350 [main] INFO  om.OzoneManager (OzoneManager.java:<init>(670)) - OM start with adminUsers: [runner]
2025-05-13 07:52:55,351 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:55,478 [main] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(914)) - S3 Multi-Tenancy is disabled
2025-05-13 07:52:55,478 [main] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(187)) - Ozone filesystem snapshot feature is enabled.
2025-05-13 07:52:55,478 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:52:55,495 [main] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4654)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2025-05-13 07:52:55,495 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(304)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-05-13 07:52:55,495 [main] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(488)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2025-05-13 07:52:55,495 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:52:55,495 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:52:55,495 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(304)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-05-13 07:52:55,496 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:55,496 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(167)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15269
2025-05-13 07:52:55,496 [main] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(618)) - TransactionInfo not found in OM DB.
2025-05-13 07:52:55,497 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-13 07:52:55,497 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:52:55,497 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15269 (fallback to raft.grpc.server.port)
2025-05-13 07:52:55,497 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:52:55,497 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15269 (fallback to raft.grpc.server.port)
2025-05-13 07:52:55,497 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-13 07:52:55,497 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15269 (custom)
2025-05-13 07:52:55,497 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 5242880 (custom)
2025-05-13 07:52:55,497 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-05-13 07:52:55,498 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2025-05-13 07:52:55,498 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:52:55,498 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:55,498 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-13 07:52:55,498 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-13 07:52:55,499 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2025-05-13 07:52:55,499 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:52:55,499 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-13 07:52:55,499 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:52:55,499 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/ratis] (custom)
2025-05-13 07:52:55,499 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-13 07:52:55,499 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-13 07:52:55,500 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - om1: addNew group-C5BA1605619E:[om1|localhost:15269] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@650f193d[Not completed]
2025-05-13 07:52:55,500 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2284)) - OzoneManager Ratis server initialized at port 15269
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|localhost:15269] with OzoneManagerStateMachine:uninitialized
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - om1@group-C5BA1605619E: ConfigurationManager, init=conf: {index: -1, cur=peers:[om1|localhost:15269]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:52:55,500 [main] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1340)) - Creating RPC Server
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:52:55,500 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:52:55,501 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2025-05-13 07:52:55,501 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:52:55,501 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:52:55,502 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:52:55,502 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:52:55,502 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:52:55,890 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 389 ms to scan 24 urls, producing 60 keys and 7515 values
2025-05-13 07:52:55,891 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:52:55,891 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 127.0.0.1:15266
2025-05-13 07:52:55,892 [Socket Reader #1 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15266
2025-05-13 07:52:55,892 [Socket Reader #2 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15266
2025-05-13 07:52:55,892 [Socket Reader #3 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15266
2025-05-13 07:52:55,892 [Socket Reader #4 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15266
2025-05-13 07:52:55,892 [Socket Reader #5 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15266
2025-05-13 07:52:55,892 [Socket Reader #6 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15266
2025-05-13 07:52:55,892 [Socket Reader #7 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15266
2025-05-13 07:52:55,893 [Socket Reader #8 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15266
2025-05-13 07:52:55,893 [Socket Reader #9 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15266
2025-05-13 07:52:55,893 [Socket Reader #10 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15266
2025-05-13 07:52:55,908 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2025-05-13 07:52:55,917 [main] INFO  om.OzoneManager (OzoneManager.java:start(1768)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15266
2025-05-13 07:52:55,917 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(628)) - Starting OzoneManagerRatisServer om1 at port 15269
2025-05-13 07:52:55,917 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:52:55,917 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:52:55,917 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/ratis] (custom)
2025-05-13 07:52:55,918 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2025-05-13 07:52:55,918 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:52:55,919 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2025-05-13 07:52:55,920 [om1-impl-thread1] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:lambda$0(138)) - om1: initialize group-C5BA1605619E with (t:0, i:~)
2025-05-13 07:52:55,920 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:52:55,920 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:52:55,920 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:55,920 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:52:55,920 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:52:55,920 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#7548,om1@group-C5BA1605619E-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-05-13 07:52:55,921 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - om1@group-C5BA1605619E: start as a follower, conf=conf: {index: -1, cur=peers:[om1|localhost:15269]|listeners:[], old=null}
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:52:55,922 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-FollowerState
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2025-05-13 07:52:55,923 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2025-05-13 07:52:55,923 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2025-05-13 07:52:55,923 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - om1@group-C5BA1605619E: Successfully started.
2025-05-13 07:52:55,923 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - om1: start RPC server
2025-05-13 07:52:55,925 [main] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - om1: GrpcService started, listening on 15269
2025-05-13 07:52:55,925 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-13 07:52:55,925 [main] INFO  om.OzoneManager (OzoneManager.java:start(1783)) - Version File has different layout version (8) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2025-05-13 07:52:55,925 [JvmPauseMonitor47] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-om1: Started
2025-05-13 07:52:55,929 [main] INFO  client.ScmTopologyClient (ScmTopologyClient.java:start(70)) - Initial network topology fetched from SCM: /.
2025-05-13 07:52:55,929 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-05-13 07:52:55,929 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-05-13 07:52:55,933 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15267
2025-05-13 07:52:55,933 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-13 07:52:55,934 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-13 07:52:55,935 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-13 07:52:55,936 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2025-05-13 07:52:55,936 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-13 07:52:55,936 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-13 07:52:55,936 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/webserver
2025-05-13 07:52:55,936 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15267
2025-05-13 07:52:55,936 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-13 07:52:55,938 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-13 07:52:55,938 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-13 07:52:55,938 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-13 07:52:55,938 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@73aee4a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-13 07:52:55,939 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@35873a1{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-05-13 07:52:55,943 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1f9ede24{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2025-05-13 07:52:55,943 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2ddf6cbd{HTTP/1.1, (http/1.1)}{0.0.0.0:15267}
2025-05-13 07:52:55,944 [main] INFO  server.Server (Server.java:doStart(415)) - Started @262082ms
2025-05-13 07:52:55,944 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-13 07:52:55,944 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of ozoneManager listening at http://0.0.0.0:15267
2025-05-13 07:52:55,944 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:52:55,944 [IPC Server listener on 15266] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15266: starting
2025-05-13 07:52:55,947 [main] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2238)) - Trash Interval set to 0. Files deleted won't move to trash
2025-05-13 07:52:56,076 [main] INFO  recon.ReconServer (HddsServerUtil.java:startupShutdownMessage(683)) - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ReconServer
STARTUP_MSG:   host = pkrvmberfyhpb9w/10.1.0.219
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.1.0-SNAPSHOT
STARTUP_MSG:   classpath = /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/hdds-server-scm-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.16.2/jackson-annotations-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.16.2/jackson-core-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.16.2/jackson-databind-2.16.2.jar:/home/runner/.m2/repository/com/google/guava/guava/32.1.3-jre/guava-32.1.3-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.37.0/checker-qual-3.37.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.29.2/error_prone_annotations-2.29.2.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/commons-io/commons-io/2.18.0/commons-io-2.18.0.jar:/home/runner/.m2/repository/info/picocli/picocli/4.7.7/picocli-4.7.7.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.6/metrics-core-3.2.6.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.27.1/commons-compress-1.27.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.12.0/commons-text-1.12.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.4.1/hadoop-auth-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.4.1/hadoop-common-3.4.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/client/target/hdds-client-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/config/target/hdds-config-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/hdds-interface-admin-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/hdds-interface-client-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/hdds-interface-server-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/hdds-server-framework-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/3.1.2/ratis-client-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/3.1.2/ratis-common-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/3.1.2/ratis-grpc-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/3.1.2/ratis-netty-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/3.1.2/ratis-proto-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/3.1.2/ratis-server-api-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.6/ratis-thirdparty-misc-1.0.6.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk18on/1.80/bcpkix-jdk18on-1.80.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk18on/1.80/bcprov-jdk18on-1.80.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.57.v20241219/jetty-webapp-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.57.v20241219/jetty-xml-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/2.0.17/slf4j-api-2.0.17.jar:/home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/target/ozone-cli-admin-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.16.2/jackson-datatype-jsr310-2.16.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.4.1/hadoop-hdfs-client-3.4.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/ozone-interface-client-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.17.1/commons-codec-1.17.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/target/ozone-cli-shell-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli-shell-jline3/4.7.7/picocli-shell-jline3-4.7.7.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.14/httpclient-4.5.14.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/ozone-filesystem-common-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/jline/jline/3.30.0/jline-3.30.0.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/2.0.17/slf4j-reload4j-2.0.17.jar:/home/runner/work/ozone/ozone/hadoop-ozone/client/target/ozone-client-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/hdds-erasurecode-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/common/target/ozone-common-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.58.0/grpc-api-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.58.0/grpc-netty-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.58.0/grpc-core-1.58.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.23/animal-sniffer-annotations-1.23.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.58.0/grpc-context-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-util/1.58.0/grpc-util-1.58.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.109.Final/netty-codec-http2-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.109.Final/netty-codec-http-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.109.Final/netty-common-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.109.Final/netty-handler-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.109.Final/netty-resolver-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.109.Final/netty-handler-proxy-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.109.Final/netty-codec-socks-4.1.109.Final.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.16/httpcore-4.4.16.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.65.Final/netty-tcnative-classes-2.0.65.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-windows-x86_64.jar:/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/ozone-csi-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.26/reload4j-1.2.26.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.58.0/grpc-protobuf-1.58.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.22.0/proto-google-common-protos-2.22.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.58.0/grpc-protobuf-lite-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.58.0/grpc-stub-1.58.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.109.Final/netty-transport-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.109.Final/netty-transport-classes-epoll-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.109.Final/netty-transport-native-unix-common-4.1.109.Final.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/ozone-filesystem-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/freon/target/ozone-freon-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.661/aws-java-sdk-core-1.12.661.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.16.2/jackson-dataformat-cbor-2.16.2.jar:/home/runner/.m2/repository/joda-time/joda-time/2.12.7/joda-time-2.12.7.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.661/aws-java-sdk-s3-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.661/aws-java-sdk-kms-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.661/jmespath-java-1.12.661.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.4.1/hadoop-hdfs-3.4.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/ozone-interface-storage-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.11/metainf-services-1.11.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/ozone-manager-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19.4/jersey-client-1.19.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.24.2/log4j-api-2.24.2.jar:/home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/target/hdds-managed-rocksdb-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/hdds-rocks-native-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.57.v20241219/jetty-io-9.4.57.v20241219.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/rocksdb-checkpoint-differ-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/github/vlsi/mxgraph/jgraphx/3.9.12/jgraphx-3.9.12.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.4.0/jgrapht-core-1.4.0.jar:/home/runner/.m2/repository/org/jheaps/jheaps/0.11/jheaps-0.11.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.4.0/jgrapht-ext-1.4.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.6.0/ranger-intg-2.6.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.6.0/ranger-plugins-common-2.6.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.16.2/jackson-jaxrs-base-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.16.2/jackson-jaxrs-json-provider-2.16.2.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/1.0.0/gethostname4j-1.0.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.6.0/ranger-plugin-classloader-2.6.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.6.0/ranger-plugins-audit-2.6.0.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-logs/1.12.765/aws-java-sdk-logs-1.12.765.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/io/airlift/aircompressor/0.27/aircompressor-0.27.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.4/httpasyncclient-4.1.4.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.16/httpcore-nio-4.4.16.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.13/httpmime-4.5.13.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/org/apache/orc/orc-shims/1.5.8/orc-shims-1.5.8.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.57.v20241219/jetty-client-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.6.0/ranger-plugins-cred-2.6.0.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.57.v20241219/jetty-util-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/reflections/reflections/0.10.2/reflections-0.10.2.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/guice/6.0.0/guice-6.0.0.jar:/home/runner/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/6.0.0/guice-assistedinject-6.0.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/6.0.0/guice-servlet-6.0.0.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/target/ozone-reconcodegen-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.57.v20241219/jetty-servlet-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.57.v20241219/jetty-security-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.6.1/guice-bridge-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.46/jersey-container-servlet-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.46/jersey-container-servlet-core-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.46/jersey-common-2.46.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.46/jersey-server-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.46/jersey-client-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.46/jersey-hk2-2.46.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.46/jersey-media-jaxb-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.46/jersey-media-json-jackson-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.46/jersey-entity-filtering-2.46.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.16.2/jackson-module-jaxb-annotations-2.16.2.jar:/home/runner/.m2/repository/org/javassist/javassist/3.30.2-GA/javassist-3.30.2-GA.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.39/spring-core-5.3.39.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.39/spring-jdbc-5.3.39.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.39/spring-beans-5.3.39.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.39/spring-tx-5.3.39.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.49.1.0/sqlite-jdbc-3.49.1.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/ozone-s3gateway-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/tools/target/ozone-tools-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-shell/3.1.2/ratis-shell-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/3.1.2/ratis-tools-3.1.2.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.9/jaxb-runtime-2.3.9.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.9/txw2-2.3.9.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.12/istack-commons-runtime-3.0.12.jar:/home/runner/.m2/repository/com/sun/activation/jakarta.activation/1.2.2/jakarta.activation-1.2.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/3.1.2/ratis-server-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-api/3.1.2/ratis-metrics-api-3.1.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.2/hamcrest-2.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/2.0.17/jul-to-slf4j-2.0.17.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.17.0/commons-lang3-3.17.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.4.1/hadoop-common-3.4.1-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_25/1.4.0/hadoop-shaded-protobuf_3_25-1.4.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.4.1/hadoop-annotations-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.3.0/hadoop-shaded-guava-1.3.0.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.8.0/commons-cli-1.8.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.11.1/commons-net-3.11.1.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.57.v20241219/jetty-server-9.4.57.v20241219.jar:/home/runner/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19.4/jersey-core-1.19.4.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19.4/jersey-servlet-1.19.4.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.22.0/jersey-json-1.22.0.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.5.4/jettison-1.5.4.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19.4/jersey-server-1.19.4.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.11.0/commons-configuration2-2.11.0.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.9.2/avro-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.7/re2j-1.7.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/dnsjava/dnsjava/3.6.1/dnsjava-3.6.1.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.7/snappy-java-1.1.10.7.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.4.1/hadoop-distcp-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.4.1/hadoop-distcp-3.4.1-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.4.1/hadoop-hdfs-3.4.1-tests.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.57.v20241219/jetty-util-ajax-9.4.57.v20241219.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.4.0/commons-daemon-1.4.0.jar:/home/runner/.m2/repository/io/netty/netty-all/4.1.109.Final/netty-all-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-dns/4.1.109.Final/netty-codec-dns-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-haproxy/4.1.109.Final/netty-codec-haproxy-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-memcache/4.1.109.Final/netty-codec-memcache-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-mqtt/4.1.109.Final/netty-codec-mqtt-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-redis/4.1.109.Final/netty-codec-redis-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-smtp/4.1.109.Final/netty-codec-smtp-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-stomp/4.1.109.Final/netty-codec-stomp-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-xml/4.1.109.Final/netty-codec-xml-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-ssl-ocsp/4.1.109.Final/netty-handler-ssl-ocsp-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns/4.1.109.Final/netty-resolver-dns-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-rxtx/4.1.109.Final/netty-transport-rxtx-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-sctp/4.1.109.Final/netty-transport-sctp-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-udt/4.1.109.Final/netty-transport-udt-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-kqueue/4.1.109.Final/netty-transport-classes-kqueue-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-classes-macos/4.1.109.Final/netty-resolver-dns-classes-macos-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final-linux-riscv64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.109.Final/netty-transport-native-kqueue-4.1.109.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.109.Final/netty-transport-native-kqueue-4.1.109.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.109.Final/netty-resolver-dns-native-macos-4.1.109.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.109.Final/netty-resolver-dns-native-macos-4.1.109.Final-osx-aarch_64.jar:/home/runner/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.1/hadoop-kms-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.1/hadoop-kms-3.4.1-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.4.1/hadoop-mapreduce-client-core-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.4.1/hadoop-yarn-client-3.4.1.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.53.v20231009/websocket-client-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.53.v20231009/websocket-common-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.53.v20231009/websocket-api-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.4.1/hadoop-yarn-api-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.4.1/hadoop-yarn-common-3.4.1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.4.1/hadoop-mapreduce-client-jobclient-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.4.1/hadoop-mapreduce-client-common-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.4.1/hadoop-minikdc-3.4.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/2.0.3/kerb-simplekdc-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/2.0.3/kerb-client-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/2.0.3/kerb-common-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/2.0.3/token-provider-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/2.0.3/kerb-admin-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/2.0.3/kerb-server-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/2.0.3/kerb-identity-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/2.0.3/kerby-xdr-2.0.3.jar:/home/runner/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.8.1/jaeger-client-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.8.1/jaeger-thrift-1.8.1.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.15.0/libthrift-0.15.0.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.12.0/okhttp-4.12.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.6.0/okio-3.6.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.6.0/okio-jvm-3.6.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.25/kotlin-stdlib-common-1.9.25.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.9.25/kotlin-stdlib-jdk8-1.9.25.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.9.25/kotlin-stdlib-jdk7-1.9.25.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.8.1/jaeger-tracerresolver-1.8.1.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.8.1/jaeger-core-1.8.1.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/runner/work/ozone/ozone/hadoop-hdds/annotations/target/hdds-annotation-processing-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-dropwizard3/3.1.2/ratis-metrics-dropwizard3-3.1.2.jar:/home/runner/.m2/repository/org/bouncycastle/bcutil-jdk18on/1.80/bcutil-jdk18on-1.80.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.9.25/kotlin-stdlib-1.9.25.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/org/slf4j/jcl-over-slf4j/2.0.17/jcl-over-slf4j-2.0.17.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.7-3/zstd-jni-1.5.7-3.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.109.Final/netty-buffer-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.109.Final/netty-codec-4.1.109.Final.jar:/home/runner/.m2/repository/log4j/apache-log4j-extras/1.2.17/apache-log4j-extras-1.2.17.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/hdds-server-framework-2.1.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/jnr/jnr-constants/0.10.4/jnr-constants-0.10.4.jar:/home/runner/.m2/repository/com/github/jnr/jnr-posix/3.1.20/jnr-posix-3.1.20.jar:/home/runner/.m2/repository/com/github/jnr/jnr-ffi/2.2.17/jnr-ffi-2.2.17.jar:/home/runner/.m2/repository/com/github/jnr/jffi/1.3.13/jffi-1.3.13.jar:/home/runner/.m2/repository/com/github/jnr/jffi/1.3.13/jffi-1.3.13-native.jar:/home/runner/.m2/repository/org/ow2/asm/asm/9.7.1/asm-9.7.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm-commons/9.7.1/asm-commons-9.7.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm-analysis/9.7.1/asm-analysis-9.7.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm-tree/9.7.1/asm-tree-9.7.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm-util/9.7.1/asm-util-9.7.1.jar:/home/runner/.m2/repository/com/github/jnr/jnr-a64asm/1.0.0/jnr-a64asm-1.0.0.jar:/home/runner/.m2/repository/com/github/jnr/jnr-x86asm/1.0.2/jnr-x86asm-1.0.2.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.16.0/simpleclient-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.16.0/simpleclient_common-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.16.0/simpleclient_dropwizard-0.16.0.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.24.2/log4j-core-2.24.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.57.v20241219/jetty-http-9.4.57.v20241219.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.4/disruptor-3.4.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.40/nimbus-jose-jwt-9.40.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/hdds-server-scm-2.1.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/hdds-test-utils-2.1.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/ozone-manager-2.1.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/target/ozone-mini-cluster-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.27.3/assertj-core-3.27.3.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.15.11/byte-buddy-1.15.11.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.12.2/junit-jupiter-api-5.12.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.12.2/junit-platform-commons-1.12.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.12.2/junit-jupiter-params-5.12.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/4.11.0/mockito-core-4.11.0.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.12.19/byte-buddy-agent-1.12.19.jar:/home/runner/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/runner/.m2/repository/org/mockito/mockito-inline/4.11.0/mockito-inline-4.11.0.jar:/home/runner/.m2/repository/org/mockito/mockito-junit-jupiter/4.11.0/mockito-junit-jupiter-4.11.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/gradle-enterprise/test-listeners.jar:
STARTUP_MSG:   build = https://github.com/apache/ozone/0d5f93381914a388de458f8da4784ebd9bcf14eb
STARTUP_MSG:   java = 21.0.7
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=4, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachine.write.wait.interval=10m, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.delete.container.timeout=60s, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp/dfs/data, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.factory.classname=org.apache.hadoop.hdds.fs.MockSpaceUsageCheckFactory$None, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.read.threadpool=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.auto-compaction-small-sst-file.interval.minutes=120, hdds.datanode.rocksdb.auto-compaction-small-sst-file.threads=1, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.choosing.policy=org.apache.hadoop.ozone.container.common.volume.CapacityVolumeChoosingPolicy, hdds.datanode.volume.min.free.space=-1, hdds.datanode.volume.min.free.space.percent=-1, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.initial-interval=2s, hdds.heartbeat.interval=1s, hdds.heartbeat.recon.initial-interval=60s, hdds.heartbeat.recon.interval=60s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.block.deletion.txn.dn.commit.map.limit=5000000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.event.timeout=12m, hdds.scm.replication.event.timeout.datanode.offset=6m, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=4MB, ozone.client.datastream.min.packet.size=256KB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=8MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=1MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=2MB, ozone.client.stream.buffer.size=1MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.compaction.service.enabled=false, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.csi.default-volume-size=1000000000, ozone.csi.mount.command=goofys --endpoint %s %s %s, ozone.csi.s3g.address=http://localhost:9878, ozone.csi.socket=/var/lib/csi.sock, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.hbase.enhancements.allowed=false, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.compaction.service.columnfamilies=keyTable,fileTable,directoryTable,deletedTable,deletedDirectoryTable,multipartInfoTable, ozone.om.compaction.service.run.interval=6h, ozone.om.compaction.service.timeout=10m, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.edekcacheloader.initial.delay.ms=3000, ozone.om.edekcacheloader.interval.ms=1000, ozone.om.edekcacheloader.max-retries=10, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=READ, LIST, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=20, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.log.appender.queue.byte-limit=4MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.s3.grpc.server_enabled=false, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.server.list.max.size=1000, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1s, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.rocksdb.metrics.enabled=false, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=5s, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.sql.db.auto.commit=true, ozone.recon.sql.db.conn.idle.max.age=3600s, ozone.recon.sql.db.conn.idle.test=SELECT 1, ozone.recon.sql.db.conn.idle.test.period=60s, ozone.recon.sql.db.conn.max.active=5, ozone.recon.sql.db.conn.max.age=1800s, ozone.recon.sql.db.conn.timeout=30000ms, ozone.recon.sql.db.driver=org.apache.derby.jdbc.EmbeddedDriver, ozone.recon.sql.db.jdbc.url=jdbc:derby:${ozone.recon.db.dir}/ozone_recon_derby.db, ozone.recon.sql.db.jooq.dialect=DERBY, ozone.recon.task.containercounttask.interval=60s, ozone.recon.task.missingcontainer.interval=300s, ozone.recon.task.pipelinesync.interval=300s, ozone.recon.task.safemode.wait.threshold=300s, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.https-address=0.0.0.0:9879, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.s3g.webadmin.https-address=0.0.0.0:19879, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=4MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=1MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=1s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=4MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=20, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=100ms, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=3, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.test.test.key=value1, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256, test.scm.client.address=localhost, test.scm.client.bind.host=0.0.0.0, test.scm.client.class=java.lang.Object, test.scm.client.compression.enabled=true, test.scm.client.duration=1h, test.scm.client.enabled=true, test.scm.client.port=9878, test.scm.client.threshold=10, test.scm.client.wait=30m, yarn.app.mapreduce.am.container.log.backups=0, yarn.app.mapreduce.am.container.log.limit.kb=0, yarn.app.mapreduce.task.container.log.backups=0, yarn.nodemanager.container.stderr.pattern={*stderr*,*STDERR*}, yarn.nodemanager.container.stderr.tail.bytes=4096, yarn.nodemanager.least-load-policy-selector.pending-container.threshold=10000, yarn.nodemanager.windows-container.cpu-limit.enabled=false, yarn.nodemanager.windows-container.memory-limit.enabled=false, yarn.resourcemanager.container.liveness-monitor.interval-ms=600000}
************************************************************/
2025-05-13 07:52:56,077 [main] WARN  recon.ReconServer (HddsServerUtil.java:startupShutdownMessage(691)) - failed to register any UNIX signal loggers: 
java.lang.IllegalStateException: Can't re-install the signal handlers.
	at org.apache.hadoop.hdds.utils.SignalLogger.register(SignalLogger.java:82)
	at org.apache.hadoop.hdds.utils.HddsServerUtil.startupShutdownMessage(HddsServerUtil.java:689)
	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:105)
	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:73)
	at picocli.CommandLine.executeUserObject(CommandLine.java:2031)
	at picocli.CommandLine.access$1500(CommandLine.java:148)
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2469)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2461)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2423)
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2277)
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2425)
	at picocli.CommandLine.execute(CommandLine.java:2174)
	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:89)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createRecon(MiniOzoneClusterImpl.java:735)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:556)
	at org.apache.hadoop.ozone.recon.TestReconAndAdminContainerCLI.init(TestReconAndAdminContainerCLI.java:131)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:775)
	at org.junit.platform.commons.support.ReflectionSupport.invokeMethod(ReflectionSupport.java:479)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.SameThreadTimeoutInvocation.proceed(SameThreadTimeoutInvocation.java:49)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:161)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:133)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:75)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:112)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:94)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:87)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$13(ClassBasedTestDescriptor.java:417)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:415)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:216)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:84)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:153)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39)
	at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25)
	at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:56)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:162)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:120)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
2025-05-13 07:52:56,100 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 8 ms to scan 1 urls, producing 21 keys and 84 values
2025-05-13 07:52:56,112 [main] INFO  recon.ReconServer (ReconServer.java:call(119)) - Initializing Recon server...
2025-05-13 07:52:56,143 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(49)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/recon/ozone_recon_derby.db 
2025-05-13 07:52:56,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:52:56,263 [main] INFO  schema.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(83)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/recon/ozone_recon_derby.db.
2025-05-13 07:52:56,264 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(142)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2025-05-13 07:52:56,265 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(695)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2025-05-13 07:52:56,286 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(49)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/recon/ozone_recon_derby.db 
2025-05-13 07:52:56,286 [main] INFO  schema.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(83)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/recon/ozone_recon_derby.db.
2025-05-13 07:52:56,287 [main] INFO  recon.ReconServer (ReconServer.java:call(146)) - Creating Recon Schema.
2025-05-13 07:52:56,313 [main] INFO  schema.SchemaVersionTableDefinition (SchemaVersionTableDefinition.java:insertInitialSLV(95)) - Inserted initial SLV '1' into SchemaVersion table.
2025-05-13 07:52:56,332 [main] INFO  schema.ContainerSchemaDefinition (ContainerSchemaDefinition.java:initializeSchema(61)) - UNHEALTHY_CONTAINERS is missing creating new one.
2025-05-13 07:52:56,346 [main] INFO  recon.ReconServer (ReconServer.java:call(150)) - Finalizing Layout Features.
2025-05-13 07:52:56,350 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 1 ms to scan 1 urls, producing 6 keys and 9 values
2025-05-13 07:52:56,351 [main] INFO  upgrade.ReconLayoutVersionManager (ReconLayoutVersionManager.java:getRegisteredFeatures(133)) - Current MLV: 1. SLV: 1. Checking features for registration...
2025-05-13 07:52:56,351 [main] INFO  recon.ReconServer (ReconServer.java:call(161)) - Recon schema versioning completed.
2025-05-13 07:52:56,352 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for recon at: http://0.0.0.0:15270
2025-05-13 07:52:56,352 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-13 07:52:56,353 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-13 07:52:56,355 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-13 07:52:56,355 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
2025-05-13 07:52:56,355 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-13 07:52:56,355 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-13 07:52:56,356 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of recon uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/webserver
2025-05-13 07:52:56,359 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task ContainerKeyMapperTaskFSO with controller.
2025-05-13 07:52:56,359 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task ContainerKeyMapperTaskOBS with controller.
2025-05-13 07:52:56,359 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task FileSizeCountTaskFSO with controller.
2025-05-13 07:52:56,359 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task FileSizeCountTaskOBS with controller.
2025-05-13 07:52:56,359 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task OmTableInsightTask with controller.
2025-05-13 07:52:56,359 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task NSSummaryTask with controller.
2025-05-13 07:52:56,359 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(723)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2025-05-13 07:52:56,360 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(742)) - No OzoneManager ServiceID configured.
2025-05-13 07:52:56,362 [main] INFO  proxy.SCMContainerLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15260]
2025-05-13 07:52:56,364 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-05-13 07:52:56,364 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-05-13 07:52:56,421 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-13 07:52:56,422 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-05-13 07:52:56,422 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(182)) - Entering startup safe mode.
2025-05-13 07:52:56,423 [main] INFO  scm.ReconNodeManager (ReconNodeManager.java:loadExistingNodes(129)) - Loaded 0 nodes from node DB.
2025-05-13 07:52:56,423 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(84)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-05-13 07:52:56,423 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:52:56,423 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15271
2025-05-13 07:52:56,424 [Socket Reader #1 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15271
2025-05-13 07:52:56,424 [Socket Reader #2 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15271
2025-05-13 07:52:56,424 [Socket Reader #3 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15271
2025-05-13 07:52:56,424 [Socket Reader #4 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15271
2025-05-13 07:52:56,424 [Socket Reader #5 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15271
2025-05-13 07:52:56,424 [Socket Reader #6 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15271
2025-05-13 07:52:56,425 [Socket Reader #7 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15271
2025-05-13 07:52:56,425 [Socket Reader #8 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15271
2025-05-13 07:52:56,425 [Socket Reader #9 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15271
2025-05-13 07:52:56,425 [Socket Reader #10 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15271
2025-05-13 07:52:56,426 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-05-13 07:52:56,429 [main] INFO  recon.ReconServer (ReconServer.java:call(174)) - Initializing support of Recon Features...
2025-05-13 07:52:56,429 [main] INFO  recon.ReconServer (ReconServer.java:start(238)) - Starting Recon server
2025-05-13 07:52:56,429 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Recon metrics system started (again)
2025-05-13 07:52:56,440 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15270
2025-05-13 07:52:56,440 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-13 07:52:56,441 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-13 07:52:56,441 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-13 07:52:56,441 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-05-13 07:52:56,442 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3f21b0fb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-13 07:52:56,442 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@258741ff{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-13 07:52:56,538 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6b031452{recon,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/webserver/jetty-0_0_0_0-15270-ozone-recon-2_1_0-SNAPSHOT_jar-_-any-5673162063153048414/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar!/webapps/recon}
2025-05-13 07:52:56,539 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@53e5a795{HTTP/1.1, (http/1.1)}{0.0.0.0:15270}
2025-05-13 07:52:56,539 [main] INFO  server.Server (Server.java:doStart(415)) - Started @262677ms
2025-05-13 07:52:56,539 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-13 07:52:56,540 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of recon listening at http://0.0.0.0:15270
2025-05-13 07:52:56,540 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:start(243)) - Starting Ozone Manager Service Provider.
2025-05-13 07:52:56,540 [main] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:start(77)) - Starting ReconOMMetadataManagerImpl
2025-05-13 07:52:56,540 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:start(239)) - Starting Recon Task Controller.
2025-05-13 07:52:56,545 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(386)) - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:15271
2025-05-13 07:52:56,549 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:initializePipelinesFromScm(486)) - Obtained 0 pipelines from SCM.
2025-05-13 07:52:56,549 [main] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 0 pipelines in house.
2025-05-13 07:52:56,549 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(399)) - SCM DB initialized
2025-05-13 07:52:56,549 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15271
2025-05-13 07:52:56,550 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:52:56,550 [IPC Server listener on 15271] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15271: starting
2025-05-13 07:52:56,608 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 13 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 13.
2025-05-13 07:52:56,973 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1051054661ns, electionTimeout:1050ms
2025-05-13 07:52:56,973 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2025-05-13 07:52:56,974 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:52:56,974 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:52:56,974 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-LeaderElection51
2025-05-13 07:52:56,974 [om1@group-C5BA1605619E-LeaderElection51] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - om1@group-C5BA1605619E-LeaderElection51 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[om1|localhost:15269]|listeners:[], old=null}
2025-05-13 07:52:56,974 [om1@group-C5BA1605619E-LeaderElection51] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - om1@group-C5BA1605619E-LeaderElection51 PRE_VOTE round 0: result PASSED (term=0)
2025-05-13 07:52:56,975 [om1@group-C5BA1605619E-LeaderElection51] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - om1@group-C5BA1605619E-LeaderElection51 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[om1|localhost:15269]|listeners:[], old=null}
2025-05-13 07:52:56,975 [om1@group-C5BA1605619E-LeaderElection51] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - om1@group-C5BA1605619E-LeaderElection51 ELECTION round 0: result PASSED (term=1)
2025-05-13 07:52:56,975 [om1@group-C5BA1605619E-LeaderElection51] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection51
2025-05-13 07:52:56,975 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-13 07:52:56,975 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2025-05-13 07:52:56,976 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - om1@group-C5BA1605619E: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:52:56,977 [om1@group-C5BA1605619E-LeaderElection51] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyLeaderChanged(174)) - om1@group-C5BA1605619E: leader changed to om1
2025-05-13 07:52:56,977 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1476ms
2025-05-13 07:52:56,977 [om1@group-C5BA1605619E-LeaderElection51] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:52:56,977 [om1@group-C5BA1605619E-LeaderElection51] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - om1@group-C5BA1605619E: set configuration conf: {index: 0, cur=peers:[om1|localhost:15269]|listeners:[], old=null}
2025-05-13 07:52:56,977 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:52:56,983 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2025-05-13 07:52:56,984 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(236)) - notifyConfigurationChanged from Ratis: term=1, index=0, New Peer list: om1(localhost:15269)
2025-05-13 07:52:56,984 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader om1@group-C5BA1605619E-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-13 07:52:57,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:52:57,928 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-13 07:52:58,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:52:58,609 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 14 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 14.
2025-05-13 07:52:59,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:52:59,929 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2025-05-13 07:53:00,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:00,609 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] ERROR scm.ReconDeadNodeHandler (ReconDeadNodeHandler.java:onMessage(81)) - Error trying to verify Node operational state from SCM.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:872)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1588)
	at org.apache.hadoop.ipc.Client.call(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1426)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:668)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:789)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:364)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1649)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	... 22 more
2025-05-13 07:53:00,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. d363bb60-5c54-4829-bd93-834a04026f30(localhost/127.0.0.1)
2025-05-13 07:53:00,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: f856f8a5-dd0e-4056-8f07-e5b79178b1f2, Nodes: [ {d363bb60-5c54-4829-bd93-834a04026f30(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d363bb60-5c54-4829-bd93-834a04026f30, CreationTimestamp2025-05-13T07:51:30.353Z[Etc/UTC]} removed.
2025-05-13 07:53:00,611 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(190)) - Processing of TypedEvent{payloadType=DatanodeDetails, name='Replication_Manager_Notify'} is skipped, EventQueue is not running
2025-05-13 07:53:00,611 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 0 for DN d363bb60-5c54-4829-bd93-834a04026f30(localhost/127.0.0.1)
2025-05-13 07:53:00,611 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/d363bb60-5c54-4829-bd93-834a04026f30
2025-05-13 07:53:00,611 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-13 07:53:01,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:01,930 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2025-05-13 07:53:02,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:02,612 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-13 07:53:03,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:03,951 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2025-05-13 07:53:04,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:04,612 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-13 07:53:05,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:05,952 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 8 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 8.
2025-05-13 07:53:06,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:06,613 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-13 07:53:07,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:07,232 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-13 07:53:07,561 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(47)) - Starting ContainerSizeCountTask Thread.
2025-05-13 07:53:07,561 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(47)) - Starting ContainerHealthTask Thread.
2025-05-13 07:53:07,561 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(47)) - Starting PipelineSyncTask Thread.
2025-05-13 07:53:07,562 [main] INFO  recon.ReconServer (ReconServer.java:call(181)) - Recon server initialized successfully!
2025-05-13 07:53:07,562 [JvmPauseMonitor48] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-Recon: Started
2025-05-13 07:53:07,569 [ContainerHealthTask] INFO  updater.ReconTaskStatusUpdater (ReconTaskStatusUpdater.java:updateDetails(124)) - Registered Task: ContainerHealthTask
2025-05-13 07:53:07,569 [PipelineSyncTask] INFO  updater.ReconTaskStatusUpdater (ReconTaskStatusUpdater.java:updateDetails(124)) - Registered Task: PipelineSyncTask
2025-05-13 07:53:07,571 [PipelineSyncTask] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 0 pipelines in house.
2025-05-13 07:53:07,572 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:07,589 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:07,589 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:07,589 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-13 07:53:07,598 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode f9ce924c-8a82-4766-a645-cb0bc56ee637(10.1.0.207/null) to 10.1.0.207
2025-05-13 07:53:07,598 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService f9ce924c-8a82-4766-a645-cb0bc56ee637(10.1.0.207/10.1.0.207)
2025-05-13 07:53:07,600 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-13 07:53:07,600 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-13 07:53:07,602 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-e7896221-c7ae-4fa1-b249-ad1189472e28 dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-13 07:53:07,602 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds to VolumeSet
2025-05-13 07:53:07,603 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis to VolumeSet
2025-05-13 07:53:07,603 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-05-13 07:53:07,603 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:07,604 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:07,614 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:07,614 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:07,615 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:07,616 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-13 07:53:07,616 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:07,616 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15276 (custom)
2025-05-13 07:53:07,616 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:07,616 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15275 (custom)
2025-05-13 07:53:07,616 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-13 07:53:07,616 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15277 (custom)
2025-05-13 07:53:07,616 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-13 07:53:07,616 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-13 07:53:07,616 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:07,617 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:53:07,617 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:07,617 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-13 07:53:07,617 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-13 07:53:07,618 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-13 07:53:07,618 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-13 07:53:07,618 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-13 07:53:07,618 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-13 07:53:07,618 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-13 07:53:07,619 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-13 07:53:07,619 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-13 07:53:07,619 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-13 07:53:07,619 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for f9ce924c-8a82-4766-a645-cb0bc56ee637-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-13 07:53:07,619 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-13 07:53:07,619 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for f9ce924c-8a82-4766-a645-cb0bc56ee637-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-13 07:53:07,620 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-13 07:53:07,620 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-13 07:53:07,620 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15278 (custom)
2025-05-13 07:53:07,620 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:07,620 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-13 07:53:07,620 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:07,621 [f9ce924c-8a82-4766-a645-cb0bc56ee637-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd39b8599] REGISTERED
2025-05-13 07:53:07,621 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis] (custom)
2025-05-13 07:53:07,621 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-13 07:53:07,621 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-13 07:53:07,621 [f9ce924c-8a82-4766-a645-cb0bc56ee637-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd39b8599] BIND: 0.0.0.0/0.0.0.0:15278
2025-05-13 07:53:07,621 [f9ce924c-8a82-4766-a645-cb0bc56ee637-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd39b8599, L:/0.0.0.0:15278] ACTIVE
2025-05-13 07:53:07,621 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/tmp
2025-05-13 07:53:07,621 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/tmp is not a group directory; ignoring it. 
2025-05-13 07:53:07,622 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-13 07:53:07,622 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-13 07:53:07,623 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-13 07:53:07,623 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-13 07:53:07,625 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15272
2025-05-13 07:53:07,625 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-13 07:53:07,629 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-13 07:53:07,631 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-13 07:53:07,631 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-13 07:53:07,631 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-13 07:53:07,631 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-13 07:53:07,632 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/meta/webserver
2025-05-13 07:53:07,632 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15272
2025-05-13 07:53:07,632 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-13 07:53:07,633 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-13 07:53:07,633 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-13 07:53:07,634 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-13 07:53:07,634 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4ba28206{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-13 07:53:07,635 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4eaa0a21{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-13 07:53:07,761 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5afa7ea1{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/meta/webserver/jetty-0_0_0_0-15272-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-16944764523266840611/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:07,762 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5d707a77{HTTP/1.1, (http/1.1)}{0.0.0.0:15272}
2025-05-13 07:53:07,762 [main] INFO  server.Server (Server.java:doStart(415)) - Started @273900ms
2025-05-13 07:53:07,762 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-13 07:53:07,762 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15272
2025-05-13 07:53:07,762 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:53:07,763 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15273
2025-05-13 07:53:07,763 [Socket Reader #1 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15273
2025-05-13 07:53:07,763 [Socket Reader #2 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15273
2025-05-13 07:53:07,763 [Socket Reader #3 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15273
2025-05-13 07:53:07,763 [Socket Reader #4 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15273
2025-05-13 07:53:07,764 [Socket Reader #5 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15273
2025-05-13 07:53:07,764 [Socket Reader #6 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15273
2025-05-13 07:53:07,764 [Socket Reader #7 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15273
2025-05-13 07:53:07,764 [Socket Reader #8 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15273
2025-05-13 07:53:07,764 [Socket Reader #9 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15273
2025-05-13 07:53:07,764 [Socket Reader #10 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15273
2025-05-13 07:53:07,766 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-13 07:53:07,766 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15273
2025-05-13 07:53:07,766 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:53:07,766 [IPC Server listener on 15273] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15273: starting
2025-05-13 07:53:07,767 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:07,767 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:07,768 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-13 07:53:07,768 [f9ce924c-8a82-4766-a645-cb0bc56ee637-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-13 07:53:07,769 [f9ce924c-8a82-4766-a645-cb0bc56ee637-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-13 07:53:07,772 [f9ce924c-8a82-4766-a645-cb0bc56ee637-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/meta/datanode.id
2025-05-13 07:53:07,778 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode ec402e9c-53dd-4038-962b-5490446c9ba5(10.1.0.207/null) to 10.1.0.207
2025-05-13 07:53:07,778 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService ec402e9c-53dd-4038-962b-5490446c9ba5(10.1.0.207/10.1.0.207)
2025-05-13 07:53:07,779 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-13 07:53:07,779 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-13 07:53:07,781 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-9ee005a0-db41-4fa9-a10a-fb22f841b88c dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-13 07:53:07,781 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds to VolumeSet
2025-05-13 07:53:07,781 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis to VolumeSet
2025-05-13 07:53:07,782 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 1ms
2025-05-13 07:53:07,782 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:07,782 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:07,793 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:07,793 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:07,794 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:07,794 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-13 07:53:07,794 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:07,794 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15284 (custom)
2025-05-13 07:53:07,794 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:07,795 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15283 (custom)
2025-05-13 07:53:07,795 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-13 07:53:07,795 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15285 (custom)
2025-05-13 07:53:07,795 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-13 07:53:07,795 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-13 07:53:07,795 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:07,795 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:53:07,795 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:07,795 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-13 07:53:07,795 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-13 07:53:07,796 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-13 07:53:07,796 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-13 07:53:07,796 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-13 07:53:07,796 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-13 07:53:07,796 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-13 07:53:07,796 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-13 07:53:07,797 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-13 07:53:07,797 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-13 07:53:07,797 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for ec402e9c-53dd-4038-962b-5490446c9ba5-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-13 07:53:07,797 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-13 07:53:07,797 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for ec402e9c-53dd-4038-962b-5490446c9ba5-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-13 07:53:07,797 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-13 07:53:07,797 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-13 07:53:07,797 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15286 (custom)
2025-05-13 07:53:07,798 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:07,798 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-13 07:53:07,798 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:07,798 [ec402e9c-53dd-4038-962b-5490446c9ba5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3a317e2d] REGISTERED
2025-05-13 07:53:07,798 [ec402e9c-53dd-4038-962b-5490446c9ba5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3a317e2d] BIND: 0.0.0.0/0.0.0.0:15286
2025-05-13 07:53:07,798 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis] (custom)
2025-05-13 07:53:07,798 [ec402e9c-53dd-4038-962b-5490446c9ba5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3a317e2d, L:/0.0.0.0:15286] ACTIVE
2025-05-13 07:53:07,798 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-13 07:53:07,798 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-13 07:53:07,799 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - ec402e9c-53dd-4038-962b-5490446c9ba5: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/tmp
2025-05-13 07:53:07,799 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - ec402e9c-53dd-4038-962b-5490446c9ba5: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2025-05-13 07:53:07,799 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-13 07:53:07,800 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-13 07:53:07,800 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-13 07:53:07,801 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-13 07:53:07,802 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15280
2025-05-13 07:53:07,802 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-13 07:53:07,803 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-13 07:53:07,804 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-13 07:53:07,804 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-13 07:53:07,804 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-13 07:53:07,804 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-13 07:53:07,805 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/meta/webserver
2025-05-13 07:53:07,805 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15280
2025-05-13 07:53:07,805 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-13 07:53:07,806 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-13 07:53:07,806 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-13 07:53:07,806 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-13 07:53:07,806 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@22f6ece6{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-13 07:53:07,807 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3d418e71{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-13 07:53:07,936 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@26368716{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/meta/webserver/jetty-0_0_0_0-15280-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-8273253693055332540/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:07,936 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@47f125f7{HTTP/1.1, (http/1.1)}{0.0.0.0:15280}
2025-05-13 07:53:07,936 [main] INFO  server.Server (Server.java:doStart(415)) - Started @274074ms
2025-05-13 07:53:07,936 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-13 07:53:07,937 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15280
2025-05-13 07:53:07,937 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:53:07,937 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15281
2025-05-13 07:53:07,937 [Socket Reader #1 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15281
2025-05-13 07:53:07,938 [Socket Reader #2 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15281
2025-05-13 07:53:07,938 [Socket Reader #3 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15281
2025-05-13 07:53:07,938 [Socket Reader #4 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15281
2025-05-13 07:53:07,938 [Socket Reader #5 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15281
2025-05-13 07:53:07,938 [Socket Reader #6 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15281
2025-05-13 07:53:07,939 [Socket Reader #7 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15281
2025-05-13 07:53:07,939 [Socket Reader #8 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15281
2025-05-13 07:53:07,939 [Socket Reader #9 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15281
2025-05-13 07:53:07,939 [Socket Reader #10 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15281
2025-05-13 07:53:07,941 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-13 07:53:07,941 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15281
2025-05-13 07:53:07,941 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:53:07,941 [IPC Server listener on 15281] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15281: starting
2025-05-13 07:53:07,943 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:07,943 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:07,943 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-13 07:53:07,944 [ec402e9c-53dd-4038-962b-5490446c9ba5-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-13 07:53:07,944 [ec402e9c-53dd-4038-962b-5490446c9ba5-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-13 07:53:07,947 [ec402e9c-53dd-4038-962b-5490446c9ba5-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/meta/datanode.id
2025-05-13 07:53:07,952 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode 58a412dd-7dde-4577-85ab-409f0726f062(10.1.0.207/null) to 10.1.0.207
2025-05-13 07:53:07,952 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService 58a412dd-7dde-4577-85ab-409f0726f062(10.1.0.207/10.1.0.207)
2025-05-13 07:53:07,952 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 9 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 9.
2025-05-13 07:53:07,954 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-13 07:53:07,954 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-13 07:53:07,955 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-56bbe301-cc58-4622-96cc-6c6186907806 dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-13 07:53:07,955 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds to VolumeSet
2025-05-13 07:53:07,956 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis to VolumeSet
2025-05-13 07:53:07,956 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-05-13 07:53:07,957 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:07,957 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:07,967 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:07,967 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:07,967 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:07,968 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-13 07:53:07,968 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:07,968 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15292 (custom)
2025-05-13 07:53:07,969 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:07,969 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15291 (custom)
2025-05-13 07:53:07,969 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-13 07:53:07,969 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15293 (custom)
2025-05-13 07:53:07,969 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-13 07:53:07,969 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-13 07:53:07,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:07,969 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:53:07,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:07,969 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-13 07:53:07,969 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-13 07:53:07,971 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-13 07:53:07,971 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-13 07:53:07,971 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-13 07:53:07,971 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-13 07:53:07,971 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-13 07:53:07,971 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-13 07:53:07,971 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-13 07:53:07,971 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-13 07:53:07,971 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 58a412dd-7dde-4577-85ab-409f0726f062-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-13 07:53:07,972 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-13 07:53:07,972 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 58a412dd-7dde-4577-85ab-409f0726f062-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-13 07:53:07,972 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-13 07:53:07,972 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-13 07:53:07,972 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15294 (custom)
2025-05-13 07:53:07,973 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:07,973 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-13 07:53:07,974 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:07,974 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis] (custom)
2025-05-13 07:53:07,974 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-13 07:53:07,974 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-13 07:53:07,974 [58a412dd-7dde-4577-85ab-409f0726f062-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf5cfeae4] REGISTERED
2025-05-13 07:53:07,974 [58a412dd-7dde-4577-85ab-409f0726f062-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf5cfeae4] BIND: 0.0.0.0/0.0.0.0:15294
2025-05-13 07:53:07,974 [58a412dd-7dde-4577-85ab-409f0726f062-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf5cfeae4, L:/0.0.0.0:15294] ACTIVE
2025-05-13 07:53:07,974 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - 58a412dd-7dde-4577-85ab-409f0726f062: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/tmp
2025-05-13 07:53:07,974 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - 58a412dd-7dde-4577-85ab-409f0726f062: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/tmp is not a group directory; ignoring it. 
2025-05-13 07:53:07,975 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-13 07:53:07,975 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-13 07:53:07,976 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-13 07:53:07,976 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-13 07:53:07,978 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15288
2025-05-13 07:53:07,978 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-13 07:53:07,979 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-13 07:53:07,980 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-13 07:53:07,980 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-13 07:53:07,980 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-13 07:53:07,980 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-13 07:53:07,981 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/meta/webserver
2025-05-13 07:53:07,981 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15288
2025-05-13 07:53:07,981 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-13 07:53:07,982 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-13 07:53:07,982 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-13 07:53:07,982 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-13 07:53:07,983 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7fcb9e8e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-13 07:53:07,983 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@31ad63c0{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-13 07:53:08,110 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7fb91def{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/meta/webserver/jetty-0_0_0_0-15288-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-15672154361944948300/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:08,111 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4ea73ad2{HTTP/1.1, (http/1.1)}{0.0.0.0:15288}
2025-05-13 07:53:08,111 [main] INFO  server.Server (Server.java:doStart(415)) - Started @274249ms
2025-05-13 07:53:08,111 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-13 07:53:08,111 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15288
2025-05-13 07:53:08,112 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:53:08,112 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15289
2025-05-13 07:53:08,112 [Socket Reader #1 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15289
2025-05-13 07:53:08,112 [Socket Reader #2 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15289
2025-05-13 07:53:08,112 [Socket Reader #3 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15289
2025-05-13 07:53:08,113 [Socket Reader #4 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15289
2025-05-13 07:53:08,113 [Socket Reader #5 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15289
2025-05-13 07:53:08,113 [Socket Reader #7 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15289
2025-05-13 07:53:08,113 [Socket Reader #8 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15289
2025-05-13 07:53:08,114 [Socket Reader #9 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15289
2025-05-13 07:53:08,114 [Socket Reader #6 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15289
2025-05-13 07:53:08,114 [Socket Reader #10 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15289
2025-05-13 07:53:08,115 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-13 07:53:08,115 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15289
2025-05-13 07:53:08,116 [IPC Server listener on 15289] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15289: starting
2025-05-13 07:53:08,116 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:53:08,117 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:08,117 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:08,118 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-13 07:53:08,119 [58a412dd-7dde-4577-85ab-409f0726f062-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-13 07:53:08,120 [58a412dd-7dde-4577-85ab-409f0726f062-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-13 07:53:08,123 [58a412dd-7dde-4577-85ab-409f0726f062-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/meta/datanode.id
2025-05-13 07:53:08,127 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode c5c2c3e6-bcf8-419e-a6b9-9661d5f86301(10.1.0.207/null) to 10.1.0.207
2025-05-13 07:53:08,127 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService c5c2c3e6-bcf8-419e-a6b9-9661d5f86301(10.1.0.207/10.1.0.207)
2025-05-13 07:53:08,129 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-13 07:53:08,129 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-13 07:53:08,131 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-7d92dfa9-442d-44a2-9974-1d1be94f503f dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-13 07:53:08,131 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds to VolumeSet
2025-05-13 07:53:08,131 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis to VolumeSet
2025-05-13 07:53:08,132 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 1ms
2025-05-13 07:53:08,132 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:08,133 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:08,148 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:08,148 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:08,149 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:08,150 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-13 07:53:08,150 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:08,150 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15300 (custom)
2025-05-13 07:53:08,150 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:08,150 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15299 (custom)
2025-05-13 07:53:08,150 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-13 07:53:08,151 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15301 (custom)
2025-05-13 07:53:08,151 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-13 07:53:08,151 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-13 07:53:08,151 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:08,151 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:53:08,151 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:08,151 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-13 07:53:08,151 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-13 07:53:08,153 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-13 07:53:08,153 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-13 07:53:08,153 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-13 07:53:08,153 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-13 07:53:08,153 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-13 07:53:08,153 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-13 07:53:08,153 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-13 07:53:08,153 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-13 07:53:08,154 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-13 07:53:08,154 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-13 07:53:08,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:08,154 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-13 07:53:08,154 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-13 07:53:08,154 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-13 07:53:08,155 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15302 (custom)
2025-05-13 07:53:08,155 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:08,155 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-13 07:53:08,156 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:08,156 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis] (custom)
2025-05-13 07:53:08,156 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-13 07:53:08,156 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-13 07:53:08,155 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xec5f031c] REGISTERED
2025-05-13 07:53:08,156 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xec5f031c] BIND: 0.0.0.0/0.0.0.0:15302
2025-05-13 07:53:08,156 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xec5f031c, L:/0.0.0.0:15302] ACTIVE
2025-05-13 07:53:08,157 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/tmp
2025-05-13 07:53:08,157 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/tmp is not a group directory; ignoring it. 
2025-05-13 07:53:08,157 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-13 07:53:08,158 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-13 07:53:08,159 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-13 07:53:08,159 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-13 07:53:08,161 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15296
2025-05-13 07:53:08,161 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-13 07:53:08,162 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-13 07:53:08,163 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-13 07:53:08,163 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-13 07:53:08,164 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-13 07:53:08,164 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-13 07:53:08,164 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/meta/webserver
2025-05-13 07:53:08,164 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15296
2025-05-13 07:53:08,164 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-13 07:53:08,165 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-13 07:53:08,165 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-13 07:53:08,166 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-05-13 07:53:08,166 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@55708d47{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-13 07:53:08,166 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@18ba312f{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-13 07:53:08,302 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4072118a{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/meta/webserver/jetty-0_0_0_0-15296-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-9487232773674803599/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:08,303 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@44cbf958{HTTP/1.1, (http/1.1)}{0.0.0.0:15296}
2025-05-13 07:53:08,303 [main] INFO  server.Server (Server.java:doStart(415)) - Started @274441ms
2025-05-13 07:53:08,303 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-13 07:53:08,303 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15296
2025-05-13 07:53:08,304 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:53:08,304 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15297
2025-05-13 07:53:08,304 [Socket Reader #1 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15297
2025-05-13 07:53:08,305 [Socket Reader #2 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15297
2025-05-13 07:53:08,305 [Socket Reader #4 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15297
2025-05-13 07:53:08,305 [Socket Reader #3 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15297
2025-05-13 07:53:08,305 [Socket Reader #5 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15297
2025-05-13 07:53:08,305 [Socket Reader #6 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15297
2025-05-13 07:53:08,305 [Socket Reader #7 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15297
2025-05-13 07:53:08,306 [Socket Reader #8 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15297
2025-05-13 07:53:08,306 [Socket Reader #9 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15297
2025-05-13 07:53:08,306 [Socket Reader #10 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15297
2025-05-13 07:53:08,306 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db to cache
2025-05-13 07:53:08,307 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db for volume DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b
2025-05-13 07:53:08,307 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-13 07:53:08,307 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15297
2025-05-13 07:53:08,308 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:53:08,308 [IPC Server listener on 15297] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15297: starting
2025-05-13 07:53:08,308 [f9ce924c-8a82-4766-a645-cb0bc56ee637-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds
2025-05-13 07:53:08,309 [f9ce924c-8a82-4766-a645-cb0bc56ee637-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds
2025-05-13 07:53:08,309 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-13 07:53:08,309 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds
2025-05-13 07:53:08,310 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds
2025-05-13 07:53:08,310 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:08,310 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-13 07:53:08,310 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-13 07:53:08,311 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-13 07:53:08,312 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-13 07:53:08,314 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/meta/datanode.id
2025-05-13 07:53:08,315 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis
2025-05-13 07:53:08,315 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis
2025-05-13 07:53:08,317 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-13 07:53:08,317 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:08,318 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:08,318 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15279
2025-05-13 07:53:08,318 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(f9ce924c-8a82-4766-a645-cb0bc56ee637)
2025-05-13 07:53:08,319 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: start RPC server
2025-05-13 07:53:08,319 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: GrpcService started, listening on 15275
2025-05-13 07:53:08,319 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: GrpcService started, listening on 15277
2025-05-13 07:53:08,320 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: GrpcService started, listening on 15276
2025-05-13 07:53:08,320 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(f9ce924c-8a82-4766-a645-cb0bc56ee637) is started using port RATIS=15275
2025-05-13 07:53:08,320 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(f9ce924c-8a82-4766-a645-cb0bc56ee637) is started using port RATIS_ADMIN=15276
2025-05-13 07:53:08,320 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(f9ce924c-8a82-4766-a645-cb0bc56ee637) is started using port RATIS_SERVER=15277
2025-05-13 07:53:08,320 [f9ce924c-8a82-4766-a645-cb0bc56ee637-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(f9ce924c-8a82-4766-a645-cb0bc56ee637) is started using port RATIS_DATASTREAM=15278
2025-05-13 07:53:08,320 [JvmPauseMonitor49] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-f9ce924c-8a82-4766-a645-cb0bc56ee637: Started
2025-05-13 07:53:08,321 [f9ce924c-8a82-4766-a645-cb0bc56ee637-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-13 07:53:08,323 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95(10.1.0.207/null) to 10.1.0.207
2025-05-13 07:53:08,324 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95(10.1.0.207/10.1.0.207)
2025-05-13 07:53:08,325 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-13 07:53:08,326 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-13 07:53:08,327 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-925d7cf7-2c75-45b3-8a19-8c4fac3232f2 dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-13 07:53:08,327 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2025-05-13 07:53:08,327 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis to VolumeSet
2025-05-13 07:53:08,328 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-05-13 07:53:08,328 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:08,329 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-13 07:53:08,340 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:08,340 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-13 07:53:08,341 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:08,341 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15308 (custom)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15307 (custom)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15309 (custom)
2025-05-13 07:53:08,342 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-13 07:53:08,342 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-13 07:53:08,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:53:08,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-13 07:53:08,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-13 07:53:08,344 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-13 07:53:08,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-13 07:53:08,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-13 07:53:08,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-13 07:53:08,344 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-13 07:53:08,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-13 07:53:08,344 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-13 07:53:08,344 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-13 07:53:08,345 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-13 07:53:08,345 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-13 07:53:08,345 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-13 07:53:08,345 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-13 07:53:08,345 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-13 07:53:08,345 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15310 (custom)
2025-05-13 07:53:08,347 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:08,347 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-13 07:53:08,347 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:08,347 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc88f32e4] REGISTERED
2025-05-13 07:53:08,347 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc88f32e4] BIND: 0.0.0.0/0.0.0.0:15310
2025-05-13 07:53:08,347 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc88f32e4, L:/0.0.0.0:15310] ACTIVE
2025-05-13 07:53:08,347 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis] (custom)
2025-05-13 07:53:08,347 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-13 07:53:08,348 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-13 07:53:08,348 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/tmp
2025-05-13 07:53:08,348 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2025-05-13 07:53:08,348 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-13 07:53:08,349 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-13 07:53:08,350 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-13 07:53:08,350 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-13 07:53:08,352 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15304
2025-05-13 07:53:08,352 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-13 07:53:08,353 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-13 07:53:08,354 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-13 07:53:08,354 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-13 07:53:08,354 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-13 07:53:08,355 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-13 07:53:08,355 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/meta/webserver
2025-05-13 07:53:08,355 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15304
2025-05-13 07:53:08,355 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-13 07:53:08,358 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-13 07:53:08,358 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-13 07:53:08,358 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-13 07:53:08,359 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5b6aa97c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-13 07:53:08,359 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@48ac2530{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-13 07:53:08,477 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69/container.db to cache
2025-05-13 07:53:08,477 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69/container.db for volume DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69
2025-05-13 07:53:08,479 [ec402e9c-53dd-4038-962b-5490446c9ba5-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds
2025-05-13 07:53:08,479 [ec402e9c-53dd-4038-962b-5490446c9ba5-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds
2025-05-13 07:53:08,479 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-13 07:53:08,480 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds
2025-05-13 07:53:08,480 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds
2025-05-13 07:53:08,483 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis
2025-05-13 07:53:08,483 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis
2025-05-13 07:53:08,484 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-13 07:53:08,484 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(74)) - Trying to initialize on demand scanner a second time on a datanode.
2025-05-13 07:53:08,484 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:08,485 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:08,485 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15287
2025-05-13 07:53:08,485 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(ec402e9c-53dd-4038-962b-5490446c9ba5)
2025-05-13 07:53:08,486 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - ec402e9c-53dd-4038-962b-5490446c9ba5: start RPC server
2025-05-13 07:53:08,486 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - ec402e9c-53dd-4038-962b-5490446c9ba5: GrpcService started, listening on 15283
2025-05-13 07:53:08,486 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - ec402e9c-53dd-4038-962b-5490446c9ba5: GrpcService started, listening on 15285
2025-05-13 07:53:08,487 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - ec402e9c-53dd-4038-962b-5490446c9ba5: GrpcService started, listening on 15284
2025-05-13 07:53:08,487 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(ec402e9c-53dd-4038-962b-5490446c9ba5) is started using port RATIS=15283
2025-05-13 07:53:08,487 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(ec402e9c-53dd-4038-962b-5490446c9ba5) is started using port RATIS_ADMIN=15284
2025-05-13 07:53:08,487 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(ec402e9c-53dd-4038-962b-5490446c9ba5) is started using port RATIS_SERVER=15285
2025-05-13 07:53:08,487 [ec402e9c-53dd-4038-962b-5490446c9ba5-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(ec402e9c-53dd-4038-962b-5490446c9ba5) is started using port RATIS_DATASTREAM=15286
2025-05-13 07:53:08,487 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-ec402e9c-53dd-4038-962b-5490446c9ba5: Started
2025-05-13 07:53:08,488 [ec402e9c-53dd-4038-962b-5490446c9ba5-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-13 07:53:08,499 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@cd4caf7{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/meta/webserver/jetty-0_0_0_0-15304-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-14397345890564222261/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:08,500 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@61e53cc0{HTTP/1.1, (http/1.1)}{0.0.0.0:15304}
2025-05-13 07:53:08,500 [main] INFO  server.Server (Server.java:doStart(415)) - Started @274638ms
2025-05-13 07:53:08,500 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-13 07:53:08,501 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15304
2025-05-13 07:53:08,501 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-13 07:53:08,501 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15305
2025-05-13 07:53:08,501 [Socket Reader #1 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15305
2025-05-13 07:53:08,502 [Socket Reader #2 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15305
2025-05-13 07:53:08,502 [Socket Reader #3 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15305
2025-05-13 07:53:08,502 [Socket Reader #4 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15305
2025-05-13 07:53:08,502 [Socket Reader #5 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15305
2025-05-13 07:53:08,502 [Socket Reader #6 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15305
2025-05-13 07:53:08,502 [Socket Reader #7 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15305
2025-05-13 07:53:08,503 [Socket Reader #8 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15305
2025-05-13 07:53:08,503 [Socket Reader #9 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15305
2025-05-13 07:53:08,503 [Socket Reader #10 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15305
2025-05-13 07:53:08,504 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-13 07:53:08,504 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15305
2025-05-13 07:53:08,504 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-13 07:53:08,504 [IPC Server listener on 15305] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15305: starting
2025-05-13 07:53:08,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2025-05-13 07:53:08,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for cluster to exit safe mode
2025-05-13 07:53:08,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-13 07:53:08,508 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-13 07:53:08,508 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-13 07:53:08,510 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/meta/datanode.id
2025-05-13 07:53:08,579 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:08,614 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-13 07:53:08,644 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-65099b77-335d-4459-bc5a-9fdc99e265ad/container.db to cache
2025-05-13 07:53:08,644 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-65099b77-335d-4459-bc5a-9fdc99e265ad/container.db for volume DS-65099b77-335d-4459-bc5a-9fdc99e265ad
2025-05-13 07:53:08,646 [58a412dd-7dde-4577-85ab-409f0726f062-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds
2025-05-13 07:53:08,646 [58a412dd-7dde-4577-85ab-409f0726f062-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds
2025-05-13 07:53:08,646 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-13 07:53:08,646 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds
2025-05-13 07:53:08,647 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds
2025-05-13 07:53:08,649 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis
2025-05-13 07:53:08,649 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis
2025-05-13 07:53:08,650 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-13 07:53:08,650 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(74)) - Trying to initialize on demand scanner a second time on a datanode.
2025-05-13 07:53:08,650 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:08,651 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:08,651 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15295
2025-05-13 07:53:08,651 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(58a412dd-7dde-4577-85ab-409f0726f062)
2025-05-13 07:53:08,652 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - 58a412dd-7dde-4577-85ab-409f0726f062: start RPC server
2025-05-13 07:53:08,652 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 58a412dd-7dde-4577-85ab-409f0726f062: GrpcService started, listening on 15291
2025-05-13 07:53:08,652 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 58a412dd-7dde-4577-85ab-409f0726f062: GrpcService started, listening on 15293
2025-05-13 07:53:08,652 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 58a412dd-7dde-4577-85ab-409f0726f062: GrpcService started, listening on 15292
2025-05-13 07:53:08,652 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(58a412dd-7dde-4577-85ab-409f0726f062) is started using port RATIS=15291
2025-05-13 07:53:08,652 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(58a412dd-7dde-4577-85ab-409f0726f062) is started using port RATIS_ADMIN=15292
2025-05-13 07:53:08,652 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(58a412dd-7dde-4577-85ab-409f0726f062) is started using port RATIS_SERVER=15293
2025-05-13 07:53:08,652 [58a412dd-7dde-4577-85ab-409f0726f062-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(58a412dd-7dde-4577-85ab-409f0726f062) is started using port RATIS_DATASTREAM=15294
2025-05-13 07:53:08,652 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-58a412dd-7dde-4577-85ab-409f0726f062: Started
2025-05-13 07:53:08,653 [58a412dd-7dde-4577-85ab-409f0726f062-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-13 07:53:08,770 [IPC Server handler 1 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:08,770 [IPC Server handler 2 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:08,770 [IPC Server handler 1 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: f9ce924c-8a82-4766-a645-cb0bc56ee637{ip: 127.0.0.1, host: localhost, ports: [HTTP=15272, CLIENT_RPC=15273, REPLICATION=15279, RATIS=15275, RATIS_ADMIN=15276, RATIS_SERVER=15277, RATIS_DATASTREAM=15278, STANDALONE=15274], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:08,770 [IPC Server handler 2 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: f9ce924c-8a82-4766-a645-cb0bc56ee637{ip: 127.0.0.1, host: localhost, ports: [HTTP=15272, CLIENT_RPC=15273, REPLICATION=15279, RATIS=15275, RATIS_ADMIN=15276, RATIS_SERVER=15277, RATIS_DATASTREAM=15278, STANDALONE=15274], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:08,770 [IPC Server handler 1 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:08,771 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-13 07:53:08,771 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node f9ce924c-8a82-4766-a645-cb0bc56ee637 to Node DB.
2025-05-13 07:53:08,771 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(79)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2025-05-13 07:53:08,772 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:08,771 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 to datanode:f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1)
2025-05-13 07:53:08,772 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:08,772 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:08,772 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 2 millisec, f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1), {type: FCR, size: 0}
2025-05-13 07:53:08,774 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:08,775 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:08,775 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:08,775 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:08,775 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 99ccdf66-83a1-4834-ac9d-a74d4160e7f3, Nodes: [ {f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-13T07:53:08.771877360Z[Etc/UTC]}
2025-05-13 07:53:08,838 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-fc6588da-94fa-4a90-b0e0-c6affa498b89/container.db to cache
2025-05-13 07:53:08,838 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-fc6588da-94fa-4a90-b0e0-c6affa498b89/container.db for volume DS-fc6588da-94fa-4a90-b0e0-c6affa498b89
2025-05-13 07:53:08,840 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds
2025-05-13 07:53:08,840 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds
2025-05-13 07:53:08,840 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-13 07:53:08,840 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds
2025-05-13 07:53:08,841 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds
2025-05-13 07:53:08,843 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis
2025-05-13 07:53:08,844 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis
2025-05-13 07:53:08,845 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-13 07:53:08,845 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(74)) - Trying to initialize on demand scanner a second time on a datanode.
2025-05-13 07:53:08,845 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:08,845 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:08,846 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15303
2025-05-13 07:53:08,846 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(c5c2c3e6-bcf8-419e-a6b9-9661d5f86301)
2025-05-13 07:53:08,847 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: start RPC server
2025-05-13 07:53:08,847 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: GrpcService started, listening on 15299
2025-05-13 07:53:08,848 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: GrpcService started, listening on 15301
2025-05-13 07:53:08,848 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: GrpcService started, listening on 15300
2025-05-13 07:53:08,849 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(c5c2c3e6-bcf8-419e-a6b9-9661d5f86301) is started using port RATIS=15299
2025-05-13 07:53:08,849 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(c5c2c3e6-bcf8-419e-a6b9-9661d5f86301) is started using port RATIS_ADMIN=15300
2025-05-13 07:53:08,849 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(c5c2c3e6-bcf8-419e-a6b9-9661d5f86301) is started using port RATIS_SERVER=15301
2025-05-13 07:53:08,849 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: Started
2025-05-13 07:53:08,849 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(c5c2c3e6-bcf8-419e-a6b9-9661d5f86301) is started using port RATIS_DATASTREAM=15302
2025-05-13 07:53:08,849 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-13 07:53:08,945 [IPC Server handler 3 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:08,945 [IPC Server handler 5 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:08,945 [IPC Server handler 3 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: ec402e9c-53dd-4038-962b-5490446c9ba5{ip: 127.0.0.1, host: localhost, ports: [HTTP=15280, CLIENT_RPC=15281, REPLICATION=15287, RATIS=15283, RATIS_ADMIN=15284, RATIS_SERVER=15285, RATIS_DATASTREAM=15286, STANDALONE=15282], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:08,945 [IPC Server handler 5 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: ec402e9c-53dd-4038-962b-5490446c9ba5{ip: 127.0.0.1, host: localhost, ports: [HTTP=15280, CLIENT_RPC=15281, REPLICATION=15287, RATIS=15283, RATIS_ADMIN=15284, RATIS_SERVER=15285, RATIS_DATASTREAM=15286, STANDALONE=15282], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:08,945 [IPC Server handler 3 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:08,945 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node ec402e9c-53dd-4038-962b-5490446c9ba5 to Node DB.
2025-05-13 07:53:08,946 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:08,946 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:08,945 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(79)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2025-05-13 07:53:08,946 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:08,946 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-13 07:53:08,946 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 to datanode:ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1)
2025-05-13 07:53:08,948 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:08,948 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:08,948 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:08,948 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:08,948 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 3d57c6b2-0bc2-4f29-b761-e9394498d2b5, Nodes: [ {ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-13T07:53:08.946653761Z[Etc/UTC]}
2025-05-13 07:53:09,035 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-07967212-7d7e-4d65-bb55-689238937a7d/container.db to cache
2025-05-13 07:53:09,035 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-07967212-7d7e-4d65-bb55-689238937a7d/container.db for volume DS-07967212-7d7e-4d65-bb55-689238937a7d
2025-05-13 07:53:09,037 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds
2025-05-13 07:53:09,037 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds
2025-05-13 07:53:09,037 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-13 07:53:09,037 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds
2025-05-13 07:53:09,037 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds
2025-05-13 07:53:09,040 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis
2025-05-13 07:53:09,040 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis
2025-05-13 07:53:09,041 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-13 07:53:09,041 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(74)) - Trying to initialize on demand scanner a second time on a datanode.
2025-05-13 07:53:09,041 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:09,041 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-13 07:53:09,042 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15311
2025-05-13 07:53:09,042 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95)
2025-05-13 07:53:09,042 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: start RPC server
2025-05-13 07:53:09,043 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: GrpcService started, listening on 15307
2025-05-13 07:53:09,043 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: GrpcService started, listening on 15309
2025-05-13 07:53:09,044 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: GrpcService started, listening on 15308
2025-05-13 07:53:09,044 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95) is started using port RATIS=15307
2025-05-13 07:53:09,044 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95) is started using port RATIS_ADMIN=15308
2025-05-13 07:53:09,044 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95) is started using port RATIS_SERVER=15309
2025-05-13 07:53:09,044 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95) is started using port RATIS_DATASTREAM=15310
2025-05-13 07:53:09,044 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: Started
2025-05-13 07:53:09,045 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-13 07:53:09,120 [IPC Server handler 6 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:09,120 [IPC Server handler 6 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:09,120 [IPC Server handler 6 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: 58a412dd-7dde-4577-85ab-409f0726f062{ip: 127.0.0.1, host: localhost, ports: [HTTP=15288, CLIENT_RPC=15289, REPLICATION=15295, RATIS=15291, RATIS_ADMIN=15292, RATIS_SERVER=15293, RATIS_DATASTREAM=15294, STANDALONE=15290], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:09,120 [IPC Server handler 6 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: 58a412dd-7dde-4577-85ab-409f0726f062{ip: 127.0.0.1, host: localhost, ports: [HTTP=15288, CLIENT_RPC=15289, REPLICATION=15295, RATIS=15291, RATIS_ADMIN=15292, RATIS_SERVER=15293, RATIS_DATASTREAM=15294, STANDALONE=15290], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:09,120 [IPC Server handler 6 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:09,121 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,121 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(79)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2025-05-13 07:53:09,121 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:09,121 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(167)) - All SCM safe mode pre check rules have passed
2025-05-13 07:53:09,121 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-05-13 07:53:09,121 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-13 07:53:09,121 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node 58a412dd-7dde-4577-85ab-409f0726f062 to Node DB.
2025-05-13 07:53:09,121 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-13 07:53:09,121 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,121 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:09,121 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f to datanode:58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1)
2025-05-13 07:53:09,123 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:09,123 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,123 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:09,123 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,123 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:09,123 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 0aac6914-0c49-425d-8e28-0b35a1acbc3f, Nodes: [ {58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-13T07:53:09.121818076Z[Etc/UTC]}
2025-05-13 07:53:09,123 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 to datanode:58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1)
2025-05-13 07:53:09,124 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 to datanode:ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1)
2025-05-13 07:53:09,124 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 to datanode:f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1)
2025-05-13 07:53:09,124 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:09,125 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,125 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:09,125 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,125 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:09,125 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: bae4124e-e3c5-446a-bc3b-87ef695dbc41, Nodes: [ {58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1), ReplicaIndex: 0}, {ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1), ReplicaIndex: 0}, {f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-13T07:53:09.123954387Z[Etc/UTC]}
2025-05-13 07:53:09,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:09,232 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:09,235 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-13 07:53:09,270 [IPC Server handler 7 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-13 07:53:09,312 [IPC Server handler 1 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/c5c2c3e6-bcf8-419e-a6b9-9661d5f86301
2025-05-13 07:53:09,312 [IPC Server handler 9 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/c5c2c3e6-bcf8-419e-a6b9-9661d5f86301
2025-05-13 07:53:09,312 [IPC Server handler 1 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: c5c2c3e6-bcf8-419e-a6b9-9661d5f86301{ip: 127.0.0.1, host: localhost, ports: [HTTP=15296, CLIENT_RPC=15297, REPLICATION=15303, RATIS=15299, RATIS_ADMIN=15300, RATIS_SERVER=15301, RATIS_DATASTREAM=15302, STANDALONE=15298], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:09,313 [IPC Server handler 9 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: c5c2c3e6-bcf8-419e-a6b9-9661d5f86301{ip: 127.0.0.1, host: localhost, ports: [HTTP=15296, CLIENT_RPC=15297, REPLICATION=15303, RATIS=15299, RATIS_ADMIN=15300, RATIS_SERVER=15301, RATIS_DATASTREAM=15302, STANDALONE=15298], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:09,313 [IPC Server handler 9 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:09,313 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-13 07:53:09,313 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:09,313 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:09,313 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node c5c2c3e6-bcf8-419e-a6b9-9661d5f86301 to Node DB.
2025-05-13 07:53:09,313 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,313 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,313 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c to datanode:c5c2c3e6-bcf8-419e-a6b9-9661d5f86301(localhost/127.0.0.1)
2025-05-13 07:53:09,315 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:09,315 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,315 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:09,315 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,315 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:09,315 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c, Nodes: [ {c5c2c3e6-bcf8-419e-a6b9-9661d5f86301(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-13T07:53:09.313810175Z[Etc/UTC]}
2025-05-13 07:53:09,445 [IPC Server handler 11 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-13 07:53:09,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Waiting for nodes to be ready. Got 4 of 5 DN Heartbeats.
2025-05-13 07:53:09,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for cluster to exit safe mode
2025-05-13 07:53:09,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-13 07:53:09,508 [IPC Server handler 2 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95
2025-05-13 07:53:09,508 [IPC Server handler 12 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95
2025-05-13 07:53:09,508 [IPC Server handler 2 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95{ip: 127.0.0.1, host: localhost, ports: [HTTP=15304, CLIENT_RPC=15305, REPLICATION=15311, RATIS=15307, RATIS_ADMIN=15308, RATIS_SERVER=15309, RATIS_DATASTREAM=15310, STANDALONE=15306], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:09,508 [IPC Server handler 12 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95{ip: 127.0.0.1, host: localhost, ports: [HTTP=15304, CLIENT_RPC=15305, REPLICATION=15311, RATIS=15307, RATIS_ADMIN=15308, RATIS_SERVER=15309, RATIS_DATASTREAM=15310, STANDALONE=15306], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-13 07:53:09,508 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:09,508 [IPC Server handler 12 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:09,509 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-13 07:53:09,509 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,509 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,509 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee to datanode:3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95(localhost/127.0.0.1)
2025-05-13 07:53:09,509 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95 to Node DB.
2025-05-13 07:53:09,509 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:09,511 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:09,511 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,511 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:09,511 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:09,511 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:09,511 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 6225616f-efd8-4e48-8f52-ebd73f383dee, Nodes: [ {3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-13T07:53:09.509463825Z[Etc/UTC]}
2025-05-13 07:53:09,582 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:09,620 [IPC Server handler 0 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-13 07:53:09,812 [IPC Server handler 2 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-13 07:53:09,812 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:09,953 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 10 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 10.
2025-05-13 07:53:10,008 [IPC Server handler 4 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-13 07:53:10,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:10,269 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:10,445 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:10,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2025-05-13 07:53:10,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for cluster to exit safe mode
2025-05-13 07:53:10,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-13 07:53:10,586 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:10,615 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2025-05-13 07:53:10,620 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,008 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:11,235 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:11,236 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-13 07:53:11,269 [f9ce924c-8a82-4766-a645-cb0bc56ee637-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: addNew group-A74D4160E7F3:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277] returns group-A74D4160E7F3:java.util.concurrent.CompletableFuture@1d20c214[Not completed]
2025-05-13 07:53:11,269 [IPC Server handler 7 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-13 07:53:11,270 [IPC Server handler 7 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: new RaftServerImpl for group-A74D4160E7F3:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277] with ContainerStateMachine:uninitialized
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: ConfigurationManager, init=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:53:11,271 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:53:11,273 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis] (custom)
2025-05-13 07:53:11,274 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/99ccdf66-83a1-4834-ac9d-a74d4160e7f3 does not exist. Creating ...
2025-05-13 07:53:11,274 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/99ccdf66-83a1-4834-ac9d-a74d4160e7f3/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:53:11,276 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/99ccdf66-83a1-4834-ac9d-a74d4160e7f3 has been successfully formatted.
2025-05-13 07:53:11,276 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: initialize group-A74D4160E7F3
2025-05-13 07:53:11,276 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-A74D4160E7F3: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-13 07:53:11,276 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:53:11,276 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:53:11,276 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,276 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:53:11,276 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:53:11,277 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3. Trying to get from SCM.
2025-05-13 07:53:11,277 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,278 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8135,f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/99ccdf66-83a1-4834-ac9d-a74d4160e7f3
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:53:11,278 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-13 07:53:11,279 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:11,279 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:11,279 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:11,279 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:11,279 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,279 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-13 07:53:11,279 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3
2025-05-13 07:53:11,279 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:11,279 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: 99ccdf66-83a1-4834-ac9d-a74d4160e7f3, Nodes: [ {f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f9ce924c-8a82-4766-a645-cb0bc56ee637, CreationTimestamp2025-05-13T07:53:08.771Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-13 07:53:11,280 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/ONE PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 reported by f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1)
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: start as a follower, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277]|listeners:[], old=null}
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:53:11,284 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: start f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A74D4160E7F3,id=f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-A74D4160E7F3,id=f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:53:11,285 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: Successfully started.
2025-05-13 07:53:11,286 [f9ce924c-8a82-4766-a645-cb0bc56ee637-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3
2025-05-13 07:53:11,286 [f9ce924c-8a82-4766-a645-cb0bc56ee637-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3.
2025-05-13 07:53:11,286 [f9ce924c-8a82-4766-a645-cb0bc56ee637-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: addNew group-87EF695DBC41:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293] returns group-87EF695DBC41:java.util.concurrent.CompletableFuture@1e9977b8[Not completed]
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: new RaftServerImpl for group-87EF695DBC41:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293] with ContainerStateMachine:uninitialized
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: ConfigurationManager, init=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:53:11,287 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis] (custom)
2025-05-13 07:53:11,289 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41 does not exist. Creating ...
2025-05-13 07:53:11,290 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:53:11,291 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41 has been successfully formatted.
2025-05-13 07:53:11,291 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: initialize group-87EF695DBC41
2025-05-13 07:53:11,291 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-87EF695DBC41: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-13 07:53:11,291 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:53:11,291 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:53:11,291 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,291 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:53:11,291 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:53:11,292 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,292 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:11,292 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,292 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41. Trying to get from SCM.
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8140,f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:53:11,293 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:53:11,294 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:53:11,294 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-13 07:53:11,294 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-13 07:53:11,294 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: bae4124e-e3c5-446a-bc3b-87ef695dbc41, Nodes: [ {58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1), ReplicaIndex: 0}, {ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1), ReplicaIndex: 0}, {f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-13T07:53:09.123Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-13 07:53:11,294 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 reported by f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1)
2025-05-13 07:53:11,298 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,298 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:53:11,298 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:53:11,298 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-13 07:53:11,299 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,299 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,299 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: start as a follower, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:11,299 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:53:11,299 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: start f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState
2025-05-13 07:53:11,299 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87EF695DBC41,id=f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-87EF695DBC41,id=f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: Successfully started.
2025-05-13 07:53:11,300 [f9ce924c-8a82-4766-a645-cb0bc56ee637-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41
2025-05-13 07:53:11,307 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 58a412dd-7dde-4577-85ab-409f0726f062: addNew group-87EF695DBC41:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293] returns group-87EF695DBC41:java.util.concurrent.CompletableFuture@260a1957[Not completed]
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 58a412dd-7dde-4577-85ab-409f0726f062: new RaftServerImpl for group-87EF695DBC41:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293] with ContainerStateMachine:uninitialized
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: ConfigurationManager, init=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:53:11,308 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis] (custom)
2025-05-13 07:53:11,310 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41 does not exist. Creating ...
2025-05-13 07:53:11,311 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:53:11,312 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41 has been successfully formatted.
2025-05-13 07:53:11,312 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 58a412dd-7dde-4577-85ab-409f0726f062: initialize group-87EF695DBC41
2025-05-13 07:53:11,312 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-87EF695DBC41: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-13 07:53:11,312 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:53:11,312 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:53:11,312 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,312 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:53:11,312 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:53:11,313 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,313 [IPC Server handler 12 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-13 07:53:11,313 [IPC Server handler 12 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:11,313 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,313 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 reported by 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8145,58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-13 07:53:11,314 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-13 07:53:11,318 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: start as a follower, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 58a412dd-7dde-4577-85ab-409f0726f062: start 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87EF695DBC41,id=58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-87EF695DBC41,id=58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:11,319 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:53:11,320 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:53:11,320 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:53:11,320 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-13 07:53:11,320 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-13 07:53:11,320 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:53:11,320 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: Successfully started.
2025-05-13 07:53:11,328 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - ec402e9c-53dd-4038-962b-5490446c9ba5: addNew group-87EF695DBC41:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293] returns group-87EF695DBC41:java.util.concurrent.CompletableFuture@f6a44bf[Not completed]
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - ec402e9c-53dd-4038-962b-5490446c9ba5: new RaftServerImpl for group-87EF695DBC41:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293] with ContainerStateMachine:uninitialized
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: ConfigurationManager, init=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:53:11,329 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:53:11,330 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:11,330 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:11,330 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:53:11,330 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:53:11,331 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:53:11,331 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:53:11,331 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:53:11,331 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:53:11,331 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis] (custom)
2025-05-13 07:53:11,331 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41 does not exist. Creating ...
2025-05-13 07:53:11,332 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:53:11,333 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41 has been successfully formatted.
2025-05-13 07:53:11,333 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - ec402e9c-53dd-4038-962b-5490446c9ba5: initialize group-87EF695DBC41
2025-05-13 07:53:11,333 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-87EF695DBC41: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-13 07:53:11,333 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:53:11,333 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:53:11,333 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,333 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:53:11,333 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:53:11,334 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,334 [IPC Server handler 13 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-13 07:53:11,334 [IPC Server handler 13 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:11,334 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,334 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 reported by ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1)
2025-05-13 07:53:11,334 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:53:11,334 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:53:11,334 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8153,ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-13 07:53:11,335 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-13 07:53:11,339 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: start as a follower, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - ec402e9c-53dd-4038-962b-5490446c9ba5: start ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87EF695DBC41,id=ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-87EF695DBC41,id=ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:53:11,341 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:53:11,341 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:53:11,340 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:11,341 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-13 07:53:11,341 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-13 07:53:11,341 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:53:11,341 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: Successfully started.
2025-05-13 07:53:11,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41.
2025-05-13 07:53:11,445 [ec402e9c-53dd-4038-962b-5490446c9ba5-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - ec402e9c-53dd-4038-962b-5490446c9ba5: addNew group-E9394498D2B5:[ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285] returns group-E9394498D2B5:java.util.concurrent.CompletableFuture@4f9eec1f[Not completed]
2025-05-13 07:53:11,445 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - ec402e9c-53dd-4038-962b-5490446c9ba5: new RaftServerImpl for group-E9394498D2B5:[ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285] with ContainerStateMachine:uninitialized
2025-05-13 07:53:11,445 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:11,445 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:53:11,445 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:53:11,445 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: ConfigurationManager, init=conf: {index: -1, cur=peers:[ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:53:11,446 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:53:11,448 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:11,448 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:11,449 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:53:11,449 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:53:11,449 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:53:11,449 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:53:11,449 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:53:11,449 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:53:11,449 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis] (custom)
2025-05-13 07:53:11,449 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/3d57c6b2-0bc2-4f29-b761-e9394498d2b5 does not exist. Creating ...
2025-05-13 07:53:11,450 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/3d57c6b2-0bc2-4f29-b761-e9394498d2b5/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:53:11,450 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/3d57c6b2-0bc2-4f29-b761-e9394498d2b5 has been successfully formatted.
2025-05-13 07:53:11,451 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - ec402e9c-53dd-4038-962b-5490446c9ba5: initialize group-E9394498D2B5
2025-05-13 07:53:11,451 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-E9394498D2B5: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-13 07:53:11,451 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:53:11,451 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:53:11,451 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,451 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:53:11,451 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:53:11,452 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5. Trying to get from SCM.
2025-05-13 07:53:11,452 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,452 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8161,ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/3d57c6b2-0bc2-4f29-b761-e9394498d2b5
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-13 07:53:11,453 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-13 07:53:11,454 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:11,454 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: 3d57c6b2-0bc2-4f29-b761-e9394498d2b5, Nodes: [ {ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ec402e9c-53dd-4038-962b-5490446c9ba5, CreationTimestamp2025-05-13T07:53:08.946Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-13 07:53:11,454 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/ONE PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 reported by ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1)
2025-05-13 07:53:11,454 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 reported by ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1)
2025-05-13 07:53:11,454 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:11,454 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:11,454 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:11,454 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,455 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5
2025-05-13 07:53:11,455 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:11,458 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,458 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:53:11,458 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:53:11,458 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-13 07:53:11,458 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,458 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: start as a follower, conf=conf: {index: -1, cur=peers:[ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285]|listeners:[], old=null}
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - ec402e9c-53dd-4038-962b-5490446c9ba5: start ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E9394498D2B5,id=ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-E9394498D2B5,id=ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-13 07:53:11,459 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:53:11,460 [ec402e9c-53dd-4038-962b-5490446c9ba5-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: Successfully started.
2025-05-13 07:53:11,460 [ec402e9c-53dd-4038-962b-5490446c9ba5-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5
2025-05-13 07:53:11,460 [ec402e9c-53dd-4038-962b-5490446c9ba5-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5.
2025-05-13 07:53:11,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2025-05-13 07:53:11,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for cluster to exit safe mode
2025-05-13 07:53:11,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-13 07:53:11,589 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:11,620 [58a412dd-7dde-4577-85ab-409f0726f062-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 58a412dd-7dde-4577-85ab-409f0726f062: addNew group-0B35A1ACBC3F:[58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293] returns group-0B35A1ACBC3F:java.util.concurrent.CompletableFuture@39453435[Not completed]
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 58a412dd-7dde-4577-85ab-409f0726f062: new RaftServerImpl for group-0B35A1ACBC3F:[58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293] with ContainerStateMachine:uninitialized
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: ConfigurationManager, init=conf: {index: -1, cur=peers:[58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:53:11,621 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis] (custom)
2025-05-13 07:53:11,623 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/0aac6914-0c49-425d-8e28-0b35a1acbc3f does not exist. Creating ...
2025-05-13 07:53:11,624 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/0aac6914-0c49-425d-8e28-0b35a1acbc3f/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:53:11,625 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/0aac6914-0c49-425d-8e28-0b35a1acbc3f has been successfully formatted.
2025-05-13 07:53:11,625 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 58a412dd-7dde-4577-85ab-409f0726f062: initialize group-0B35A1ACBC3F
2025-05-13 07:53:11,625 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-0B35A1ACBC3F: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-13 07:53:11,625 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:53:11,625 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:53:11,625 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,625 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:53:11,625 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:53:11,626 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,626 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,626 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f. Trying to get from SCM.
2025-05-13 07:53:11,626 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:53:11,626 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:53:11,626 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8166,58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/0aac6914-0c49-425d-8e28-0b35a1acbc3f
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-13 07:53:11,627 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:11,627 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:11,627 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-13 07:53:11,627 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:11,627 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:11,627 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,627 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f
2025-05-13 07:53:11,628 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:11,628 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: 0aac6914-0c49-425d-8e28-0b35a1acbc3f, Nodes: [ {58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:58a412dd-7dde-4577-85ab-409f0726f062, CreationTimestamp2025-05-13T07:53:09.121Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-13 07:53:11,628 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 reported by 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1)
2025-05-13 07:53:11,632 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,632 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:53:11,632 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:53:11,632 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-13 07:53:11,632 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,632 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: start as a follower, conf=conf: {index: -1, cur=peers:[58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 58a412dd-7dde-4577-85ab-409f0726f062: start 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B35A1ACBC3F,id=58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-0B35A1ACBC3F,id=58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-13 07:53:11,633 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:53:11,634 [58a412dd-7dde-4577-85ab-409f0726f062-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: Successfully started.
2025-05-13 07:53:11,634 [58a412dd-7dde-4577-85ab-409f0726f062-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f
2025-05-13 07:53:11,634 [58a412dd-7dde-4577-85ab-409f0726f062-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f.
2025-05-13 07:53:11,812 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: addNew group-EC4769D0C27C:[c5c2c3e6-bcf8-419e-a6b9-9661d5f86301|127.0.0.1:15301] returns group-EC4769D0C27C:java.util.concurrent.CompletableFuture@52411571[Not completed]
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: new RaftServerImpl for group-EC4769D0C27C:[c5c2c3e6-bcf8-419e-a6b9-9661d5f86301|127.0.0.1:15301] with ContainerStateMachine:uninitialized
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: ConfigurationManager, init=conf: {index: -1, cur=peers:[c5c2c3e6-bcf8-419e-a6b9-9661d5f86301|127.0.0.1:15301]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:53:11,813 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:53:11,814 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,814 [IPC Server handler 3 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-13 07:53:11,814 [IPC Server handler 3 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:11,815 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c. Trying to get from SCM.
2025-05-13 07:53:11,815 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:11,815 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:11,815 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:53:11,815 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:53:11,815 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:53:11,816 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:53:11,816 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:53:11,816 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:53:11,816 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis] (custom)
2025-05-13 07:53:11,816 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c does not exist. Creating ...
2025-05-13 07:53:11,816 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: 5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c, Nodes: [ {c5c2c3e6-bcf8-419e-a6b9-9661d5f86301(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-13T07:53:09.313Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-13 07:53:11,816 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/ONE PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c reported by c5c2c3e6-bcf8-419e-a6b9-9661d5f86301(localhost/127.0.0.1)
2025-05-13 07:53:11,817 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:53:11,818 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c has been successfully formatted.
2025-05-13 07:53:11,818 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: initialize group-EC4769D0C27C
2025-05-13 07:53:11,818 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-EC4769D0C27C: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-13 07:53:11,818 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:53:11,818 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:53:11,818 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,818 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:53:11,818 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:53:11,819 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,819 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8172,c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-13 07:53:11,820 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-13 07:53:11,821 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:11,821 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:11,821 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:11,821 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:11,821 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:11,822 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c
2025-05-13 07:53:11,822 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:11,825 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:11,825 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:53:11,825 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:53:11,825 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: start as a follower, conf=conf: {index: -1, cur=peers:[c5c2c3e6-bcf8-419e-a6b9-9661d5f86301|127.0.0.1:15301]|listeners:[], old=null}
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: start c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EC4769D0C27C,id=c5c2c3e6-bcf8-419e-a6b9-9661d5f86301
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-EC4769D0C27C,id=c5c2c3e6-bcf8-419e-a6b9-9661d5f86301
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:53:11,827 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-13 07:53:11,827 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-13 07:53:11,827 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:53:11,826 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:11,827 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:11,827 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: Successfully started.
2025-05-13 07:53:11,827 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c
2025-05-13 07:53:11,827 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c.
2025-05-13 07:53:11,954 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 11 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 11.
2025-05-13 07:53:12,008 [IPC Server handler 6 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-13 07:53:12,008 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: addNew group-EBD73F383DEE:[3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95|127.0.0.1:15309] returns group-EBD73F383DEE:java.util.concurrent.CompletableFuture@7f59e7e2[Not completed]
2025-05-13 07:53:12,008 [IPC Server handler 6 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: new RaftServerImpl for group-EBD73F383DEE:[3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95|127.0.0.1:15309] with ContainerStateMachine:uninitialized
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: ConfigurationManager, init=conf: {index: -1, cur=peers:[3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95|127.0.0.1:15309]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-13 07:53:12,009 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis] (custom)
2025-05-13 07:53:12,012 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/6225616f-efd8-4e48-8f52-ebd73f383dee does not exist. Creating ...
2025-05-13 07:53:12,013 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/6225616f-efd8-4e48-8f52-ebd73f383dee/in_use.lock acquired by nodename 47914@pkrvmberfyhpb9w
2025-05-13 07:53:12,014 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/6225616f-efd8-4e48-8f52-ebd73f383dee has been successfully formatted.
2025-05-13 07:53:12,014 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: initialize group-EBD73F383DEE
2025-05-13 07:53:12,014 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-EBD73F383DEE: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-13 07:53:12,014 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-13 07:53:12,014 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-13 07:53:12,014 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:12,015 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-13 07:53:12,015 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-13 07:53:12,015 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:12,016 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee. Trying to get from SCM.
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8180,3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-cacheEviction-AwaitToRun,5,main] started
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/6225616f-efd8-4e48-8f52-ebd73f383dee
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-13 07:53:12,016 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-13 07:53:12,017 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-13 07:53:12,017 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:12,017 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:12,017 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-13 07:53:12,017 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:12,017 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:12,018 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee
2025-05-13 07:53:12,018 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:12,018 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: 6225616f-efd8-4e48-8f52-ebd73f383dee, Nodes: [ {3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95, CreationTimestamp2025-05-13T07:53:09.509Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-13 07:53:12,019 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/ONE PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee reported by 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95(localhost/127.0.0.1)
2025-05-13 07:53:12,022 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:12,022 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-13 07:53:12,022 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-13 07:53:12,022 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-13 07:53:12,022 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:12,022 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-13 07:53:12,022 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: start as a follower, conf=conf: {index: -1, cur=peers:[3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95|127.0.0.1:15309]|listeners:[], old=null}
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: start 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EBD73F383DEE,id=3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-EBD73F383DEE,id=3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-13 07:53:12,023 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: Successfully started.
2025-05-13 07:53:12,024 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee
2025-05-13 07:53:12,024 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee.
2025-05-13 07:53:12,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:12,293 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 reported by f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1)
2025-05-13 07:53:12,293 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:12,293 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:12,340 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1055549920ns, electionTimeout:1055ms
2025-05-13 07:53:12,340 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState
2025-05-13 07:53:12,340 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:53:12,340 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:53:12,340 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: start f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52
2025-05-13 07:53:12,341 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277]|listeners:[], old=null}
2025-05-13 07:53:12,341 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52 PRE_VOTE round 0: result PASSED (term=0)
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277]|listeners:[], old=null}
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52 ELECTION round 0: result PASSED (term=1)
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:53:12,342 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: start f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderStateImpl
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-A74D4160E7F3 with new leaderId: f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: change Leader from null to f9ce924c-8a82-4766-a645-cb0bc56ee637 at term 1 for becomeLeader, leader elected after 1071ms
2025-05-13 07:53:12,343 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:53:12,344 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderElection52] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: set configuration conf: {index: 0, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277]|listeners:[], old=null}
2025-05-13 07:53:12,344 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:53:12,344 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:12,345 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:12,345 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 reported by f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1)
2025-05-13 07:53:12,350 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/99ccdf66-83a1-4834-ac9d-a74d4160e7f3/current/log_inprogress_0
2025-05-13 07:53:12,351 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-13 07:53:12,363 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1022543940ns, electionTimeout:1022ms
2025-05-13 07:53:12,363 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState
2025-05-13 07:53:12,363 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:53:12,363 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:53:12,363 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - ec402e9c-53dd-4038-962b-5490446c9ba5: start ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53
2025-05-13 07:53:12,363 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,363 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277
2025-05-13 07:53:12,364 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293
2025-05-13 07:53:12,364 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:12,364 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:12,367 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: receive requestVote(PRE_VOTE, ec402e9c-53dd-4038-962b-5490446c9ba5, group-87EF695DBC41, 0, (t:0, i:0))
2025-05-13 07:53:12,367 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: receive requestVote(PRE_VOTE, ec402e9c-53dd-4038-962b-5490446c9ba5, group-87EF695DBC41, 0, (t:0, i:0))
2025-05-13 07:53:12,368 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FOLLOWER: reject PRE_VOTE from ec402e9c-53dd-4038-962b-5490446c9ba5: our priority 1 > candidate's priority 0
2025-05-13 07:53:12,368 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FOLLOWER: accept PRE_VOTE from ec402e9c-53dd-4038-962b-5490446c9ba5: our priority 0 <= candidate's priority 0
2025-05-13 07:53:12,368 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41 replies to PRE_VOTE vote request: ec402e9c-53dd-4038-962b-5490446c9ba5<-58a412dd-7dde-4577-85ab-409f0726f062#0:FAIL-t0. Peer's state: 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41:t0, leader=null, voted=, raftlog=Memoized:58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,368 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41 replies to PRE_VOTE vote request: ec402e9c-53dd-4038-962b-5490446c9ba5<-f9ce924c-8a82-4766-a645-cb0bc56ee637#0:OK-t0. Peer's state: f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41:t0, leader=null, voted=, raftlog=Memoized:f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,369 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2025-05-13 07:53:12,369 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: ec402e9c-53dd-4038-962b-5490446c9ba5<-58a412dd-7dde-4577-85ab-409f0726f062#0:FAIL-t0
2025-05-13 07:53:12,369 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53 PRE_VOTE round 0: result REJECTED
2025-05-13 07:53:12,369 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2025-05-13 07:53:12,369 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53
2025-05-13 07:53:12,369 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - ec402e9c-53dd-4038-962b-5490446c9ba5: start ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState
2025-05-13 07:53:12,369 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-LeaderElection53] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: set firstElectionSinceStartup to false for REJECTED
2025-05-13 07:53:12,414 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:12,414 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:12,446 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1126466672ns, electionTimeout:1126ms
2025-05-13 07:53:12,446 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState
2025-05-13 07:53:12,446 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:53:12,446 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:53:12,446 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 58a412dd-7dde-4577-85ab-409f0726f062: start 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54
2025-05-13 07:53:12,446 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,446 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277
2025-05-13 07:53:12,447 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:12,447 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285
2025-05-13 07:53:12,447 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:12,451 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: receive requestVote(PRE_VOTE, 58a412dd-7dde-4577-85ab-409f0726f062, group-87EF695DBC41, 0, (t:0, i:0))
2025-05-13 07:53:12,451 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: receive requestVote(PRE_VOTE, 58a412dd-7dde-4577-85ab-409f0726f062, group-87EF695DBC41, 0, (t:0, i:0))
2025-05-13 07:53:12,451 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FOLLOWER: accept PRE_VOTE from 58a412dd-7dde-4577-85ab-409f0726f062: our priority 0 <= candidate's priority 1
2025-05-13 07:53:12,451 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FOLLOWER: accept PRE_VOTE from 58a412dd-7dde-4577-85ab-409f0726f062: our priority 0 <= candidate's priority 1
2025-05-13 07:53:12,451 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41 replies to PRE_VOTE vote request: 58a412dd-7dde-4577-85ab-409f0726f062<-ec402e9c-53dd-4038-962b-5490446c9ba5#0:OK-t0. Peer's state: ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41:t0, leader=null, voted=, raftlog=Memoized:ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,451 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41 replies to PRE_VOTE vote request: 58a412dd-7dde-4577-85ab-409f0726f062<-f9ce924c-8a82-4766-a645-cb0bc56ee637#0:OK-t0. Peer's state: f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41:t0, leader=null, voted=, raftlog=Memoized:f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,452 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2025-05-13 07:53:12,452 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 58a412dd-7dde-4577-85ab-409f0726f062<-ec402e9c-53dd-4038-962b-5490446c9ba5#0:OK-t0
2025-05-13 07:53:12,452 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54 PRE_VOTE round 0: result PASSED
2025-05-13 07:53:12,454 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,454 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-13 07:53:12,454 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-13 07:53:12,455 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: receive requestVote(ELECTION, 58a412dd-7dde-4577-85ab-409f0726f062, group-87EF695DBC41, 1, (t:0, i:0))
2025-05-13 07:53:12,455 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FOLLOWER: accept ELECTION from 58a412dd-7dde-4577-85ab-409f0726f062: our priority 0 <= candidate's priority 1
2025-05-13 07:53:12,455 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: changes role from  FOLLOWER to FOLLOWER at term 0 for candidate:58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:12,455 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState
2025-05-13 07:53:12,455 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: receive requestVote(ELECTION, 58a412dd-7dde-4577-85ab-409f0726f062, group-87EF695DBC41, 1, (t:0, i:0))
2025-05-13 07:53:12,455 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState was interrupted
2025-05-13 07:53:12,455 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: start f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState
2025-05-13 07:53:12,455 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FOLLOWER: accept ELECTION from 58a412dd-7dde-4577-85ab-409f0726f062: our priority 0 <= candidate's priority 1
2025-05-13 07:53:12,455 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: changes role from  FOLLOWER to FOLLOWER at term 0 for candidate:58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:12,455 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState
2025-05-13 07:53:12,455 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - ec402e9c-53dd-4038-962b-5490446c9ba5: start ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState
2025-05-13 07:53:12,455 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: set firstElectionSinceStartup to false for candidate:58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:12,455 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState was interrupted
2025-05-13 07:53:12,456 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41 replies to ELECTION vote request: 58a412dd-7dde-4577-85ab-409f0726f062<-f9ce924c-8a82-4766-a645-cb0bc56ee637#0:OK-t1. Peer's state: f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41:t1, leader=null, voted=58a412dd-7dde-4577-85ab-409f0726f062, raftlog=Memoized:f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,457 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41 replies to ELECTION vote request: 58a412dd-7dde-4577-85ab-409f0726f062<-ec402e9c-53dd-4038-962b-5490446c9ba5#0:OK-t1. Peer's state: ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41:t1, leader=null, voted=58a412dd-7dde-4577-85ab-409f0726f062, raftlog=Memoized:ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,457 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54: ELECTION PASSED received 1 response(s) and 0 exception(s):
2025-05-13 07:53:12,457 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 58a412dd-7dde-4577-85ab-409f0726f062<-f9ce924c-8a82-4766-a645-cb0bc56ee637#0:OK-t1
2025-05-13 07:53:12,457 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54 ELECTION round 0: result PASSED
2025-05-13 07:53:12,457 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54
2025-05-13 07:53:12,457 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-13 07:53:12,457 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:53:12,457 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,457 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,458 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:12,459 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 58a412dd-7dde-4577-85ab-409f0726f062: start 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderStateImpl
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-87EF695DBC41 with new leaderId: 58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:12,460 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: change Leader from null to 58a412dd-7dde-4577-85ab-409f0726f062 at term 1 for becomeLeader, leader elected after 1152ms
2025-05-13 07:53:12,461 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:53:12,461 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderElection54] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: set configuration conf: {index: 0, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,461 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:53:12,461 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 reported by 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1)
2025-05-13 07:53:12,461 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:12,461 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-13 07:53:12,463 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-13 07:53:12,463 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:12,463 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2025-05-13 07:53:12,463 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-13 07:53:12,463 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-13 07:53:12,463 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41
2025-05-13 07:53:12,463 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-05-13 07:53:12,463 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - HealthyPipelineSafeModeRule rule is successfully validated
2025-05-13 07:53:12,463 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(155)) - ScmSafeModeManager, all rules are successfully validated
2025-05-13 07:53:12,464 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(178)) - SCM exiting safe mode.
2025-05-13 07:53:12,464 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-05-13 07:53:12,464 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(78)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2025-05-13 07:53:12,464 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(78)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2025-05-13 07:53:12,464 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(258)) - notifyStatusChanged:RUNNING
2025-05-13 07:53:12,464 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1387)) - Service ReplicationManager transitions to RUNNING.
2025-05-13 07:53:12,464 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(134)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2025-05-13 07:53:12,464 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:notifyStatusChanged(78)) - Service SCMHATransactionMonitor transitions to RUNNING.
2025-05-13 07:53:12,467 [f9ce924c-8a82-4766-a645-cb0bc56ee637-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-87EF695DBC41 with new leaderId: 58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:12,467 [f9ce924c-8a82-4766-a645-cb0bc56ee637-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: change Leader from null to 58a412dd-7dde-4577-85ab-409f0726f062 at term 1 for appendEntries, leader elected after 1179ms
2025-05-13 07:53:12,469 [ec402e9c-53dd-4038-962b-5490446c9ba5-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-87EF695DBC41 with new leaderId: 58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:12,469 [ec402e9c-53dd-4038-962b-5490446c9ba5-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: change Leader from null to 58a412dd-7dde-4577-85ab-409f0726f062 at term 1 for appendEntries, leader elected after 1139ms
2025-05-13 07:53:12,469 [f9ce924c-8a82-4766-a645-cb0bc56ee637-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: set configuration conf: {index: 0, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,469 [f9ce924c-8a82-4766-a645-cb0bc56ee637-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:53:12,470 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:53:12,470 [ec402e9c-53dd-4038-962b-5490446c9ba5-server-thread3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: set configuration conf: {index: 0, cur=peers:[f9ce924c-8a82-4766-a645-cb0bc56ee637|127.0.0.1:15277, ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285, 58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,470 [ec402e9c-53dd-4038-962b-5490446c9ba5-server-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:53:12,471 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/current/log_inprogress_0
2025-05-13 07:53:12,471 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:53:12,476 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/current/log_inprogress_0
2025-05-13 07:53:12,477 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/current/log_inprogress_0
2025-05-13 07:53:12,478 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-13 07:53:12,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2025-05-13 07:53:12,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Cluster exits safe mode
2025-05-13 07:53:12,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-13 07:53:12,509 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2025-05-13 07:53:12,509 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2025-05-13 07:53:12,509 [main] INFO  proxy.SCMContainerLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15260]
2025-05-13 07:53:12,509 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2025-05-13 07:53:12,509 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2025-05-13 07:53:12,509 [main] INFO  proxy.SecretKeyProtocolFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol SecretKeyProtocolScmPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:9961]
2025-05-13 07:53:12,513 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(463)) - Creating Volume: vol1, with user38012 as owner and space quota set to -1 bytes, counts quota set to -1
2025-05-13 07:53:12,527 [om1-OMStateMachineApplyTransactionThread - 0] WARN  helpers.OzoneAclUtil (OzoneAclUtil.java:getDefaultAclList(77)) - Failed to get primary group from user user38012 (auth:SIMPLE)
2025-05-13 07:53:12,527 [om1-OMStateMachineApplyTransactionThread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(203)) - created volume:vol1 for user:user38012
2025-05-13 07:53:12,530 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(688)) - Creating Bucket: vol1/bucket1, with bucket layout FILE_SYSTEM_OPTIMIZED, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2025-05-13 07:53:12,532 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1073514742ns, electionTimeout:1073ms
2025-05-13 07:53:12,532 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState
2025-05-13 07:53:12,532 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:53:12,532 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:53:12,533 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - ec402e9c-53dd-4038-962b-5490446c9ba5: start ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55
2025-05-13 07:53:12,533 [om1-OMStateMachineApplyTransactionThread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(292)) - created bucket: bucket1 of layout FILE_SYSTEM_OPTIMIZED in volume: vol1
2025-05-13 07:53:12,533 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285]|listeners:[], old=null}
2025-05-13 07:53:12,533 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55 PRE_VOTE round 0: result PASSED (term=0)
2025-05-13 07:53:12,534 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285]|listeners:[], old=null}
2025-05-13 07:53:12,534 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55 ELECTION round 0: result PASSED (term=1)
2025-05-13 07:53:12,534 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55
2025-05-13 07:53:12,534 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-13 07:53:12,534 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:53:12,534 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,534 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-13 07:53:12,535 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-13 07:53:12,535 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:53:12,535 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:53:12,535 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:53:12,535 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:53:12,535 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:12,535 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:53:12,535 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,536 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:53:12,536 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - ec402e9c-53dd-4038-962b-5490446c9ba5: start ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderStateImpl
2025-05-13 07:53:12,536 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:53:12,536 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-E9394498D2B5 with new leaderId: ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:12,536 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: change Leader from null to ec402e9c-53dd-4038-962b-5490446c9ba5 at term 1 for becomeLeader, leader elected after 1089ms
2025-05-13 07:53:12,536 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:53:12,536 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderElection55] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: set configuration conf: {index: 0, cur=peers:[ec402e9c-53dd-4038-962b-5490446c9ba5|127.0.0.1:15285]|listeners:[], old=null}
2025-05-13 07:53:12,536 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:53:12,539 [IPC Server handler 2 on default port 15261] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(136)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2025-05-13 07:53:12,542 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(249)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 115816896921600000.
2025-05-13 07:53:12,543 [IPC Server handler 2 on default port 15261] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(136)) - Allocate a batch for localId, change lastId from 115816896921600000 to 115816896921601000.
2025-05-13 07:53:12,543 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/3d57c6b2-0bc2-4f29-b761-e9394498d2b5/current/log_inprogress_0
2025-05-13 07:53:12,544 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-13 07:53:12,568 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(242)) - Successfully added container #1 to Recon.
2025-05-13 07:53:12,569 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 3 millisec, 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1), {type: ICR, size: 1}
2025-05-13 07:53:12,569 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(251)) - Event remained in queue for long time 3 millisec, ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1), {type: ICR, size: 1}
2025-05-13 07:53:12,570 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 4 millisec, ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1), {type: ICR, size: 1}
2025-05-13 07:53:12,570 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 4 millisec, ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15270/api/v1/triggerdbsync/om ...
Connection Refused. Please make sure the Recon Server has been started.
2025-05-13 07:53:12,592 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:12,615 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2025-05-13 07:53:12,767 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1134586711ns, electionTimeout:1134ms
2025-05-13 07:53:12,767 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState
2025-05-13 07:53:12,768 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:53:12,768 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:53:12,768 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 58a412dd-7dde-4577-85ab-409f0726f062: start 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56
2025-05-13 07:53:12,768 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,768 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56 PRE_VOTE round 0: result PASSED (term=0)
2025-05-13 07:53:12,769 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,769 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56 ELECTION round 0: result PASSED (term=1)
2025-05-13 07:53:12,769 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56
2025-05-13 07:53:12,769 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-13 07:53:12,769 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 58a412dd-7dde-4577-85ab-409f0726f062: start 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderStateImpl
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:53:12,770 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-0B35A1ACBC3F with new leaderId: 58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:12,771 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: change Leader from null to 58a412dd-7dde-4577-85ab-409f0726f062 at term 1 for becomeLeader, leader elected after 1149ms
2025-05-13 07:53:12,771 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:53:12,771 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:53:12,772 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderElection56] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: set configuration conf: {index: 0, cur=peers:[58a412dd-7dde-4577-85ab-409f0726f062|127.0.0.1:15293]|listeners:[], old=null}
2025-05-13 07:53:12,777 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/0aac6914-0c49-425d-8e28-0b35a1acbc3f/current/log_inprogress_0
2025-05-13 07:53:12,778 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-13 07:53:12,871 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1044734080ns, electionTimeout:1044ms
2025-05-13 07:53:12,871 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState
2025-05-13 07:53:12,871 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:53:12,871 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:53:12,871 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: start c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57
2025-05-13 07:53:12,871 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[c5c2c3e6-bcf8-419e-a6b9-9661d5f86301|127.0.0.1:15301]|listeners:[], old=null}
2025-05-13 07:53:12,872 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57 PRE_VOTE round 0: result PASSED (term=0)
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[c5c2c3e6-bcf8-419e-a6b9-9661d5f86301|127.0.0.1:15301]|listeners:[], old=null}
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57 ELECTION round 0: result PASSED (term=1)
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:53:12,873 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: start c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderStateImpl
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-EC4769D0C27C with new leaderId: c5c2c3e6-bcf8-419e-a6b9-9661d5f86301
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: change Leader from null to c5c2c3e6-bcf8-419e-a6b9-9661d5f86301 at term 1 for becomeLeader, leader elected after 1060ms
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:53:12,874 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderElection57] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: set configuration conf: {index: 0, cur=peers:[c5c2c3e6-bcf8-419e-a6b9-9661d5f86301|127.0.0.1:15301]|listeners:[], old=null}
2025-05-13 07:53:12,875 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:53:12,881 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c/current/log_inprogress_0
2025-05-13 07:53:12,882 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-13 07:53:13,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:13,183 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1160524736ns, electionTimeout:1160ms
2025-05-13 07:53:13,183 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState
2025-05-13 07:53:13,183 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-13 07:53:13,183 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-13 07:53:13,183 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: start 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58
2025-05-13 07:53:13,184 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95|127.0.0.1:15309]|listeners:[], old=null}
2025-05-13 07:53:13,184 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58 PRE_VOTE round 0: result PASSED (term=0)
2025-05-13 07:53:13,202 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95|127.0.0.1:15309]|listeners:[], old=null}
2025-05-13 07:53:13,202 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58 ELECTION round 0: result PASSED (term=1)
2025-05-13 07:53:13,202 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58
2025-05-13 07:53:13,202 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-13 07:53:13,202 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-13 07:53:13,202 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:13,202 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: start 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderStateImpl
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: set firstElectionSinceStartup to false for becomeLeader
2025-05-13 07:53:13,203 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-EBD73F383DEE with new leaderId: 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95
2025-05-13 07:53:13,204 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: change Leader from null to 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95 at term 1 for becomeLeader, leader elected after 1194ms
2025-05-13 07:53:13,204 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-13 07:53:13,204 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-13 07:53:13,206 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderElection58] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: set configuration conf: {index: 0, cur=peers:[3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95|127.0.0.1:15309]|listeners:[], old=null}
2025-05-13 07:53:13,210 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/6225616f-efd8-4e48-8f52-ebd73f383dee/current/log_inprogress_0
2025-05-13 07:53:13,212 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-13 07:53:13,236 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:13,236 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-13 07:53:13,596 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:13,955 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 12 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 12.
2025-05-13 07:53:14,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:14,600 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:14,620 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2025-05-13 07:53:15,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-13 07:53:15,236 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:15,237 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-13 07:53:15,603 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:15,955 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 13 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 13.
2025-05-13 07:53:16,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-13 07:53:16,607 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:16,621 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 8 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 8.
2025-05-13 07:53:17,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:17,237 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:17,238 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2025-05-13 07:53:17,610 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:17,956 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 14 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 14.
2025-05-13 07:53:18,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:18,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:18,622 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 9 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 9.
2025-05-13 07:53:19,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:19,238 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:19,238 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2025-05-13 07:53:19,618 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:19,961 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] ERROR scm.ReconDeadNodeHandler (ReconDeadNodeHandler.java:onMessage(81)) - Error trying to verify Node operational state from SCM.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:872)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1588)
	at org.apache.hadoop.ipc.Client.call(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1426)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:668)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:789)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:364)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1649)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	... 22 more
2025-05-13 07:53:19,961 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. b5119e3f-d2b6-46f7-bcf1-9ce12c57b52e(localhost/127.0.0.1)
2025-05-13 07:53:19,961 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: 945a377c-bef1-4283-bcd2-251da4958659, Nodes: [ {b5119e3f-d2b6-46f7-bcf1-9ce12c57b52e(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:b5119e3f-d2b6-46f7-bcf1-9ce12c57b52e, CreationTimestamp2025-05-13T07:52:19.466Z[Etc/UTC]} removed.
2025-05-13 07:53:19,962 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(190)) - Processing of TypedEvent{payloadType=DatanodeDetails, name='Replication_Manager_Notify'} is skipped, EventQueue is not running
2025-05-13 07:53:19,962 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 0 for DN b5119e3f-d2b6-46f7-bcf1-9ce12c57b52e(localhost/127.0.0.1)
2025-05-13 07:53:19,962 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/b5119e3f-d2b6-46f7-bcf1-9ce12c57b52e
2025-05-13 07:53:19,962 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-13 07:53:20,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:20,622 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:20,622 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 10 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 10.
2025-05-13 07:53:21,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:21,239 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:21,239 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2025-05-13 07:53:21,626 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:21,963 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-13 07:53:22,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:22,623 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 11 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 11.
2025-05-13 07:53:22,629 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:23,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:23,239 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:23,240 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 8 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 8.
2025-05-13 07:53:23,633 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:23,963 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-13 07:53:24,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:24,624 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 12 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 12.
2025-05-13 07:53:24,636 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:25,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:25,240 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:25,245 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 9 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 9.
2025-05-13 07:53:25,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:25,964 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-13 07:53:26,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:26,624 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 13 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 13.
2025-05-13 07:53:26,644 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:27,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:27,245 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:27,245 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 10 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 10.
2025-05-13 07:53:27,647 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:27,965 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-13 07:53:28,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:28,625 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 14 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 14.
2025-05-13 07:53:28,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:29,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:29,245 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:29,246 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 11 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 11.
2025-05-13 07:53:29,654 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:29,965 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2025-05-13 07:53:30,160 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:30,630 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] ERROR scm.ReconDeadNodeHandler (ReconDeadNodeHandler.java:onMessage(81)) - Error trying to verify Node operational state from SCM.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:872)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1588)
	at org.apache.hadoop.ipc.Client.call(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1426)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:668)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:789)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:364)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1649)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	... 22 more
2025-05-13 07:53:30,658 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:31,161 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:31,246 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:31,247 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 12 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 12.
2025-05-13 07:53:31,661 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:31,966 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2025-05-13 07:53:32,161 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:32,605 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(394)) - Shutting down the Mini Ozone Cluster
2025-05-13 07:53:32,605 [main] INFO  db.CodecTestUtil (CodecTestUtil.java:gc(49)) - gc 0
2025-05-13 07:53:32,730 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:32,827 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(410)) - Stopping the Mini Ozone Cluster
2025-05-13 07:53:32,827 [main] INFO  om.OzoneManager (OzoneManager.java:stop(2328)) - om1[localhost:15266]: Stopping Ozone Manager
2025-05-13 07:53:32,827 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15266
2025-05-13 07:53:32,829 [IPC Server listener on 15266] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15266
2025-05-13 07:53:32,829 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:stop(634)) - Stopping org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer@3338ffa9 at port 15269
2025-05-13 07:53:32,829 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - om1: close
2025-05-13 07:53:32,829 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - om1: shutdown server GrpcServerProtocolService now
2025-05-13 07:53:32,829 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:32,829 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - om1@group-C5BA1605619E: shutdown
2025-05-13 07:53:32,830 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-05-13 07:53:32,830 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - om1: shutdown server GrpcServerProtocolService successfully
2025-05-13 07:53:32,830 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2025-05-13 07:53:32,830 [om1-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2025-05-13 07:53:32,831 [om1-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 8
2025-05-13 07:53:32,852 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(515)) - om1: taking snapshot. applied = (t:1, i:8), skipped = 7, notified = (t:1, i:8), current snapshot index = (t:1, i:8), took 21 ms
2025-05-13 07:53:32,852 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 8
2025-05-13 07:53:32,852 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 8
2025-05-13 07:53:32,853 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - om1@group-C5BA1605619E-StateMachineUpdater: closing OzoneManagerStateMachine, lastApplied=(t:1, i:8)
2025-05-13 07:53:32,853 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(555)) - Stopping OzoneManagerStateMachine:om1:group-C5BA1605619E.
2025-05-13 07:53:32,853 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(499)) - Stopping OMDoubleBuffer flush thread
2025-05-13 07:53:32,853 [om1-OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(558)) - OMDoubleBuffer flush thread om1-OMDoubleBufferFlushThread is interrupted and will exit.
2025-05-13 07:53:32,853 [om1@group-C5BA1605619E-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - om1@group-C5BA1605619E-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:33,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:33,247 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:33,248 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 13 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 13.
2025-05-13 07:53:33,581 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2025-05-13 07:53:33,581 [JvmPauseMonitor47] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-om1: Stopped
2025-05-13 07:53:33,581 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service KeyDeletingService
2025-05-13 07:53:33,582 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service DirectoryDeletingService
2025-05-13 07:53:33,583 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service OpenKeyCleanupService
2025-05-13 07:53:33,583 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SstFilteringService
2025-05-13 07:53:33,583 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDeletingService
2025-05-13 07:53:33,584 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service MultipartUploadCleanupService
2025-05-13 07:53:33,585 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1f9ede24{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2025-05-13 07:53:33,585 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@2ddf6cbd{HTTP/1.1, (http/1.1)}{0.0.0.0:15267}
2025-05-13 07:53:33,585 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-13 07:53:33,585 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@35873a1{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-05-13 07:53:33,586 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@73aee4a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-13 07:53:33,586 [main] INFO  rocksdiff.RocksDBCheckpointDiffer (RocksDBCheckpointDiffer.java:close(299)) - Shutting down CompactionDagPruningService.
2025-05-13 07:53:33,588 [main] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1696)) - Shutting down executorService: 'SnapDiffExecutor'
2025-05-13 07:53:33,589 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDiffCleanupService
2025-05-13 07:53:33,590 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(476)) - Stopping the HddsDatanodes
2025-05-13 07:53:33,591 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-13 07:53:33,591 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-13 07:53:33,591 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:33,592 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-13 07:53:33,592 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:33,592 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@6d195dde exiting.
2025-05-13 07:53:33,592 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-13 07:53:33,592 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:33,592 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@484a6 exiting.
2025-05-13 07:53:33,592 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds) is shutting down. 
2025-05-13 07:53:33,592 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@3f479c40 exiting.
2025-05-13 07:53:33,593 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds) is shutting down. 
2025-05-13 07:53:33,593 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds) is shutting down. 
2025-05-13 07:53:33,593 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:33,593 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:33,593 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds, DS-fc6588da-94fa-4a90-b0e0-c6affa498b89) exiting.
2025-05-13 07:53:33,593 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds, DS-07967212-7d7e-4d65-bb55-689238937a7d) exiting.
2025-05-13 07:53:33,593 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:shutdownScanner(208)) - On-demand container scanner is shutting down.
2025-05-13 07:53:33,593 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:33,593 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds, DS-65099b77-335d-4459-bc5a-9fdc99e265ad) exiting.
2025-05-13 07:53:33,593 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:33,594 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@3a60e663 exiting.
2025-05-13 07:53:33,594 [ForkJoinPool.commonPool-worker-2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(c5c2c3e6-bcf8-419e-a6b9-9661d5f86301)
2025-05-13 07:53:33,594 [ForkJoinPool.commonPool-worker-3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95)
2025-05-13 07:53:33,594 [ForkJoinPool.commonPool-worker-3] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: close
2025-05-13 07:53:33,594 [ForkJoinPool.commonPool-worker-2] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: close
2025-05-13 07:53:33,594 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE: shutdown
2025-05-13 07:53:33,594 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(58a412dd-7dde-4577-85ab-409f0726f062)
2025-05-13 07:53:33,594 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - 58a412dd-7dde-4577-85ab-409f0726f062: close
2025-05-13 07:53:33,594 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds) is shutting down. 
2025-05-13 07:53:33,594 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C: shutdown
2025-05-13 07:53:33,595 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-13 07:53:33,594 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EBD73F383DEE,id=3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95
2025-05-13 07:53:33,595 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-LeaderStateImpl
2025-05-13 07:53:33,595 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-EC4769D0C27C,id=c5c2c3e6-bcf8-419e-a6b9-9661d5f86301
2025-05-13 07:53:33,595 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-LeaderStateImpl
2025-05-13 07:53:33,595 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-PendingRequests: sendNotLeaderResponses
2025-05-13 07:53:33,595 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:33,595 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds, DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69) exiting.
2025-05-13 07:53:33,595 [ForkJoinPool.commonPool-worker-1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(ec402e9c-53dd-4038-962b-5490446c9ba5)
2025-05-13 07:53:33,595 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-PendingRequests: sendNotLeaderResponses
2025-05-13 07:53:33,595 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater: set stopIndex = 0
2025-05-13 07:53:33,596 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-EC4769D0C27C: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c/sm/snapshot.1_0
2025-05-13 07:53:33,594 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F: shutdown
2025-05-13 07:53:33,596 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0B35A1ACBC3F,id=58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:33,596 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-LeaderStateImpl
2025-05-13 07:53:33,594 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-13 07:53:33,596 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-PendingRequests: sendNotLeaderResponses
2025-05-13 07:53:33,595 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - ec402e9c-53dd-4038-962b-5490446c9ba5: close
2025-05-13 07:53:33,596 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater: set stopIndex = 0
2025-05-13 07:53:33,596 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-0B35A1ACBC3F: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/0aac6914-0c49-425d-8e28-0b35a1acbc3f/sm/snapshot.1_0
2025-05-13 07:53:33,597 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5: shutdown
2025-05-13 07:53:33,597 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E9394498D2B5,id=ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:33,597 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-LeaderStateImpl
2025-05-13 07:53:33,597 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-PendingRequests: sendNotLeaderResponses
2025-05-13 07:53:33,597 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-0B35A1ACBC3F: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/0aac6914-0c49-425d-8e28-0b35a1acbc3f/sm/snapshot.1_0 took: 1 ms
2025-05-13 07:53:33,597 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-EBD73F383DEE: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/6225616f-efd8-4e48-8f52-ebd73f383dee/sm/snapshot.1_0
2025-05-13 07:53:33,597 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater: Took a snapshot at index 0
2025-05-13 07:53:33,597 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-13 07:53:33,597 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater: set stopIndex = 0
2025-05-13 07:53:33,598 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-E9394498D2B5: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/3d57c6b2-0bc2-4f29-b761-e9394498d2b5/sm/snapshot.1_0
2025-05-13 07:53:33,598 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-EBD73F383DEE: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/ratis/6225616f-efd8-4e48-8f52-ebd73f383dee/sm/snapshot.1_0 took: 1 ms
2025-05-13 07:53:33,598 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater: Took a snapshot at index 0
2025-05-13 07:53:33,598 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-13 07:53:33,598 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-13 07:53:33,597 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-StateMachineUpdater: set stopIndex = 0
2025-05-13 07:53:33,598 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:33,597 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-EC4769D0C27C: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/ratis/5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c/sm/snapshot.1_0 took: 2 ms
2025-05-13 07:53:33,599 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater: Took a snapshot at index 0
2025-05-13 07:53:33,599 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-13 07:53:33,599 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-13 07:53:33,598 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-E9394498D2B5: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/3d57c6b2-0bc2-4f29-b761-e9394498d2b5/sm/snapshot.1_0 took: 1 ms
2025-05-13 07:53:33,599 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:33,599 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater: Took a snapshot at index 0
2025-05-13 07:53:33,599 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-13 07:53:33,599 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-13 07:53:33,599 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:33,598 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-13 07:53:33,600 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-13 07:53:33,600 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41: shutdown
2025-05-13 07:53:33,600 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-13 07:53:33,600 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown server GrpcServerProtocolService now
2025-05-13 07:53:33,600 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-87EF695DBC41,id=58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:33,600 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-LeaderStateImpl
2025-05-13 07:53:33,600 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->f9ce924c-8a82-4766-a645-cb0bc56ee637-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->f9ce924c-8a82-4766-a645-cb0bc56ee637-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-05-13 07:53:33,600 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-PendingRequests: sendNotLeaderResponses
2025-05-13 07:53:33,600 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->ec402e9c-53dd-4038-962b-5490446c9ba5-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->ec402e9c-53dd-4038-962b-5490446c9ba5-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-05-13 07:53:33,601 [58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:33,601 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown server GrpcServerProtocolService successfully
2025-05-13 07:53:33,601 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-13 07:53:33,601 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: Completed APPEND_ENTRIES, lastRequest: null
2025-05-13 07:53:33,601 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - ec402e9c-53dd-4038-962b-5490446c9ba5: Completed APPEND_ENTRIES, lastRequest: null
2025-05-13 07:53:33,602 [Thread-6195] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(105)) - f9ce924c-8a82-4766-a645-cb0bc56ee637 Close channels
2025-05-13 07:53:33,601 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - ec402e9c-53dd-4038-962b-5490446c9ba5: Completed APPEND_ENTRIES, lastRequest: 58a412dd-7dde-4577-85ab-409f0726f062->ec402e9c-53dd-4038-962b-5490446c9ba5#6-t1,previous=(t:1, i:2),leaderCommit=2,initializing? false,entries: size=2, first=(t:1, i:3), METADATAENTRY(c:1)
2025-05-13 07:53:33,602 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: Completed APPEND_ENTRIES, lastRequest: 58a412dd-7dde-4577-85ab-409f0726f062->f9ce924c-8a82-4766-a645-cb0bc56ee637#6-t1,previous=(t:1, i:2),leaderCommit=2,initializing? false,entries: size=2, first=(t:1, i:3), METADATAENTRY(c:1)
2025-05-13 07:53:33,602 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: Completed APPEND_ENTRIES, lastReply: null
2025-05-13 07:53:33,602 [Thread-6196] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(105)) - ec402e9c-53dd-4038-962b-5490446c9ba5 Close channels
2025-05-13 07:53:33,603 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-13 07:53:33,602 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "58a412dd-7dde-4577-85ab-409f0726f062"
  replyId: "f9ce924c-8a82-4766-a645-cb0bc56ee637"
  raftGroupId {
    id: "\272\344\022N\343\305Dj\274;\207\357i]\274A"
  }
  callId: 19
  success: true
}
term: 1
nextIndex: 5
followerCommit: 4
matchIndex: 18446744073709551615
isHearbeat: true

2025-05-13 07:53:33,602 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-13 07:53:33,603 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-13 07:53:33,603 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown server GrpcServerProtocolService now
2025-05-13 07:53:33,602 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-87EF695DBC41: Taking a snapshot at:(t:1, i:4) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/sm/snapshot.1_4
2025-05-13 07:53:33,603 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xec5f031c, L:/0.0.0.0:15302] CLOSE
2025-05-13 07:53:33,603 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xec5f031c, L:/0.0.0.0:15302] INACTIVE
2025-05-13 07:53:33,603 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xec5f031c, L:/0.0.0.0:15302] UNREGISTERED
2025-05-13 07:53:33,602 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater: set stopIndex = 4
2025-05-13 07:53:33,604 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-87EF695DBC41: Finished taking a snapshot at:(t:1, i:4) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/sm/snapshot.1_4 took: 2 ms
2025-05-13 07:53:33,604 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater: Took a snapshot at index 4
2025-05-13 07:53:33,604 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 4
2025-05-13 07:53:33,604 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:4)
2025-05-13 07:53:33,603 [Thread-6198] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(105)) - f9ce924c-8a82-4766-a645-cb0bc56ee637 Close channels
2025-05-13 07:53:33,603 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->f9ce924c-8a82-4766-a645-cb0bc56ee637-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-05-13 07:53:33,603 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown server GrpcServerProtocolService successfully
2025-05-13 07:53:33,604 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-13 07:53:33,603 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41: shutdown
2025-05-13 07:53:33,603 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - ec402e9c-53dd-4038-962b-5490446c9ba5: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "58a412dd-7dde-4577-85ab-409f0726f062"
  replyId: "ec402e9c-53dd-4038-962b-5490446c9ba5"
  raftGroupId {
    id: "\272\344\022N\343\305Dj\274;\207\357i]\274A"
  }
  callId: 18
  success: true
}
term: 1
nextIndex: 5
followerCommit: 4
matchIndex: 18446744073709551615
isHearbeat: true

2025-05-13 07:53:33,605 [Thread-6201] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(105)) - 58a412dd-7dde-4577-85ab-409f0726f062 Close channels
2025-05-13 07:53:33,605 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-87EF695DBC41,id=ec402e9c-53dd-4038-962b-5490446c9ba5
2025-05-13 07:53:33,602 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - ec402e9c-53dd-4038-962b-5490446c9ba5: Completed APPEND_ENTRIES, lastReply: null
2025-05-13 07:53:33,605 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-13 07:53:33,605 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc88f32e4, L:/0.0.0.0:15310] CLOSE
2025-05-13 07:53:33,605 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc88f32e4, L:/0.0.0.0:15310] INACTIVE
2025-05-13 07:53:33,605 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc88f32e4, L:/0.0.0.0:15310] UNREGISTERED
2025-05-13 07:53:33,605 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-13 07:53:33,605 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown server GrpcServerProtocolService now
2025-05-13 07:53:33,606 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->f9ce924c-8a82-4766-a645-cb0bc56ee637-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-05-13 07:53:33,606 [grpc-default-executor-1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(230)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->f9ce924c-8a82-4766-a645-cb0bc56ee637-GrpcLogAppender: Failed to getClient for f9ce924c-8a82-4766-a645-cb0bc56ee637
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 58a412dd-7dde-4577-85ab-409f0726f062 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:67)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:124)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:200)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:205)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:64)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:551)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-13 07:53:33,605 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState
2025-05-13 07:53:33,606 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-87EF695DBC41: Taking a snapshot at:(t:1, i:4) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/sm/snapshot.1_4
2025-05-13 07:53:33,607 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater: set stopIndex = 4
2025-05-13 07:53:33,607 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-FollowerState was interrupted
2025-05-13 07:53:33,607 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->ec402e9c-53dd-4038-962b-5490446c9ba5-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-05-13 07:53:33,607 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(230)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->ec402e9c-53dd-4038-962b-5490446c9ba5-GrpcLogAppender: Failed to getClient for ec402e9c-53dd-4038-962b-5490446c9ba5
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 58a412dd-7dde-4577-85ab-409f0726f062 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:67)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:124)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:200)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:205)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:64)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:551)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-13 07:53:33,604 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(230)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->f9ce924c-8a82-4766-a645-cb0bc56ee637-GrpcLogAppender: Failed to getClient for f9ce924c-8a82-4766-a645-cb0bc56ee637
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 58a412dd-7dde-4577-85ab-409f0726f062 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:67)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:124)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:200)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:205)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:64)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:551)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:489)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:453)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:486)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-13 07:53:33,604 [58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:33,607 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown server GrpcServerProtocolService successfully
2025-05-13 07:53:33,607 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-13 07:53:33,606 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->ec402e9c-53dd-4038-962b-5490446c9ba5-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-05-13 07:53:33,607 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-13 07:53:33,608 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown server GrpcServerProtocolService now
2025-05-13 07:53:33,608 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-87EF695DBC41: Finished taking a snapshot at:(t:1, i:4) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/sm/snapshot.1_4 took: 1 ms
2025-05-13 07:53:33,607 [grpc-default-executor-4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(230)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41->ec402e9c-53dd-4038-962b-5490446c9ba5-GrpcLogAppender: Failed to getClient for ec402e9c-53dd-4038-962b-5490446c9ba5
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 58a412dd-7dde-4577-85ab-409f0726f062 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:67)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:124)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:200)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:205)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:64)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:551)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:489)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:453)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:486)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-13 07:53:33,608 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater: Took a snapshot at index 4
2025-05-13 07:53:33,608 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 4
2025-05-13 07:53:33,608 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown server GrpcServerProtocolService successfully
2025-05-13 07:53:33,608 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-13 07:53:33,608 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:4)
2025-05-13 07:53:33,608 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - ec402e9c-53dd-4038-962b-5490446c9ba5: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-13 07:53:33,609 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 58a412dd-7dde-4577-85ab-409f0726f062: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-13 07:53:33,609 [ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:33,619 [ec402e9c-53dd-4038-962b-5490446c9ba5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3a317e2d, L:/0.0.0.0:15286] CLOSE
2025-05-13 07:53:33,619 [ec402e9c-53dd-4038-962b-5490446c9ba5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3a317e2d, L:/0.0.0.0:15286] INACTIVE
2025-05-13 07:53:33,619 [ec402e9c-53dd-4038-962b-5490446c9ba5-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3a317e2d, L:/0.0.0.0:15286] UNREGISTERED
2025-05-13 07:53:33,620 [58a412dd-7dde-4577-85ab-409f0726f062-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf5cfeae4, L:/0.0.0.0:15294] CLOSE
2025-05-13 07:53:33,620 [58a412dd-7dde-4577-85ab-409f0726f062-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf5cfeae4, L:/0.0.0.0:15294] INACTIVE
2025-05-13 07:53:33,620 [58a412dd-7dde-4577-85ab-409f0726f062-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf5cfeae4, L:/0.0.0.0:15294] UNREGISTERED
2025-05-13 07:53:33,734 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:33,780 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-0B35A1ACBC3F-SegmentedRaftLogWorker close()
2025-05-13 07:53:33,780 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-0B35A1ACBC3F is closed by HddsDatanodeService
2025-05-13 07:53:33,884 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - c5c2c3e6-bcf8-419e-a6b9-9661d5f86301@group-EC4769D0C27C-SegmentedRaftLogWorker close()
2025-05-13 07:53:33,884 [c5c2c3e6-bcf8-419e-a6b9-9661d5f86301-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-EC4769D0C27C is closed by HddsDatanodeService
2025-05-13 07:53:33,884 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-c5c2c3e6-bcf8-419e-a6b9-9661d5f86301: Stopped
2025-05-13 07:53:33,967 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2025-05-13 07:53:34,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:34,214 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95@group-EBD73F383DEE-SegmentedRaftLogWorker close()
2025-05-13 07:53:34,214 [3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-EBD73F383DEE is closed by HddsDatanodeService
2025-05-13 07:53:34,214 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95: Stopped
2025-05-13 07:53:34,546 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-E9394498D2B5-SegmentedRaftLogWorker close()
2025-05-13 07:53:34,547 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-E9394498D2B5 is closed by HddsDatanodeService
2025-05-13 07:53:34,571 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 58a412dd-7dde-4577-85ab-409f0726f062@group-87EF695DBC41-SegmentedRaftLogWorker close()
2025-05-13 07:53:34,571 [58a412dd-7dde-4577-85ab-409f0726f062-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-87EF695DBC41 is closed by HddsDatanodeService
2025-05-13 07:53:34,572 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-58a412dd-7dde-4577-85ab-409f0726f062: Stopped
2025-05-13 07:53:34,575 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - ec402e9c-53dd-4038-962b-5490446c9ba5@group-87EF695DBC41-SegmentedRaftLogWorker close()
2025-05-13 07:53:34,575 [ec402e9c-53dd-4038-962b-5490446c9ba5-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-87EF695DBC41 is closed by HddsDatanodeService
2025-05-13 07:53:34,575 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-ec402e9c-53dd-4038-962b-5490446c9ba5: Stopped
2025-05-13 07:53:34,738 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:35,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-13 07:53:35,248 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:35,248 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 14 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 14.
2025-05-13 07:53:35,742 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:35,826 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f, PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41]
2025-05-13 07:53:35,826 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f, PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41]
2025-05-13 07:53:35,827 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f moved to CLOSED state
2025-05-13 07:53:35,828 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(487)) - Container #1 closed for pipeline=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41
2025-05-13 07:53:35,828 [Recon-EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2025-05-13 07:53:35,828 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 moved to CLOSED state
2025-05-13 07:53:35,828 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode 58a412dd-7dde-4577-85ab-409f0726f062.
2025-05-13 07:53:35,828 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f moved to CLOSED state
2025-05-13 07:53:35,829 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode ec402e9c-53dd-4038-962b-5490446c9ba5.
2025-05-13 07:53:35,829 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode f9ce924c-8a82-4766-a645-cb0bc56ee637.
2025-05-13 07:53:35,830 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(487)) - Container #1 closed for pipeline=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41
2025-05-13 07:53:35,830 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2025-05-13 07:53:35,831 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 moved to CLOSED state
2025-05-13 07:53:35,833 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-13 07:53:35,833 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f already exists in Recon pipeline metadata.
2025-05-13 07:53:35,833 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c already exists in Recon pipeline metadata.
2025-05-13 07:53:35,833 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee already exists in Recon pipeline metadata.
2025-05-13 07:53:35,834 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 already exists in Recon pipeline metadata.
2025-05-13 07:53:35,834 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 already exists in Recon pipeline metadata.
2025-05-13 07:53:35,834 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 already exists in Recon pipeline metadata.
2025-05-13 07:53:35,887 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-65099b77-335d-4459-bc5a-9fdc99e265ad/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-fc6588da-94fa-4a90-b0e0-c6affa498b89/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-07967212-7d7e-4d65-bb55-689238937a7d/container.db]
2025-05-13 07:53:35,888 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-fc6588da-94fa-4a90-b0e0-c6affa498b89/container.db from cache
2025-05-13 07:53:35,888 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-4/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-fc6588da-94fa-4a90-b0e0-c6affa498b89/container.db for volume DS-fc6588da-94fa-4a90-b0e0-c6affa498b89
2025-05-13 07:53:35,888 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-13 07:53:35,888 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-13 07:53:35,889 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-13 07:53:35,901 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4072118a{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:35,901 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@44cbf958{HTTP/1.1, (http/1.1)}{0.0.0.0:15296}
2025-05-13 07:53:35,901 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-13 07:53:35,901 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@18ba312f{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-13 07:53:35,901 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@55708d47{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-13 07:53:35,902 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-13 07:53:35,902 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15297
2025-05-13 07:53:35,903 [IPC Server listener on 15297] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15297
2025-05-13 07:53:35,903 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:35,905 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-13 07:53:35,905 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:35,905 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@1da95983 exiting.
2025-05-13 07:53:35,905 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds) is shutting down. 
2025-05-13 07:53:35,905 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-13 07:53:35,905 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds, DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b) exiting.
2025-05-13 07:53:35,906 [ForkJoinPool.commonPool-worker-2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(f9ce924c-8a82-4766-a645-cb0bc56ee637)
2025-05-13 07:53:35,906 [ForkJoinPool.commonPool-worker-2] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: close
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3: shutdown
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A74D4160E7F3,id=f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:35,906 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-LeaderStateImpl
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-PendingRequests: sendNotLeaderResponses
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41: shutdown
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-87EF695DBC41,id=f9ce924c-8a82-4766-a645-cb0bc56ee637
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater: set stopIndex = 4
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-FollowerState was interrupted
2025-05-13 07:53:35,906 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-87EF695DBC41: Taking a snapshot at:(t:1, i:4) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/sm/snapshot.1_4
2025-05-13 07:53:35,907 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-13 07:53:35,907 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown server GrpcServerProtocolService now
2025-05-13 07:53:35,907 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown server GrpcServerProtocolService successfully
2025-05-13 07:53:35,907 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-13 07:53:35,907 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - f9ce924c-8a82-4766-a645-cb0bc56ee637: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-13 07:53:35,907 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater: set stopIndex = 0
2025-05-13 07:53:35,908 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-87EF695DBC41: Finished taking a snapshot at:(t:1, i:4) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/bae4124e-e3c5-446a-bc3b-87ef695dbc41/sm/snapshot.1_4 took: 1 ms
2025-05-13 07:53:35,907 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-A74D4160E7F3: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/99ccdf66-83a1-4834-ac9d-a74d4160e7f3/sm/snapshot.1_0
2025-05-13 07:53:35,908 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater: Took a snapshot at index 4
2025-05-13 07:53:35,908 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 4
2025-05-13 07:53:35,908 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:4)
2025-05-13 07:53:35,908 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-A74D4160E7F3: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/ratis/99ccdf66-83a1-4834-ac9d-a74d4160e7f3/sm/snapshot.1_0 took: 1 ms
2025-05-13 07:53:35,908 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater: Took a snapshot at index 0
2025-05-13 07:53:35,908 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-13 07:53:35,909 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-13 07:53:35,909 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:35,909 [f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:35,911 [f9ce924c-8a82-4766-a645-cb0bc56ee637-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd39b8599, L:/0.0.0.0:15278] CLOSE
2025-05-13 07:53:35,912 [f9ce924c-8a82-4766-a645-cb0bc56ee637-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd39b8599, L:/0.0.0.0:15278] INACTIVE
2025-05-13 07:53:35,912 [f9ce924c-8a82-4766-a645-cb0bc56ee637-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd39b8599, L:/0.0.0.0:15278] UNREGISTERED
2025-05-13 07:53:35,926 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode c5c2c3e6-bcf8-419e-a6b9-9661d5f86301(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c]
2025-05-13 07:53:35,926 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode c5c2c3e6-bcf8-419e-a6b9-9661d5f86301(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c]
2025-05-13 07:53:35,927 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c moved to CLOSED state
2025-05-13 07:53:35,927 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c moved to CLOSED state
2025-05-13 07:53:35,930 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-13 07:53:35,930 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f already exists in Recon pipeline metadata.
2025-05-13 07:53:35,930 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c already exists in Recon pipeline metadata.
2025-05-13 07:53:35,930 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee already exists in Recon pipeline metadata.
2025-05-13 07:53:35,931 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 already exists in Recon pipeline metadata.
2025-05-13 07:53:35,931 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 already exists in Recon pipeline metadata.
2025-05-13 07:53:35,931 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 already exists in Recon pipeline metadata.
2025-05-13 07:53:35,972 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 8 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 8.
2025-05-13 07:53:36,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1) with datanode deadline 1747123176163 and scm deadline 1747123536163
2025-05-13 07:53:36,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1) with datanode deadline 1747123176163 and scm deadline 1747123536163
2025-05-13 07:53:36,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1) with datanode deadline 1747123176163 and scm deadline 1747123536163
2025-05-13 07:53:36,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:36,216 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-65099b77-335d-4459-bc5a-9fdc99e265ad/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-07967212-7d7e-4d65-bb55-689238937a7d/container.db]
2025-05-13 07:53:36,217 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-07967212-7d7e-4d65-bb55-689238937a7d/container.db from cache
2025-05-13 07:53:36,217 [ForkJoinPool.commonPool-worker-3] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-5/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-07967212-7d7e-4d65-bb55-689238937a7d/container.db for volume DS-07967212-7d7e-4d65-bb55-689238937a7d
2025-05-13 07:53:36,217 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-13 07:53:36,218 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-13 07:53:36,219 [ForkJoinPool.commonPool-worker-3] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-13 07:53:36,226 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee]
2025-05-13 07:53:36,226 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode 3da2ba28-06c1-4dfa-9ae4-8e0db8e99f95(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee]
2025-05-13 07:53:36,227 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee moved to CLOSED state
2025-05-13 07:53:36,228 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee moved to CLOSED state
2025-05-13 07:53:36,231 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-13 07:53:36,231 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f already exists in Recon pipeline metadata.
2025-05-13 07:53:36,231 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c already exists in Recon pipeline metadata.
2025-05-13 07:53:36,231 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee already exists in Recon pipeline metadata.
2025-05-13 07:53:36,231 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 already exists in Recon pipeline metadata.
2025-05-13 07:53:36,232 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 already exists in Recon pipeline metadata.
2025-05-13 07:53:36,232 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 already exists in Recon pipeline metadata.
2025-05-13 07:53:36,232 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@cd4caf7{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:36,232 [ForkJoinPool.commonPool-worker-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@61e53cc0{HTTP/1.1, (http/1.1)}{0.0.0.0:15304}
2025-05-13 07:53:36,233 [ForkJoinPool.commonPool-worker-3] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-13 07:53:36,233 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@48ac2530{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-13 07:53:36,233 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5b6aa97c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-13 07:53:36,234 [ForkJoinPool.commonPool-worker-3] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-13 07:53:36,234 [ForkJoinPool.commonPool-worker-3] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15305
2025-05-13 07:53:36,235 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:36,235 [IPC Server listener on 15305] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15305
2025-05-13 07:53:36,354 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-A74D4160E7F3-SegmentedRaftLogWorker close()
2025-05-13 07:53:36,354 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-A74D4160E7F3 is closed by HddsDatanodeService
2025-05-13 07:53:36,573 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - f9ce924c-8a82-4766-a645-cb0bc56ee637@group-87EF695DBC41-SegmentedRaftLogWorker close()
2025-05-13 07:53:36,574 [f9ce924c-8a82-4766-a645-cb0bc56ee637-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-87EF695DBC41 is closed by HddsDatanodeService
2025-05-13 07:53:36,574 [JvmPauseMonitor49] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-f9ce924c-8a82-4766-a645-cb0bc56ee637: Stopped
2025-05-13 07:53:36,574 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-65099b77-335d-4459-bc5a-9fdc99e265ad/container.db]
2025-05-13 07:53:36,576 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-65099b77-335d-4459-bc5a-9fdc99e265ad/container.db from cache
2025-05-13 07:53:36,576 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-3/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-65099b77-335d-4459-bc5a-9fdc99e265ad/container.db for volume DS-65099b77-335d-4459-bc5a-9fdc99e265ad
2025-05-13 07:53:36,576 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-13 07:53:36,576 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-13 07:53:36,577 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69/container.db]
2025-05-13 07:53:36,577 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-13 07:53:36,578 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69/container.db from cache
2025-05-13 07:53:36,578 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-2/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69/container.db for volume DS-2778a05f-37f4-4b6e-997e-4c2a4c573e69
2025-05-13 07:53:36,578 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-13 07:53:36,579 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-13 07:53:36,580 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-13 07:53:36,592 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7fb91def{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:36,593 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4ea73ad2{HTTP/1.1, (http/1.1)}{0.0.0.0:15288}
2025-05-13 07:53:36,593 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-13 07:53:36,593 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@31ad63c0{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-13 07:53:36,593 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7fcb9e8e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-13 07:53:36,594 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-13 07:53:36,594 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15289
2025-05-13 07:53:36,595 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@26368716{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:36,595 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@47f125f7{HTTP/1.1, (http/1.1)}{0.0.0.0:15280}
2025-05-13 07:53:36,595 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-13 07:53:36,595 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3d418e71{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-13 07:53:36,596 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@22f6ece6{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-13 07:53:36,596 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-13 07:53:36,596 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15281
2025-05-13 07:53:36,596 [IPC Server listener on 15289] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15289
2025-05-13 07:53:36,596 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:36,598 [IPC Server listener on 15281] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15281
2025-05-13 07:53:36,598 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:36,626 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5, PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41]
2025-05-13 07:53:36,626 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5, PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41]
2025-05-13 07:53:36,627 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 moved to CLOSED state
2025-05-13 07:53:36,628 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 moved to CLOSED state
2025-05-13 07:53:36,630 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-13 07:53:36,630 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f already exists in Recon pipeline metadata.
2025-05-13 07:53:36,630 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c already exists in Recon pipeline metadata.
2025-05-13 07:53:36,630 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee already exists in Recon pipeline metadata.
2025-05-13 07:53:36,631 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 already exists in Recon pipeline metadata.
2025-05-13 07:53:36,631 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 already exists in Recon pipeline metadata.
2025-05-13 07:53:36,631 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 already exists in Recon pipeline metadata.
2025-05-13 07:53:36,745 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:37,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1) with datanode deadline 1747123177164 and scm deadline 1747123537164
2025-05-13 07:53:37,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1) with datanode deadline 1747123177164 and scm deadline 1747123537164
2025-05-13 07:53:37,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1) with datanode deadline 1747123177164 and scm deadline 1747123537164
2025-05-13 07:53:37,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-13 07:53:37,249 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1670 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-13 07:53:37,249 [Recon-SyncSCMContainerInfo-0] ERROR scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:syncWithSCMContainerInfo(583)) - Unable to refresh Recon SCM DB Snapshot. 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:872)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1588)
	at org.apache.hadoop.ipc.Client.call(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1426)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getContainerCount(StorageContainerLocationProtocolClientSideTranslatorPB.java:1170)
	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getContainerCount(StorageContainerServiceProviderImpl.java:127)
	at org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade.syncWithSCMContainerInfo(ReconStorageContainerManagerFacade.java:542)
	at org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade.lambda$start$0(ReconStorageContainerManagerFacade.java:419)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:668)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:789)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:364)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1649)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	... 24 more
2025-05-13 07:53:37,748 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:37,973 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 9 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 9.
2025-05-13 07:53:38,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1) with datanode deadline 1747123178164 and scm deadline 1747123538164
2025-05-13 07:53:38,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1) with datanode deadline 1747123178164 and scm deadline 1747123538164
2025-05-13 07:53:38,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-13T07:53:35.829858130Z, pipelineID=PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41, owner=omServiceIdDefault} to 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1) with datanode deadline 1747123178165 and scm deadline 1747123538165
2025-05-13 07:53:38,165 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-13 07:53:38,577 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db]
2025-05-13 07:53:38,578 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db from cache
2025-05-13 07:53:38,578 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/ozone-meta/datanode-1/data-0/hdds/01ec88a1-3fd2-489c-9e5a-a61bb3107d3c/DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b/container.db for volume DS-6ced98b2-3d09-4b3b-83dc-97b38afe9b7b
2025-05-13 07:53:38,578 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-13 07:53:38,579 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-13 07:53:38,580 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-13 07:53:38,593 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5afa7ea1{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-13 07:53:38,593 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5d707a77{HTTP/1.1, (http/1.1)}{0.0.0.0:15272}
2025-05-13 07:53:38,593 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-13 07:53:38,593 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4eaa0a21{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-13 07:53:38,593 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4ba28206{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-13 07:53:38,593 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-13 07:53:38,593 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15273
2025-05-13 07:53:38,595 [IPC Server listener on 15273] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15273
2025-05-13 07:53:38,595 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:38,595 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(491)) - Stopping the StorageContainerManager
2025-05-13 07:53:38,595 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1608)) - Container Balancer is not running.
2025-05-13 07:53:38,595 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1742)) - Stopping Replication Manager Service.
2025-05-13 07:53:38,595 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(316)) - Stopping Replication Monitor Thread.
2025-05-13 07:53:38,595 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1617)) - Stopping the Datanode Admin Monitor.
2025-05-13 07:53:38,595 [OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - OverReplicatedProcessor interrupted. Exiting...
2025-05-13 07:53:38,595 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1624)) - Stopping datanode service RPC server
2025-05-13 07:53:38,596 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(447)) - Stopping the RPC server for DataNodes
2025-05-13 07:53:38,596 [UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - UnderReplicatedProcessor interrupted. Exiting...
2025-05-13 07:53:38,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(936)) - Replication Monitor Thread is stopped
2025-05-13 07:53:38,596 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15262
2025-05-13 07:53:38,599 [IPC Server listener on 15262] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15262
2025-05-13 07:53:38,599 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:38,628 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3, PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41]
2025-05-13 07:53:38,628 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3, PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41]
2025-05-13 07:53:38,628 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(909)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-05-13 07:53:38,628 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1632)) - Stopping block service RPC server
2025-05-13 07:53:38,628 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(175)) - Stopping the RPC server for Block Protocol
2025-05-13 07:53:38,629 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15261
2025-05-13 07:53:38,629 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 moved to CLOSED state
2025-05-13 07:53:38,632 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 moved to CLOSED state
2025-05-13 07:53:38,633 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-13 07:53:38,633 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=0aac6914-0c49-425d-8e28-0b35a1acbc3f already exists in Recon pipeline metadata.
2025-05-13 07:53:38,633 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=5c4c35a5-2c65-4d4d-8f1e-ec4769d0c27c already exists in Recon pipeline metadata.
2025-05-13 07:53:38,634 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=6225616f-efd8-4e48-8f52-ebd73f383dee already exists in Recon pipeline metadata.
2025-05-13 07:53:38,634 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=3d57c6b2-0bc2-4f29-b761-e9394498d2b5 already exists in Recon pipeline metadata.
2025-05-13 07:53:38,634 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=99ccdf66-83a1-4834-ac9d-a74d4160e7f3 already exists in Recon pipeline metadata.
2025-05-13 07:53:38,634 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=bae4124e-e3c5-446a-bc3b-87ef695dbc41 already exists in Recon pipeline metadata.
2025-05-13 07:53:38,636 [IPC Server listener on 15261] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15261
2025-05-13 07:53:38,636 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:38,636 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1639)) - Stopping the StorageContainerLocationProtocol RPC server
2025-05-13 07:53:38,637 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(216)) - Stopping the RPC server for Client Protocol
2025-05-13 07:53:38,637 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15260
2025-05-13 07:53:38,641 [IPC Server listener on 15260] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15260
2025-05-13 07:53:38,641 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1646)) - Stopping Storage Container Manager HTTP server.
2025-05-13 07:53:38,641 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:38,641 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7ea95d85{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-05-13 07:53:38,642 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@46870b92{HTTP/1.1, (http/1.1)}{0.0.0.0:15263}
2025-05-13 07:53:38,643 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-13 07:53:38,643 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@587d34b7{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-05-13 07:53:38,643 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@72031e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-13 07:53:38,644 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1654)) - Stopping SCM LayoutVersionManager Service.
2025-05-13 07:53:38,644 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1666)) - Stopping Block Manager Service.
2025-05-13 07:53:38,644 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2025-05-13 07:53:38,644 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2025-05-13 07:53:38,645 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1691)) - Stopping SCM Event Queue.
2025-05-13 07:53:38,645 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1698)) - Stopping SCM HA services.
2025-05-13 07:53:38,645 [main] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:stop(266)) - stopping ratis server 0.0.0.0:15264
2025-05-13 07:53:38,646 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - 22a047fb-99fa-46e1-9d16-532806e028b1: close
2025-05-13 07:53:38,646 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown server GrpcServerProtocolService now
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C: shutdown
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A61BB3107D3C,id=22a047fb-99fa-46e1-9d16-532806e028b1
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderStateImpl
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-PendingRequests: sendNotLeaderResponses
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyNotLeader(211)) - current leader SCM steps down.
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(95)) - update <isLeader,term> from <true,2> to <false,0>
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(101)) - update <isLeaderReady> from <true> to <false>
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(84)) - Service BackgroundPipelineScrubber transitions to PAUSING.
2025-05-13 07:53:38,646 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(84)) - Service ExpiredContainerReplicaOpScrubber transitions to PAUSING.
2025-05-13 07:53:38,647 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:notifyStatusChanged(84)) - Service SCMHATransactionMonitor transitions to PAUSING.
2025-05-13 07:53:38,647 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater: set stopIndex = 48
2025-05-13 07:53:38,647 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:takeSnapshot(330)) - Current Snapshot Index 48, takeSnapshot took 0 ms
2025-05-13 07:53:38,647 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater: Took a snapshot at index 48
2025-05-13 07:53:38,647 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 48
2025-05-13 07:53:38,648 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:2, i:48)
2025-05-13 07:53:38,648 [22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-13 07:53:38,651 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 22a047fb-99fa-46e1-9d16-532806e028b1: shutdown server GrpcServerProtocolService successfully
2025-05-13 07:53:38,751 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-13 07:53:38,828 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1)
2025-05-13 07:53:38,829 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: 0aac6914-0c49-425d-8e28-0b35a1acbc3f, Nodes: [ {58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:58a412dd-7dde-4577-85ab-409f0726f062, CreationTimestamp2025-05-13T07:53:09.121Z[Etc/UTC]} removed.
2025-05-13 07:53:38,829 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: bae4124e-e3c5-446a-bc3b-87ef695dbc41, Nodes: [ {58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1), ReplicaIndex: 0}, {ec402e9c-53dd-4038-962b-5490446c9ba5(localhost/127.0.0.1), ReplicaIndex: 0}, {f9ce924c-8a82-4766-a645-cb0bc56ee637(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:58a412dd-7dde-4577-85ab-409f0726f062, CreationTimestamp2025-05-13T07:53:09.123Z[Etc/UTC]} removed.
2025-05-13 07:53:38,830 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 0 for DN 58a412dd-7dde-4577-85ab-409f0726f062(localhost/127.0.0.1)
2025-05-13 07:53:38,830 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/58a412dd-7dde-4577-85ab-409f0726f062
2025-05-13 07:53:38,830 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "pkrvmberfyhpb9w/10.1.0.219"; destination host is: "0.0.0.0":15260; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15260. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-13 07:53:39,633 [22a047fb-99fa-46e1-9d16-532806e028b1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-SegmentedRaftLogWorker close()
2025-05-13 07:53:39,634 [JvmPauseMonitor46] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-22a047fb-99fa-46e1-9d16-532806e028b1: Stopped
2025-05-13 07:53:39,635 [main] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(127)) - Stopping SCMHATransactionMonitor Service.
2025-05-13 07:53:39,635 [SCMHATransactionMonitor] WARN  SCMHATransactionMonitor (BackgroundSCMService.java:run(111)) - SCMHATransactionMonitor is interrupted, exit
2025-05-13 07:53:39,635 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping RatisPipelineUtilsThread.
2025-05-13 07:53:39,635 [RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - RatisPipelineUtilsThread is interrupted.
2025-05-13 07:53:39,635 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(127)) - Stopping BackgroundPipelineScrubber Service.
2025-05-13 07:53:39,635 [BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(111)) - BackgroundPipelineScrubber is interrupted, exit
2025-05-13 07:53:39,636 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2025-05-13 07:53:39,637 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2025-05-13 07:53:39,637 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2025-05-13 07:53:39,637 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - RatisPipelineUtilsThread is not running, just ignore.
2025-05-13 07:53:39,637 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(122)) - BackgroundPipelineScrubber Service is not running, skip stop.
2025-05-13 07:53:39,637 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(127)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2025-05-13 07:53:39,638 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2025-05-13 07:53:39,637 [ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(111)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2025-05-13 07:53:39,638 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(323)) - Replication Monitor Thread is not running.
2025-05-13 07:53:39,638 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(350)) - Cannot stop Container Balancer because it's not running or stopping
2025-05-13 07:53:39,638 [main] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(122)) - SCMHATransactionMonitor Service is not running, skip stop.
2025-05-13 07:53:39,638 [LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(285)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1133)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:283)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-13 07:53:39,638 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1733)) - Stopping SCM MetadataStore.
2025-05-13 07:53:39,640 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopRecon(506)) - Stopping Recon
2025-05-13 07:53:39,640 [main] INFO  recon.ReconServer (ReconServer.java:stop(262)) - Stopping Recon server
2025-05-13 07:53:39,642 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@6b031452{recon,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar!/webapps/recon}
2025-05-13 07:53:39,642 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@53e5a795{HTTP/1.1, (http/1.1)}{0.0.0.0:15270}
2025-05-13 07:53:39,642 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-13 07:53:39,642 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@258741ff{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-13 07:53:39,642 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3f21b0fb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-13 07:53:39,643 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(447)) - Stopping the RPC server for DataNodes
2025-05-13 07:53:39,643 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15271
2025-05-13 07:53:39,646 [IPC Server listener on 15271] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15271
2025-05-13 07:53:39,646 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-13 07:53:39,729 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(909)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-05-13 07:53:39,729 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(63)) - Stopping ContainerSizeCountTask Thread.
2025-05-13 07:53:39,729 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(63)) - Stopping ContainerHealthTask Thread.
2025-05-13 07:53:39,729 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(63)) - Stopping PipelineSyncTask Thread.
2025-05-13 07:53:39,729 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(460)) - Stopping SCM Event Queue.
2025-05-13 07:53:39,730 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(468)) - Flushing container replica history to DB.
2025-05-13 07:53:39,732 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:stop(364)) - Stopping Ozone Manager Service Provider.
2025-05-13 07:53:39,732 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:stop(247)) - Stopping Recon Task Controller.
2025-05-13 07:53:39,732 [main] INFO  recon.ReconServer (ReconServer.java:stop(287)) - Closing Recon Container Key DB.
2025-05-13 07:53:39,732 [ContainerSizeCountTask] INFO  updater.ReconTaskStatusUpdater (ReconTaskStatusUpdater.java:updateDetails(124)) - Registered Task: ContainerSizeCountTask
2025-05-13 07:53:39,734 [JvmPauseMonitor48] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-Recon: Stopped
====> TestReconAndAdminContainerCLI TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2025-05-13 07:53:39,812

"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=6076 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"MutableQuantiles-0" daemon prio=5 tid=668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Notification Thread" daemon prio=9 tid=22 runnable
java.lang.Thread.State: RUNNABLE
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=3857 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=1847 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer6" daemon prio=5 tid=1112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=2451 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer1" daemon prio=5 tid=1080 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=3162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=5309 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-shared-destroyer-0" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer4" daemon prio=5 tid=1085 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15271" daemon prio=5 tid=7938 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:613)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1121)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=5310 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Finalizer" daemon prio=8 tid=10 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:339)
        at java.base@21.0.7/java.lang.ref.NativeReferenceQueue.await(NativeReferenceQueue.java:48)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:158)
        at java.base@21.0.7/java.lang.ref.NativeReferenceQueue.remove(NativeReferenceQueue.java:89)
        at java.base@21.0.7/java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:173)
"PipelineSyncTask" daemon prio=5 tid=662 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007ff6e0bd9930.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-2" daemon prio=5 tid=1079 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Reference Handler" daemon prio=10 tid=9 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.7/java.lang.ref.Reference.waitForReferencePendingList(Native Method)
        at java.base@21.0.7/java.lang.ref.Reference.processPendingReferences(Reference.java:246)
        at java.base@21.0.7/java.lang.ref.Reference$ReferenceHandler.run(Reference.java:208)
"LeakDetector-OzoneClientObject1" daemon prio=5 tid=1097 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.await(ReferenceQueue.java:67)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:158)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:234)
        at app//org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:79)
        at app//org.apache.hadoop.hdds.utils.LeakDetector$$Lambda/0x00007ff6e0444bf0.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer3" daemon prio=5 tid=1084 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"ForkJoinPool.commonPool-worker-2" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkUntil(LockSupport.java:449)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1891)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.7/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=1770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=43 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=6153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=8225 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer5" daemon prio=5 tid=1109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=4609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=7644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=25 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.7/java.io.FileInputStream.readBytes(Native Method)
        at java.base@21.0.7/java.io.FileInputStream.read(FileInputStream.java:287)
        at java.base@21.0.7/java.io.BufferedInputStream.read1(BufferedInputStream.java:345)
        at java.base@21.0.7/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)
        at java.base@21.0.7/java.io.BufferedInputStream.read(BufferedInputStream.java:399)
        at java.base@21.0.7/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)
        at java.base@21.0.7/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)
        at java.base@21.0.7/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)
        at java.base@21.0.7/java.io.BufferedInputStream.read(BufferedInputStream.java:399)
        at app//org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:169)
        at app//org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:50)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.read(AbstractStreamDecoder.java:430)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.read(AbstractStreamDecoder.java:419)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.readMessageType(AbstractStreamDecoder.java:116)
        at app//org.apache.maven.surefire.booter.stream.CommandDecoder.decode(CommandDecoder.java:77)
        at app//org.apache.maven.surefire.booter.spi.CommandChannelDecoder.decode(CommandChannelDecoder.java:60)
        at app//org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:290)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=7527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-stream-flusher" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Common-Cleaner" daemon prio=8 tid=17 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1852)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.await(ReferenceQueue.java:71)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:143)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:218)
        at java.base@21.0.7/jdk.internal.ref.CleanerImpl.run(CleanerImpl.java:140)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
        at java.base@21.0.7/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:186)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15260" daemon prio=5 tid=8498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:613)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1121)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"LeakDetector-ManagedRocksObject0" daemon prio=5 tid=49 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.await(ReferenceQueue.java:67)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:158)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:234)
        at app//org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:79)
        at app//org.apache.hadoop.hdds.utils.LeakDetector$$Lambda/0x00007ff6e0444bf0.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=3856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=6791 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"gradle-enterprise-test-client-gradle-enterprise-test-listener"  prio=5 tid=31 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:420)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.a(SourceFile:130)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.b(SourceFile:93)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a$$Lambda/0x00007ff6e01299f8.run(Unknown Source)
        at java.base@21.0.7/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
        at java.base@21.0.7/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Timer-1" daemon prio=5 tid=517 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:339)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:537)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=8214 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"process reaper" daemon prio=10 tid=29 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
        at java.base@21.0.7/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:186)
"PipelineSyncTask" daemon prio=5 tid=6334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007ff6e0bd9930.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=7528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=6077 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool.commonPool-worker-1" daemon prio=5 tid=35 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.7/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=6780 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=8215 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=4685 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=1027 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:193)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:304)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:368)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=7604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=7775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007ff6e0bd9930.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=6195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=3407 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007ff6e0bd9930.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=1029 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=3161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=2441 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"22a047fb-99fa-46e1-9d16-532806e028b1@group-A61BB3107D3C-LeaderStateImpl" daemon prio=5 tid=7422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:763)
"IPC Client (751285821) connection to 0.0.0.0/0.0.0.0:15262 from runner" daemon prio=5 tid=7939 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1042)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1093)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=3845 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-EventQueue-DeadNodeForReconDeadNodeHandler" daemon prio=5 tid=7113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:135)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:112)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
        at app/jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
        at app//org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor$$Lambda/0x00007ff6e0c74068.run(Unknown Source)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=1105 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer7" daemon prio=5 tid=1113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=6781 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-worker-ELG-3-4" daemon prio=5 tid=1031 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=5322 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-worker-ELG-3-3" daemon prio=5 tid=1030 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-5" daemon prio=5 tid=5493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer0" daemon prio=5 tid=1114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"pool-1063-thread-1"  prio=5 tid=7110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=2005 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007ff6e0bd9930.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"surefire-process-checker" daemon prio=5 tid=26 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=1106 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=3280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=4866 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007ff6e0bd9930.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=2452 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=1123 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-4" daemon prio=5 tid=2409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=8226 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-3" daemon prio=5 tid=1088 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=6794 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15262" daemon prio=5 tid=7940 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:613)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1121)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer2" daemon prio=5 tid=1081 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=2440 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool.commonPool-worker-3" daemon prio=5 tid=447 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.7/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"Signal Dispatcher" daemon prio=9 tid=11 runnable
java.lang.Thread.State: RUNNABLE
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=4725 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.7/java.lang.Thread.dumpThreads(Native Method)
        at java.base@21.0.7/java.lang.Thread.getAllStackTraces(Thread.java:2522)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:81)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:67)
        at app//org.apache.ozone.test.TimedOutTestsListener.lambda$executionFinished$0(TimedOutTestsListener.java:53)
        at app//org.apache.ozone.test.TimedOutTestsListener$$Lambda/0x00007ff6e0f147d0.accept(Unknown Source)
        at java.base@21.0.7/java.util.Optional.ifPresent(Optional.java:178)
        at app//org.apache.ozone.test.TimedOutTestsListener.executionFinished(TimedOutTestsListener.java:49)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$executionFinished$10(CompositeTestExecutionListener.java:74)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda/0x00007ff6e0f11348.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$notifyEach$21(CompositeTestExecutionListener.java:110)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda/0x00007ff6e0121660.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:243)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.notifyEach(CompositeTestExecutionListener.java:108)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.executionFinished(CompositeTestExecutionListener.java:73)
        at app//org.junit.platform.launcher.core.ExecutionListenerAdapter.executionFinished(ExecutionListenerAdapter.java:57)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$executionFinished$6(CompositeEngineExecutionListener.java:60)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda/0x00007ff6e0f10000.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$notifyEach$13(CompositeEngineExecutionListener.java:82)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda/0x00007ff6e01415a8.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:243)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.notifyEach(CompositeEngineExecutionListener.java:80)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.executionFinished(CompositeEngineExecutionListener.java:59)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:47)
        at app//org.junit.platform.launcher.core.StackTracePruningEngineExecutionListener.executionFinished(StackTracePruningEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:47)
        at app//org.junit.platform.launcher.core.OutcomeDelayingEngineExecutionListener.executionFinished(OutcomeDelayingEngineExecutionListener.java:63)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion(NodeTestTask.java:200)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:105)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda/0x00007ff6e0147de0.accept(Unknown Source)
        at java.base@21.0.7/java.util.ArrayList.forEach(ArrayList.java:1596)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007ff6e0146ea8.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007ff6e0146c90.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007ff6e0146888.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda/0x00007ff6e011ba60.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
        at app//org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at app//org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39)
        at app//org.junit.platform.launcher.core.InterceptingLauncher$$Lambda/0x00007ff6e009a968.proceed(Unknown Source)
        at app//org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25)
        at app//org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38)
        at app//org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at app//org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:56)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:162)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:120)
        at app//org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
        at app//org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at app//org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
        at app//org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
"IPC Client (751285821) connection to 0.0.0.0/0.0.0.0:15271 from runner" daemon prio=5 tid=7937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1042)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1093)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=1122 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=1771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"junit-jupiter-timeout-watcher"  prio=10 tid=7120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"pool-1319-thread-1"  prio=5 tid=8544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=5323 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-EventQueue-DeadNodeForReconDeadNodeHandler" daemon prio=5 tid=8549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:135)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:112)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
        at app/jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
        at app//org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor$$Lambda/0x00007ff6e0c74068.run(Unknown Source)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=3238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-1" daemon prio=5 tid=1064 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=3846 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=4608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=1887 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)

2025-05-13 07:53:39,994 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 10 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 10.
