2025-05-12 14:15:54,424 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2025-05-12 14:15:54,424 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2025-05-12 14:15:54,424 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(138)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:54,430 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is null
2025-05-12 14:15:54,430 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(166)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-05-12 14:15:54,430 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:54,431 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-12 14:15:54,431 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:15:54,431 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15264 (fallback to raft.grpc.server.port)
2025-05-12 14:15:54,431 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:15:54,432 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15264 (fallback to raft.grpc.server.port)
2025-05-12 14:15:54,432 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-12 14:15:54,432 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15264 (custom)
2025-05-12 14:15:54,432 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 5242880 (custom)
2025-05-12 14:15:54,432 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-05-12 14:15:54,432 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-05-12 14:15:54,432 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:15:54,432 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:54,432 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-12 14:15:54,432 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-12 14:15:54,436 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2025-05-12 14:15:54,436 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:15:54,436 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-12 14:15:54,436 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:15:54,437 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha] (custom)
2025-05-12 14:15:54,437 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-12 14:15:54,437 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-12 14:15:54,439 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: addNew group-A5584FEC4A7A:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264] returns group-A5584FEC4A7A:java.util.concurrent.CompletableFuture@34d81a76[Not completed]
2025-05-12 14:15:54,439 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: new RaftServerImpl for group-A5584FEC4A7A:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264] with SCMStateMachine:uninitialized
2025-05-12 14:15:54,439 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5000ms (custom)
2025-05-12 14:15:54,439 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:15:54,439 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:15:54,439 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-05-12 14:15:54,439 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:15:54,439 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:15:54,439 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:15:54,440 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: ConfigurationManager, init=conf: {index: -1, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:15:54,440 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 60s (default)
2025-05-12 14:15:54,440 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:15:54,440 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 60000ms (default)
2025-05-12 14:15:54,440 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:15:54,440 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:15:54,440 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:15:54,440 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-05-12 14:15:54,441 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:15:54,441 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:15:54,441 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:15:54,441 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:15:54,441 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:15:54,443 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:15:54,444 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:15:54,444 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha] (custom)
2025-05-12 14:15:54,444 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a does not exist. Creating ...
2025-05-12 14:15:54,445 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:15:54,446 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a has been successfully formatted.
2025-05-12 14:15:54,446 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: initialize group-A5584FEC4A7A
2025-05-12 14:15:54,446 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:15:54,446 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:15:54,446 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:54,446 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:15:54,446 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:15:54,447 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-12 14:15:54,447 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:15:54,447 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:15:54,447 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:54,448 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#7109,fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:15:54,448 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a
2025-05-12 14:15:54,448 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-05-12 14:15:54,449 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2025-05-12 14:15:54,449 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-12 14:15:54,450 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:15:54,450 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:15:54,450 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:15:54,451 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:15:54,451 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-05-12 14:15:54,451 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2025-05-12 14:15:54,452 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:54,452 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:15:54,453 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:15:54,453 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2025-05-12 14:15:54,454 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:15:54,454 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:15:54,454 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: start as a follower, conf=conf: {index: -1, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:54,455 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:15:54,455 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: start fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState
2025-05-12 14:15:54,456 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A5584FEC4A7A,id=fe26b7a1-1f7d-4969-b43e-0bdee51a4d81
2025-05-12 14:15:54,456 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:15:54,457 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-A5584FEC4A7A,id=fe26b7a1-1f7d-4969-b43e-0bdee51a4d81
2025-05-12 14:15:54,457 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:15:54,457 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:15:54,457 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:15:54,458 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-05-12 14:15:54,458 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2025-05-12 14:15:54,458 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:15:54,457 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:15:54,459 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: Successfully started.
2025-05-12 14:15:54,459 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: start RPC server
2025-05-12 14:15:54,460 [main] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: GrpcService started, listening on 15264
2025-05-12 14:15:54,461 [JvmPauseMonitor45] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: Started
2025-05-12 14:15:55,531 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-12 14:15:55,537 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1081653250ns, electionTimeout:1079ms
2025-05-12 14:15:55,537 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState
2025-05-12 14:15:55,537 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:15:55,537 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:15:55,537 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: start fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46
2025-05-12 14:15:55,538 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:55,538 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46 PRE_VOTE round 0: result PASSED (term=0)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46 ELECTION round 0: result PASSED (term=1)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5000ms (custom)
2025-05-12 14:15:55,539 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:15:55,540 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-12 14:15:55,540 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:15:55,540 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: start fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderStateImpl
2025-05-12 14:15:55,540 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:15:55,540 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: change Leader from null to fe26b7a1-1f7d-4969-b43e-0bdee51a4d81 at term 1 for becomeLeader, leader elected after 1100ms
2025-05-12 14:15:55,540 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:15:55,540 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection46] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: set configuration conf: {index: 0, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:55,540 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:15:55,545 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a/current/log_inprogress_0
2025-05-12 14:15:55,546 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-12 14:15:56,200 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 11 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 11.
2025-05-12 14:15:56,461 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: close
2025-05-12 14:15:56,461 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown server GrpcServerProtocolService now
2025-05-12 14:15:56,461 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: shutdown
2025-05-12 14:15:56,462 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A5584FEC4A7A,id=fe26b7a1-1f7d-4969-b43e-0bdee51a4d81
2025-05-12 14:15:56,462 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderStateImpl
2025-05-12 14:15:56,462 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-PendingRequests: sendNotLeaderResponses
2025-05-12 14:15:56,462 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown server GrpcServerProtocolService successfully
2025-05-12 14:15:56,462 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater: Took a snapshot at index 0
2025-05-12 14:15:56,462 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-12 14:15:56,462 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:1, i:0)
2025-05-12 14:15:56,462 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater: set stopIndex = 0
2025-05-12 14:15:56,463 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:15:56,547 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker close()
2025-05-12 14:15:56,547 [JvmPauseMonitor45] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: Stopped
2025-05-12 14:15:56,547 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(138)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:56,548 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is null
2025-05-12 14:15:56,548 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(166)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-05-12 14:15:56,548 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:56,548 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:56,595 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-05-12 14:15:56,595 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-05-12 14:15:56,610 [main] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:<init>(100)) - starting Raft server for scm:fe26b7a1-1f7d-4969-b43e-0bdee51a4d81
2025-05-12 14:15:56,610 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:56,611 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-12 14:15:56,611 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:15:56,611 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15264 (fallback to raft.grpc.server.port)
2025-05-12 14:15:56,611 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:15:56,611 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15264 (fallback to raft.grpc.server.port)
2025-05-12 14:15:56,611 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-12 14:15:56,611 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15264 (custom)
2025-05-12 14:15:56,611 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 5242880 (custom)
2025-05-12 14:15:56,611 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-05-12 14:15:56,612 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-05-12 14:15:56,612 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:15:56,612 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:56,612 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-12 14:15:56,612 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-12 14:15:56,612 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2025-05-12 14:15:56,613 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:15:56,613 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-12 14:15:56,613 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:15:56,613 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha] (custom)
2025-05-12 14:15:56,613 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-12 14:15:56,613 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-12 14:15:56,613 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a
2025-05-12 14:15:56,614 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: addNew group-A5584FEC4A7A:[] returns group-A5584FEC4A7A:java.util.concurrent.CompletableFuture@55cee9b9[Not completed]
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: new RaftServerImpl for group-A5584FEC4A7A:[] with SCMStateMachine:uninitialized
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5000ms (custom)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 60s (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 60000ms (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:15:56,614 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:15:56,615 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-05-12 14:15:56,615 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:15:56,615 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:15:56,615 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:15:56,615 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:15:56,615 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:15:56,615 [main] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:<init>(61)) - Initializing SCM Snapshot Provider
2025-05-12 14:15:56,615 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(304)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-05-12 14:15:56,615 [main] WARN  ha.SCMHAUtils (SCMHAUtils.java:getSCMRatisSnapshotDirectory(120)) - SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2025-05-12 14:15:56,616 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-12 14:15:56,617 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(355)) - upgrade localId to 115816896921600000
2025-05-12 14:15:56,618 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(365)) - upgrade delTxnId to 0
2025-05-12 14:15:56,618 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(382)) - upgrade containerId to 0
2025-05-12 14:15:56,619 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(419)) - upgrade CertificateId to 2
2025-05-12 14:15:56,619 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-05-12 14:15:56,620 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(182)) - Entering startup safe mode.
2025-05-12 14:15:56,620 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(84)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-05-12 14:15:56,620 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(84)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-05-12 14:15:56,620 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-05-12 14:15:56,621 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(55)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-05-12 14:15:56,621 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(84)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-05-12 14:15:56,621 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2025-05-12 14:15:56,621 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting RatisPipelineUtilsThread.
2025-05-12 14:15:56,621 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(64)) - Starting BackgroundPipelineScrubber Service.
2025-05-12 14:15:56,621 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2025-05-12 14:15:56,621 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(64)) - Starting ExpiredContainerReplicaOpScrubber Service.
2025-05-12 14:15:56,622 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2025-05-12 14:15:56,622 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-05-12 14:15:56,622 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-05-12 14:15:56,623 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2025-05-12 14:15:56,623 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(285)) - Starting Replication Monitor Thread.
2025-05-12 14:15:56,624 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2025-05-12 14:15:56,624 [main] INFO  safemode.RatisContainerSafeModeRule (RatisContainerSafeModeRule.java:initializeRule(160)) - Refreshed Containers with one replica threshold count 0.
2025-05-12 14:15:56,624 [main] INFO  safemode.ECContainerSafeModeRule (ECContainerSafeModeRule.java:initializeRule(205)) - Refreshed Containers with ec n replica threshold count 0.
2025-05-12 14:15:56,625 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(177)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:15:56,625 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(190)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-05-12 14:15:56,625 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(430)) - SCM start with adminUsers: [runner]
2025-05-12 14:15:56,625 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:15:56,626 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15262
2025-05-12 14:15:56,626 [Socket Reader #1 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15262
2025-05-12 14:15:56,626 [Socket Reader #2 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15262
2025-05-12 14:15:56,627 [Socket Reader #3 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15262
2025-05-12 14:15:56,627 [Socket Reader #4 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15262
2025-05-12 14:15:56,627 [Socket Reader #5 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15262
2025-05-12 14:15:56,627 [Socket Reader #6 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15262
2025-05-12 14:15:56,627 [Socket Reader #7 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15262
2025-05-12 14:15:56,627 [Socket Reader #8 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15262
2025-05-12 14:15:56,628 [Socket Reader #9 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15262
2025-05-12 14:15:56,628 [Socket Reader #10 for port 15262] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15262
2025-05-12 14:15:56,628 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:15:56,629 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15261
2025-05-12 14:15:56,629 [Socket Reader #1 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15261
2025-05-12 14:15:56,629 [Socket Reader #2 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15261
2025-05-12 14:15:56,629 [Socket Reader #3 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15261
2025-05-12 14:15:56,629 [Socket Reader #4 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15261
2025-05-12 14:15:56,630 [Socket Reader #5 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15261
2025-05-12 14:15:56,630 [Socket Reader #6 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15261
2025-05-12 14:15:56,630 [Socket Reader #7 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15261
2025-05-12 14:15:56,630 [Socket Reader #8 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15261
2025-05-12 14:15:56,630 [Socket Reader #9 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15261
2025-05-12 14:15:56,631 [Socket Reader #10 for port 15261] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15261
2025-05-12 14:15:56,631 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:15:56,632 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15260
2025-05-12 14:15:56,632 [Socket Reader #1 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15260
2025-05-12 14:15:56,632 [Socket Reader #2 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15260
2025-05-12 14:15:56,632 [Socket Reader #3 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15260
2025-05-12 14:15:56,632 [Socket Reader #4 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15260
2025-05-12 14:15:56,632 [Socket Reader #5 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15260
2025-05-12 14:15:56,632 [Socket Reader #6 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15260
2025-05-12 14:15:56,633 [Socket Reader #7 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15260
2025-05-12 14:15:56,633 [Socket Reader #8 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15260
2025-05-12 14:15:56,633 [Socket Reader #9 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15260
2025-05-12 14:15:56,633 [Socket Reader #10 for port 15260] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15260
2025-05-12 14:15:56,635 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2025-05-12 14:15:56,635 [main] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-05-12 14:15:56,635 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1507)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15260
2025-05-12 14:15:56,636 [main] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:start(203)) - starting ratis server 0.0.0.0:15264
2025-05-12 14:15:56,636 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:15:56,636 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:15:56,636 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha] (custom)
2025-05-12 14:15:56,637 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:15:56,637 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:analyzeAndRecoverStorage(118)) - Read RaftStorageMetadata{term=1, votedFor=fe26b7a1-1f7d-4969-b43e-0bdee51a4d81} from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a/current/raft-meta
2025-05-12 14:15:56,637 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: set configuration conf: {index: 0, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:56,637 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: initialize group-A5584FEC4A7A
2025-05-12 14:15:56,637 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:15:56,637 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#7183,fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:15:56,638 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2025-05-12 14:15:56,639 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: set configuration conf: {index: 0, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(171)) - Successfully read 1 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a/current/log_inprogress_0
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 (append) at position 82
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: start as a follower, conf=conf: {index: 0, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: changes role from      null to FOLLOWER at term 1 for startAsFollower
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: start fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A5584FEC4A7A,id=fe26b7a1-1f7d-4969-b43e-0bdee51a4d81
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-A5584FEC4A7A,id=fe26b7a1-1f7d-4969-b43e-0bdee51a4d81
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:15:56,640 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:15:56,641 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-05-12 14:15:56,641 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2025-05-12 14:15:56,641 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:15:56,641 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: Successfully started.
2025-05-12 14:15:56,641 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: start RPC server
2025-05-12 14:15:56,642 [main] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: GrpcService started, listening on 15264
2025-05-12 14:15:56,642 [main] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:start(131)) -  scm role is FOLLOWER peers [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]
2025-05-12 14:15:56,642 [main] INFO  ha.InterSCMGrpcService (InterSCMGrpcProtocolService.java:start(98)) - Starting SCM Grpc Service at port 15265
2025-05-12 14:15:56,642 [JvmPauseMonitor46] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: Started
2025-05-12 14:15:56,642 [main] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(64)) - Starting SCMHATransactionMonitor Service.
2025-05-12 14:15:56,642 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMHATransactionMonitor.
2025-05-12 14:15:56,642 [main] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(61)) - SCMHATransactionMonitor Service is already running, skip start.
2025-05-12 14:15:56,643 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(138)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2025-05-12 14:15:56,644 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2025-05-12 14:15:56,644 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2025-05-12 14:15:56,655 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2025-05-12 14:15:56,655 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2025-05-12 14:15:56,666 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(207)) - RPC server for Client  is listening at /0.0.0.0:15260
2025-05-12 14:15:56,666 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:15:56,666 [IPC Server listener on 15260] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15260: starting
2025-05-12 14:15:56,676 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1520)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15261
2025-05-12 14:15:56,676 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(166)) - RPC server for Block Protocol is listening at /0.0.0.0:15261
2025-05-12 14:15:56,677 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:15:56,677 [IPC Server listener on 15261] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15261: starting
2025-05-12 14:15:56,688 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for scm at: http://0.0.0.0:15263
2025-05-12 14:15:56,688 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-12 14:15:56,695 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-12 14:15:56,697 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-12 14:15:56,698 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2025-05-12 14:15:56,698 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-12 14:15:56,698 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-12 14:15:56,698 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/webserver
2025-05-12 14:15:56,698 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15263
2025-05-12 14:15:56,699 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-12 14:15:56,700 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-12 14:15:56,700 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-12 14:15:56,700 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-12 14:15:56,701 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@122c3b77{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-12 14:15:56,701 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7c7ab7dd{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-05-12 14:15:56,704 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5e018f16{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-05-12 14:15:56,705 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@78a6bea1{HTTP/1.1, (http/1.1)}{0.0.0.0:15263}
2025-05-12 14:15:56,705 [main] INFO  server.Server (Server.java:doStart(415)) - Started @262247ms
2025-05-12 14:15:56,705 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-12 14:15:56,705 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of scm listening at http://0.0.0.0:15263
2025-05-12 14:15:56,705 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:56,707 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(113)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2025-05-12 14:15:56,707 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(224)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15266
2025-05-12 14:15:56,707 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(252)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2025-05-12 14:15:56,707 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(259)) - OM Node ID is not set. Setting it to the default ID: om1
2025-05-12 14:15:56,707 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:56,708 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = DELEGATION_TOKEN_SYMMETRIC_SIGN (version = 8), software layout = DELEGATION_TOKEN_SYMMETRIC_SIGN (version = 8)
2025-05-12 14:15:56,781 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 73 ms to scan 2 urls, producing 207 keys and 618 values
2025-05-12 14:15:56,781 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(110)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2025-05-12 14:15:56,781 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(110)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2025-05-12 14:15:56,781 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:56,781 [main] INFO  om.OzoneManager (OzoneManager.java:setReplicationFromConfig(4596)) - Set default replication in OM: RATIS/3 -> RATIS/THREE
2025-05-12 14:15:56,782 [main] INFO  proxy.SCMContainerLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15260]
2025-05-12 14:15:56,782 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15261]
2025-05-12 14:15:56,783 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15261]
2025-05-12 14:15:57,532 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-12 14:15:57,704 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1063599671ns, electionTimeout:1063ms
2025-05-12 14:15:57,704 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState
2025-05-12 14:15:57,704 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2025-05-12 14:15:57,704 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:15:57,704 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: start fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47
2025-05-12 14:15:57,704 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47 PRE_VOTE round 0: submit vote requests at term 1 for conf: {index: 0, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:57,704 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47 PRE_VOTE round 0: result PASSED (term=1)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47 ELECTION round 0: submit vote requests at term 2 for conf: {index: 0, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47 ELECTION round 0: result PASSED (term=2)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5000ms (custom)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: start fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderStateImpl
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:15:57,706 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(291)) - current SCM becomes leader of term 2.
2025-05-12 14:15:57,707 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(95)) - update <isLeader,term> from <false,0> to <true,2>
2025-05-12 14:15:57,707 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: change Leader from null to fe26b7a1-1f7d-4969-b43e-0bdee51a4d81 at term 2 for becomeLeader, leader elected after 1092ms
2025-05-12 14:15:57,707 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(443)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2025-05-12 14:15:57,707 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderElection47] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: set configuration conf: {index: 1, cur=peers:[fe26b7a1-1f7d-4969-b43e-0bdee51a4d81|pkrvmberfyhpb9w:15264]|listeners:[], old=null}
2025-05-12 14:15:57,707 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(601)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a/current/log_inprogress_0 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a/current/log_0-0
2025-05-12 14:15:57,707 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_1 at position 0
2025-05-12 14:15:57,713 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/scm-ha/552457b8-2cd5-4350-b50d-a5584fec4a7a/current/log_inprogress_1
2025-05-12 14:15:57,715 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderStateImpl is ready since appliedIndex == startIndex == 1
2025-05-12 14:15:57,715 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  ha.SCMContext (SCMContext.java:setLeaderReady(122)) - update <isLeaderReady> from <false> to <true>
2025-05-12 14:15:57,715 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(268)) - Service BackgroundPipelineCreator transitions to RUNNING.
2025-05-12 14:15:57,715 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.RatisContainerSafeModeRule (RatisContainerSafeModeRule.java:initializeRule(160)) - Refreshed Containers with one replica threshold count 0.
2025-05-12 14:15:57,715 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:15:57,715 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.ECContainerSafeModeRule (ECContainerSafeModeRule.java:initializeRule(205)) - Refreshed Containers with ec n replica threshold count 0.
2025-05-12 14:15:57,715 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(186)) - Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-05-12 14:15:57,715 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15262
2025-05-12 14:15:57,716 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:15:57,716 [IPC Server listener on 15262] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15262: starting
2025-05-12 14:15:58,201 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 12 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 12.
2025-05-12 14:15:58,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:15:58,790 [main] INFO  om.OzoneManager (OzoneManager.java:<init>(670)) - OM start with adminUsers: [runner]
2025-05-12 14:15:58,791 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:58,918 [main] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(914)) - S3 Multi-Tenancy is disabled
2025-05-12 14:15:58,918 [main] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(187)) - Ozone filesystem snapshot feature is enabled.
2025-05-12 14:15:58,919 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(292)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:15:58,934 [main] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4654)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2025-05-12 14:15:58,934 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(304)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-05-12 14:15:58,934 [main] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(488)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2025-05-12 14:15:58,935 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:15:58,935 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:15:58,935 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(304)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-05-12 14:15:58,935 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:58,936 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(167)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15269
2025-05-12 14:15:58,936 [main] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(618)) - TransactionInfo not found in OM DB.
2025-05-12 14:15:58,937 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-12 14:15:58,937 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:15:58,937 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15269 (fallback to raft.grpc.server.port)
2025-05-12 14:15:58,937 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:15:58,937 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15269 (fallback to raft.grpc.server.port)
2025-05-12 14:15:58,937 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-12 14:15:58,937 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15269 (custom)
2025-05-12 14:15:58,937 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 5242880 (custom)
2025-05-12 14:15:58,937 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-05-12 14:15:58,937 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2025-05-12 14:15:58,937 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:15:58,938 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:58,938 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-12 14:15:58,938 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-12 14:15:58,939 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2025-05-12 14:15:58,939 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:15:58,939 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-12 14:15:58,939 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:15:58,939 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/ratis] (custom)
2025-05-12 14:15:58,939 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-12 14:15:58,939 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-12 14:15:58,940 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - om1: addNew group-C5BA1605619E:[om1|localhost:15269] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@120831da[Not completed]
2025-05-12 14:15:58,940 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2284)) - OzoneManager Ratis server initialized at port 15269
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|localhost:15269] with OzoneManagerStateMachine:uninitialized
2025-05-12 14:15:58,940 [main] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1340)) - Creating RPC Server
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - om1@group-C5BA1605619E: ConfigurationManager, init=conf: {index: -1, cur=peers:[om1|localhost:15269]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2025-05-12 14:15:58,940 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:15:58,941 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2025-05-12 14:15:58,941 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:15:58,941 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:15:58,941 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:15:58,942 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2025-05-12 14:15:58,942 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:15:58,942 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:15:58,942 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:15:58,942 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:15:58,942 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:15:59,302 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 360 ms to scan 24 urls, producing 60 keys and 7515 values
2025-05-12 14:15:59,303 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:15:59,303 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 127.0.0.1:15266
2025-05-12 14:15:59,303 [Socket Reader #1 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15266
2025-05-12 14:15:59,303 [Socket Reader #2 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15266
2025-05-12 14:15:59,304 [Socket Reader #3 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15266
2025-05-12 14:15:59,304 [Socket Reader #4 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15266
2025-05-12 14:15:59,304 [Socket Reader #5 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15266
2025-05-12 14:15:59,304 [Socket Reader #6 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15266
2025-05-12 14:15:59,304 [Socket Reader #7 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15266
2025-05-12 14:15:59,304 [Socket Reader #8 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15266
2025-05-12 14:15:59,304 [Socket Reader #9 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15266
2025-05-12 14:15:59,304 [Socket Reader #10 for port 15266] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15266
2025-05-12 14:15:59,320 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2025-05-12 14:15:59,328 [main] INFO  om.OzoneManager (OzoneManager.java:start(1768)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15266
2025-05-12 14:15:59,329 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(628)) - Starting OzoneManagerRatisServer om1 at port 15269
2025-05-12 14:15:59,329 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:15:59,329 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:15:59,329 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/ratis] (custom)
2025-05-12 14:15:59,329 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2025-05-12 14:15:59,330 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:15:59,331 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2025-05-12 14:15:59,331 [om1-impl-thread1] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:lambda$0(138)) - om1: initialize group-C5BA1605619E with (t:0, i:~)
2025-05-12 14:15:59,331 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:15:59,331 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:15:59,331 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:59,332 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:15:59,332 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:15:59,332 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-12 14:15:59,332 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:15:59,332 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:15:59,332 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#7534,om1@group-C5BA1605619E-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2025-05-12 14:15:59,333 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - om1@group-C5BA1605619E: start as a follower, conf=conf: {index: -1, cur=peers:[om1|localhost:15269]|listeners:[], old=null}
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-FollowerState
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2025-05-12 14:15:59,334 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2025-05-12 14:15:59,335 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2025-05-12 14:15:59,334 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2025-05-12 14:15:59,335 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2025-05-12 14:15:59,335 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - om1@group-C5BA1605619E: Successfully started.
2025-05-12 14:15:59,335 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - om1: start RPC server
2025-05-12 14:15:59,335 [main] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - om1: GrpcService started, listening on 15269
2025-05-12 14:15:59,336 [JvmPauseMonitor47] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-om1: Started
2025-05-12 14:15:59,336 [main] INFO  om.OzoneManager (OzoneManager.java:start(1783)) - Version File has different layout version (8) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2025-05-12 14:15:59,338 [main] INFO  client.ScmTopologyClient (ScmTopologyClient.java:start(70)) - Initial network topology fetched from SCM: /.
2025-05-12 14:15:59,338 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-05-12 14:15:59,339 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-05-12 14:15:59,342 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15267
2025-05-12 14:15:59,342 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-12 14:15:59,343 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-12 14:15:59,345 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-12 14:15:59,345 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2025-05-12 14:15:59,345 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-12 14:15:59,345 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-12 14:15:59,346 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/webserver
2025-05-12 14:15:59,346 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15267
2025-05-12 14:15:59,346 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-12 14:15:59,347 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-12 14:15:59,347 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-12 14:15:59,348 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-05-12 14:15:59,348 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2b530a01{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-12 14:15:59,348 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@56dc3d65{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-05-12 14:15:59,353 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6f83a59d{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2025-05-12 14:15:59,353 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@583d465a{HTTP/1.1, (http/1.1)}{0.0.0.0:15267}
2025-05-12 14:15:59,353 [main] INFO  server.Server (Server.java:doStart(415)) - Started @264895ms
2025-05-12 14:15:59,353 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-12 14:15:59,354 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of ozoneManager listening at http://0.0.0.0:15267
2025-05-12 14:15:59,354 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:15:59,354 [IPC Server listener on 15266] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15266: starting
2025-05-12 14:15:59,356 [main] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2238)) - Trash Interval set to 0. Files deleted won't move to trash
2025-05-12 14:15:59,464 [main] INFO  recon.ReconServer (HddsServerUtil.java:startupShutdownMessage(683)) - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ReconServer
STARTUP_MSG:   host = pkrvmberfyhpb9w/10.1.0.72
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.1.0-SNAPSHOT
STARTUP_MSG:   classpath = /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/hdds-server-scm-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.16.2/jackson-annotations-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.16.2/jackson-core-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.16.2/jackson-databind-2.16.2.jar:/home/runner/.m2/repository/com/google/guava/guava/32.1.3-jre/guava-32.1.3-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.37.0/checker-qual-3.37.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.29.2/error_prone_annotations-2.29.2.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/commons-io/commons-io/2.18.0/commons-io-2.18.0.jar:/home/runner/.m2/repository/info/picocli/picocli/4.7.7/picocli-4.7.7.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.6/metrics-core-3.2.6.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.27.1/commons-compress-1.27.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.12.0/commons-text-1.12.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.4.1/hadoop-auth-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.4.1/hadoop-common-3.4.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/client/target/hdds-client-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/config/target/hdds-config-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/hdds-interface-admin-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/hdds-interface-client-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/hdds-interface-server-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/hdds-server-framework-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/3.1.2/ratis-client-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/3.1.2/ratis-common-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/3.1.2/ratis-grpc-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/3.1.2/ratis-netty-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/3.1.2/ratis-proto-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/3.1.2/ratis-server-api-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.6/ratis-thirdparty-misc-1.0.6.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk18on/1.80/bcpkix-jdk18on-1.80.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk18on/1.80/bcprov-jdk18on-1.80.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.57.v20241219/jetty-webapp-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.57.v20241219/jetty-xml-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/2.0.17/slf4j-api-2.0.17.jar:/home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/target/ozone-cli-admin-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.16.2/jackson-datatype-jsr310-2.16.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.4.1/hadoop-hdfs-client-3.4.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/ozone-interface-client-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.17.1/commons-codec-1.17.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/target/ozone-cli-shell-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli-shell-jline3/4.7.7/picocli-shell-jline3-4.7.7.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.14/httpclient-4.5.14.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/ozone-filesystem-common-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/jline/jline/3.30.0/jline-3.30.0.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/2.0.17/slf4j-reload4j-2.0.17.jar:/home/runner/work/ozone/ozone/hadoop-ozone/client/target/ozone-client-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/hdds-erasurecode-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/common/target/ozone-common-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.58.0/grpc-api-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.58.0/grpc-netty-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.58.0/grpc-core-1.58.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.23/animal-sniffer-annotations-1.23.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.58.0/grpc-context-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-util/1.58.0/grpc-util-1.58.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.109.Final/netty-codec-http2-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.109.Final/netty-codec-http-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.109.Final/netty-common-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.109.Final/netty-handler-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.109.Final/netty-resolver-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.109.Final/netty-handler-proxy-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.109.Final/netty-codec-socks-4.1.109.Final.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.16/httpcore-4.4.16.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.65.Final/netty-tcnative-classes-2.0.65.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-windows-x86_64.jar:/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/ozone-csi-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.26/reload4j-1.2.26.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.58.0/grpc-protobuf-1.58.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.22.0/proto-google-common-protos-2.22.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.58.0/grpc-protobuf-lite-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.58.0/grpc-stub-1.58.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.109.Final/netty-transport-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.109.Final/netty-transport-classes-epoll-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.109.Final/netty-transport-native-unix-common-4.1.109.Final.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/ozone-filesystem-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/freon/target/ozone-freon-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.661/aws-java-sdk-core-1.12.661.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.16.2/jackson-dataformat-cbor-2.16.2.jar:/home/runner/.m2/repository/joda-time/joda-time/2.12.7/joda-time-2.12.7.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.661/aws-java-sdk-s3-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.661/aws-java-sdk-kms-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.661/jmespath-java-1.12.661.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.4.1/hadoop-hdfs-3.4.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/ozone-interface-storage-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.11/metainf-services-1.11.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/ozone-manager-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19.4/jersey-client-1.19.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.24.2/log4j-api-2.24.2.jar:/home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/target/hdds-managed-rocksdb-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/hdds-rocks-native-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.57.v20241219/jetty-io-9.4.57.v20241219.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/rocksdb-checkpoint-differ-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/github/vlsi/mxgraph/jgraphx/3.9.12/jgraphx-3.9.12.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.4.0/jgrapht-core-1.4.0.jar:/home/runner/.m2/repository/org/jheaps/jheaps/0.11/jheaps-0.11.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.4.0/jgrapht-ext-1.4.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.6.0/ranger-intg-2.6.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.6.0/ranger-plugins-common-2.6.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.16.2/jackson-jaxrs-base-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.16.2/jackson-jaxrs-json-provider-2.16.2.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/1.0.0/gethostname4j-1.0.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.6.0/ranger-plugin-classloader-2.6.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.6.0/ranger-plugins-audit-2.6.0.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-logs/1.12.765/aws-java-sdk-logs-1.12.765.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/io/airlift/aircompressor/0.27/aircompressor-0.27.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.4/httpasyncclient-4.1.4.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.16/httpcore-nio-4.4.16.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.13/httpmime-4.5.13.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/org/apache/orc/orc-shims/1.5.8/orc-shims-1.5.8.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.57.v20241219/jetty-client-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.6.0/ranger-plugins-cred-2.6.0.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.57.v20241219/jetty-util-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/reflections/reflections/0.10.2/reflections-0.10.2.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/guice/6.0.0/guice-6.0.0.jar:/home/runner/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/6.0.0/guice-assistedinject-6.0.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/6.0.0/guice-servlet-6.0.0.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/target/ozone-reconcodegen-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.57.v20241219/jetty-servlet-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.57.v20241219/jetty-security-9.4.57.v20241219.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.6.1/guice-bridge-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.46/jersey-container-servlet-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.46/jersey-container-servlet-core-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.46/jersey-common-2.46.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.46/jersey-server-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.46/jersey-client-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.46/jersey-hk2-2.46.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.46/jersey-media-jaxb-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.46/jersey-media-json-jackson-2.46.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.46/jersey-entity-filtering-2.46.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.16.2/jackson-module-jaxb-annotations-2.16.2.jar:/home/runner/.m2/repository/org/javassist/javassist/3.30.2-GA/javassist-3.30.2-GA.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.39/spring-core-5.3.39.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.39/spring-jdbc-5.3.39.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.39/spring-beans-5.3.39.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.39/spring-tx-5.3.39.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.49.1.0/sqlite-jdbc-3.49.1.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/ozone-s3gateway-2.1.0-SNAPSHOT.jar:/home/runner/work/ozone/ozone/hadoop-ozone/tools/target/ozone-tools-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-shell/3.1.2/ratis-shell-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/3.1.2/ratis-tools-3.1.2.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.9/jaxb-runtime-2.3.9.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.9/txw2-2.3.9.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.12/istack-commons-runtime-3.0.12.jar:/home/runner/.m2/repository/com/sun/activation/jakarta.activation/1.2.2/jakarta.activation-1.2.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/3.1.2/ratis-server-3.1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-api/3.1.2/ratis-metrics-api-3.1.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.2/hamcrest-2.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/2.0.17/jul-to-slf4j-2.0.17.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.17.0/commons-lang3-3.17.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.4.1/hadoop-common-3.4.1-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_25/1.4.0/hadoop-shaded-protobuf_3_25-1.4.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.4.1/hadoop-annotations-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.3.0/hadoop-shaded-guava-1.3.0.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.8.0/commons-cli-1.8.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.11.1/commons-net-3.11.1.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.57.v20241219/jetty-server-9.4.57.v20241219.jar:/home/runner/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19.4/jersey-core-1.19.4.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19.4/jersey-servlet-1.19.4.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.22.0/jersey-json-1.22.0.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.5.4/jettison-1.5.4.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19.4/jersey-server-1.19.4.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.11.0/commons-configuration2-2.11.0.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.9.2/avro-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.7/re2j-1.7.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/dnsjava/dnsjava/3.6.1/dnsjava-3.6.1.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.7/snappy-java-1.1.10.7.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.4.1/hadoop-distcp-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.4.1/hadoop-distcp-3.4.1-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.4.1/hadoop-hdfs-3.4.1-tests.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.57.v20241219/jetty-util-ajax-9.4.57.v20241219.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.4.0/commons-daemon-1.4.0.jar:/home/runner/.m2/repository/io/netty/netty-all/4.1.109.Final/netty-all-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-dns/4.1.109.Final/netty-codec-dns-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-haproxy/4.1.109.Final/netty-codec-haproxy-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-memcache/4.1.109.Final/netty-codec-memcache-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-mqtt/4.1.109.Final/netty-codec-mqtt-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-redis/4.1.109.Final/netty-codec-redis-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-smtp/4.1.109.Final/netty-codec-smtp-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-stomp/4.1.109.Final/netty-codec-stomp-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-xml/4.1.109.Final/netty-codec-xml-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-ssl-ocsp/4.1.109.Final/netty-handler-ssl-ocsp-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns/4.1.109.Final/netty-resolver-dns-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-rxtx/4.1.109.Final/netty-transport-rxtx-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-sctp/4.1.109.Final/netty-transport-sctp-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-udt/4.1.109.Final/netty-transport-udt-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-kqueue/4.1.109.Final/netty-transport-classes-kqueue-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-classes-macos/4.1.109.Final/netty-resolver-dns-classes-macos-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final-linux-riscv64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.109.Final/netty-transport-native-kqueue-4.1.109.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.109.Final/netty-transport-native-kqueue-4.1.109.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.109.Final/netty-resolver-dns-native-macos-4.1.109.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-resolver-dns-native-macos/4.1.109.Final/netty-resolver-dns-native-macos-4.1.109.Final-osx-aarch_64.jar:/home/runner/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.1/hadoop-kms-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.1/hadoop-kms-3.4.1-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.4.1/hadoop-mapreduce-client-core-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.4.1/hadoop-yarn-client-3.4.1.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.53.v20231009/websocket-client-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.53.v20231009/websocket-common-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.53.v20231009/websocket-api-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.4.1/hadoop-yarn-api-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.4.1/hadoop-yarn-common-3.4.1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.4.1/hadoop-mapreduce-client-jobclient-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.4.1/hadoop-mapreduce-client-common-3.4.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.4.1/hadoop-minikdc-3.4.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/2.0.3/kerb-simplekdc-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/2.0.3/kerb-client-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/2.0.3/kerb-common-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/2.0.3/token-provider-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/2.0.3/kerb-admin-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/2.0.3/kerb-server-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/2.0.3/kerb-identity-2.0.3.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/2.0.3/kerby-xdr-2.0.3.jar:/home/runner/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.8.1/jaeger-client-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.8.1/jaeger-thrift-1.8.1.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.15.0/libthrift-0.15.0.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.12.0/okhttp-4.12.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.6.0/okio-3.6.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.6.0/okio-jvm-3.6.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.25/kotlin-stdlib-common-1.9.25.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.9.25/kotlin-stdlib-jdk8-1.9.25.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.9.25/kotlin-stdlib-jdk7-1.9.25.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.8.1/jaeger-tracerresolver-1.8.1.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.8.1/jaeger-core-1.8.1.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/runner/work/ozone/ozone/hadoop-hdds/annotations/target/hdds-annotation-processing-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-dropwizard3/3.1.2/ratis-metrics-dropwizard3-3.1.2.jar:/home/runner/.m2/repository/org/bouncycastle/bcutil-jdk18on/1.80/bcutil-jdk18on-1.80.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.9.25/kotlin-stdlib-1.9.25.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/org/slf4j/jcl-over-slf4j/2.0.17/jcl-over-slf4j-2.0.17.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.7-3/zstd-jni-1.5.7-3.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.109.Final/netty-buffer-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.109.Final/netty-codec-4.1.109.Final.jar:/home/runner/.m2/repository/log4j/apache-log4j-extras/1.2.17/apache-log4j-extras-1.2.17.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/hdds-server-framework-2.1.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/jnr/jnr-constants/0.10.4/jnr-constants-0.10.4.jar:/home/runner/.m2/repository/com/github/jnr/jnr-posix/3.1.20/jnr-posix-3.1.20.jar:/home/runner/.m2/repository/com/github/jnr/jnr-ffi/2.2.17/jnr-ffi-2.2.17.jar:/home/runner/.m2/repository/com/github/jnr/jffi/1.3.13/jffi-1.3.13.jar:/home/runner/.m2/repository/com/github/jnr/jffi/1.3.13/jffi-1.3.13-native.jar:/home/runner/.m2/repository/org/ow2/asm/asm/9.7.1/asm-9.7.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm-commons/9.7.1/asm-commons-9.7.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm-analysis/9.7.1/asm-analysis-9.7.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm-tree/9.7.1/asm-tree-9.7.1.jar:/home/runner/.m2/repository/org/ow2/asm/asm-util/9.7.1/asm-util-9.7.1.jar:/home/runner/.m2/repository/com/github/jnr/jnr-a64asm/1.0.0/jnr-a64asm-1.0.0.jar:/home/runner/.m2/repository/com/github/jnr/jnr-x86asm/1.0.2/jnr-x86asm-1.0.2.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.16.0/simpleclient-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.16.0/simpleclient_common-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.16.0/simpleclient_dropwizard-0.16.0.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.24.2/log4j-core-2.24.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.57.v20241219/jetty-http-9.4.57.v20241219.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.4/disruptor-3.4.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.40/nimbus-jose-jwt-9.40.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/hdds-server-scm-2.1.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/hdds-test-utils-2.1.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/ozone-manager-2.1.0-SNAPSHOT-tests.jar:/home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/target/ozone-mini-cluster-2.1.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.27.3/assertj-core-3.27.3.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.15.11/byte-buddy-1.15.11.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.12.2/junit-jupiter-api-5.12.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.12.2/junit-platform-commons-1.12.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.12.2/junit-jupiter-params-5.12.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/4.11.0/mockito-core-4.11.0.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.12.19/byte-buddy-agent-1.12.19.jar:/home/runner/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/runner/.m2/repository/org/mockito/mockito-inline/4.11.0/mockito-inline-4.11.0.jar:/home/runner/.m2/repository/org/mockito/mockito-junit-jupiter/4.11.0/mockito-junit-jupiter-4.11.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/gradle-enterprise/test-listeners.jar:
STARTUP_MSG:   build = https://github.com/apache/ozone/d92f0ed87e7396665972628463cce3b55daa0626
STARTUP_MSG:   java = 21.0.7
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=4, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachine.write.wait.interval=10m, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.delete.container.timeout=60s, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp/dfs/data, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.factory.classname=org.apache.hadoop.hdds.fs.MockSpaceUsageCheckFactory$None, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.read.threadpool=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.auto-compaction-small-sst-file.interval.minutes=120, hdds.datanode.rocksdb.auto-compaction-small-sst-file.threads=1, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.choosing.policy=org.apache.hadoop.ozone.container.common.volume.CapacityVolumeChoosingPolicy, hdds.datanode.volume.min.free.space=-1, hdds.datanode.volume.min.free.space.percent=-1, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.initial-interval=2s, hdds.heartbeat.interval=1s, hdds.heartbeat.recon.initial-interval=60s, hdds.heartbeat.recon.interval=60s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.block.deletion.txn.dn.commit.map.limit=5000000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.event.timeout=12m, hdds.scm.replication.event.timeout.datanode.offset=6m, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=4MB, ozone.client.datastream.min.packet.size=256KB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=8MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=1MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=2MB, ozone.client.stream.buffer.size=1MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.compaction.service.enabled=false, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.csi.default-volume-size=1000000000, ozone.csi.mount.command=goofys --endpoint %s %s %s, ozone.csi.s3g.address=http://localhost:9878, ozone.csi.socket=/var/lib/csi.sock, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.hbase.enhancements.allowed=false, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.compaction.service.columnfamilies=keyTable,fileTable,directoryTable,deletedTable,deletedDirectoryTable,multipartInfoTable, ozone.om.compaction.service.run.interval=6h, ozone.om.compaction.service.timeout=10m, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.edekcacheloader.initial.delay.ms=3000, ozone.om.edekcacheloader.interval.ms=1000, ozone.om.edekcacheloader.max-retries=10, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=READ, LIST, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=20, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.log.appender.queue.byte-limit=4MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.s3.grpc.server_enabled=false, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.server.list.max.size=1000, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1s, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.rocksdb.metrics.enabled=false, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=5s, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.sql.db.auto.commit=true, ozone.recon.sql.db.conn.idle.max.age=3600s, ozone.recon.sql.db.conn.idle.test=SELECT 1, ozone.recon.sql.db.conn.idle.test.period=60s, ozone.recon.sql.db.conn.max.active=5, ozone.recon.sql.db.conn.max.age=1800s, ozone.recon.sql.db.conn.timeout=30000ms, ozone.recon.sql.db.driver=org.apache.derby.jdbc.EmbeddedDriver, ozone.recon.sql.db.jdbc.url=jdbc:derby:${ozone.recon.db.dir}/ozone_recon_derby.db, ozone.recon.sql.db.jooq.dialect=DERBY, ozone.recon.task.containercounttask.interval=60s, ozone.recon.task.missingcontainer.interval=300s, ozone.recon.task.pipelinesync.interval=300s, ozone.recon.task.safemode.wait.threshold=300s, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.https-address=0.0.0.0:9879, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.s3g.webadmin.https-address=0.0.0.0:19879, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=4MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=1MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=1s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=4MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=20, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=100ms, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=3, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.test.test.key=value1, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256, test.scm.client.address=localhost, test.scm.client.bind.host=0.0.0.0, test.scm.client.class=java.lang.Object, test.scm.client.compression.enabled=true, test.scm.client.duration=1h, test.scm.client.enabled=true, test.scm.client.port=9878, test.scm.client.threshold=10, test.scm.client.wait=30m, yarn.app.mapreduce.am.container.log.backups=0, yarn.app.mapreduce.am.container.log.limit.kb=0, yarn.app.mapreduce.task.container.log.backups=0, yarn.nodemanager.container.stderr.pattern={*stderr*,*STDERR*}, yarn.nodemanager.container.stderr.tail.bytes=4096, yarn.nodemanager.least-load-policy-selector.pending-container.threshold=10000, yarn.nodemanager.windows-container.cpu-limit.enabled=false, yarn.nodemanager.windows-container.memory-limit.enabled=false, yarn.resourcemanager.container.liveness-monitor.interval-ms=600000}
************************************************************/
2025-05-12 14:15:59,465 [main] WARN  recon.ReconServer (HddsServerUtil.java:startupShutdownMessage(691)) - failed to register any UNIX signal loggers: 
java.lang.IllegalStateException: Can't re-install the signal handlers.
	at org.apache.hadoop.hdds.utils.SignalLogger.register(SignalLogger.java:82)
	at org.apache.hadoop.hdds.utils.HddsServerUtil.startupShutdownMessage(HddsServerUtil.java:689)
	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:105)
	at org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:73)
	at picocli.CommandLine.executeUserObject(CommandLine.java:2031)
	at picocli.CommandLine.access$1500(CommandLine.java:148)
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2469)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2461)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2423)
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2277)
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2425)
	at picocli.CommandLine.execute(CommandLine.java:2174)
	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:89)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createRecon(MiniOzoneClusterImpl.java:735)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:556)
	at org.apache.hadoop.ozone.recon.TestReconAndAdminContainerCLI.init(TestReconAndAdminContainerCLI.java:131)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:775)
	at org.junit.platform.commons.support.ReflectionSupport.invokeMethod(ReflectionSupport.java:479)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.SameThreadTimeoutInvocation.proceed(SameThreadTimeoutInvocation.java:49)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:161)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:133)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:75)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:112)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:94)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:87)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$13(ClassBasedTestDescriptor.java:417)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:415)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:216)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:84)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:153)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39)
	at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25)
	at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:56)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:162)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:120)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
2025-05-12 14:15:59,485 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 5 ms to scan 1 urls, producing 21 keys and 84 values
2025-05-12 14:15:59,497 [main] INFO  recon.ReconServer (ReconServer.java:call(119)) - Initializing Recon server...
2025-05-12 14:15:59,526 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(49)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/recon/ozone_recon_derby.db 
2025-05-12 14:15:59,533 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-12 14:15:59,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:15:59,632 [main] INFO  schema.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(83)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/recon/ozone_recon_derby.db.
2025-05-12 14:15:59,633 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(142)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2025-05-12 14:15:59,634 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(695)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2025-05-12 14:15:59,649 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(49)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/recon/ozone_recon_derby.db 
2025-05-12 14:15:59,650 [main] INFO  schema.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(83)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/recon/ozone_recon_derby.db.
2025-05-12 14:15:59,650 [main] INFO  recon.ReconServer (ReconServer.java:call(146)) - Creating Recon Schema.
2025-05-12 14:15:59,674 [main] INFO  schema.SchemaVersionTableDefinition (SchemaVersionTableDefinition.java:insertInitialSLV(95)) - Inserted initial SLV '1' into SchemaVersion table.
2025-05-12 14:15:59,698 [main] INFO  schema.ContainerSchemaDefinition (ContainerSchemaDefinition.java:initializeSchema(61)) - UNHEALTHY_CONTAINERS is missing creating new one.
2025-05-12 14:15:59,703 [main] INFO  recon.ReconServer (ReconServer.java:call(150)) - Finalizing Layout Features.
2025-05-12 14:15:59,707 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 1 ms to scan 1 urls, producing 6 keys and 9 values
2025-05-12 14:15:59,708 [main] INFO  upgrade.ReconLayoutVersionManager (ReconLayoutVersionManager.java:getRegisteredFeatures(133)) - Current MLV: 1. SLV: 1. Checking features for registration...
2025-05-12 14:15:59,708 [main] INFO  recon.ReconServer (ReconServer.java:call(161)) - Recon schema versioning completed.
2025-05-12 14:15:59,709 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for recon at: http://0.0.0.0:15270
2025-05-12 14:15:59,709 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-12 14:15:59,710 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-12 14:15:59,712 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-12 14:15:59,712 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
2025-05-12 14:15:59,713 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-12 14:15:59,713 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-12 14:15:59,713 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of recon uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/webserver
2025-05-12 14:15:59,716 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task ContainerKeyMapperTaskFSO with controller.
2025-05-12 14:15:59,716 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task ContainerKeyMapperTaskOBS with controller.
2025-05-12 14:15:59,716 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task FileSizeCountTaskFSO with controller.
2025-05-12 14:15:59,716 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task FileSizeCountTaskOBS with controller.
2025-05-12 14:15:59,716 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task OmTableInsightTask with controller.
2025-05-12 14:15:59,717 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(82)) - Registered task NSSummaryTask with controller.
2025-05-12 14:15:59,717 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(723)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2025-05-12 14:15:59,717 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(742)) - No OzoneManager ServiceID configured.
2025-05-12 14:15:59,720 [main] INFO  proxy.SCMContainerLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15260]
2025-05-12 14:15:59,722 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-05-12 14:15:59,722 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-05-12 14:15:59,774 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-12 14:15:59,774 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-05-12 14:15:59,775 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(182)) - Entering startup safe mode.
2025-05-12 14:15:59,775 [main] INFO  scm.ReconNodeManager (ReconNodeManager.java:loadExistingNodes(129)) - Loaded 0 nodes from node DB.
2025-05-12 14:15:59,775 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(84)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-05-12 14:15:59,776 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:15:59,776 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15271
2025-05-12 14:15:59,776 [Socket Reader #1 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15271
2025-05-12 14:15:59,777 [Socket Reader #2 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15271
2025-05-12 14:15:59,777 [Socket Reader #3 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15271
2025-05-12 14:15:59,777 [Socket Reader #4 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15271
2025-05-12 14:15:59,777 [Socket Reader #5 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15271
2025-05-12 14:15:59,777 [Socket Reader #6 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15271
2025-05-12 14:15:59,777 [Socket Reader #7 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15271
2025-05-12 14:15:59,777 [Socket Reader #8 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15271
2025-05-12 14:15:59,778 [Socket Reader #9 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15271
2025-05-12 14:15:59,778 [Socket Reader #10 for port 15271] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15271
2025-05-12 14:15:59,779 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-05-12 14:15:59,782 [main] INFO  recon.ReconServer (ReconServer.java:call(174)) - Initializing support of Recon Features...
2025-05-12 14:15:59,782 [main] INFO  recon.ReconServer (ReconServer.java:start(238)) - Starting Recon server
2025-05-12 14:15:59,782 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Recon metrics system started (again)
2025-05-12 14:15:59,793 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15270
2025-05-12 14:15:59,793 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-12 14:15:59,794 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-12 14:15:59,794 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-12 14:15:59,794 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-12 14:15:59,795 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@694ca345{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-12 14:15:59,795 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@21d97b2e{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-12 14:15:59,903 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@777d0cde{recon,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/webserver/jetty-0_0_0_0-15270-ozone-recon-2_1_0-SNAPSHOT_jar-_-any-17550644064273040960/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar!/webapps/recon}
2025-05-12 14:15:59,904 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@52cd51de{HTTP/1.1, (http/1.1)}{0.0.0.0:15270}
2025-05-12 14:15:59,905 [main] INFO  server.Server (Server.java:doStart(415)) - Started @265447ms
2025-05-12 14:15:59,905 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-12 14:15:59,905 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of recon listening at http://0.0.0.0:15270
2025-05-12 14:15:59,905 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:start(243)) - Starting Ozone Manager Service Provider.
2025-05-12 14:15:59,905 [main] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:start(77)) - Starting ReconOMMetadataManagerImpl
2025-05-12 14:15:59,905 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:start(239)) - Starting Recon Task Controller.
2025-05-12 14:15:59,912 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(386)) - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:15271
2025-05-12 14:15:59,915 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:initializePipelinesFromScm(486)) - Obtained 0 pipelines from SCM.
2025-05-12 14:15:59,915 [main] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 0 pipelines in house.
2025-05-12 14:15:59,915 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(399)) - SCM DB initialized
2025-05-12 14:15:59,916 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15271
2025-05-12 14:15:59,916 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:15:59,917 [IPC Server listener on 15271] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15271: starting
2025-05-12 14:16:00,201 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 13 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 13.
2025-05-12 14:16:00,514 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1179795160ns, electionTimeout:1179ms
2025-05-12 14:16:00,514 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2025-05-12 14:16:00,514 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:16:00,514 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:16:00,514 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-LeaderElection48
2025-05-12 14:16:00,515 [om1@group-C5BA1605619E-LeaderElection48] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - om1@group-C5BA1605619E-LeaderElection48 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[om1|localhost:15269]|listeners:[], old=null}
2025-05-12 14:16:00,515 [om1@group-C5BA1605619E-LeaderElection48] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - om1@group-C5BA1605619E-LeaderElection48 PRE_VOTE round 0: result PASSED (term=0)
2025-05-12 14:16:00,516 [om1@group-C5BA1605619E-LeaderElection48] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - om1@group-C5BA1605619E-LeaderElection48 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[om1|localhost:15269]|listeners:[], old=null}
2025-05-12 14:16:00,516 [om1@group-C5BA1605619E-LeaderElection48] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - om1@group-C5BA1605619E-LeaderElection48 ELECTION round 0: result PASSED (term=1)
2025-05-12 14:16:00,516 [om1@group-C5BA1605619E-LeaderElection48] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection48
2025-05-12 14:16:00,516 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-12 14:16:00,516 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:16:00,516 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-12 14:16:00,516 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - om1@group-C5BA1605619E: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyLeaderChanged(174)) - om1@group-C5BA1605619E: leader changed to om1
2025-05-12 14:16:00,517 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1576ms
2025-05-12 14:16:00,518 [om1@group-C5BA1605619E-LeaderElection48] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:00,518 [om1@group-C5BA1605619E-LeaderElection48] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - om1@group-C5BA1605619E: set configuration conf: {index: 0, cur=peers:[om1|localhost:15269]|listeners:[], old=null}
2025-05-12 14:16:00,518 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:00,524 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2025-05-12 14:16:00,526 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(236)) - notifyConfigurationChanged from Ratis: term=1, index=0, New Peer list: om1(localhost:15269)
2025-05-12 14:16:00,526 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader om1@group-C5BA1605619E-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-12 14:16:00,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:01,538 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-12 14:16:01,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:02,202 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 14 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 14.
2025-05-12 14:16:02,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:03,538 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2025-05-12 14:16:03,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:04,203 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] ERROR scm.ReconDeadNodeHandler (ReconDeadNodeHandler.java:onMessage(81)) - Error trying to verify Node operational state from SCM.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:872)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1588)
	at org.apache.hadoop.ipc.Client.call(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1426)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:668)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:789)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:364)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1649)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	... 22 more
2025-05-12 14:16:04,203 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. f9a93fbd-e026-4acd-84ab-278d72cb1cda(localhost/127.0.0.1)
2025-05-12 14:16:04,204 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: e7414f4a-7772-42a8-846e-1dce13588a2b, Nodes: [ {f9a93fbd-e026-4acd-84ab-278d72cb1cda(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:f9a93fbd-e026-4acd-84ab-278d72cb1cda, CreationTimestamp2025-05-12T14:14:34.608Z[Etc/UTC]} removed.
2025-05-12 14:16:04,204 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(190)) - Processing of TypedEvent{payloadType=DatanodeDetails, name='Replication_Manager_Notify'} is skipped, EventQueue is not running
2025-05-12 14:16:04,204 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 0 for DN f9a93fbd-e026-4acd-84ab-278d72cb1cda(localhost/127.0.0.1)
2025-05-12 14:16:04,204 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/f9a93fbd-e026-4acd-84ab-278d72cb1cda
2025-05-12 14:16:04,204 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-12 14:16:04,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:05,539 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2025-05-12 14:16:05,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:06,205 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-12 14:16:06,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:07,544 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2025-05-12 14:16:07,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:08,206 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-12 14:16:08,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:09,545 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 8 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 8.
2025-05-12 14:16:09,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:10,207 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-12 14:16:10,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:10,818 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-12 14:16:10,930 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(47)) - Starting PipelineSyncTask Thread.
2025-05-12 14:16:10,931 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(47)) - Starting ContainerHealthTask Thread.
2025-05-12 14:16:10,931 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(47)) - Starting ContainerSizeCountTask Thread.
2025-05-12 14:16:10,931 [main] INFO  recon.ReconServer (ReconServer.java:call(181)) - Recon server initialized successfully!
2025-05-12 14:16:10,932 [JvmPauseMonitor48] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-Recon: Started
2025-05-12 14:16:10,939 [ContainerHealthTask] INFO  updater.ReconTaskStatusUpdater (ReconTaskStatusUpdater.java:updateDetails(124)) - Registered Task: ContainerHealthTask
2025-05-12 14:16:10,939 [PipelineSyncTask] INFO  updater.ReconTaskStatusUpdater (ReconTaskStatusUpdater.java:updateDetails(124)) - Registered Task: PipelineSyncTask
2025-05-12 14:16:10,941 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:10,942 [PipelineSyncTask] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 0 pipelines in house.
2025-05-12 14:16:10,959 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:10,959 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:10,959 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-12 14:16:10,969 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(pkrvmberfyhpb9w.internal.cloudapp.net/null) to 10.1.0.72
2025-05-12 14:16:10,970 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(pkrvmberfyhpb9w.internal.cloudapp.net/10.1.0.72)
2025-05-12 14:16:10,971 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-12 14:16:10,972 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-12 14:16:10,973 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-54755e82-105b-43de-91a6-d91f456337eb dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-12 14:16:10,973 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds to VolumeSet
2025-05-12 14:16:10,974 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis to VolumeSet
2025-05-12 14:16:10,974 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-05-12 14:16:10,974 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:10,975 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:10,985 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:10,985 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:10,986 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:10,986 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-12 14:16:10,987 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:10,987 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15276 (custom)
2025-05-12 14:16:10,987 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:10,987 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15275 (custom)
2025-05-12 14:16:10,987 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-12 14:16:10,987 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15277 (custom)
2025-05-12 14:16:10,987 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-12 14:16:10,987 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-12 14:16:10,987 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:10,987 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:16:10,988 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:10,988 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-12 14:16:10,988 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-12 14:16:10,989 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-12 14:16:10,989 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-12 14:16:10,989 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-12 14:16:10,989 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-12 14:16:10,989 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-12 14:16:10,990 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-12 14:16:10,990 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-12 14:16:10,990 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-12 14:16:10,990 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-12 14:16:10,990 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-12 14:16:10,990 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-12 14:16:10,991 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-12 14:16:10,991 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-12 14:16:10,991 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15278 (custom)
2025-05-12 14:16:10,991 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:10,991 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-12 14:16:10,991 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:10,991 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xce86fc5d] REGISTERED
2025-05-12 14:16:10,991 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis] (custom)
2025-05-12 14:16:10,992 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xce86fc5d] BIND: 0.0.0.0/0.0.0.0:15278
2025-05-12 14:16:10,992 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-12 14:16:10,992 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-12 14:16:10,992 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xce86fc5d, L:/0.0.0.0:15278] ACTIVE
2025-05-12 14:16:10,992 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/tmp
2025-05-12 14:16:10,992 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/tmp is not a group directory; ignoring it. 
2025-05-12 14:16:10,993 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-12 14:16:10,993 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-12 14:16:10,994 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-12 14:16:10,994 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-12 14:16:10,996 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15272
2025-05-12 14:16:10,996 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-12 14:16:11,002 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-12 14:16:11,003 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-12 14:16:11,004 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-12 14:16:11,004 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-12 14:16:11,004 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-12 14:16:11,004 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/meta/webserver
2025-05-12 14:16:11,005 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15272
2025-05-12 14:16:11,005 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-12 14:16:11,006 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-12 14:16:11,006 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-12 14:16:11,006 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-12 14:16:11,007 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7d78fbb9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-12 14:16:11,007 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5d40ba3e{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-12 14:16:11,134 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4c326a28{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/meta/webserver/jetty-0_0_0_0-15272-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-15670423146850915221/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:11,135 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5e385492{HTTP/1.1, (http/1.1)}{0.0.0.0:15272}
2025-05-12 14:16:11,135 [main] INFO  server.Server (Server.java:doStart(415)) - Started @276677ms
2025-05-12 14:16:11,135 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-12 14:16:11,136 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15272
2025-05-12 14:16:11,136 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:16:11,136 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15273
2025-05-12 14:16:11,136 [Socket Reader #1 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15273
2025-05-12 14:16:11,136 [Socket Reader #2 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15273
2025-05-12 14:16:11,137 [Socket Reader #3 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15273
2025-05-12 14:16:11,137 [Socket Reader #4 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15273
2025-05-12 14:16:11,137 [Socket Reader #5 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15273
2025-05-12 14:16:11,137 [Socket Reader #6 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15273
2025-05-12 14:16:11,137 [Socket Reader #7 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15273
2025-05-12 14:16:11,137 [Socket Reader #8 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15273
2025-05-12 14:16:11,138 [Socket Reader #9 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15273
2025-05-12 14:16:11,138 [Socket Reader #10 for port 15273] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15273
2025-05-12 14:16:11,139 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-12 14:16:11,139 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15273
2025-05-12 14:16:11,139 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:16:11,139 [IPC Server listener on 15273] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15273: starting
2025-05-12 14:16:11,141 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:11,141 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:11,141 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-12 14:16:11,141 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-12 14:16:11,142 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-12 14:16:11,145 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/meta/datanode.id
2025-05-12 14:16:11,151 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode 11452936-83cb-47e1-bf10-894668a55a8a(pkrvmberfyhpb9w.internal.cloudapp.net/null) to 10.1.0.72
2025-05-12 14:16:11,151 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService 11452936-83cb-47e1-bf10-894668a55a8a(pkrvmberfyhpb9w.internal.cloudapp.net/10.1.0.72)
2025-05-12 14:16:11,153 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-12 14:16:11,153 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-12 14:16:11,154 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-7accf6f3-c1bd-46c2-bc38-339dc2ecdd2f dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-12 14:16:11,154 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds to VolumeSet
2025-05-12 14:16:11,155 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis to VolumeSet
2025-05-12 14:16:11,155 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-05-12 14:16:11,156 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:11,156 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:11,166 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:11,166 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:11,166 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:11,167 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-12 14:16:11,167 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:11,167 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15284 (custom)
2025-05-12 14:16:11,167 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:11,167 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15283 (custom)
2025-05-12 14:16:11,167 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-12 14:16:11,167 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15285 (custom)
2025-05-12 14:16:11,167 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-12 14:16:11,167 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-12 14:16:11,167 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:11,167 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:16:11,168 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:11,168 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-12 14:16:11,168 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-12 14:16:11,169 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-12 14:16:11,169 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-12 14:16:11,169 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-12 14:16:11,169 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-12 14:16:11,169 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-12 14:16:11,169 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-12 14:16:11,169 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-12 14:16:11,169 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-12 14:16:11,169 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 11452936-83cb-47e1-bf10-894668a55a8a-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-12 14:16:11,170 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-12 14:16:11,170 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 11452936-83cb-47e1-bf10-894668a55a8a-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-12 14:16:11,170 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-12 14:16:11,170 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-12 14:16:11,170 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15286 (custom)
2025-05-12 14:16:11,170 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:11,170 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-12 14:16:11,170 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:11,171 [11452936-83cb-47e1-bf10-894668a55a8a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaaca7d6b] REGISTERED
2025-05-12 14:16:11,171 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis] (custom)
2025-05-12 14:16:11,171 [11452936-83cb-47e1-bf10-894668a55a8a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaaca7d6b] BIND: 0.0.0.0/0.0.0.0:15286
2025-05-12 14:16:11,171 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-12 14:16:11,171 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-12 14:16:11,171 [11452936-83cb-47e1-bf10-894668a55a8a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaaca7d6b, L:/0.0.0.0:15286] ACTIVE
2025-05-12 14:16:11,171 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - 11452936-83cb-47e1-bf10-894668a55a8a: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/tmp
2025-05-12 14:16:11,172 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - 11452936-83cb-47e1-bf10-894668a55a8a: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2025-05-12 14:16:11,172 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-12 14:16:11,172 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-12 14:16:11,173 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-12 14:16:11,174 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-12 14:16:11,175 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15280
2025-05-12 14:16:11,175 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-12 14:16:11,176 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-12 14:16:11,178 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-12 14:16:11,178 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-12 14:16:11,178 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-12 14:16:11,178 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-12 14:16:11,178 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/meta/webserver
2025-05-12 14:16:11,178 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15280
2025-05-12 14:16:11,178 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-12 14:16:11,180 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-12 14:16:11,180 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-12 14:16:11,180 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-12 14:16:11,180 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@47bc6e24{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-12 14:16:11,180 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2236ff0a{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-12 14:16:11,308 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3401e335{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/meta/webserver/jetty-0_0_0_0-15280-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-10613166247017015443/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:11,308 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7b8faa17{HTTP/1.1, (http/1.1)}{0.0.0.0:15280}
2025-05-12 14:16:11,308 [main] INFO  server.Server (Server.java:doStart(415)) - Started @276851ms
2025-05-12 14:16:11,309 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-12 14:16:11,309 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15280
2025-05-12 14:16:11,309 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:16:11,309 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15281
2025-05-12 14:16:11,310 [Socket Reader #1 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15281
2025-05-12 14:16:11,310 [Socket Reader #2 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15281
2025-05-12 14:16:11,310 [Socket Reader #3 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15281
2025-05-12 14:16:11,310 [Socket Reader #4 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15281
2025-05-12 14:16:11,310 [Socket Reader #5 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15281
2025-05-12 14:16:11,311 [Socket Reader #6 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15281
2025-05-12 14:16:11,311 [Socket Reader #7 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15281
2025-05-12 14:16:11,311 [Socket Reader #8 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15281
2025-05-12 14:16:11,311 [Socket Reader #9 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15281
2025-05-12 14:16:11,311 [Socket Reader #10 for port 15281] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15281
2025-05-12 14:16:11,312 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-12 14:16:11,313 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15281
2025-05-12 14:16:11,313 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:16:11,313 [IPC Server listener on 15281] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15281: starting
2025-05-12 14:16:11,314 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:11,314 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:11,314 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-12 14:16:11,315 [11452936-83cb-47e1-bf10-894668a55a8a-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-12 14:16:11,315 [11452936-83cb-47e1-bf10-894668a55a8a-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-12 14:16:11,318 [11452936-83cb-47e1-bf10-894668a55a8a-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/meta/datanode.id
2025-05-12 14:16:11,325 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode c4cac530-e369-4db2-afb8-073a8db2a7dc(pkrvmberfyhpb9w.internal.cloudapp.net/null) to 10.1.0.72
2025-05-12 14:16:11,325 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService c4cac530-e369-4db2-afb8-073a8db2a7dc(pkrvmberfyhpb9w.internal.cloudapp.net/10.1.0.72)
2025-05-12 14:16:11,326 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-12 14:16:11,326 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-12 14:16:11,328 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-ee8c2361-daad-4d93-875e-080866ad18ea dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-12 14:16:11,328 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds to VolumeSet
2025-05-12 14:16:11,328 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis to VolumeSet
2025-05-12 14:16:11,329 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-05-12 14:16:11,329 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:11,329 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:11,340 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:11,340 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:11,341 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:11,342 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15292 (custom)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15291 (custom)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15293 (custom)
2025-05-12 14:16:11,342 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-12 14:16:11,342 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-12 14:16:11,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:16:11,342 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-12 14:16:11,342 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-12 14:16:11,343 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-12 14:16:11,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-12 14:16:11,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-12 14:16:11,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-12 14:16:11,344 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-12 14:16:11,344 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-12 14:16:11,344 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-12 14:16:11,344 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-12 14:16:11,344 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for c4cac530-e369-4db2-afb8-073a8db2a7dc-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-12 14:16:11,344 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-12 14:16:11,344 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for c4cac530-e369-4db2-afb8-073a8db2a7dc-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-12 14:16:11,345 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-12 14:16:11,345 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-12 14:16:11,345 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15294 (custom)
2025-05-12 14:16:11,345 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:11,345 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-12 14:16:11,345 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:11,345 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis] (custom)
2025-05-12 14:16:11,346 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-12 14:16:11,346 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-12 14:16:11,345 [c4cac530-e369-4db2-afb8-073a8db2a7dc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1125e196] REGISTERED
2025-05-12 14:16:11,346 [c4cac530-e369-4db2-afb8-073a8db2a7dc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1125e196] BIND: 0.0.0.0/0.0.0.0:15294
2025-05-12 14:16:11,346 [c4cac530-e369-4db2-afb8-073a8db2a7dc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1125e196, L:/0.0.0.0:15294] ACTIVE
2025-05-12 14:16:11,346 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/tmp
2025-05-12 14:16:11,346 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/tmp is not a group directory; ignoring it. 
2025-05-12 14:16:11,346 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-12 14:16:11,347 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-12 14:16:11,348 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-12 14:16:11,348 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-12 14:16:11,349 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15288
2025-05-12 14:16:11,349 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-12 14:16:11,350 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-12 14:16:11,351 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-12 14:16:11,352 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-12 14:16:11,352 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-12 14:16:11,352 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-12 14:16:11,352 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/meta/webserver
2025-05-12 14:16:11,353 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15288
2025-05-12 14:16:11,353 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-12 14:16:11,354 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-12 14:16:11,354 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-12 14:16:11,354 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-05-12 14:16:11,355 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@25e41605{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-12 14:16:11,355 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7bca50a3{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-12 14:16:11,486 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@52f7de61{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/meta/webserver/jetty-0_0_0_0-15288-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-11211693300978133172/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:11,486 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2e2acb42{HTTP/1.1, (http/1.1)}{0.0.0.0:15288}
2025-05-12 14:16:11,487 [main] INFO  server.Server (Server.java:doStart(415)) - Started @277029ms
2025-05-12 14:16:11,487 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-12 14:16:11,487 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15288
2025-05-12 14:16:11,487 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:16:11,488 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15289
2025-05-12 14:16:11,488 [Socket Reader #1 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15289
2025-05-12 14:16:11,488 [Socket Reader #2 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15289
2025-05-12 14:16:11,488 [Socket Reader #3 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15289
2025-05-12 14:16:11,489 [Socket Reader #4 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15289
2025-05-12 14:16:11,489 [Socket Reader #5 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15289
2025-05-12 14:16:11,489 [Socket Reader #6 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15289
2025-05-12 14:16:11,489 [Socket Reader #7 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15289
2025-05-12 14:16:11,489 [Socket Reader #8 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15289
2025-05-12 14:16:11,490 [Socket Reader #9 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15289
2025-05-12 14:16:11,490 [Socket Reader #10 for port 15289] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15289
2025-05-12 14:16:11,491 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-12 14:16:11,491 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15289
2025-05-12 14:16:11,492 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:16:11,492 [IPC Server listener on 15289] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15289: starting
2025-05-12 14:16:11,493 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:11,493 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:11,493 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-12 14:16:11,494 [c4cac530-e369-4db2-afb8-073a8db2a7dc-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-12 14:16:11,494 [c4cac530-e369-4db2-afb8-073a8db2a7dc-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-12 14:16:11,497 [c4cac530-e369-4db2-afb8-073a8db2a7dc-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/meta/datanode.id
2025-05-12 14:16:11,504 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode de559106-0595-44cd-a7e8-c94ad5654e48(pkrvmberfyhpb9w.internal.cloudapp.net/null) to 10.1.0.72
2025-05-12 14:16:11,504 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService de559106-0595-44cd-a7e8-c94ad5654e48(pkrvmberfyhpb9w.internal.cloudapp.net/10.1.0.72)
2025-05-12 14:16:11,506 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-12 14:16:11,506 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-12 14:16:11,508 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-773fe21f-49f6-4858-ac7f-e3b0ceb73f29 dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-12 14:16:11,508 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds to VolumeSet
2025-05-12 14:16:11,509 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis to VolumeSet
2025-05-12 14:16:11,509 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-05-12 14:16:11,509 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:11,510 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:11,521 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:11,521 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:11,522 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:11,523 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-12 14:16:11,523 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:11,523 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15300 (custom)
2025-05-12 14:16:11,523 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:11,523 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15299 (custom)
2025-05-12 14:16:11,523 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-12 14:16:11,523 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15301 (custom)
2025-05-12 14:16:11,523 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-12 14:16:11,523 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-12 14:16:11,524 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:11,524 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:16:11,524 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:11,524 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-12 14:16:11,524 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-12 14:16:11,525 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-12 14:16:11,525 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-12 14:16:11,525 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-12 14:16:11,525 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-12 14:16:11,525 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-12 14:16:11,526 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-12 14:16:11,526 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-12 14:16:11,526 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-12 14:16:11,526 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for de559106-0595-44cd-a7e8-c94ad5654e48-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-12 14:16:11,526 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-12 14:16:11,526 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for de559106-0595-44cd-a7e8-c94ad5654e48-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-12 14:16:11,526 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-12 14:16:11,527 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-12 14:16:11,527 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15302 (custom)
2025-05-12 14:16:11,527 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:11,527 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-12 14:16:11,527 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:11,527 [de559106-0595-44cd-a7e8-c94ad5654e48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a96ce83] REGISTERED
2025-05-12 14:16:11,527 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis] (custom)
2025-05-12 14:16:11,527 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-12 14:16:11,528 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-12 14:16:11,527 [de559106-0595-44cd-a7e8-c94ad5654e48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a96ce83] BIND: 0.0.0.0/0.0.0.0:15302
2025-05-12 14:16:11,528 [de559106-0595-44cd-a7e8-c94ad5654e48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a96ce83, L:/0.0.0.0:15302] ACTIVE
2025-05-12 14:16:11,529 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - de559106-0595-44cd-a7e8-c94ad5654e48: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/tmp
2025-05-12 14:16:11,529 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - de559106-0595-44cd-a7e8-c94ad5654e48: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/tmp is not a group directory; ignoring it. 
2025-05-12 14:16:11,529 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-12 14:16:11,530 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-12 14:16:11,530 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-12 14:16:11,531 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-12 14:16:11,532 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15296
2025-05-12 14:16:11,532 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-12 14:16:11,533 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-12 14:16:11,534 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-12 14:16:11,535 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-12 14:16:11,535 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-12 14:16:11,535 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-12 14:16:11,535 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/meta/webserver
2025-05-12 14:16:11,536 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15296
2025-05-12 14:16:11,536 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-12 14:16:11,537 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-12 14:16:11,537 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-12 14:16:11,537 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-05-12 14:16:11,538 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2cfdce9e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-12 14:16:11,538 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@30e6148f{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-12 14:16:11,545 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 9 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 9.
2025-05-12 14:16:11,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:11,666 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@131dc42b{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/meta/webserver/jetty-0_0_0_0-15296-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-16712819574639671996/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:11,667 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3a6d0b0f{HTTP/1.1, (http/1.1)}{0.0.0.0:15296}
2025-05-12 14:16:11,667 [main] INFO  server.Server (Server.java:doStart(415)) - Started @277209ms
2025-05-12 14:16:11,667 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-12 14:16:11,667 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15296
2025-05-12 14:16:11,668 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:16:11,668 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15297
2025-05-12 14:16:11,668 [Socket Reader #1 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15297
2025-05-12 14:16:11,668 [Socket Reader #2 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15297
2025-05-12 14:16:11,669 [Socket Reader #3 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15297
2025-05-12 14:16:11,669 [Socket Reader #4 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15297
2025-05-12 14:16:11,669 [Socket Reader #5 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15297
2025-05-12 14:16:11,669 [Socket Reader #6 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15297
2025-05-12 14:16:11,669 [Socket Reader #7 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15297
2025-05-12 14:16:11,669 [Socket Reader #8 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15297
2025-05-12 14:16:11,669 [Socket Reader #9 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15297
2025-05-12 14:16:11,670 [Socket Reader #10 for port 15297] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15297
2025-05-12 14:16:11,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8/container.db to cache
2025-05-12 14:16:11,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8/container.db for volume DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8
2025-05-12 14:16:11,671 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-12 14:16:11,671 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15297
2025-05-12 14:16:11,671 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:16:11,672 [IPC Server listener on 15297] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15297: starting
2025-05-12 14:16:11,673 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds
2025-05-12 14:16:11,673 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds
2025-05-12 14:16:11,673 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-12 14:16:11,673 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds
2025-05-12 14:16:11,673 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:11,673 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-05-12 14:16:11,674 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2025-05-12 14:16:11,674 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds
2025-05-12 14:16:11,674 [de559106-0595-44cd-a7e8-c94ad5654e48-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-12 14:16:11,675 [de559106-0595-44cd-a7e8-c94ad5654e48-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-12 14:16:11,678 [de559106-0595-44cd-a7e8-c94ad5654e48-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/meta/datanode.id
2025-05-12 14:16:11,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis
2025-05-12 14:16:11,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis
2025-05-12 14:16:11,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-12 14:16:11,679 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:11,679 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:11,679 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15279
2025-05-12 14:16:11,680 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a)
2025-05-12 14:16:11,680 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: start RPC server
2025-05-12 14:16:11,680 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: GrpcService started, listening on 15275
2025-05-12 14:16:11,681 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: GrpcService started, listening on 15277
2025-05-12 14:16:11,681 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: GrpcService started, listening on 15276
2025-05-12 14:16:11,681 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a) is started using port RATIS=15275
2025-05-12 14:16:11,681 [JvmPauseMonitor49] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: Started
2025-05-12 14:16:11,681 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a) is started using port RATIS_ADMIN=15276
2025-05-12 14:16:11,681 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a) is started using port RATIS_SERVER=15277
2025-05-12 14:16:11,681 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a) is started using port RATIS_DATASTREAM=15278
2025-05-12 14:16:11,682 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-12 14:16:11,686 [main] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(199)) - Updating IP address of datanode d6468b48-4b84-4546-9e40-0ea0f44d9603(pkrvmberfyhpb9w.internal.cloudapp.net/null) to 10.1.0.72
2025-05-12 14:16:11,686 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(234)) - HddsDatanodeService d6468b48-4b84-4546-9e40-0ea0f44d9603(pkrvmberfyhpb9w.internal.cloudapp.net/10.1.0.72)
2025-05-12 14:16:11,687 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-05-12 14:16:11,688 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(298)) - Datanode State Machine Task Thread Pool size 2
2025-05-12 14:16:11,689 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(158)) - HddsVolume: { id=DS-78fe2ad2-5188-487e-8229-5d04aa843a9d dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=5368709120 committed=0 }
2025-05-12 14:16:11,689 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2025-05-12 14:16:11,690 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(166)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis to VolumeSet
2025-05-12 14:16:11,690 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-05-12 14:16:11,691 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:11,691 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-05-12 14:16:11,701 [main] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(79)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:11,701 [main] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(87)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-05-12 14:16:11,702 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:11,702 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15308 (custom)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15307 (custom)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15309 (custom)
2025-05-12 14:16:11,703 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 34603008 (custom)
2025-05-12 14:16:11,703 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-05-12 14:16:11,703 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:16:11,703 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-05-12 14:16:11,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-05-12 14:16:11,705 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2025-05-12 14:16:11,705 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2025-05-12 14:16:11,705 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2025-05-12 14:16:11,705 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2025-05-12 14:16:11,705 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2025-05-12 14:16:11,705 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2025-05-12 14:16:11,705 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2025-05-12 14:16:11,705 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2025-05-12 14:16:11,705 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for d6468b48-4b84-4546-9e40-0ea0f44d9603-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-05-12 14:16:11,706 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2025-05-12 14:16:11,706 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for d6468b48-4b84-4546-9e40-0ea0f44d9603-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-05-12 14:16:11,706 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2025-05-12 14:16:11,706 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2025-05-12 14:16:11,706 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15310 (custom)
2025-05-12 14:16:11,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:11,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2025-05-12 14:16:11,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:11,707 [d6468b48-4b84-4546-9e40-0ea0f44d9603-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5530cda0] REGISTERED
2025-05-12 14:16:11,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis] (custom)
2025-05-12 14:16:11,707 [d6468b48-4b84-4546-9e40-0ea0f44d9603-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5530cda0] BIND: 0.0.0.0/0.0.0.0:15310
2025-05-12 14:16:11,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2025-05-12 14:16:11,707 [d6468b48-4b84-4546-9e40-0ea0f44d9603-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5530cda0, L:/0.0.0.0:15310] ACTIVE
2025-05-12 14:16:11,708 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2025-05-12 14:16:11,708 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(265)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/tmp
2025-05-12 14:16:11,708 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(270)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2025-05-12 14:16:11,708 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(84)) - Initializing replication server with thread count = 10 queue length = 4096
2025-05-12 14:16:11,709 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(131)) - GrpcServer channel type EpollServerSocketChannel
2025-05-12 14:16:11,710 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-05-12 14:16:11,710 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-05-12 14:16:11,712 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(229)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15304
2025-05-12 14:16:11,712 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(107)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-05-12 14:16:11,713 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-05-12 14:16:11,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1042)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-05-12 14:16:11,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1018)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-05-12 14:16:11,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-05-12 14:16:11,715 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1026)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-05-12 14:16:11,715 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(195)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/meta/webserver
2025-05-12 14:16:11,715 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1242)) - Jetty bound to port 15304
2025-05-12 14:16:11,715 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.7+6-LTS
2025-05-12 14:16:11,717 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-05-12 14:16:11,717 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-05-12 14:16:11,717 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-05-12 14:16:11,717 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@253c5b81{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-05-12 14:16:11,718 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@651c8a24{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-05-12 14:16:11,844 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57/container.db to cache
2025-05-12 14:16:11,844 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57/container.db for volume DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57
2025-05-12 14:16:11,846 [11452936-83cb-47e1-bf10-894668a55a8a-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds
2025-05-12 14:16:11,846 [11452936-83cb-47e1-bf10-894668a55a8a-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds
2025-05-12 14:16:11,847 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-12 14:16:11,847 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds
2025-05-12 14:16:11,847 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds
2025-05-12 14:16:11,851 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis
2025-05-12 14:16:11,851 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis
2025-05-12 14:16:11,852 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6570ccf9{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/meta/webserver/jetty-0_0_0_0-15304-hdds-container-service-2_1_0-SNAPSHOT_jar-_-any-7341413425068454200/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:11,853 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@755a9b8f{HTTP/1.1, (http/1.1)}{0.0.0.0:15304}
2025-05-12 14:16:11,853 [main] INFO  server.Server (Server.java:doStart(415)) - Started @277395ms
2025-05-12 14:16:11,853 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-05-12 14:16:11,853 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-12 14:16:11,853 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(74)) - Trying to initialize on demand scanner a second time on a datanode.
2025-05-12 14:16:11,854 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(359)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15304
2025-05-12 14:16:11,854 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-05-12 14:16:11,854 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:11,854 [main] INFO  ipc.Server (Server.java:<init>(1438)) - Listener at 0.0.0.0:15305
2025-05-12 14:16:11,855 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:11,855 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15287
2025-05-12 14:16:11,855 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(11452936-83cb-47e1-bf10-894668a55a8a)
2025-05-12 14:16:11,855 [Socket Reader #1 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #1 for port 15305
2025-05-12 14:16:11,855 [Socket Reader #2 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #2 for port 15305
2025-05-12 14:16:11,856 [Socket Reader #3 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #3 for port 15305
2025-05-12 14:16:11,856 [Socket Reader #4 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #4 for port 15305
2025-05-12 14:16:11,857 [Socket Reader #5 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #5 for port 15305
2025-05-12 14:16:11,857 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - 11452936-83cb-47e1-bf10-894668a55a8a: start RPC server
2025-05-12 14:16:11,857 [Socket Reader #6 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #6 for port 15305
2025-05-12 14:16:11,857 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 11452936-83cb-47e1-bf10-894668a55a8a: GrpcService started, listening on 15283
2025-05-12 14:16:11,858 [Socket Reader #7 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #7 for port 15305
2025-05-12 14:16:11,858 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 11452936-83cb-47e1-bf10-894668a55a8a: GrpcService started, listening on 15285
2025-05-12 14:16:11,858 [Socket Reader #8 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #8 for port 15305
2025-05-12 14:16:11,858 [Socket Reader #9 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #9 for port 15305
2025-05-12 14:16:11,858 [Socket Reader #10 for port 15305] INFO  ipc.Server (Server.java:run(1474)) - Starting Socket Reader #10 for port 15305
2025-05-12 14:16:11,859 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - 11452936-83cb-47e1-bf10-894668a55a8a: GrpcService started, listening on 15284
2025-05-12 14:16:11,860 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(11452936-83cb-47e1-bf10-894668a55a8a) is started using port RATIS=15283
2025-05-12 14:16:11,860 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(11452936-83cb-47e1-bf10-894668a55a8a) is started using port RATIS_ADMIN=15284
2025-05-12 14:16:11,860 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(11452936-83cb-47e1-bf10-894668a55a8a) is started using port RATIS_SERVER=15285
2025-05-12 14:16:11,860 [11452936-83cb-47e1-bf10-894668a55a8a-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(11452936-83cb-47e1-bf10-894668a55a8a) is started using port RATIS_DATASTREAM=15286
2025-05-12 14:16:11,860 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-11452936-83cb-47e1-bf10-894668a55a8a: Started
2025-05-12 14:16:11,860 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(325)) - Datanode start with admins: [runner]
2025-05-12 14:16:11,860 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15305
2025-05-12 14:16:11,861 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1713)) - IPC Server Responder: starting
2025-05-12 14:16:11,861 [IPC Server listener on 15305] INFO  ipc.Server (Server.java:run(1553)) - IPC Server listener on 15305: starting
2025-05-12 14:16:11,862 [11452936-83cb-47e1-bf10-894668a55a8a-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-12 14:16:11,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2025-05-12 14:16:11,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for cluster to exit safe mode
2025-05-12 14:16:11,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-12 14:16:11,865 [d6468b48-4b84-4546-9e40-0ea0f44d9603-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(340)) - Ozone container server started.
2025-05-12 14:16:11,865 [d6468b48-4b84-4546-9e40-0ea0f44d9603-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(184)) - Adding Recon Server : /0.0.0.0:15271
2025-05-12 14:16:11,867 [d6468b48-4b84-4546-9e40-0ea0f44d9603-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/meta/datanode.id
2025-05-12 14:16:11,949 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:12,020 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-859dad2e-7827-48aa-8063-996dd404ca30/container.db to cache
2025-05-12 14:16:12,021 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-859dad2e-7827-48aa-8063-996dd404ca30/container.db for volume DS-859dad2e-7827-48aa-8063-996dd404ca30
2025-05-12 14:16:12,022 [c4cac530-e369-4db2-afb8-073a8db2a7dc-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds
2025-05-12 14:16:12,022 [c4cac530-e369-4db2-afb8-073a8db2a7dc-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds
2025-05-12 14:16:12,023 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-12 14:16:12,023 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds
2025-05-12 14:16:12,023 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds
2025-05-12 14:16:12,026 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis
2025-05-12 14:16:12,026 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis
2025-05-12 14:16:12,027 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-12 14:16:12,027 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(74)) - Trying to initialize on demand scanner a second time on a datanode.
2025-05-12 14:16:12,027 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:12,027 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:12,028 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15295
2025-05-12 14:16:12,028 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(c4cac530-e369-4db2-afb8-073a8db2a7dc)
2025-05-12 14:16:12,028 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: start RPC server
2025-05-12 14:16:12,029 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: GrpcService started, listening on 15291
2025-05-12 14:16:12,029 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: GrpcService started, listening on 15293
2025-05-12 14:16:12,029 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: GrpcService started, listening on 15292
2025-05-12 14:16:12,029 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(c4cac530-e369-4db2-afb8-073a8db2a7dc) is started using port RATIS=15291
2025-05-12 14:16:12,029 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(c4cac530-e369-4db2-afb8-073a8db2a7dc) is started using port RATIS_ADMIN=15292
2025-05-12 14:16:12,029 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(c4cac530-e369-4db2-afb8-073a8db2a7dc) is started using port RATIS_SERVER=15293
2025-05-12 14:16:12,029 [c4cac530-e369-4db2-afb8-073a8db2a7dc-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(c4cac530-e369-4db2-afb8-073a8db2a7dc) is started using port RATIS_DATASTREAM=15294
2025-05-12 14:16:12,029 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-c4cac530-e369-4db2-afb8-073a8db2a7dc: Started
2025-05-12 14:16:12,030 [c4cac530-e369-4db2-afb8-073a8db2a7dc-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-12 14:16:12,143 [IPC Server handler 2 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:12,143 [IPC Server handler 1 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:12,144 [IPC Server handler 2 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a{ip: 127.0.0.1, host: localhost, ports: [HTTP=15272, CLIENT_RPC=15273, REPLICATION=15279, RATIS=15275, RATIS_ADMIN=15276, RATIS_SERVER=15277, RATIS_DATASTREAM=15278, STANDALONE=15274], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,144 [IPC Server handler 1 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a{ip: 127.0.0.1, host: localhost, ports: [HTTP=15272, CLIENT_RPC=15273, REPLICATION=15279, RATIS=15275, RATIS_ADMIN=15276, RATIS_SERVER=15277, RATIS_DATASTREAM=15278, STANDALONE=15274], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,144 [IPC Server handler 1 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:12,144 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-12 14:16:12,145 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 to datanode:144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1)
2025-05-12 14:16:12,145 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a to Node DB.
2025-05-12 14:16:12,145 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(79)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2025-05-12 14:16:12,145 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,146 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,146 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 2 millisec, 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1), {type: FCR, size: 0}
2025-05-12 14:16:12,146 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,148 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,148 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:12,148 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,148 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,148 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: a2d07b4d-d13e-4869-801f-303d3d0838b0, Nodes: [ {144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-12T14:16:12.145063027Z[Etc/UTC]}
2025-05-12 14:16:12,202 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db to cache
2025-05-12 14:16:12,202 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db for volume DS-08a093c1-1426-4ba8-9d46-b1b2037bee20
2025-05-12 14:16:12,204 [de559106-0595-44cd-a7e8-c94ad5654e48-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds
2025-05-12 14:16:12,204 [de559106-0595-44cd-a7e8-c94ad5654e48-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds
2025-05-12 14:16:12,204 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-12 14:16:12,204 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds
2025-05-12 14:16:12,205 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds
2025-05-12 14:16:12,207 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-12 14:16:12,207 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis
2025-05-12 14:16:12,208 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis
2025-05-12 14:16:12,208 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-12 14:16:12,208 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(74)) - Trying to initialize on demand scanner a second time on a datanode.
2025-05-12 14:16:12,209 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:12,209 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:12,209 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15303
2025-05-12 14:16:12,209 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(de559106-0595-44cd-a7e8-c94ad5654e48)
2025-05-12 14:16:12,210 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - de559106-0595-44cd-a7e8-c94ad5654e48: start RPC server
2025-05-12 14:16:12,210 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - de559106-0595-44cd-a7e8-c94ad5654e48: GrpcService started, listening on 15299
2025-05-12 14:16:12,210 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - de559106-0595-44cd-a7e8-c94ad5654e48: GrpcService started, listening on 15301
2025-05-12 14:16:12,211 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - de559106-0595-44cd-a7e8-c94ad5654e48: GrpcService started, listening on 15300
2025-05-12 14:16:12,211 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(de559106-0595-44cd-a7e8-c94ad5654e48) is started using port RATIS=15299
2025-05-12 14:16:12,211 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(de559106-0595-44cd-a7e8-c94ad5654e48) is started using port RATIS_ADMIN=15300
2025-05-12 14:16:12,211 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-de559106-0595-44cd-a7e8-c94ad5654e48: Started
2025-05-12 14:16:12,211 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(de559106-0595-44cd-a7e8-c94ad5654e48) is started using port RATIS_SERVER=15301
2025-05-12 14:16:12,211 [de559106-0595-44cd-a7e8-c94ad5654e48-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(de559106-0595-44cd-a7e8-c94ad5654e48) is started using port RATIS_DATASTREAM=15302
2025-05-12 14:16:12,212 [de559106-0595-44cd-a7e8-c94ad5654e48-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-12 14:16:12,316 [IPC Server handler 4 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:12,316 [IPC Server handler 3 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:12,316 [IPC Server handler 4 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: 11452936-83cb-47e1-bf10-894668a55a8a{ip: 127.0.0.1, host: localhost, ports: [HTTP=15280, CLIENT_RPC=15281, REPLICATION=15287, RATIS=15283, RATIS_ADMIN=15284, RATIS_SERVER=15285, RATIS_DATASTREAM=15286, STANDALONE=15282], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,316 [IPC Server handler 3 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: 11452936-83cb-47e1-bf10-894668a55a8a{ip: 127.0.0.1, host: localhost, ports: [HTTP=15280, CLIENT_RPC=15281, REPLICATION=15287, RATIS=15283, RATIS_ADMIN=15284, RATIS_SERVER=15285, RATIS_DATASTREAM=15286, STANDALONE=15282], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,316 [IPC Server handler 3 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:12,316 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(79)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2025-05-12 14:16:12,317 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-12 14:16:12,316 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,317 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node 11452936-83cb-47e1-bf10-894668a55a8a to Node DB.
2025-05-12 14:16:12,317 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,317 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 to datanode:11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1)
2025-05-12 14:16:12,317 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,319 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,319 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:12,319 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,319 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,319 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 80098ea9-029b-4e0e-b39c-b88182d2fac1, Nodes: [ {11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-12T14:16:12.317511500Z[Etc/UTC]}
2025-05-12 14:16:12,393 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-5ac90093-0921-4259-a3a1-cfd6377c774d/container.db to cache
2025-05-12 14:16:12,393 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(510)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-5ac90093-0921-4259-a3a1-cfd6377c774d/container.db for volume DS-5ac90093-0921-4259-a3a1-cfd6377c774d
2025-05-12 14:16:12,395 [d6468b48-4b84-4546-9e40-0ea0f44d9603-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(144)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds
2025-05-12 14:16:12,395 [d6468b48-4b84-4546-9e40-0ea0f44d9603-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(174)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds
2025-05-12 14:16:12,395 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(364)) - Build ContainerSet costs 0s
2025-05-12 14:16:12,395 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds
2025-05-12 14:16:12,396 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds
2025-05-12 14:16:12,400 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis
2025-05-12 14:16:12,400 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(215)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis
2025-05-12 14:16:12,401 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(512)) - Attempting to start container services.
2025-05-12 14:16:12,401 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(74)) - Trying to initialize on demand scanner a second time on a datanode.
2025-05-12 14:16:12,401 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:12,402 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-05-12 14:16:12,402 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(137)) - ReplicationServer is started using port 15311
2025-05-12 14:16:12,402 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(d6468b48-4b84-4546-9e40-0ea0f44d9603)
2025-05-12 14:16:12,403 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(407)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: start RPC server
2025-05-12 14:16:12,403 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: GrpcService started, listening on 15307
2025-05-12 14:16:12,403 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: GrpcService started, listening on 15309
2025-05-12 14:16:12,403 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(334)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: GrpcService started, listening on 15308
2025-05-12 14:16:12,403 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(d6468b48-4b84-4546-9e40-0ea0f44d9603) is started using port RATIS=15307
2025-05-12 14:16:12,403 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(d6468b48-4b84-4546-9e40-0ea0f44d9603) is started using port RATIS_ADMIN=15308
2025-05-12 14:16:12,404 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(d6468b48-4b84-4546-9e40-0ea0f44d9603) is started using port RATIS_SERVER=15309
2025-05-12 14:16:12,404 [d6468b48-4b84-4546-9e40-0ea0f44d9603-EndpointStateMachineTaskThread-/0.0.0.0:15262-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(d6468b48-4b84-4546-9e40-0ea0f44d9603) is started using port RATIS_DATASTREAM=15310
2025-05-12 14:16:12,404 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-d6468b48-4b84-4546-9e40-0ea0f44d9603: Started
2025-05-12 14:16:12,404 [d6468b48-4b84-4546-9e40-0ea0f44d9603-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(83)) - Chosen 0/5000 blocks from 0 candidate containers.
2025-05-12 14:16:12,495 [IPC Server handler 5 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:12,495 [IPC Server handler 14 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:12,495 [IPC Server handler 5 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: c4cac530-e369-4db2-afb8-073a8db2a7dc{ip: 127.0.0.1, host: localhost, ports: [HTTP=15288, CLIENT_RPC=15289, REPLICATION=15295, RATIS=15291, RATIS_ADMIN=15292, RATIS_SERVER=15293, RATIS_DATASTREAM=15294, STANDALONE=15290], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,495 [IPC Server handler 14 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: c4cac530-e369-4db2-afb8-073a8db2a7dc{ip: 127.0.0.1, host: localhost, ports: [HTTP=15288, CLIENT_RPC=15289, REPLICATION=15295, RATIS=15291, RATIS_ADMIN=15292, RATIS_SERVER=15293, RATIS_DATASTREAM=15294, STANDALONE=15290], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,495 [IPC Server handler 5 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:12,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(79)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2025-05-12 14:16:12,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:12,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(167)) - All SCM safe mode pre check rules have passed
2025-05-12 14:16:12,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-05-12 14:16:12,496 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-12 14:16:12,496 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,496 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,496 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,496 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node c4cac530-e369-4db2-afb8-073a8db2a7dc to Node DB.
2025-05-12 14:16:12,496 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-12 14:16:12,496 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 to datanode:c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:12,498 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:12,498 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,498 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:12,498 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,498 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,498 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 1c927b84-b3e1-463b-ba8c-ffa6453324d9, Nodes: [ {c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-12T14:16:12.496651489Z[Etc/UTC]}
2025-05-12 14:16:12,498 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 to datanode:144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1)
2025-05-12 14:16:12,498 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 to datanode:c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:12,498 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 to datanode:11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1)
2025-05-12 14:16:12,499 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:12,499 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,499 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:12,500 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,500 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,500 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 37cd9420-6324-41d7-8689-4a19e22733c5, Nodes: [ {144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1), ReplicaIndex: 0}, {c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), ReplicaIndex: 0}, {11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-12T14:16:12.498805259Z[Etc/UTC]}
2025-05-12 14:16:12,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:12,643 [IPC Server handler 6 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-12 14:16:12,644 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,676 [IPC Server handler 12 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/de559106-0595-44cd-a7e8-c94ad5654e48
2025-05-12 14:16:12,676 [IPC Server handler 7 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/de559106-0595-44cd-a7e8-c94ad5654e48
2025-05-12 14:16:12,676 [IPC Server handler 12 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: de559106-0595-44cd-a7e8-c94ad5654e48{ip: 127.0.0.1, host: localhost, ports: [HTTP=15296, CLIENT_RPC=15297, REPLICATION=15303, RATIS=15299, RATIS_ADMIN=15300, RATIS_SERVER=15301, RATIS_DATASTREAM=15302, STANDALONE=15298], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,676 [IPC Server handler 7 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: de559106-0595-44cd-a7e8-c94ad5654e48{ip: 127.0.0.1, host: localhost, ports: [HTTP=15296, CLIENT_RPC=15297, REPLICATION=15303, RATIS=15299, RATIS_ADMIN=15300, RATIS_SERVER=15301, RATIS_DATASTREAM=15302, STANDALONE=15298], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,676 [IPC Server handler 7 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:12,676 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-12 14:16:12,676 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,676 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:12,677 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,677 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,677 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node de559106-0595-44cd-a7e8-c94ad5654e48 to Node DB.
2025-05-12 14:16:12,677 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 to datanode:de559106-0595-44cd-a7e8-c94ad5654e48(localhost/127.0.0.1)
2025-05-12 14:16:12,678 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:12,679 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,679 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:12,679 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,679 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,679 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: ebcc11cb-261b-4635-a8cc-c4f7b421a0f8, Nodes: [ {de559106-0595-44cd-a7e8-c94ad5654e48(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-12T14:16:12.677277996Z[Etc/UTC]}
2025-05-12 14:16:12,816 [IPC Server handler 8 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-12 14:16:12,816 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,818 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:12,822 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-12 14:16:12,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Waiting for nodes to be ready. Got 4 of 5 DN Heartbeats.
2025-05-12 14:16:12,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for cluster to exit safe mode
2025-05-12 14:16:12,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-12 14:16:12,866 [IPC Server handler 9 on default port 15271] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/d6468b48-4b84-4546-9e40-0ea0f44d9603
2025-05-12 14:16:12,866 [IPC Server handler 1 on default port 15262] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/d6468b48-4b84-4546-9e40-0ea0f44d9603
2025-05-12 14:16:12,867 [IPC Server handler 1 on default port 15262] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: d6468b48-4b84-4546-9e40-0ea0f44d9603{ip: 127.0.0.1, host: localhost, ports: [HTTP=15304, CLIENT_RPC=15305, REPLICATION=15311, RATIS=15307, RATIS_ADMIN=15308, RATIS_SERVER=15309, RATIS_DATASTREAM=15310, STANDALONE=15306], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,866 [IPC Server handler 9 on default port 15271] INFO  node.SCMNodeManager (SCMNodeManager.java:register(426)) - Registered datanode: d6468b48-4b84-4546-9e40-0ea0f44d9603{ip: 127.0.0.1, host: localhost, ports: [HTTP=15304, CLIENT_RPC=15305, REPLICATION=15311, RATIS=15307, RATIS_ADMIN=15308, RATIS_SERVER=15309, RATIS_DATASTREAM=15310, STANDALONE=15306], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-05-12 14:16:12,867 [IPC Server handler 9 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:12,867 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:12,867 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,867 [EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,867 [EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,867 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on RatisPipelineUtilsThread.
2025-05-12 14:16:12,868 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(148)) - Adding new node d6468b48-4b84-4546-9e40-0ea0f44d9603 to Node DB.
2025-05-12 14:16:12,868 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 to datanode:d6468b48-4b84-4546-9e40-0ea0f44d9603(localhost/127.0.0.1)
2025-05-12 14:16:12,870 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:12,870 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,870 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:12,870 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:12,870 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,871 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: de4019d5-adfb-4cd2-85ea-cdc12ea84350, Nodes: [ {d6468b48-4b84-4546-9e40-0ea0f44d9603(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-12T14:16:12.868529754Z[Etc/UTC]}
2025-05-12 14:16:12,953 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:12,995 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:12,995 [IPC Server handler 0 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-12 14:16:13,176 [IPC Server handler 2 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-12 14:16:13,366 [IPC Server handler 4 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for localhost
2025-05-12 14:16:13,366 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:13,546 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 10 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 10.
2025-05-12 14:16:13,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:13,642 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:13,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2025-05-12 14:16:13,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for cluster to exit safe mode
2025-05-12 14:16:13,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-12 14:16:13,956 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:14,176 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,208 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2025-05-12 14:16:14,367 [d6468b48-4b84-4546-9e40-0ea0f44d9603-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: addNew group-CDC12EA84350:[d6468b48-4b84-4546-9e40-0ea0f44d9603|127.0.0.1:15309] returns group-CDC12EA84350:java.util.concurrent.CompletableFuture@7a03efa3[Not completed]
2025-05-12 14:16:14,367 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,368 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: new RaftServerImpl for group-CDC12EA84350:[d6468b48-4b84-4546-9e40-0ea0f44d9603|127.0.0.1:15309] with ContainerStateMachine:uninitialized
2025-05-12 14:16:14,368 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:14,368 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:16:14,368 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:16:14,368 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-12 14:16:14,368 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: ConfigurationManager, init=conf: {index: -1, cur=peers:[d6468b48-4b84-4546-9e40-0ea0f44d9603|127.0.0.1:15309]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:16:14,369 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis] (custom)
2025-05-12 14:16:14,372 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/de4019d5-adfb-4cd2-85ea-cdc12ea84350 does not exist. Creating ...
2025-05-12 14:16:14,373 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/de4019d5-adfb-4cd2-85ea-cdc12ea84350/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:16:14,374 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/de4019d5-adfb-4cd2-85ea-cdc12ea84350 has been successfully formatted.
2025-05-12 14:16:14,374 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: initialize group-CDC12EA84350
2025-05-12 14:16:14,374 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-CDC12EA84350: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-12 14:16:14,375 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:16:14,375 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:16:14,375 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,375 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:16:14,375 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:16:14,375 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,376 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,376 [IPC Server handler 5 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-12 14:16:14,377 [IPC Server handler 5 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8119,d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/de4019d5-adfb-4cd2-85ea-cdc12ea84350
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,377 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350. Trying to get from SCM.
2025-05-12 14:16:14,377 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:16:14,378 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:16:14,378 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:16:14,378 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:16:14,378 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:14,378 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:14,378 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-12 14:16:14,378 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-12 14:16:14,378 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:14,378 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:14,378 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,379 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350
2025-05-12 14:16:14,379 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: de4019d5-adfb-4cd2-85ea-cdc12ea84350, Nodes: [ {d6468b48-4b84-4546-9e40-0ea0f44d9603(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:d6468b48-4b84-4546-9e40-0ea0f44d9603, CreationTimestamp2025-05-12T14:16:12.868Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-12 14:16:14,379 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:14,383 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,383 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:16:14,383 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:16:14,383 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-12 14:16:14,383 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,383 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: start as a follower, conf=conf: {index: -1, cur=peers:[d6468b48-4b84-4546-9e40-0ea0f44d9603|127.0.0.1:15309]|listeners:[], old=null}
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: start d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CDC12EA84350,id=d6468b48-4b84-4546-9e40-0ea0f44d9603
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-CDC12EA84350,id=d6468b48-4b84-4546-9e40-0ea0f44d9603
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:14,384 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-12 14:16:14,385 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-12 14:16:14,385 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:16:14,385 [d6468b48-4b84-4546-9e40-0ea0f44d9603-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: Successfully started.
2025-05-12 14:16:14,385 [d6468b48-4b84-4546-9e40-0ea0f44d9603-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350
2025-05-12 14:16:14,385 [d6468b48-4b84-4546-9e40-0ea0f44d9603-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350.
2025-05-12 14:16:14,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:14,643 [IPC Server handler 6 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-12 14:16:14,643 [IPC Server handler 6 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:14,643 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: addNew group-303D3D0838B0:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277] returns group-303D3D0838B0:java.util.concurrent.CompletableFuture@11bf1753[Not completed]
2025-05-12 14:16:14,644 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: new RaftServerImpl for group-303D3D0838B0:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277] with ContainerStateMachine:uninitialized
2025-05-12 14:16:14,644 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:14,644 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:16:14,644 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: ConfigurationManager, init=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:16:14,645 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:16:14,646 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:14,646 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:14,647 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:16:14,647 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:16:14,647 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:16:14,647 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:16:14,647 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:16:14,647 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:16:14,647 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis] (custom)
2025-05-12 14:16:14,647 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/a2d07b4d-d13e-4869-801f-303d3d0838b0 does not exist. Creating ...
2025-05-12 14:16:14,648 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/a2d07b4d-d13e-4869-801f-303d3d0838b0/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:16:14,649 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/a2d07b4d-d13e-4869-801f-303d3d0838b0 has been successfully formatted.
2025-05-12 14:16:14,649 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: initialize group-303D3D0838B0
2025-05-12 14:16:14,649 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-303D3D0838B0: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-12 14:16:14,649 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:16:14,649 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:16:14,649 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,650 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:16:14,650 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:16:14,650 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,650 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0. Trying to get from SCM.
2025-05-12 14:16:14,651 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,651 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:16:14,651 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:16:14,651 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,651 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8126,144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/a2d07b4d-d13e-4869-801f-303d3d0838b0
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-12 14:16:14,652 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: a2d07b4d-d13e-4869-801f-303d3d0838b0, Nodes: [ {144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a, CreationTimestamp2025-05-12T14:16:12.145Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-12 14:16:14,652 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/ONE PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 reported by 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1)
2025-05-12 14:16:14,652 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-12 14:16:14,656 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:14,656 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:14,656 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:14,656 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:14,656 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,656 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0
2025-05-12 14:16:14,657 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:14,658 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,659 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:16:14,659 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:16:14,659 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-12 14:16:14,659 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,659 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,659 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: start as a follower, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277]|listeners:[], old=null}
2025-05-12 14:16:14,659 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:16:14,659 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: start 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-303D3D0838B0,id=144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-303D3D0838B0,id=144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-12 14:16:14,660 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:16:14,661 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: Successfully started.
2025-05-12 14:16:14,661 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0
2025-05-12 14:16:14,661 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0.
2025-05-12 14:16:14,661 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: addNew group-4A19E22733C5:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285] returns group-4A19E22733C5:java.util.concurrent.CompletableFuture@60cdeecc[Not completed]
2025-05-12 14:16:14,662 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: new RaftServerImpl for group-4A19E22733C5:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285] with ContainerStateMachine:uninitialized
2025-05-12 14:16:14,662 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:14,662 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: ConfigurationManager, init=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:16:14,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:16:14,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:14,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:14,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:16:14,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:16:14,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:16:14,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:16:14,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:16:14,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:16:14,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis] (custom)
2025-05-12 14:16:14,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/37cd9420-6324-41d7-8689-4a19e22733c5 does not exist. Creating ...
2025-05-12 14:16:14,667 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:16:14,668 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/37cd9420-6324-41d7-8689-4a19e22733c5 has been successfully formatted.
2025-05-12 14:16:14,668 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: initialize group-4A19E22733C5
2025-05-12 14:16:14,668 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-4A19E22733C5: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-12 14:16:14,668 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:16:14,668 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:16:14,668 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,668 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:16:14,668 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:16:14,669 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5. Trying to get from SCM.
2025-05-12 14:16:14,669 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:16:14,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:16:14,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,670 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,670 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:14,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8130,144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:16:14,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/37cd9420-6324-41d7-8689-4a19e22733c5
2025-05-12 14:16:14,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-12 14:16:14,670 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-12 14:16:14,671 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,671 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:16:14,671 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:16:14,671 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:16:14,671 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:16:14,671 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-12 14:16:14,671 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: 37cd9420-6324-41d7-8689-4a19e22733c5, Nodes: [ {144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1), ReplicaIndex: 0}, {c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), ReplicaIndex: 0}, {11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-12T14:16:12.498Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-12 14:16:14,671 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 reported by 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1)
2025-05-12 14:16:14,671 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-12 14:16:14,677 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,677 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:16:14,677 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:16:14,677 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-12 14:16:14,677 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,677 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: start as a follower, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: start 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A19E22733C5,id=144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-4A19E22733C5,id=144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:16:14,678 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:14,679 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: Successfully started.
2025-05-12 14:16:14,679 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5
2025-05-12 14:16:14,686 [grpc-default-executor-6] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: addNew group-4A19E22733C5:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285] returns group-4A19E22733C5:java.util.concurrent.CompletableFuture@244459a7[Not completed]
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: new RaftServerImpl for group-4A19E22733C5:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285] with ContainerStateMachine:uninitialized
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: ConfigurationManager, init=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:16:14,687 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis] (custom)
2025-05-12 14:16:14,689 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/37cd9420-6324-41d7-8689-4a19e22733c5 does not exist. Creating ...
2025-05-12 14:16:14,690 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:16:14,691 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/37cd9420-6324-41d7-8689-4a19e22733c5 has been successfully formatted.
2025-05-12 14:16:14,691 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: initialize group-4A19E22733C5
2025-05-12 14:16:14,691 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-4A19E22733C5: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-12 14:16:14,692 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:16:14,692 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:16:14,692 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,692 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:16:14,692 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:16:14,692 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,693 [IPC Server handler 9 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-12 14:16:14,693 [IPC Server handler 9 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:14,693 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,693 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 reported by c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:14,693 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:16:14,693 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:16:14,693 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,693 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8135,c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:16:14,693 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/37cd9420-6324-41d7-8689-4a19e22733c5
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-12 14:16:14,694 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-12 14:16:14,698 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,698 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:16:14,698 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:16:14,698 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: start as a follower, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: start c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A19E22733C5,id=c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-4A19E22733C5,id=c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:16:14,699 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:16:14,700 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-12 14:16:14,700 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-12 14:16:14,700 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:16:14,700 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: Successfully started.
2025-05-12 14:16:14,709 [grpc-default-executor-6] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 11452936-83cb-47e1-bf10-894668a55a8a: addNew group-4A19E22733C5:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285] returns group-4A19E22733C5:java.util.concurrent.CompletableFuture@27bd0abd[Not completed]
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 11452936-83cb-47e1-bf10-894668a55a8a: new RaftServerImpl for group-4A19E22733C5:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285] with ContainerStateMachine:uninitialized
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: ConfigurationManager, init=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:16:14,710 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis] (custom)
2025-05-12 14:16:14,712 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/37cd9420-6324-41d7-8689-4a19e22733c5 does not exist. Creating ...
2025-05-12 14:16:14,713 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:16:14,714 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/37cd9420-6324-41d7-8689-4a19e22733c5 has been successfully formatted.
2025-05-12 14:16:14,714 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 11452936-83cb-47e1-bf10-894668a55a8a: initialize group-4A19E22733C5
2025-05-12 14:16:14,714 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-4A19E22733C5: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-12 14:16:14,714 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:16:14,714 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:16:14,714 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,714 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:16:14,714 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:16:14,715 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,715 [IPC Server handler 10 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-12 14:16:14,716 [IPC Server handler 10 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:14,716 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,716 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 reported by 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1)
2025-05-12 14:16:14,716 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:16:14,716 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8143,11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/37cd9420-6324-41d7-8689-4a19e22733c5
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-12 14:16:14,717 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-12 14:16:14,722 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,722 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:16:14,722 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:16:14,722 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-12 14:16:14,722 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,722 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: start as a follower, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 11452936-83cb-47e1-bf10-894668a55a8a: start 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A19E22733C5,id=11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-4A19E22733C5,id=11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-12 14:16:14,723 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:16:14,724 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: Successfully started.
2025-05-12 14:16:14,726 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5.
2025-05-12 14:16:14,816 [11452936-83cb-47e1-bf10-894668a55a8a-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 11452936-83cb-47e1-bf10-894668a55a8a: addNew group-B88182D2FAC1:[11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285] returns group-B88182D2FAC1:java.util.concurrent.CompletableFuture@d67efad[Not completed]
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - 11452936-83cb-47e1-bf10-894668a55a8a: new RaftServerImpl for group-B88182D2FAC1:[11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285] with ContainerStateMachine:uninitialized
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: ConfigurationManager, init=conf: {index: -1, cur=peers:[11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:16:14,817 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis] (custom)
2025-05-12 14:16:14,819 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/80098ea9-029b-4e0e-b39c-b88182d2fac1 does not exist. Creating ...
2025-05-12 14:16:14,820 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/80098ea9-029b-4e0e-b39c-b88182d2fac1/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:16:14,821 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/80098ea9-029b-4e0e-b39c-b88182d2fac1 has been successfully formatted.
2025-05-12 14:16:14,821 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 11452936-83cb-47e1-bf10-894668a55a8a: initialize group-B88182D2FAC1
2025-05-12 14:16:14,821 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-B88182D2FAC1: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-12 14:16:14,821 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:16:14,821 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:16:14,821 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,821 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:16:14,821 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:16:14,822 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,822 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1. Trying to get from SCM.
2025-05-12 14:16:14,822 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,822 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,823 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8151,11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/80098ea9-029b-4e0e-b39c-b88182d2fac1
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-12 14:16:14,823 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-12 14:16:14,823 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-12 14:16:14,824 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:14,824 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: 80098ea9-029b-4e0e-b39c-b88182d2fac1, Nodes: [ {11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:11452936-83cb-47e1-bf10-894668a55a8a, CreationTimestamp2025-05-12T14:16:12.317Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-12 14:16:14,825 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/ONE PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 reported by 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1)
2025-05-12 14:16:14,825 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 reported by 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1)
2025-05-12 14:16:14,825 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:14,825 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:14,825 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:14,825 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:14,826 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1
2025-05-12 14:16:14,826 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:14,828 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:14,828 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: start as a follower, conf=conf: {index: -1, cur=peers:[11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 11452936-83cb-47e1-bf10-894668a55a8a: start 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B88182D2FAC1,id=11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-B88182D2FAC1,id=11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-12 14:16:14,829 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:16:14,830 [11452936-83cb-47e1-bf10-894668a55a8a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: Successfully started.
2025-05-12 14:16:14,830 [11452936-83cb-47e1-bf10-894668a55a8a-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1
2025-05-12 14:16:14,830 [11452936-83cb-47e1-bf10-894668a55a8a-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1.
2025-05-12 14:16:14,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2025-05-12 14:16:14,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for cluster to exit safe mode
2025-05-12 14:16:14,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-12 14:16:14,973 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:14,995 [c4cac530-e369-4db2-afb8-073a8db2a7dc-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: addNew group-FFA6453324D9:[c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293] returns group-FFA6453324D9:java.util.concurrent.CompletableFuture@5cfc0d2[Not completed]
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: new RaftServerImpl for group-FFA6453324D9:[c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293] with ContainerStateMachine:uninitialized
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: ConfigurationManager, init=conf: {index: -1, cur=peers:[c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:16:14,996 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis] (custom)
2025-05-12 14:16:14,998 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/1c927b84-b3e1-463b-ba8c-ffa6453324d9 does not exist. Creating ...
2025-05-12 14:16:14,999 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/1c927b84-b3e1-463b-ba8c-ffa6453324d9/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:16:15,000 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/1c927b84-b3e1-463b-ba8c-ffa6453324d9 has been successfully formatted.
2025-05-12 14:16:15,000 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: initialize group-FFA6453324D9
2025-05-12 14:16:15,000 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-FFA6453324D9: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-12 14:16:15,000 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:16:15,000 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:16:15,000 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:15,000 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:16:15,000 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:16:15,001 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,001 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 reported by c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:15,002 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9. Trying to get from SCM.
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8158,c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/1c927b84-b3e1-463b-ba8c-ffa6453324d9
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:16:15,002 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:16:15,003 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:16:15,003 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-12 14:16:15,003 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-12 14:16:15,004 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: 1c927b84-b3e1-463b-ba8c-ffa6453324d9, Nodes: [ {c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c4cac530-e369-4db2-afb8-073a8db2a7dc, CreationTimestamp2025-05-12T14:16:12.496Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-12 14:16:15,004 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/ONE PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 reported by c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:15,005 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:15,005 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:15,006 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:15,007 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:15,007 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,007 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9
2025-05-12 14:16:15,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: start as a follower, conf=conf: {index: -1, cur=peers:[c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293]|listeners:[], old=null}
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:16:15,009 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: start c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FFA6453324D9,id=c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-FFA6453324D9,id=c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: Successfully started.
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9
2025-05-12 14:16:15,010 [c4cac530-e369-4db2-afb8-073a8db2a7dc-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9.
2025-05-12 14:16:15,176 [de559106-0595-44cd-a7e8-c94ad5654e48-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - de559106-0595-44cd-a7e8-c94ad5654e48: addNew group-C4F7B421A0F8:[de559106-0595-44cd-a7e8-c94ad5654e48|127.0.0.1:15301] returns group-C4F7B421A0F8:java.util.concurrent.CompletableFuture@7d8be17a[Not completed]
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(255)) - de559106-0595-44cd-a7e8-c94ad5654e48: new RaftServerImpl for group-C4F7B421A0F8:[de559106-0595-44cd-a7e8-c94ad5654e48|127.0.0.1:15301] with ContainerStateMachine:uninitialized
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(114)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: ConfigurationManager, init=conf: {index: -1, cur=peers:[de559106-0595-44cd-a7e8-c94ad5654e48|127.0.0.1:15301]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2025-05-12 14:16:15,177 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-05-12 14:16:15,178 [IPC Server handler 3 on default port 15271] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for localhost
2025-05-12 14:16:15,178 [IPC Server handler 3 on default port 15271] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(76)) - Update healthStatus of Recon from true to true.
2025-05-12 14:16:15,179 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(251)) - Event remained in queue for long time 2 millisec, de559106-0595-44cd-a7e8-c94ad5654e48(localhost/127.0.0.1), {type: FCR, size: 0}
2025-05-12 14:16:15,179 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 2 millisec, de559106-0595-44cd-a7e8-c94ad5654e48(localhost/127.0.0.1), {type: FCR, size: 0}
2025-05-12 14:16:15,179 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,179 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(66)) - Unknown pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8. Trying to get from SCM.
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2025-05-12 14:16:15,180 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis] (custom)
2025-05-12 14:16:15,181 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(85)) - Pipeline Pipeline{ Id: ebcc11cb-261b-4635-a8cc-c4f7b421a0f8, Nodes: [ {de559106-0595-44cd-a7e8-c94ad5654e48(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-05-12T14:16:12.677Z[Etc/UTC]} verified from SCM and added to Recon pipeline metadata.
2025-05-12 14:16:15,181 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/ONE PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 reported by de559106-0595-44cd-a7e8-c94ad5654e48(localhost/127.0.0.1)
2025-05-12 14:16:15,181 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 does not exist. Creating ...
2025-05-12 14:16:15,181 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/ebcc11cb-261b-4635-a8cc-c4f7b421a0f8/in_use.lock acquired by nodename 53750@pkrvmberfyhpb9w
2025-05-12 14:16:15,182 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 has been successfully formatted.
2025-05-12 14:16:15,183 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - de559106-0595-44cd-a7e8-c94ad5654e48: initialize group-C4F7B421A0F8
2025-05-12 14:16:15,183 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-C4F7B421A0F8: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2025-05-12 14:16:15,183 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2025-05-12 14:16:15,183 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2025-05-12 14:16:15,183 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:15,183 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-05-12 14:16:15,183 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2025-05-12 14:16:15,184 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,184 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:15,184 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#8164,de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-cacheEviction-AwaitToRun,5,main] started
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(188)) - new de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/ebcc11cb-261b-4635-a8cc-c4f7b421a0f8
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-05-12 14:16:15,185 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:15,185 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:15,186 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-05-12 14:16:15,186 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:15,186 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,185 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-05-12 14:16:15,186 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8
2025-05-12 14:16:15,186 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(139)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(391)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: start as a follower, conf=conf: {index: -1, cur=peers:[de559106-0595-44cd-a7e8-c94ad5654e48|127.0.0.1:15301]|listeners:[], old=null}
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-05-12 14:16:15,190 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - de559106-0595-44cd-a7e8-c94ad5654e48: start de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C4F7B421A0F8,id=de559106-0595-44cd-a7e8-c94ad5654e48
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-C4F7B421A0F8,id=de559106-0595-44cd-a7e8-c94ad5654e48
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-05-12 14:16:15,191 [de559106-0595-44cd-a7e8-c94ad5654e48-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(405)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: Successfully started.
2025-05-12 14:16:15,192 [de559106-0595-44cd-a7e8-c94ad5654e48-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(843)) - Created group PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8
2025-05-12 14:16:15,192 [de559106-0595-44cd-a7e8-c94ad5654e48-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(128)) - Created Pipeline RATIS ONE PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8.
2025-05-12 14:16:15,375 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,375 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:15,503 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1118816896ns, electionTimeout:1118ms
2025-05-12 14:16:15,503 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState
2025-05-12 14:16:15,503 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:16:15,503 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:16:15,503 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: start d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49
2025-05-12 14:16:15,503 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[d6468b48-4b84-4546-9e40-0ea0f44d9603|127.0.0.1:15309]|listeners:[], old=null}
2025-05-12 14:16:15,503 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49 PRE_VOTE round 0: result PASSED (term=0)
2025-05-12 14:16:15,504 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[d6468b48-4b84-4546-9e40-0ea0f44d9603|127.0.0.1:15309]|listeners:[], old=null}
2025-05-12 14:16:15,504 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49 ELECTION round 0: result PASSED (term=1)
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:16:15,505 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: start d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderStateImpl
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-CDC12EA84350 with new leaderId: d6468b48-4b84-4546-9e40-0ea0f44d9603
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: change Leader from null to d6468b48-4b84-4546-9e40-0ea0f44d9603 at term 1 for becomeLeader, leader elected after 1137ms
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:15,506 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderElection49] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: set configuration conf: {index: 0, cur=peers:[d6468b48-4b84-4546-9e40-0ea0f44d9603|127.0.0.1:15309]|listeners:[], old=null}
2025-05-12 14:16:15,507 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:15,507 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,507 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:15,512 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/de4019d5-adfb-4cd2-85ea-cdc12ea84350/current/log_inprogress_0
2025-05-12 14:16:15,513 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-12 14:16:15,547 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 11 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 11.
2025-05-12 14:16:15,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:15,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1003710585ns, electionTimeout:1003ms
2025-05-12 14:16:15,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState
2025-05-12 14:16:15,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:16:15,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:16:15,663 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: start 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50
2025-05-12 14:16:15,664 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277]|listeners:[], old=null}
2025-05-12 14:16:15,664 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50 PRE_VOTE round 0: result PASSED (term=0)
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277]|listeners:[], old=null}
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50 ELECTION round 0: result PASSED (term=1)
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:16:15,665 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: start 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderStateImpl
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-303D3D0838B0 with new leaderId: 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: change Leader from null to 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a at term 1 for becomeLeader, leader elected after 1021ms
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:15,666 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderElection50] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: set configuration conf: {index: 0, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277]|listeners:[], old=null}
2025-05-12 14:16:15,667 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:15,667 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,667 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 reported by 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1)
2025-05-12 14:16:15,667 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:15,672 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/a2d07b4d-d13e-4869-801f-303d3d0838b0/current/log_inprogress_0
2025-05-12 14:16:15,673 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-12 14:16:15,822 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,822 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:15,822 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 reported by 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1)
2025-05-12 14:16:15,835 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1156828557ns, electionTimeout:1156ms
2025-05-12 14:16:15,835 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState
2025-05-12 14:16:15,835 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:16:15,835 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:16:15,835 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: start 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51
2025-05-12 14:16:15,835 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,836 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293
2025-05-12 14:16:15,836 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285
2025-05-12 14:16:15,836 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:15,836 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:15,840 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: receive requestVote(PRE_VOTE, 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a, group-4A19E22733C5, 0, (t:0, i:0))
2025-05-12 14:16:15,840 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1117458326ns, electionTimeout:1117ms
2025-05-12 14:16:15,840 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: receive requestVote(PRE_VOTE, 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a, group-4A19E22733C5, 0, (t:0, i:0))
2025-05-12 14:16:15,840 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState
2025-05-12 14:16:15,841 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:16:15,841 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FOLLOWER: accept PRE_VOTE from 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: our priority 0 <= candidate's priority 0
2025-05-12 14:16:15,841 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:16:15,841 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 11452936-83cb-47e1-bf10-894668a55a8a: start 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52
2025-05-12 14:16:15,841 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5 replies to PRE_VOTE vote request: 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a<-c4cac530-e369-4db2-afb8-073a8db2a7dc#0:OK-t0. Peer's state: c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5:t0, leader=null, voted=, raftlog=Memoized:c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,841 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,841 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-CANDIDATE: reject PRE_VOTE from 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: our priority 1 > candidate's priority 0
2025-05-12 14:16:15,841 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5 replies to PRE_VOTE vote request: 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a<-11452936-83cb-47e1-bf10-894668a55a8a#0:FAIL-t0. Peer's state: 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5:t0, leader=null, voted=, raftlog=Memoized:11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,841 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277
2025-05-12 14:16:15,842 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293
2025-05-12 14:16:15,842 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2025-05-12 14:16:15,842 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a<-11452936-83cb-47e1-bf10-894668a55a8a#0:FAIL-t0
2025-05-12 14:16:15,842 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51 PRE_VOTE round 0: result REJECTED
2025-05-12 14:16:15,842 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2025-05-12 14:16:15,842 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51
2025-05-12 14:16:15,843 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: start 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState
2025-05-12 14:16:15,843 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:15,843 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:15,844 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:15,844 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:15,844 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-LeaderElection51] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: set firstElectionSinceStartup to false for REJECTED
2025-05-12 14:16:15,846 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: receive requestVote(PRE_VOTE, 11452936-83cb-47e1-bf10-894668a55a8a, group-4A19E22733C5, 0, (t:0, i:0))
2025-05-12 14:16:15,846 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: receive requestVote(PRE_VOTE, 11452936-83cb-47e1-bf10-894668a55a8a, group-4A19E22733C5, 0, (t:0, i:0))
2025-05-12 14:16:15,846 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FOLLOWER: accept PRE_VOTE from 11452936-83cb-47e1-bf10-894668a55a8a: our priority 0 <= candidate's priority 1
2025-05-12 14:16:15,846 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FOLLOWER: accept PRE_VOTE from 11452936-83cb-47e1-bf10-894668a55a8a: our priority 0 <= candidate's priority 1
2025-05-12 14:16:15,847 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5 replies to PRE_VOTE vote request: 11452936-83cb-47e1-bf10-894668a55a8a<-144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a#0:OK-t0. Peer's state: 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5:t0, leader=null, voted=, raftlog=Memoized:144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,847 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5 replies to PRE_VOTE vote request: 11452936-83cb-47e1-bf10-894668a55a8a<-c4cac530-e369-4db2-afb8-073a8db2a7dc#0:OK-t0. Peer's state: c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5:t0, leader=null, voted=, raftlog=Memoized:c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,847 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2025-05-12 14:16:15,847 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 11452936-83cb-47e1-bf10-894668a55a8a<-144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a#0:OK-t0
2025-05-12 14:16:15,847 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52 PRE_VOTE round 0: result PASSED
2025-05-12 14:16:15,848 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,849 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-05-12 14:16:15,849 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-05-12 14:16:15,850 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: receive requestVote(ELECTION, 11452936-83cb-47e1-bf10-894668a55a8a, group-4A19E22733C5, 1, (t:0, i:0))
2025-05-12 14:16:15,850 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FOLLOWER: accept ELECTION from 11452936-83cb-47e1-bf10-894668a55a8a: our priority 0 <= candidate's priority 1
2025-05-12 14:16:15,850 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: changes role from  FOLLOWER to FOLLOWER at term 0 for candidate:11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:15,850 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState
2025-05-12 14:16:15,850 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: start 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState
2025-05-12 14:16:15,850 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState was interrupted
2025-05-12 14:16:15,851 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1407)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: receive requestVote(ELECTION, 11452936-83cb-47e1-bf10-894668a55a8a, group-4A19E22733C5, 1, (t:0, i:0))
2025-05-12 14:16:15,851 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FOLLOWER: accept ELECTION from 11452936-83cb-47e1-bf10-894668a55a8a: our priority 0 <= candidate's priority 1
2025-05-12 14:16:15,851 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: changes role from  FOLLOWER to FOLLOWER at term 0 for candidate:11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:15,851 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState
2025-05-12 14:16:15,851 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: start c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState
2025-05-12 14:16:15,851 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState was interrupted
2025-05-12 14:16:15,851 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: set firstElectionSinceStartup to false for candidate:11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:15,851 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5 replies to ELECTION vote request: 11452936-83cb-47e1-bf10-894668a55a8a<-144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a#0:OK-t1. Peer's state: 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5:t1, leader=null, voted=11452936-83cb-47e1-bf10-894668a55a8a, raftlog=Memoized:144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,852 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52: ELECTION PASSED received 1 response(s) and 0 exception(s):
2025-05-12 14:16:15,852 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 11452936-83cb-47e1-bf10-894668a55a8a<-144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a#0:OK-t1
2025-05-12 14:16:15,852 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52 ELECTION round 0: result PASSED
2025-05-12 14:16:15,852 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52
2025-05-12 14:16:15,852 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-12 14:16:15,852 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1441)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5 replies to ELECTION vote request: 11452936-83cb-47e1-bf10-894668a55a8a<-c4cac530-e369-4db2-afb8-073a8db2a7dc#0:OK-t1. Peer's state: c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5:t1, leader=null, voted=11452936-83cb-47e1-bf10-894668a55a8a, raftlog=Memoized:c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,852 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:15,853 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:15,854 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2025-05-12 14:16:15,855 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2025-05-12 14:16:15,855 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2025-05-12 14:16:15,855 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:15,855 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:16:15,855 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2025-05-12 14:16:15,855 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-05-12 14:16:15,855 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 11452936-83cb-47e1-bf10-894668a55a8a: start 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderStateImpl
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-4A19E22733C5 with new leaderId: 11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: change Leader from null to 11452936-83cb-47e1-bf10-894668a55a8a at term 1 for becomeLeader, leader elected after 1146ms
2025-05-12 14:16:15,856 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:15,857 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderElection52] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: set configuration conf: {index: 0, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,857 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:15,858 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,858 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(102)) - Pipeline RATIS/THREE PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 reported by 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1)
2025-05-12 14:16:15,859 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-05-12 14:16:15,863 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - DataNodeSafeModeRule rule is successfully validated
2025-05-12 14:16:15,863 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - RatisContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:15,863 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(173)) - Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2025-05-12 14:16:15,863 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - ECContainerSafeModeRule rule is successfully validated
2025-05-12 14:16:15,863 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - AtleastOneDatanodeReportedRule rule is successfully validated
2025-05-12 14:16:15,863 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(134)) - Opened pipeline PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(141)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(140)) - HealthyPipelineSafeModeRule rule is successfully validated
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(155)) - ScmSafeModeManager, all rules are successfully validated
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(178)) - SCM exiting safe mode.
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(78)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(78)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(258)) - notifyStatusChanged:RUNNING
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1387)) - Service ReplicationManager transitions to RUNNING.
2025-05-12 14:16:15,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(134)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2025-05-12 14:16:15,865 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:notifyStatusChanged(78)) - Service SCMHATransactionMonitor transitions to RUNNING.
2025-05-12 14:16:15,866 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(191)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2025-05-12 14:16:15,867 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Cluster exits safe mode
2025-05-12 14:16:15,867 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(196)) - SCM became leader
2025-05-12 14:16:15,867 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-server-thread2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-4A19E22733C5 with new leaderId: 11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:15,867 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: change Leader from null to 11452936-83cb-47e1-bf10-894668a55a8a at term 1 for appendEntries, leader elected after 1204ms
2025-05-12 14:16:15,866 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/current/log_inprogress_0
2025-05-12 14:16:15,868 [c4cac530-e369-4db2-afb8-073a8db2a7dc-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-4A19E22733C5 with new leaderId: 11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:15,868 [c4cac530-e369-4db2-afb8-073a8db2a7dc-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: change Leader from null to 11452936-83cb-47e1-bf10-894668a55a8a at term 1 for appendEntries, leader elected after 1180ms
2025-05-12 14:16:15,868 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: set configuration conf: {index: 0, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,868 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:15,868 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:15,867 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2025-05-12 14:16:15,869 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2025-05-12 14:16:15,869 [main] INFO  proxy.SCMContainerLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15260]
2025-05-12 14:16:15,870 [c4cac530-e369-4db2-afb8-073a8db2a7dc-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: set configuration conf: {index: 0, cur=peers:[144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a|127.0.0.1:15277, c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293, 11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,870 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2025-05-12 14:16:15,871 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(58)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2025-05-12 14:16:15,872 [main] INFO  proxy.SecretKeyProtocolFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol SecretKeyProtocolScmPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:9961]
2025-05-12 14:16:15,871 [c4cac530-e369-4db2-afb8-073a8db2a7dc-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:15,873 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:15,875 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/current/log_inprogress_0
2025-05-12 14:16:15,877 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(463)) - Creating Volume: vol1, with user05219 as owner and space quota set to -1 bytes, counts quota set to -1
2025-05-12 14:16:15,879 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/current/log_inprogress_0
2025-05-12 14:16:15,879 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-12 14:16:15,891 [om1-OMStateMachineApplyTransactionThread - 0] WARN  helpers.OzoneAclUtil (OzoneAclUtil.java:getDefaultAclList(77)) - Failed to get primary group from user user05219 (auth:SIMPLE)
2025-05-12 14:16:15,892 [om1-OMStateMachineApplyTransactionThread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(203)) - created volume:vol1 for user:user05219
2025-05-12 14:16:15,894 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(688)) - Creating Bucket: vol1/bucket1, with bucket layout FILE_SYSTEM_OPTIMIZED, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2025-05-12 14:16:15,896 [om1-OMStateMachineApplyTransactionThread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(292)) - created bucket: bucket1 of layout FILE_SYSTEM_OPTIMIZED in volume: vol1
2025-05-12 14:16:15,901 [IPC Server handler 2 on default port 15261] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(136)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2025-05-12 14:16:15,903 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(249)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 115816896921600000.
2025-05-12 14:16:15,904 [IPC Server handler 2 on default port 15261] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(136)) - Allocate a batch for localId, change lastId from 115816896921600000 to 115816896921601000.
2025-05-12 14:16:15,926 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(242)) - Successfully added container #1 to Recon.
2025-05-12 14:16:15,926 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1097490346ns, electionTimeout:1097ms
2025-05-12 14:16:15,929 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState
2025-05-12 14:16:15,929 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:16:15,929 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:16:15,927 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(242)) - Successfully added container #1 to Recon.
2025-05-12 14:16:15,929 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 11452936-83cb-47e1-bf10-894668a55a8a: start 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53
2025-05-12 14:16:15,929 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 3 millisec, 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1), {type: ICR, size: 1}
2025-05-12 14:16:15,930 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,930 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 5 millisec, c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), {type: ICR, size: 1}
2025-05-12 14:16:15,930 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53 PRE_VOTE round 0: result PASSED (term=0)
2025-05-12 14:16:15,931 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(264)) - Event taken long execution time 7 millisec, 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1), {type: ICR, size: 1}
2025-05-12 14:16:15,933 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,933 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53 ELECTION round 0: result PASSED (term=1)
2025-05-12 14:16:15,933 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53
2025-05-12 14:16:15,933 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-12 14:16:15,933 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:16:15,933 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:15,933 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 11452936-83cb-47e1-bf10-894668a55a8a: start 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderStateImpl
2025-05-12 14:16:15,934 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:16:15,935 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-B88182D2FAC1 with new leaderId: 11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:15,935 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: change Leader from null to 11452936-83cb-47e1-bf10-894668a55a8a at term 1 for becomeLeader, leader elected after 1117ms
2025-05-12 14:16:15,935 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:15,935 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderElection53] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: set configuration conf: {index: 0, cur=peers:[11452936-83cb-47e1-bf10-894668a55a8a|127.0.0.1:15285]|listeners:[], old=null}
2025-05-12 14:16:15,936 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:15,942 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/80098ea9-029b-4e0e-b39c-b88182d2fac1/current/log_inprogress_0
2025-05-12 14:16:15,944 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderStateImpl is ready since appliedIndex == startIndex == 0
Connecting to Recon: http://0.0.0.0:15270/api/v1/triggerdbsync/om ...
Connection Refused. Please make sure the Recon Server has been started.
2025-05-12 14:16:15,977 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:16,133 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1124178632ns, electionTimeout:1123ms
2025-05-12 14:16:16,134 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState
2025-05-12 14:16:16,134 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:16:16,134 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:16:16,134 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: start c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54
2025-05-12 14:16:16,134 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293]|listeners:[], old=null}
2025-05-12 14:16:16,134 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54 PRE_VOTE round 0: result PASSED (term=0)
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293]|listeners:[], old=null}
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54 ELECTION round 0: result PASSED (term=1)
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:16:16,135 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: start c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderStateImpl
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-FFA6453324D9 with new leaderId: c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: change Leader from null to c4cac530-e369-4db2-afb8-073a8db2a7dc at term 1 for becomeLeader, leader elected after 1139ms
2025-05-12 14:16:16,136 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:16,137 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderElection54] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: set configuration conf: {index: 0, cur=peers:[c4cac530-e369-4db2-afb8-073a8db2a7dc|127.0.0.1:15293]|listeners:[], old=null}
2025-05-12 14:16:16,137 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:16,142 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/1c927b84-b3e1-463b-ba8c-ffa6453324d9/current/log_inprogress_0
2025-05-12 14:16:16,143 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-12 14:16:16,198 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1007658061ns, electionTimeout:1007ms
2025-05-12 14:16:16,198 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState
2025-05-12 14:16:16,198 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-05-12 14:16:16,198 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2025-05-12 14:16:16,198 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - de559106-0595-44cd-a7e8-c94ad5654e48: start de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55
2025-05-12 14:16:16,199 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[de559106-0595-44cd-a7e8-c94ad5654e48|127.0.0.1:15301]|listeners:[], old=null}
2025-05-12 14:16:16,199 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55 PRE_VOTE round 0: result PASSED (term=0)
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(332)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[de559106-0595-44cd-a7e8-c94ad5654e48|127.0.0.1:15301]|listeners:[], old=null}
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(334)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55 ELECTION round 0: result PASSED (term=1)
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(378)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 30s (custom)
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2025-05-12 14:16:16,200 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.log-metadata.enabled = true (default)
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - de559106-0595-44cd-a7e8-c94ad5654e48: start de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderStateImpl
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(562)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: set firstElectionSinceStartup to false for becomeLeader
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(944)) - Leader change notification received for group: group-C4F7B421A0F8 with new leaderId: de559106-0595-44cd-a7e8-c94ad5654e48
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServer$Division (ServerState.java:setLeader(272)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: change Leader from null to de559106-0595-44cd-a7e8-c94ad5654e48 at term 1 for becomeLeader, leader elected after 1023ms
2025-05-12 14:16:16,201 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(438)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-SegmentedRaftLogWorker: Starting segment from index:0
2025-05-12 14:16:16,202 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderElection55] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: set configuration conf: {index: 0, cur=peers:[de559106-0595-44cd-a7e8-c94ad5654e48|127.0.0.1:15301]|listeners:[], old=null}
2025-05-12 14:16:16,202 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-05-12 14:16:16,207 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(644)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/ebcc11cb-261b-4635-a8cc-c4f7b421a0f8/current/log_inprogress_0
2025-05-12 14:16:16,209 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(313)) - Leader de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-05-12 14:16:16,209 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2025-05-12 14:16:16,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:16,823 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:16,824 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-12 14:16:16,980 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:17,547 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 12 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 12.
2025-05-12 14:16:17,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:17,984 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:18,213 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2025-05-12 14:16:18,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(357)) - Replication Manager is not ready to run until 3000ms after safemode exit
2025-05-12 14:16:18,824 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:18,825 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-12 14:16:18,988 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:19,548 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 13 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 13.
2025-05-12 14:16:19,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:19,992 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:20,214 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 8 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 8.
2025-05-12 14:16:20,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:20,825 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:20,826 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2025-05-12 14:16:20,995 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:21,549 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 14 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 14.
2025-05-12 14:16:21,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:21,999 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:22,215 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 9 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 9.
2025-05-12 14:16:22,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:22,826 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:22,826 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2025-05-12 14:16:23,002 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:23,554 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] ERROR scm.ReconDeadNodeHandler (ReconDeadNodeHandler.java:onMessage(81)) - Error trying to verify Node operational state from SCM.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:872)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1588)
	at org.apache.hadoop.ipc.Client.call(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1426)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:668)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:789)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:364)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1649)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	... 22 more
2025-05-12 14:16:23,554 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. 81168679-53d5-42e7-8afd-95ecd679d056(localhost/127.0.0.1)
2025-05-12 14:16:23,554 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: 705ea5ce-c8bd-45d8-aabf-95b8cb15bc59, Nodes: [ {81168679-53d5-42e7-8afd-95ecd679d056(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:81168679-53d5-42e7-8afd-95ecd679d056, CreationTimestamp2025-05-12T14:15:23.058Z[Etc/UTC]} removed.
2025-05-12 14:16:23,555 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(190)) - Processing of TypedEvent{payloadType=DatanodeDetails, name='Replication_Manager_Notify'} is skipped, EventQueue is not running
2025-05-12 14:16:23,555 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 0 for DN 81168679-53d5-42e7-8afd-95ecd679d056(localhost/127.0.0.1)
2025-05-12 14:16:23,555 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/81168679-53d5-42e7-8afd-95ecd679d056
2025-05-12 14:16:23,555 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-12 14:16:23,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-12 14:16:24,005 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:24,215 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 10 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 10.
2025-05-12 14:16:24,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:24,826 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:24,827 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2025-05-12 14:16:25,009 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:25,556 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-12 14:16:25,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:26,012 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:26,216 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 11 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 11.
2025-05-12 14:16:26,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:26,827 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:26,827 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 8 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 8.
2025-05-12 14:16:27,015 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:27,556 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-12 14:16:27,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-12 14:16:28,018 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:28,216 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 12 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 12.
2025-05-12 14:16:28,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:28,828 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:28,830 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 9 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 9.
2025-05-12 14:16:29,022 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:29,557 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-12 14:16:29,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:30,025 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:30,217 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 13 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 13.
2025-05-12 14:16:30,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:30,830 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:30,831 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 10 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 10.
2025-05-12 14:16:31,028 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:31,557 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-12 14:16:31,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-12 14:16:32,032 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:32,217 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 14 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 14.
2025-05-12 14:16:32,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:32,831 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:32,832 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 11 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 11.
2025-05-12 14:16:33,036 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:33,558 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2025-05-12 14:16:33,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:34,039 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:34,221 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] ERROR scm.ReconDeadNodeHandler (ReconDeadNodeHandler.java:onMessage(81)) - Error trying to verify Node operational state from SCM.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:872)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1588)
	at org.apache.hadoop.ipc.Client.call(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1426)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
	at org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:668)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:789)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:364)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1649)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	... 22 more
2025-05-12 14:16:34,222 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. b624e2bb-01a6-406f-bb8d-99b59f3099e9(localhost/127.0.0.1)
2025-05-12 14:16:34,222 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: f3941d74-5247-4f03-b3f8-55e0ffb46c6a, Nodes: [ {b624e2bb-01a6-406f-bb8d-99b59f3099e9(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:b624e2bb-01a6-406f-bb8d-99b59f3099e9, CreationTimestamp2025-05-12T14:14:34.969Z[Etc/UTC]} removed.
2025-05-12 14:16:34,222 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(190)) - Processing of TypedEvent{payloadType=DatanodeDetails, name='Replication_Manager_Notify'} is skipped, EventQueue is not running
2025-05-12 14:16:34,222 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 0 for DN b624e2bb-01a6-406f-bb8d-99b59f3099e9(localhost/127.0.0.1)
2025-05-12 14:16:34,222 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/b624e2bb-01a6-406f-bb8d-99b59f3099e9
2025-05-12 14:16:34,222 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-12 14:16:34,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:34,832 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:34,832 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 12 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 12.
2025-05-12 14:16:35,042 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:35,558 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2025-05-12 14:16:35,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-12 14:16:35,967 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(394)) - Shutting down the Mini Ozone Cluster
2025-05-12 14:16:35,967 [main] INFO  db.CodecTestUtil (CodecTestUtil.java:gc(49)) - gc 0
2025-05-12 14:16:36,102 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:36,198 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(410)) - Stopping the Mini Ozone Cluster
2025-05-12 14:16:36,198 [main] INFO  om.OzoneManager (OzoneManager.java:stop(2328)) - om1[localhost:15266]: Stopping Ozone Manager
2025-05-12 14:16:36,198 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15266
2025-05-12 14:16:36,201 [IPC Server listener on 15266] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15266
2025-05-12 14:16:36,201 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:36,201 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:stop(634)) - Stopping org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer@5105c7cd at port 15269
2025-05-12 14:16:36,201 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - om1: close
2025-05-12 14:16:36,202 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - om1: shutdown server GrpcServerProtocolService now
2025-05-12 14:16:36,202 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - om1@group-C5BA1605619E: shutdown
2025-05-12 14:16:36,202 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-05-12 14:16:36,202 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2025-05-12 14:16:36,202 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - om1: shutdown server GrpcServerProtocolService successfully
2025-05-12 14:16:36,202 [om1-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2025-05-12 14:16:36,203 [om1-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 8
2025-05-12 14:16:36,218 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(515)) - om1: taking snapshot. applied = (t:1, i:8), skipped = 7, notified = (t:1, i:8), current snapshot index = (t:1, i:8), took 15 ms
2025-05-12 14:16:36,218 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 8
2025-05-12 14:16:36,219 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 8
2025-05-12 14:16:36,219 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - om1@group-C5BA1605619E-StateMachineUpdater: closing OzoneManagerStateMachine, lastApplied=(t:1, i:8)
2025-05-12 14:16:36,219 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(555)) - Stopping OzoneManagerStateMachine:om1:group-C5BA1605619E.
2025-05-12 14:16:36,219 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(499)) - Stopping OMDoubleBuffer flush thread
2025-05-12 14:16:36,219 [om1-OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(558)) - OMDoubleBuffer flush thread om1-OMDoubleBufferFlushThread is interrupted and will exit.
2025-05-12 14:16:36,219 [om1@group-C5BA1605619E-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - om1@group-C5BA1605619E-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:36,223 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-05-12 14:16:36,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:36,832 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:36,833 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 13 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 13.
2025-05-12 14:16:36,944 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2025-05-12 14:16:36,945 [JvmPauseMonitor47] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-om1: Stopped
2025-05-12 14:16:36,945 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service KeyDeletingService
2025-05-12 14:16:36,945 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service DirectoryDeletingService
2025-05-12 14:16:36,946 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service OpenKeyCleanupService
2025-05-12 14:16:36,947 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SstFilteringService
2025-05-12 14:16:36,947 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDeletingService
2025-05-12 14:16:36,947 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service MultipartUploadCleanupService
2025-05-12 14:16:36,948 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@6f83a59d{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2025-05-12 14:16:36,949 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@583d465a{HTTP/1.1, (http/1.1)}{0.0.0.0:15267}
2025-05-12 14:16:36,949 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-12 14:16:36,949 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@56dc3d65{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-05-12 14:16:36,949 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2b530a01{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-12 14:16:36,950 [main] INFO  rocksdiff.RocksDBCheckpointDiffer (RocksDBCheckpointDiffer.java:close(299)) - Shutting down CompactionDagPruningService.
2025-05-12 14:16:36,952 [main] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1696)) - Shutting down executorService: 'SnapDiffExecutor'
2025-05-12 14:16:36,952 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDiffCleanupService
2025-05-12 14:16:36,953 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(476)) - Stopping the HddsDatanodes
2025-05-12 14:16:36,954 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-12 14:16:36,954 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:36,954 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@7e9bead1 exiting.
2025-05-12 14:16:36,954 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-12 14:16:36,955 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:36,954 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-12 14:16:36,954 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-12 14:16:36,955 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@39d29539 exiting.
2025-05-12 14:16:36,955 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds) is shutting down. 
2025-05-12 14:16:36,955 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:36,955 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@26ec0c40 exiting.
2025-05-12 14:16:36,955 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:36,955 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds) is shutting down. 
2025-05-12 14:16:36,955 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@5e47812c exiting.
2025-05-12 14:16:36,955 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:36,955 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds) is shutting down. 
2025-05-12 14:16:36,956 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:36,956 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds, DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57) exiting.
2025-05-12 14:16:36,956 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:shutdownScanner(208)) - On-demand container scanner is shutting down.
2025-05-12 14:16:36,955 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:36,956 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds, DS-5ac90093-0921-4259-a3a1-cfd6377c774d) exiting.
2025-05-12 14:16:36,956 [ForkJoinPool.commonPool-worker-1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(11452936-83cb-47e1-bf10-894668a55a8a)
2025-05-12 14:16:36,956 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - 11452936-83cb-47e1-bf10-894668a55a8a: close
2025-05-12 14:16:36,955 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds, DS-859dad2e-7827-48aa-8063-996dd404ca30) exiting.
2025-05-12 14:16:36,956 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1: shutdown
2025-05-12 14:16:36,956 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B88182D2FAC1,id=11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:36,956 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-LeaderStateImpl
2025-05-12 14:16:36,956 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-PendingRequests: sendNotLeaderResponses
2025-05-12 14:16:36,957 [main] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(c4cac530-e369-4db2-afb8-073a8db2a7dc)
2025-05-12 14:16:36,957 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: close
2025-05-12 14:16:36,957 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-12 14:16:36,957 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5: shutdown
2025-05-12 14:16:36,957 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A19E22733C5,id=c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:36,957 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5: shutdown
2025-05-12 14:16:36,957 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater: set stopIndex = 0
2025-05-12 14:16:36,955 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds) is shutting down. 
2025-05-12 14:16:36,957 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-B88182D2FAC1: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/80098ea9-029b-4e0e-b39c-b88182d2fac1/sm/snapshot.1_0
2025-05-12 14:16:36,957 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A19E22733C5,id=11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:36,958 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-LeaderStateImpl
2025-05-12 14:16:36,958 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-PendingRequests: sendNotLeaderResponses
2025-05-12 14:16:36,957 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState
2025-05-12 14:16:36,956 [ForkJoinPool.commonPool-worker-3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(d6468b48-4b84-4546-9e40-0ea0f44d9603)
2025-05-12 14:16:36,958 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->c4cac530-e369-4db2-afb8-073a8db2a7dc-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->c4cac530-e369-4db2-afb8-073a8db2a7dc-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-05-12 14:16:36,958 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater: set stopIndex = 3
2025-05-12 14:16:36,958 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-B88182D2FAC1: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/80098ea9-029b-4e0e-b39c-b88182d2fac1/sm/snapshot.1_0 took: 1 ms
2025-05-12 14:16:36,958 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(293)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-05-12 14:16:36,958 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater: Took a snapshot at index 0
2025-05-12 14:16:36,959 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-12 14:16:36,959 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-12 14:16:36,959 [Thread-6179] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(105)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a Close channels
2025-05-12 14:16:36,958 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:36,959 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds, DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8) exiting.
2025-05-12 14:16:36,959 [Thread-6180] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(105)) - c4cac530-e369-4db2-afb8-073a8db2a7dc Close channels
2025-05-12 14:16:36,959 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-FollowerState was interrupted
2025-05-12 14:16:36,959 [ForkJoinPool.commonPool-worker-2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a)
2025-05-12 14:16:36,958 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-4A19E22733C5: Taking a snapshot at:(t:1, i:3) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/sm/snapshot.1_3
2025-05-12 14:16:36,959 [ForkJoinPool.commonPool-worker-2] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: close
2025-05-12 14:16:36,959 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater: set stopIndex = 3
2025-05-12 14:16:36,958 [ForkJoinPool.commonPool-worker-3] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: close
2025-05-12 14:16:36,960 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-12 14:16:36,960 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0: shutdown
2025-05-12 14:16:36,960 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: Completed APPEND_ENTRIES, lastRequest: null
2025-05-12 14:16:36,960 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: Completed APPEND_ENTRIES, lastRequest: null
2025-05-12 14:16:36,961 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-4A19E22733C5: Finished taking a snapshot at:(t:1, i:3) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/sm/snapshot.1_3 took: 3 ms
2025-05-12 14:16:36,961 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater: Took a snapshot at index 3
2025-05-12 14:16:36,961 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2025-05-12 14:16:36,961 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "11452936-83cb-47e1-bf10-894668a55a8a"
  replyId: "c4cac530-e369-4db2-afb8-073a8db2a7dc"
  raftGroupId {
    id: "7\315\224 c$A\327\206\211J\031\342\'3\305"
  }
  callId: 17
  success: true
}
term: 1
nextIndex: 4
followerCommit: 3
matchIndex: 18446744073709551615
isHearbeat: true

2025-05-12 14:16:36,961 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:3)
2025-05-12 14:16:36,961 [11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:36,961 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-12 14:16:36,960 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-4A19E22733C5: Taking a snapshot at:(t:1, i:3) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/sm/snapshot.1_3
2025-05-12 14:16:36,961 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9: shutdown
2025-05-12 14:16:36,961 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-303D3D0838B0,id=144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:36,962 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-LeaderStateImpl
2025-05-12 14:16:36,962 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-PendingRequests: sendNotLeaderResponses
2025-05-12 14:16:36,961 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5: shutdown
2025-05-12 14:16:36,961 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-12 14:16:36,961 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350: shutdown
2025-05-12 14:16:36,963 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-4A19E22733C5: Finished taking a snapshot at:(t:1, i:3) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/sm/snapshot.1_3 took: 3 ms
2025-05-12 14:16:36,963 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:36,963 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater: Took a snapshot at index 3
2025-05-12 14:16:36,963 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2025-05-12 14:16:36,961 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "11452936-83cb-47e1-bf10-894668a55a8a"
  replyId: "144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a"
  raftGroupId {
    id: "7\315\224 c$A\327\206\211J\031\342\'3\305"
  }
  callId: 19
  success: true
}
term: 1
nextIndex: 4
followerCommit: 3
matchIndex: 18446744073709551615
isHearbeat: true

2025-05-12 14:16:36,960 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: Completed APPEND_ENTRIES, lastRequest: 11452936-83cb-47e1-bf10-894668a55a8a->c4cac530-e369-4db2-afb8-073a8db2a7dc#6-t1,previous=(t:1, i:2),leaderCommit=2,initializing? false,entries: size=1, first=(t:1, i:3), METADATAENTRY(c:2)
2025-05-12 14:16:36,963 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: Completed APPEND_ENTRIES, lastReply: null
2025-05-12 14:16:36,960 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: Completed APPEND_ENTRIES, lastRequest: 11452936-83cb-47e1-bf10-894668a55a8a->144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a#5-t1,previous=(t:1, i:2),leaderCommit=2,initializing? false,entries: size=1, first=(t:1, i:3), METADATAENTRY(c:2)
2025-05-12 14:16:36,963 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: Completed APPEND_ENTRIES, lastReply: null
2025-05-12 14:16:36,963 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:3)
2025-05-12 14:16:36,963 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FFA6453324D9,id=c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:36,963 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-LeaderStateImpl
2025-05-12 14:16:36,964 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-PendingRequests: sendNotLeaderResponses
2025-05-12 14:16:36,964 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-12 14:16:36,964 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown server GrpcServerProtocolService now
2025-05-12 14:16:36,964 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CDC12EA84350,id=d6468b48-4b84-4546-9e40-0ea0f44d9603
2025-05-12 14:16:36,963 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A19E22733C5,id=144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:36,964 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState
2025-05-12 14:16:36,964 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-LeaderStateImpl
2025-05-12 14:16:36,964 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-PendingRequests: sendNotLeaderResponses
2025-05-12 14:16:36,964 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater: set stopIndex = 3
2025-05-12 14:16:36,964 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown server GrpcServerProtocolService successfully
2025-05-12 14:16:36,964 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-4A19E22733C5: Taking a snapshot at:(t:1, i:3) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/sm/snapshot.1_3
2025-05-12 14:16:36,964 [11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:36,965 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-12 14:16:36,965 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - d6468b48-4b84-4546-9e40-0ea0f44d9603: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-12 14:16:36,965 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-FollowerState was interrupted
2025-05-12 14:16:36,965 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-12 14:16:36,965 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown server GrpcServerProtocolService now
2025-05-12 14:16:36,965 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->c4cac530-e369-4db2-afb8-073a8db2a7dc-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-05-12 14:16:36,965 [d6468b48-4b84-4546-9e40-0ea0f44d9603-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5530cda0, L:/0.0.0.0:15310] CLOSE
2025-05-12 14:16:36,965 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(230)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->c4cac530-e369-4db2-afb8-073a8db2a7dc-GrpcLogAppender: Failed to getClient for c4cac530-e369-4db2-afb8-073a8db2a7dc
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 11452936-83cb-47e1-bf10-894668a55a8a is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:67)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:124)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:200)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:205)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:64)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:551)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-12 14:16:36,966 [d6468b48-4b84-4546-9e40-0ea0f44d9603-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5530cda0, L:/0.0.0.0:15310] INACTIVE
2025-05-12 14:16:36,966 [d6468b48-4b84-4546-9e40-0ea0f44d9603-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5530cda0, L:/0.0.0.0:15310] UNREGISTERED
2025-05-12 14:16:36,966 [grpc-default-executor-7] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->c4cac530-e369-4db2-afb8-073a8db2a7dc-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-05-12 14:16:36,965 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-4A19E22733C5: Finished taking a snapshot at:(t:1, i:3) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/37cd9420-6324-41d7-8689-4a19e22733c5/sm/snapshot.1_3 took: 2 ms
2025-05-12 14:16:36,966 [Thread-6188] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(105)) - c4cac530-e369-4db2-afb8-073a8db2a7dc Close channels
2025-05-12 14:16:36,966 [Thread-6190] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(105)) - 11452936-83cb-47e1-bf10-894668a55a8a Close channels
2025-05-12 14:16:36,966 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown server GrpcServerProtocolService successfully
2025-05-12 14:16:36,967 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-12 14:16:36,967 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-05-12 14:16:36,967 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(230)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-GrpcLogAppender: Failed to getClient for 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 11452936-83cb-47e1-bf10-894668a55a8a is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:67)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:124)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:200)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:205)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:64)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:551)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:489)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:453)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:486)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-12 14:16:36,966 [grpc-default-executor-7] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(230)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->c4cac530-e369-4db2-afb8-073a8db2a7dc-GrpcLogAppender: Failed to getClient for c4cac530-e369-4db2-afb8-073a8db2a7dc
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 11452936-83cb-47e1-bf10-894668a55a8a is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:67)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:124)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:200)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:205)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:64)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:551)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:489)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:453)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:486)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-12 14:16:36,967 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - c4cac530-e369-4db2-afb8-073a8db2a7dc: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-12 14:16:36,966 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater: Took a snapshot at index 3
2025-05-12 14:16:36,969 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-12 14:16:36,970 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown server GrpcServerProtocolService now
2025-05-12 14:16:36,970 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2025-05-12 14:16:36,968 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-12 14:16:36,968 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(550)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-05-12 14:16:36,971 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(230)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5->144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-GrpcLogAppender: Failed to getClient for 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 11452936-83cb-47e1-bf10-894668a55a8a is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:67)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:124)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:200)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:205)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:64)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:551)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-12 14:16:36,971 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown server GrpcServerProtocolService now
2025-05-12 14:16:36,971 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown server GrpcServerProtocolService successfully
2025-05-12 14:16:36,971 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-12 14:16:36,971 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:3)
2025-05-12 14:16:36,971 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown server GrpcServerProtocolService successfully
2025-05-12 14:16:36,971 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-12 14:16:36,972 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 11452936-83cb-47e1-bf10-894668a55a8a: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-12 14:16:36,972 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:36,972 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-12 14:16:36,973 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater: set stopIndex = 0
2025-05-12 14:16:36,973 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-FFA6453324D9: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/1c927b84-b3e1-463b-ba8c-ffa6453324d9/sm/snapshot.1_0
2025-05-12 14:16:36,973 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater: set stopIndex = 0
2025-05-12 14:16:36,973 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-CDC12EA84350: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/de4019d5-adfb-4cd2-85ea-cdc12ea84350/sm/snapshot.1_0
2025-05-12 14:16:36,974 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater: set stopIndex = 0
2025-05-12 14:16:36,974 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-303D3D0838B0: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/a2d07b4d-d13e-4869-801f-303d3d0838b0/sm/snapshot.1_0
2025-05-12 14:16:36,975 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-FFA6453324D9: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/ratis/1c927b84-b3e1-463b-ba8c-ffa6453324d9/sm/snapshot.1_0 took: 2 ms
2025-05-12 14:16:36,975 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater: Took a snapshot at index 0
2025-05-12 14:16:36,975 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-12 14:16:36,975 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-12 14:16:36,975 [c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:36,975 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-CDC12EA84350: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/ratis/de4019d5-adfb-4cd2-85ea-cdc12ea84350/sm/snapshot.1_0 took: 2 ms
2025-05-12 14:16:36,975 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater: Took a snapshot at index 0
2025-05-12 14:16:36,975 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-303D3D0838B0: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/ratis/a2d07b4d-d13e-4869-801f-303d3d0838b0/sm/snapshot.1_0 took: 1 ms
2025-05-12 14:16:36,976 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater: Took a snapshot at index 0
2025-05-12 14:16:36,976 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-12 14:16:36,976 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-12 14:16:36,976 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-12 14:16:36,976 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-12 14:16:36,976 [d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:36,976 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:36,983 [11452936-83cb-47e1-bf10-894668a55a8a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaaca7d6b, L:/0.0.0.0:15286] CLOSE
2025-05-12 14:16:36,983 [11452936-83cb-47e1-bf10-894668a55a8a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaaca7d6b, L:/0.0.0.0:15286] INACTIVE
2025-05-12 14:16:36,983 [11452936-83cb-47e1-bf10-894668a55a8a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xaaca7d6b, L:/0.0.0.0:15286] UNREGISTERED
2025-05-12 14:16:36,984 [c4cac530-e369-4db2-afb8-073a8db2a7dc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1125e196, L:/0.0.0.0:15294] CLOSE
2025-05-12 14:16:36,984 [c4cac530-e369-4db2-afb8-073a8db2a7dc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1125e196, L:/0.0.0.0:15294] INACTIVE
2025-05-12 14:16:36,984 [c4cac530-e369-4db2-afb8-073a8db2a7dc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1125e196, L:/0.0.0.0:15294] UNREGISTERED
2025-05-12 14:16:36,985 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xce86fc5d, L:/0.0.0.0:15278] CLOSE
2025-05-12 14:16:36,985 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xce86fc5d, L:/0.0.0.0:15278] INACTIVE
2025-05-12 14:16:36,985 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xce86fc5d, L:/0.0.0.0:15278] UNREGISTERED
2025-05-12 14:16:37,106 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:37,145 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-FFA6453324D9-SegmentedRaftLogWorker close()
2025-05-12 14:16:37,145 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-FFA6453324D9 is closed by HddsDatanodeService
2025-05-12 14:16:37,515 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - d6468b48-4b84-4546-9e40-0ea0f44d9603@group-CDC12EA84350-SegmentedRaftLogWorker close()
2025-05-12 14:16:37,515 [d6468b48-4b84-4546-9e40-0ea0f44d9603-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-CDC12EA84350 is closed by HddsDatanodeService
2025-05-12 14:16:37,515 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-d6468b48-4b84-4546-9e40-0ea0f44d9603: Stopped
2025-05-12 14:16:37,559 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2025-05-12 14:16:37,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:37,675 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-303D3D0838B0-SegmentedRaftLogWorker close()
2025-05-12 14:16:37,675 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-303D3D0838B0 is closed by HddsDatanodeService
2025-05-12 14:16:37,931 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-4A19E22733C5-SegmentedRaftLogWorker close()
2025-05-12 14:16:37,932 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-4A19E22733C5 is closed by HddsDatanodeService
2025-05-12 14:16:37,933 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - c4cac530-e369-4db2-afb8-073a8db2a7dc@group-4A19E22733C5-SegmentedRaftLogWorker close()
2025-05-12 14:16:37,933 [c4cac530-e369-4db2-afb8-073a8db2a7dc-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-4A19E22733C5 is closed by HddsDatanodeService
2025-05-12 14:16:37,934 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-c4cac530-e369-4db2-afb8-073a8db2a7dc: Stopped
2025-05-12 14:16:37,935 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a@group-4A19E22733C5-SegmentedRaftLogWorker close()
2025-05-12 14:16:37,935 [144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-4A19E22733C5 is closed by HddsDatanodeService
2025-05-12 14:16:37,935 [JvmPauseMonitor49] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a: Stopped
2025-05-12 14:16:37,945 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - 11452936-83cb-47e1-bf10-894668a55a8a@group-B88182D2FAC1-SegmentedRaftLogWorker close()
2025-05-12 14:16:37,945 [11452936-83cb-47e1-bf10-894668a55a8a-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-B88182D2FAC1 is closed by HddsDatanodeService
2025-05-12 14:16:37,946 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-11452936-83cb-47e1-bf10-894668a55a8a: Stopped
2025-05-12 14:16:38,110 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:38,224 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-05-12 14:16:38,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:38,833 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:38,834 [Recon-SyncSCMContainerInfo-0] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 14 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 14.
2025-05-12 14:16:39,113 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:39,196 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9]
2025-05-12 14:16:39,196 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9, PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5]
2025-05-12 14:16:39,197 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(487)) - Container #1 closed for pipeline=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5
2025-05-12 14:16:39,197 [Recon-EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2025-05-12 14:16:39,198 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 moved to CLOSED state
2025-05-12 14:16:39,198 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a.
2025-05-12 14:16:39,198 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode c4cac530-e369-4db2-afb8-073a8db2a7dc.
2025-05-12 14:16:39,198 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode 11452936-83cb-47e1-bf10-894668a55a8a.
2025-05-12 14:16:39,198 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 moved to CLOSED state
2025-05-12 14:16:39,199 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 moved to CLOSED state
2025-05-12 14:16:39,200 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(487)) - Container #1 closed for pipeline=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5
2025-05-12 14:16:39,200 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2025-05-12 14:16:39,201 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 moved to CLOSED state
2025-05-12 14:16:39,202 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-12 14:16:39,202 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,202 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,203 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,203 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,203 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,203 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,518 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-859dad2e-7827-48aa-8063-996dd404ca30/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-5ac90093-0921-4259-a3a1-cfd6377c774d/container.db]
2025-05-12 14:16:39,518 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-5ac90093-0921-4259-a3a1-cfd6377c774d/container.db from cache
2025-05-12 14:16:39,518 [ForkJoinPool.commonPool-worker-3] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-5/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-5ac90093-0921-4259-a3a1-cfd6377c774d/container.db for volume DS-5ac90093-0921-4259-a3a1-cfd6377c774d
2025-05-12 14:16:39,519 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-12 14:16:39,519 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-12 14:16:39,520 [ForkJoinPool.commonPool-worker-3] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-12 14:16:39,531 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@6570ccf9{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:39,531 [ForkJoinPool.commonPool-worker-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@755a9b8f{HTTP/1.1, (http/1.1)}{0.0.0.0:15304}
2025-05-12 14:16:39,532 [ForkJoinPool.commonPool-worker-3] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-12 14:16:39,532 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@651c8a24{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-12 14:16:39,532 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@253c5b81{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-12 14:16:39,532 [ForkJoinPool.commonPool-worker-3] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-12 14:16:39,532 [ForkJoinPool.commonPool-worker-3] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15305
2025-05-12 14:16:39,533 [IPC Server listener on 15305] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15305
2025-05-12 14:16:39,534 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:39,535 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(536)) - Attempting to stop container services.
2025-05-12 14:16:39,535 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:39,535 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@1decf4ad exiting.
2025-05-12 14:16:39,535 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds) is shutting down. 
2025-05-12 14:16:39,535 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-05-12 14:16:39,535 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds, DS-08a093c1-1426-4ba8-9d46-b1b2037bee20) exiting.
2025-05-12 14:16:39,536 [ForkJoinPool.commonPool-worker-3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(de559106-0595-44cd-a7e8-c94ad5654e48)
2025-05-12 14:16:39,536 [ForkJoinPool.commonPool-worker-3] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - de559106-0595-44cd-a7e8-c94ad5654e48: close
2025-05-12 14:16:39,536 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-05-12 14:16:39,536 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8: shutdown
2025-05-12 14:16:39,536 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C4F7B421A0F8,id=de559106-0595-44cd-a7e8-c94ad5654e48
2025-05-12 14:16:39,536 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-LeaderStateImpl
2025-05-12 14:16:39,536 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-PendingRequests: sendNotLeaderResponses
2025-05-12 14:16:39,536 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-05-12 14:16:39,536 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown server GrpcServerProtocolService now
2025-05-12 14:16:39,536 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown server GrpcServerProtocolService successfully
2025-05-12 14:16:39,536 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-05-12 14:16:39,536 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - de559106-0595-44cd-a7e8-c94ad5654e48: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-05-12 14:16:39,536 [de559106-0595-44cd-a7e8-c94ad5654e48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a96ce83, L:/0.0.0.0:15302] CLOSE
2025-05-12 14:16:39,537 [de559106-0595-44cd-a7e8-c94ad5654e48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a96ce83, L:/0.0.0.0:15302] INACTIVE
2025-05-12 14:16:39,537 [de559106-0595-44cd-a7e8-c94ad5654e48-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a96ce83, L:/0.0.0.0:15302] UNREGISTERED
2025-05-12 14:16:39,537 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater: set stopIndex = 0
2025-05-12 14:16:39,537 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-C4F7B421A0F8: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/ebcc11cb-261b-4635-a8cc-c4f7b421a0f8/sm/snapshot.1_0
2025-05-12 14:16:39,538 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-C4F7B421A0F8: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/ratis/ebcc11cb-261b-4635-a8cc-c4f7b421a0f8/sm/snapshot.1_0 took: 1 ms
2025-05-12 14:16:39,538 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater: Took a snapshot at index 0
2025-05-12 14:16:39,538 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-05-12 14:16:39,538 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-05-12 14:16:39,539 [de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:39,565 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 8 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 8.
2025-05-12 14:16:39,596 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode d6468b48-4b84-4546-9e40-0ea0f44d9603(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350]
2025-05-12 14:16:39,596 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode d6468b48-4b84-4546-9e40-0ea0f44d9603(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350]
2025-05-12 14:16:39,597 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 moved to CLOSED state
2025-05-12 14:16:39,598 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 moved to CLOSED state
2025-05-12 14:16:39,600 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-12 14:16:39,600 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,600 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,600 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,600 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,601 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,601 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 already exists in Recon pipeline metadata.
2025-05-12 14:16:39,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1) with datanode deadline 1747059759633 and scm deadline 1747060119633
2025-05-12 14:16:39,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1) with datanode deadline 1747059759634 and scm deadline 1747060119634
2025-05-12 14:16:39,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1) with datanode deadline 1747059759634 and scm deadline 1747060119634
2025-05-12 14:16:39,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-12 14:16:39,936 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-859dad2e-7827-48aa-8063-996dd404ca30/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db]
2025-05-12 14:16:39,937 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-859dad2e-7827-48aa-8063-996dd404ca30/container.db from cache
2025-05-12 14:16:39,937 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-3/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-859dad2e-7827-48aa-8063-996dd404ca30/container.db for volume DS-859dad2e-7827-48aa-8063-996dd404ca30
2025-05-12 14:16:39,937 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-12 14:16:39,937 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db]
2025-05-12 14:16:39,938 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-12 14:16:39,938 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8/container.db from cache
2025-05-12 14:16:39,938 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-1/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8/container.db for volume DS-da7e9eee-7f37-4457-8762-a7ae2b0138b8
2025-05-12 14:16:39,938 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-12 14:16:39,939 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-12 14:16:39,939 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-12 14:16:39,940 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-12 14:16:39,947 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db]
2025-05-12 14:16:39,948 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57/container.db from cache
2025-05-12 14:16:39,948 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-2/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57/container.db for volume DS-b8ca958a-2bd8-4513-9e81-621b2bd40d57
2025-05-12 14:16:39,948 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-12 14:16:39,949 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-12 14:16:39,950 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-12 14:16:39,955 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@52f7de61{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:39,955 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4c326a28{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:39,955 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@2e2acb42{HTTP/1.1, (http/1.1)}{0.0.0.0:15288}
2025-05-12 14:16:39,955 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-12 14:16:39,956 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7bca50a3{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-12 14:16:39,956 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@25e41605{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-12 14:16:39,957 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5e385492{HTTP/1.1, (http/1.1)}{0.0.0.0:15272}
2025-05-12 14:16:39,957 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-12 14:16:39,957 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5d40ba3e{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-12 14:16:39,957 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-12 14:16:39,957 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15289
2025-05-12 14:16:39,957 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7d78fbb9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-12 14:16:39,958 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-12 14:16:39,958 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15273
2025-05-12 14:16:39,960 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:39,960 [IPC Server listener on 15289] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15289
2025-05-12 14:16:39,961 [IPC Server listener on 15273] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15273
2025-05-12 14:16:39,961 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:39,965 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3401e335{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:39,965 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7b8faa17{HTTP/1.1, (http/1.1)}{0.0.0.0:15280}
2025-05-12 14:16:39,965 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-12 14:16:39,965 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2236ff0a{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-12 14:16:39,965 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@47bc6e24{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-12 14:16:39,966 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-12 14:16:39,966 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15281
2025-05-12 14:16:39,967 [IPC Server listener on 15281] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15281
2025-05-12 14:16:39,967 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:39,997 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1, PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5]
2025-05-12 14:16:39,997 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1, PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5]
2025-05-12 14:16:39,997 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 moved to CLOSED state
2025-05-12 14:16:39,998 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 moved to CLOSED state
2025-05-12 14:16:39,998 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0, PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5]
2025-05-12 14:16:39,999 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 moved to CLOSED state
2025-05-12 14:16:40,001 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-12 14:16:40,001 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,001 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,001 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,001 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,002 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,002 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,003 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0, PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5]
2025-05-12 14:16:40,005 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 6 pipelines in house.
2025-05-12 14:16:40,005 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,006 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,006 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,006 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,006 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,006 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 already exists in Recon pipeline metadata.
2025-05-12 14:16:40,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:40,210 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - de559106-0595-44cd-a7e8-c94ad5654e48@group-C4F7B421A0F8-SegmentedRaftLogWorker close()
2025-05-12 14:16:40,211 [de559106-0595-44cd-a7e8-c94ad5654e48-impl-thread1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-C4F7B421A0F8 is closed by HddsDatanodeService
2025-05-12 14:16:40,211 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-de559106-0595-44cd-a7e8-c94ad5654e48: Stopped
2025-05-12 14:16:40,224 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-05-12 14:16:40,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1) with datanode deadline 1747059760634 and scm deadline 1747060120634
2025-05-12 14:16:40,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1) with datanode deadline 1747059760634 and scm deadline 1747060120634
2025-05-12 14:16:40,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1) with datanode deadline 1747059760634 and scm deadline 1747060120634
2025-05-12 14:16:40,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:40,834 [Recon-SyncSCMContainerInfo-0] WARN  retry.RetryInvocationHandler (RetryInvocationHandler.java:failover(225)) - A failover has occurred since the start of call #1703 $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208
2025-05-12 14:16:40,834 [Recon-SyncSCMContainerInfo-0] ERROR scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:syncWithSCMContainerInfo(583)) - Unable to refresh Recon SCM DB Snapshot. 
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:872)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1588)
	at org.apache.hadoop.ipc.Client.call(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1426)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
	at jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getContainerCount(StorageContainerLocationProtocolClientSideTranslatorPB.java:1170)
	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getContainerCount(StorageContainerServiceProviderImpl.java:127)
	at org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade.syncWithSCMContainerInfo(ReconStorageContainerManagerFacade.java:542)
	at org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade.lambda$start$0(ReconStorageContainerManagerFacade.java:419)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:668)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:789)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:364)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1649)
	at org.apache.hadoop.ipc.Client.call(Client.java:1473)
	... 24 more
2025-05-12 14:16:41,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:41,566 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 9 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 9.
2025-05-12 14:16:41,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1) with datanode deadline 1747059761635 and scm deadline 1747060121635
2025-05-12 14:16:41,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1) with datanode deadline 1747059761635 and scm deadline 1747060121635
2025-05-12 14:16:41,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1) with datanode deadline 1747059761635 and scm deadline 1747060121635
2025-05-12 14:16:41,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2025-05-12 14:16:42,123 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:42,200 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:42,200 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:42,201 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: 37cd9420-6324-41d7-8689-4a19e22733c5, Nodes: [ {144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1), ReplicaIndex: 0}, {c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), ReplicaIndex: 0}, {11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:11452936-83cb-47e1-bf10-894668a55a8a, CreationTimestamp2025-05-12T14:16:12.498Z[Etc/UTC]} removed.
2025-05-12 14:16:42,201 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: 1c927b84-b3e1-463b-ba8c-ffa6453324d9, Nodes: [ {c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:c4cac530-e369-4db2-afb8-073a8db2a7dc, CreationTimestamp2025-05-12T14:16:12.496Z[Etc/UTC]} removed.
2025-05-12 14:16:42,202 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 0 for DN c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:42,202 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(273)) - Send pipeline:PipelineID=1c927b84-b3e1-463b-ba8c-ffa6453324d9 close command to datanode c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:42,202 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:42,202 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: 1c927b84-b3e1-463b-ba8c-ffa6453324d9, Nodes: [ {c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:c4cac530-e369-4db2-afb8-073a8db2a7dc, CreationTimestamp2025-05-12T14:16:12.496Z[Etc/UTC]} removed.
2025-05-12 14:16:42,203 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(273)) - Send pipeline:PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 close command to datanode 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a
2025-05-12 14:16:42,203 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(273)) - Send pipeline:PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 close command to datanode c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:42,203 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(273)) - Send pipeline:PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5 close command to datanode 11452936-83cb-47e1-bf10-894668a55a8a
2025-05-12 14:16:42,203 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: 37cd9420-6324-41d7-8689-4a19e22733c5, Nodes: [ {144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1), ReplicaIndex: 0}, {c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1), ReplicaIndex: 0}, {11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:11452936-83cb-47e1-bf10-894668a55a8a, CreationTimestamp2025-05-12T14:16:12.498Z[Etc/UTC]} removed.
2025-05-12 14:16:42,203 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 6 for DN c4cac530-e369-4db2-afb8-073a8db2a7dc(localhost/127.0.0.1)
2025-05-12 14:16:42,204 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/c4cac530-e369-4db2-afb8-073a8db2a7dc
2025-05-12 14:16:42,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to 144de3a8-1dcf-4c8c-bdc0-06d4ed465e0a(localhost/127.0.0.1) with datanode deadline 1747059762204 and scm deadline 1747060122204
2025-05-12 14:16:42,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(663)) - Sending command [closeContainerCommand: cmdID: 1, encodedToken: "", term: 0, deadlineMsSinceEpoch: 0, containerID: 1, pipelineID: PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2025-05-12T14:16:39.200131098Z, pipelineID=PipelineID=37cd9420-6324-41d7-8689-4a19e22733c5, owner=omServiceIdDefault} to 11452936-83cb-47e1-bf10-894668a55a8a(localhost/127.0.0.1) with datanode deadline 1747059762204 and scm deadline 1747060122204
2025-05-12 14:16:42,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(382)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2025-05-12 14:16:42,212 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:42,212 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$5(222)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 0 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7
2025-05-12 14:16:42,213 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(114)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db]
2025-05-12 14:16:42,214 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(108)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db from cache
2025-05-12 14:16:42,214 [ForkJoinPool.commonPool-worker-3] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(543)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-552457b8-2cd5-4350-b50d-a5584fec4a7a/ozone-meta/datanode-4/data-0/hdds/552457b8-2cd5-4350-b50d-a5584fec4a7a/DS-08a093c1-1426-4ba8-9d46-b1b2037bee20/container.db for volume DS-08a093c1-1426-4ba8-9d46-b1b2037bee20
2025-05-12 14:16:42,214 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2025-05-12 14:16:42,215 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-05-12 14:16:42,216 [ForkJoinPool.commonPool-worker-3] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(630)) - Ozone container server stopped.
2025-05-12 14:16:42,216 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 4 pipelines in house.
2025-05-12 14:16:42,216 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 already exists in Recon pipeline metadata.
2025-05-12 14:16:42,217 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 already exists in Recon pipeline metadata.
2025-05-12 14:16:42,217 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 already exists in Recon pipeline metadata.
2025-05-12 14:16:42,217 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 already exists in Recon pipeline metadata.
2025-05-12 14:16:42,225 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15156 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2025-05-12 14:16:42,229 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@131dc42b{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-05-12 14:16:42,229 [ForkJoinPool.commonPool-worker-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3a6d0b0f{HTTP/1.1, (http/1.1)}{0.0.0.0:15296}
2025-05-12 14:16:42,229 [ForkJoinPool.commonPool-worker-3] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-12 14:16:42,229 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@30e6148f{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-12 14:16:42,229 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2cfdce9e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-12 14:16:42,230 [ForkJoinPool.commonPool-worker-3] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-05-12 14:16:42,230 [ForkJoinPool.commonPool-worker-3] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15297
2025-05-12 14:16:42,231 [IPC Server listener on 15297] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15297
2025-05-12 14:16:42,231 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:42,231 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(491)) - Stopping the StorageContainerManager
2025-05-12 14:16:42,232 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1608)) - Container Balancer is not running.
2025-05-12 14:16:42,232 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1742)) - Stopping Replication Manager Service.
2025-05-12 14:16:42,232 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(316)) - Stopping Replication Monitor Thread.
2025-05-12 14:16:42,232 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1617)) - Stopping the Datanode Admin Monitor.
2025-05-12 14:16:42,232 [OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - OverReplicatedProcessor interrupted. Exiting...
2025-05-12 14:16:42,232 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(936)) - Replication Monitor Thread is stopped
2025-05-12 14:16:42,232 [UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - UnderReplicatedProcessor interrupted. Exiting...
2025-05-12 14:16:42,232 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1624)) - Stopping datanode service RPC server
2025-05-12 14:16:42,232 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(447)) - Stopping the RPC server for DataNodes
2025-05-12 14:16:42,232 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15262
2025-05-12 14:16:42,236 [IPC Server listener on 15262] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15262
2025-05-12 14:16:42,236 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:42,299 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(909)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-05-12 14:16:42,299 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode de559106-0595-44cd-a7e8-c94ad5654e48(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8]
2025-05-12 14:16:42,300 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1632)) - Stopping block service RPC server
2025-05-12 14:16:42,300 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(175)) - Stopping the RPC server for Block Protocol
2025-05-12 14:16:42,300 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15261
2025-05-12 14:16:42,300 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(51)) - Datanode de559106-0595-44cd-a7e8-c94ad5654e48(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8]
2025-05-12 14:16:42,301 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 moved to CLOSED state
2025-05-12 14:16:42,302 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(509)) - Pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 moved to CLOSED state
2025-05-12 14:16:42,305 [IPC Server listener on 15261] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15261
2025-05-12 14:16:42,305 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1639)) - Stopping the StorageContainerLocationProtocol RPC server
2025-05-12 14:16:42,305 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:42,306 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(101)) - Recon has 4 pipelines in house.
2025-05-12 14:16:42,306 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=a2d07b4d-d13e-4869-801f-303d3d0838b0 already exists in Recon pipeline metadata.
2025-05-12 14:16:42,306 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(216)) - Stopping the RPC server for Client Protocol
2025-05-12 14:16:42,306 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15260
2025-05-12 14:16:42,306 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=80098ea9-029b-4e0e-b39c-b88182d2fac1 already exists in Recon pipeline metadata.
2025-05-12 14:16:42,307 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=ebcc11cb-261b-4635-a8cc-c4f7b421a0f8 already exists in Recon pipeline metadata.
2025-05-12 14:16:42,308 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] WARN  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(107)) - Pipeline PipelineID=de4019d5-adfb-4cd2-85ea-cdc12ea84350 already exists in Recon pipeline metadata.
2025-05-12 14:16:42,313 [IPC Server listener on 15260] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15260
2025-05-12 14:16:42,314 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1646)) - Stopping Storage Container Manager HTTP server.
2025-05-12 14:16:42,313 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:42,314 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5e018f16{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-05-12 14:16:42,315 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@78a6bea1{HTTP/1.1, (http/1.1)}{0.0.0.0:15263}
2025-05-12 14:16:42,315 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-12 14:16:42,315 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7c7ab7dd{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-05-12 14:16:42,315 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@122c3b77{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-12 14:16:42,316 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1654)) - Stopping SCM LayoutVersionManager Service.
2025-05-12 14:16:42,316 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1666)) - Stopping Block Manager Service.
2025-05-12 14:16:42,316 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2025-05-12 14:16:42,316 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2025-05-12 14:16:42,317 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1691)) - Stopping SCM Event Queue.
2025-05-12 14:16:42,317 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1698)) - Stopping SCM HA services.
2025-05-12 14:16:42,318 [main] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:stop(266)) - stopping ratis server 0.0.0.0:15264
2025-05-12 14:16:42,318 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(417)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: close
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(513)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A: shutdown
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A5584FEC4A7A,id=fe26b7a1-1f7d-4969-b43e-0bdee51a4d81
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderStateImpl
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(287)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-PendingRequests: sendNotLeaderResponses
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyNotLeader(211)) - current leader SCM steps down.
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(95)) - update <isLeader,term> from <true,2> to <false,0>
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(101)) - update <isLeaderReady> from <true> to <false>
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(84)) - Service BackgroundPipelineScrubber transitions to PAUSING.
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(84)) - Service ExpiredContainerReplicaOpScrubber transitions to PAUSING.
2025-05-12 14:16:42,318 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:notifyStatusChanged(84)) - Service SCMHATransactionMonitor transitions to PAUSING.
2025-05-12 14:16:42,319 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(343)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown server GrpcServerProtocolService now
2025-05-12 14:16:42,319 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(164)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater: set stopIndex = 52
2025-05-12 14:16:42,320 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:takeSnapshot(330)) - Current Snapshot Index 52, takeSnapshot took 1 ms
2025-05-12 14:16:42,320 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(303)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater: Took a snapshot at index 52
2025-05-12 14:16:42,320 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(102)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 52
2025-05-12 14:16:42,320 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(141)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:2, i:52)
2025-05-12 14:16:42,320 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-05-12 14:16:42,325 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(352)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: shutdown server GrpcServerProtocolService successfully
2025-05-12 14:16:42,600 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(91)) - A dead datanode is detected. d6468b48-4b84-4546-9e40-0ea0f44d9603(localhost/127.0.0.1)
2025-05-12 14:16:42,600 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(462)) - Pipeline Pipeline{ Id: de4019d5-adfb-4cd2-85ea-cdc12ea84350, Nodes: [ {d6468b48-4b84-4546-9e40-0ea0f44d9603(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d6468b48-4b84-4546-9e40-0ea0f44d9603, CreationTimestamp2025-05-12T14:16:12.868Z[Etc/UTC]} removed.
2025-05-12 14:16:42,601 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(113)) - Clearing command queue of size 0 for DN d6468b48-4b84-4546-9e40-0ea0f44d9603(localhost/127.0.0.1)
2025-05-12 14:16:42,601 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/d6468b48-4b84-4546-9e40-0ea0f44d9603
2025-05-12 14:16:42,601 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "pkrvmberfyhpb9w/10.1.0.72"; destination host is: "0.0.0.0":15260; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15260. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2025-05-12 14:16:43,127 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(194)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2025-05-12 14:16:43,127 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$5(222)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 0 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7
2025-05-12 14:16:43,303 [fe26b7a1-1f7d-4969-b43e-0bdee51a4d81-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(252)) - fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-SegmentedRaftLogWorker close()
2025-05-12 14:16:43,303 [JvmPauseMonitor46] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-fe26b7a1-1f7d-4969-b43e-0bdee51a4d81: Stopped
2025-05-12 14:16:43,304 [main] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(127)) - Stopping SCMHATransactionMonitor Service.
2025-05-12 14:16:43,304 [SCMHATransactionMonitor] WARN  SCMHATransactionMonitor (BackgroundSCMService.java:run(111)) - SCMHATransactionMonitor is interrupted, exit
2025-05-12 14:16:43,304 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping RatisPipelineUtilsThread.
2025-05-12 14:16:43,304 [RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - RatisPipelineUtilsThread is interrupted.
2025-05-12 14:16:43,304 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(127)) - Stopping BackgroundPipelineScrubber Service.
2025-05-12 14:16:43,304 [BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(111)) - BackgroundPipelineScrubber is interrupted, exit
2025-05-12 14:16:43,304 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2025-05-12 14:16:43,306 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2025-05-12 14:16:43,306 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2025-05-12 14:16:43,306 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - RatisPipelineUtilsThread is not running, just ignore.
2025-05-12 14:16:43,306 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(122)) - BackgroundPipelineScrubber Service is not running, skip stop.
2025-05-12 14:16:43,306 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(127)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2025-05-12 14:16:43,306 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2025-05-12 14:16:43,306 [ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(111)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2025-05-12 14:16:43,307 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(323)) - Replication Monitor Thread is not running.
2025-05-12 14:16:43,307 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(350)) - Cannot stop Container Balancer because it's not running or stopping
2025-05-12 14:16:43,307 [main] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(122)) - SCMHATransactionMonitor Service is not running, skip stop.
2025-05-12 14:16:43,307 [LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(285)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1133)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:283)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-05-12 14:16:43,307 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1733)) - Stopping SCM MetadataStore.
2025-05-12 14:16:43,309 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopRecon(506)) - Stopping Recon
2025-05-12 14:16:43,309 [main] INFO  recon.ReconServer (ReconServer.java:stop(262)) - Stopping Recon server
2025-05-12 14:16:43,310 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@777d0cde{recon,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar!/webapps/recon}
2025-05-12 14:16:43,311 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@52cd51de{HTTP/1.1, (http/1.1)}{0.0.0.0:15270}
2025-05-12 14:16:43,311 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-05-12 14:16:43,311 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@21d97b2e{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/ozone-recon-2.1.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-05-12 14:16:43,311 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@694ca345{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-05-12 14:16:43,312 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(447)) - Stopping the RPC server for DataNodes
2025-05-12 14:16:43,312 [main] INFO  ipc.Server (Server.java:stop(3697)) - Stopping server on 15271
2025-05-12 14:16:43,315 [IPC Server listener on 15271] INFO  ipc.Server (Server.java:run(1585)) - Stopping IPC Server listener on 15271
2025-05-12 14:16:43,316 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1718)) - Stopping IPC Server Responder
2025-05-12 14:16:43,401 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(909)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-05-12 14:16:43,401 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(63)) - Stopping PipelineSyncTask Thread.
2025-05-12 14:16:43,401 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(63)) - Stopping ContainerHealthTask Thread.
2025-05-12 14:16:43,401 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(63)) - Stopping ContainerSizeCountTask Thread.
2025-05-12 14:16:43,402 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(460)) - Stopping SCM Event Queue.
2025-05-12 14:16:43,402 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(468)) - Flushing container replica history to DB.
2025-05-12 14:16:43,404 [ContainerSizeCountTask] INFO  updater.ReconTaskStatusUpdater (ReconTaskStatusUpdater.java:updateDetails(124)) - Registered Task: ContainerSizeCountTask
2025-05-12 14:16:43,405 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:stop(364)) - Stopping Ozone Manager Service Provider.
2025-05-12 14:16:43,405 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:stop(247)) - Stopping Recon Task Controller.
2025-05-12 14:16:43,405 [main] INFO  recon.ReconServer (ReconServer.java:stop(287)) - Closing Recon Container Key DB.
2025-05-12 14:16:43,407 [JvmPauseMonitor48] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-Recon: Stopped
====> TestReconAndAdminContainerCLI TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2025-05-12 02:16:43,465

"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=1770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=8212 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"pool-1063-thread-1"  prio=5 tid=7096 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Reference Handler" daemon prio=10 tid=9 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.7/java.lang.ref.Reference.waitForReferencePendingList(Native Method)
        at java.base@21.0.7/java.lang.ref.Reference.processPendingReferences(Reference.java:246)
        at java.base@21.0.7/java.lang.ref.Reference$ReferenceHandler.run(Reference.java:208)
"junit-jupiter-timeout-watcher"  prio=10 tid=7106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=4867 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007f1468bd94e8.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-shared-destroyer-0" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=3161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-5" daemon prio=5 tid=4017 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=1121 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=4684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=1022 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=3856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"pool-1319-thread-1"  prio=5 tid=8538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=2456 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Notification Thread" daemon prio=9 tid=22 runnable
java.lang.Thread.State: RUNNABLE
"Timer-1" daemon prio=5 tid=517 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:339)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:537)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=7514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=3408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007f1468bd94e8.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=6142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=6322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007f1468bd94e8.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=3845 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=6775 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=2445 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=1111 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer3" daemon prio=5 tid=1069 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15271" daemon prio=5 tid=7926 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:613)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1121)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15260" daemon prio=5 tid=8513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:613)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1121)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=4724 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=3160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-0" daemon prio=5 tid=1023 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=6776 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-worker-ELG-3-3" daemon prio=5 tid=1025 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:193)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:304)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:368)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=6066 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool.commonPool-worker-2" daemon prio=5 tid=36 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.7/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"MutableQuantiles-0" daemon prio=5 tid=668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=7630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fe26b7a1-1f7d-4969-b43e-0bdee51a4d81@group-A5584FEC4A7A-LeaderStateImpl" daemon prio=5 tid=7408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:763)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=8200 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=2457 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Finalizer" daemon prio=8 tid=10 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:339)
        at java.base@21.0.7/java.lang.ref.NativeReferenceQueue.await(NativeReferenceQueue.java:48)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:158)
        at java.base@21.0.7/java.lang.ref.NativeReferenceQueue.remove(NativeReferenceQueue.java:89)
        at java.base@21.0.7/java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:173)
"timer5" daemon prio=5 tid=1098 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=5304 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=3277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Signal Dispatcher" daemon prio=9 tid=11 runnable
java.lang.Thread.State: RUNNABLE
"PipelineSyncTask" daemon prio=5 tid=7759 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007f1468bd94e8.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=3855 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"fileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=5315 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"IPC Client (1455659337) connection to 0.0.0.0/0.0.0.0:15271 from runner" daemon prio=5 tid=7925 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1042)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1093)
"grpc-default-worker-ELG-3-4" daemon prio=5 tid=1026 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-3" daemon prio=5 tid=1061 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=1122 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"surefire-process-checker" daemon prio=5 tid=26 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=6764 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer2" daemon prio=5 tid=1064 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"timer4" daemon prio=5 tid=1071 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"Common-Cleaner" daemon prio=8 tid=17 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1852)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.await(ReferenceQueue.java:71)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:143)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:218)
        at java.base@21.0.7/jdk.internal.ref.CleanerImpl.run(CleanerImpl.java:140)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
        at java.base@21.0.7/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:186)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=1769 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-EventQueue-DeadNodeForReconDeadNodeHandler" daemon prio=5 tid=8542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:135)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:112)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
        at app/jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
        at app//org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor$$Lambda/0x00007f1468c6f4f0.run(Unknown Source)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-2" daemon prio=5 tid=1060 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-EventQueue-DeadNodeForReconDeadNodeHandler" daemon prio=5 tid=5649 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:135)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:112)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
        at app/jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
        at app//org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor$$Lambda/0x00007f1468c6f4f0.run(Unknown Source)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"LeakDetector-ManagedRocksObject0" daemon prio=5 tid=49 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.await(ReferenceQueue.java:67)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:158)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:234)
        at app//org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:79)
        at app//org.apache.hadoop.hdds.utils.LeakDetector$$Lambda/0x00007f1468445b90.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=8199 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"gradle-enterprise-test-client-gradle-enterprise-test-listener"  prio=5 tid=31 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.7/java.io.ObjectOutputStream$BlockDataOutputStream.getUTFLength(ObjectOutputStream.java:2165)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeString(ObjectOutputStream.java:1319)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1188)
        at java.base@21.0.7/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1585)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1542)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1451)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1194)
        at java.base@21.0.7/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1585)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1542)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1451)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1194)
        at java.base@21.0.7/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1585)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1542)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1451)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1194)
        at java.base@21.0.7/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:358)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.a(SourceFile:141)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.b(SourceFile:93)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a$$Lambda/0x00007f146812c478.run(Unknown Source)
        at java.base@21.0.7/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
        at java.base@21.0.7/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=2009 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007f1468bd94e8.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-7" daemon prio=5 tid=8377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=7513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-stream-flusher" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=1110 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=4607 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=4608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"PipelineSyncTask" daemon prio=5 tid=662 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007f1468bd94e8.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer6" daemon prio=5 tid=1099 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=1024 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"derby.rawStoreDaemon" daemon prio=5 tid=1846 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=6184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"ContainerHealthTask" daemon prio=5 tid=7760 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ozone.recon.fsck.ContainerHealthTask.run(ContainerHealthTask.java:120)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda/0x00007f1468bd94e8.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool.commonPool-worker-1" daemon prio=5 tid=35 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.7/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"timer1" daemon prio=5 tid=1063 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"derby.rawStoreDaemon" daemon prio=5 tid=3237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-executor-6" daemon prio=5 tid=4018 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-EventQueue-DeadNodeForReconDeadNodeHandler" daemon prio=5 tid=7099 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.7/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:135)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:112)
        at app//org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
        at app/jdk.proxy2/jdk.proxy2.$Proxy59.submitRequest(Unknown Source)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:201)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:191)
        at app//org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.queryNode(StorageContainerLocationProtocolClientSideTranslatorPB.java:513)
        at app//org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getNodes(StorageContainerServiceProviderImpl.java:115)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:65)
        at app//org.apache.hadoop.ozone.recon.scm.ReconDeadNodeHandler.onMessage(ReconDeadNodeHandler.java:37)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:66)
        at app//org.apache.hadoop.hdds.server.events.SingleThreadExecutor$$Lambda/0x00007f1468c6f4f0.run(Unknown Source)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=25 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.7/java.io.FileInputStream.readBytes(Native Method)
        at java.base@21.0.7/java.io.FileInputStream.read(FileInputStream.java:287)
        at java.base@21.0.7/java.io.BufferedInputStream.read1(BufferedInputStream.java:345)
        at java.base@21.0.7/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)
        at java.base@21.0.7/java.io.BufferedInputStream.read(BufferedInputStream.java:399)
        at java.base@21.0.7/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)
        at java.base@21.0.7/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)
        at java.base@21.0.7/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)
        at java.base@21.0.7/java.io.BufferedInputStream.read(BufferedInputStream.java:399)
        at app//org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:169)
        at app//org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:50)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.read(AbstractStreamDecoder.java:430)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.read(AbstractStreamDecoder.java:419)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.readMessageType(AbstractStreamDecoder.java:116)
        at app//org.apache.maven.surefire.booter.stream.CommandDecoder.decode(CommandDecoder.java:77)
        at app//org.apache.maven.surefire.booter.spi.CommandChannelDecoder.decode(CommandChannelDecoder.java:60)
        at app//org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:290)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer0" daemon prio=5 tid=1101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=6065 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"process reaper" daemon prio=10 tid=6760 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
        at java.base@21.0.7/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:186)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=3844 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"directoryTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=5303 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=6765 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"timer7" daemon prio=5 tid=1100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.7/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.7/java.util.TimerThread.run(Timer.java:516)
"IPC Client (1455659337) connection to 0.0.0.0/0.0.0.0:15262 from runner" daemon prio=5 tid=7923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1042)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1093)
"derby.rawStoreDaemon" daemon prio=5 tid=7588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/java.lang.Object.wait0(Native Method)
        at java.base@21.0.7/java.lang.Object.wait(Object.java:366)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=43 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:220)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:213)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:308)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:365)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool.commonPool-worker-3" daemon prio=5 tid=447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkUntil(LockSupport.java:449)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1891)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.7/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.7/java.lang.Thread.dumpThreads(Native Method)
        at java.base@21.0.7/java.lang.Thread.getAllStackTraces(Thread.java:2522)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:81)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:67)
        at app//org.apache.ozone.test.TimedOutTestsListener.lambda$executionFinished$0(TimedOutTestsListener.java:53)
        at app//org.apache.ozone.test.TimedOutTestsListener$$Lambda/0x00007f1468f12e00.accept(Unknown Source)
        at java.base@21.0.7/java.util.Optional.ifPresent(Optional.java:178)
        at app//org.apache.ozone.test.TimedOutTestsListener.executionFinished(TimedOutTestsListener.java:49)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$executionFinished$10(CompositeTestExecutionListener.java:74)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda/0x00007f1468f08a18.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$notifyEach$21(CompositeTestExecutionListener.java:110)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda/0x00007f1468120000.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:243)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.notifyEach(CompositeTestExecutionListener.java:108)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.executionFinished(CompositeTestExecutionListener.java:73)
        at app//org.junit.platform.launcher.core.ExecutionListenerAdapter.executionFinished(ExecutionListenerAdapter.java:57)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$executionFinished$6(CompositeEngineExecutionListener.java:60)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda/0x00007f1468f0fd00.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$notifyEach$13(CompositeEngineExecutionListener.java:82)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda/0x00007f146813f7f0.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:243)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.notifyEach(CompositeEngineExecutionListener.java:80)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.executionFinished(CompositeEngineExecutionListener.java:59)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:47)
        at app//org.junit.platform.launcher.core.StackTracePruningEngineExecutionListener.executionFinished(StackTracePruningEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:47)
        at app//org.junit.platform.launcher.core.OutcomeDelayingEngineExecutionListener.executionFinished(OutcomeDelayingEngineExecutionListener.java:63)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion(NodeTestTask.java:200)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:105)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda/0x00007f1468142460.accept(Unknown Source)
        at java.base@21.0.7/java.util.ArrayList.forEach(ArrayList.java:1596)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f1468147388.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f1468147170.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f1468146d68.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:201)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:170)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:94)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:59)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda/0x00007f146811e470.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:142)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:58)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
        at app//org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at app//org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39)
        at app//org.junit.platform.launcher.core.InterceptingLauncher$$Lambda/0x00007f146809ebf8.proceed(Unknown Source)
        at app//org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25)
        at app//org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38)
        at app//org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at app//org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:56)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:162)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:120)
        at app//org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
        at app//org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at app//org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
        at app//org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"openFileTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=2446 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"LeakDetector-OzoneClientObject1" daemon prio=5 tid=1102 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.await(ReferenceQueue.java:67)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:158)
        at java.base@21.0.7/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:234)
        at app//org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:79)
        at app//org.apache.hadoop.hdds.utils.LeakDetector$$Lambda/0x00007f1468445b90.run(Unknown Source)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=1886 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15262" daemon prio=5 tid=7924 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.7/java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:613)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.7/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1121)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1763)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.7/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=5316 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)
"deletedTable_PartialTableCache-Cleanup-0" daemon prio=5 tid=8213 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.7/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.7/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.7/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.7/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1712)
        at java.base@21.0.7/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.7/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.7/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.7/java.lang.Thread.run(Thread.java:1583)

2025-05-12 14:16:43,567 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking $Proxy59.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15208 after 10 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 10.
2025-05-12 14:16:43,814 [shutdown-hook-0] INFO  recon.ReconServer (HddsServerUtil.java:lambda$startupShutdownMessage$0(695)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at pkrvmberfyhpb9w/10.1.0.13
************************************************************/
2025-05-12 14:16:43,814 [shutdown-hook-0] INFO  recon.ReconServer (HddsServerUtil.java:lambda$startupShutdownMessage$0(695)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at pkrvmberfyhpb9w/10.1.0.114
************************************************************/
2025-05-12 14:16:43,814 [shutdown-hook-0] INFO  recon.ReconServer (HddsServerUtil.java:lambda$startupShutdownMessage$0(695)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at pkrvmberfyhpb9w/10.1.0.114
************************************************************/
2025-05-12 14:16:43,815 [shutdown-hook-0] INFO  recon.ReconServer (HddsServerUtil.java:lambda$startupShutdownMessage$0(695)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at pkrvmberfyhpb9w/10.1.0.114
************************************************************/
2025-05-12 14:16:43,815 [shutdown-hook-0] INFO  recon.ReconServer (HddsServerUtil.java:lambda$startupShutdownMessage$0(695)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at pkrvmberfyhpb9w/10.1.0.13
************************************************************/
2025-05-12 14:16:43,815 [shutdown-hook-0] INFO  recon.ReconServer (HddsServerUtil.java:lambda$startupShutdownMessage$0(695)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at pkrvmberfyhpb9w/10.1.0.72
************************************************************/
