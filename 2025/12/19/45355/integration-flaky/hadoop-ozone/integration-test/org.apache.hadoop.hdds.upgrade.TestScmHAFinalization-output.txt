2025-12-19 13:34:04,794 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:04,795 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:04,795 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:04,795 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:04,795 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:04,795 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:04,795 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:04,795 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-1, RPC Address: localhost:15493 and Ratis port: 15493
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-1: 127.0.0.1:15494
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-1: 127.0.0.1:15497
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-1: 127.0.0.1:15495
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-1: 127.0.0.1:15492
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-1: 15493
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-1: 15496
2025-12-19 13:34:04,796 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-1: 127.0.0.1:15490
2025-12-19 13:34:04,797 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-1: 127.0.0.1:15491
2025-12-19 13:34:04,797 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-1: 127.0.0.1
2025-12-19 13:34:04,797 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:04,797 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:04,797 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:04,803 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:04,804 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:04,804 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:04,804 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:04,805 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:04,805 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:04,805 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:04,805 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-1, RPC Address: localhost:15493 and Ratis port: 15493
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-1: 127.0.0.1:15494
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-1: 127.0.0.1:15497
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-1: 127.0.0.1:15495
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-1: 127.0.0.1:15492
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-1: 15493
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-1: 15496
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-1: 127.0.0.1:15490
2025-12-19 13:34:04,806 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-1: 127.0.0.1:15491
2025-12-19 13:34:04,807 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-1: 127.0.0.1
2025-12-19 13:34:04,807 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:04,807 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:04,807 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:04,808 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:04,809 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.appender.buffer.byte-limit = 4194304 (default)
2025-12-19 13:34:04,810 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:04,811 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:04,811 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:04,811 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:04,811 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:04,811 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:04,811 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:04,811 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.port = 15493 (fallback to raft.grpc.server.port)
2025-12-19 13:34:04,811 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:04,812 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.port = 15493 (fallback to raft.grpc.server.port)
2025-12-19 13:34:04,812 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15493 (custom)
2025-12-19 13:34:04,812 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (ConfUtils.java:logGet(62)) - raft.grpc.message.size.max = 5242880 (custom)
2025-12-19 13:34:04,812 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (ConfUtils.java:logGet(62)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-12-19 13:34:04,813 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-19 13:34:04,814 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis] (custom)
2025-12-19 13:34:04,815 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: addNew group-3149B70783DC:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493] returns group-3149B70783DC:java.util.concurrent.CompletableFuture@22c842c0[Not completed]
2025-12-19 13:34:04,815 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: new RaftServerImpl for group-3149B70783DC:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493] with SCMStateMachine-173:uninitialized
2025-12-19 13:34:04,815 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-19 13:34:04,815 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: ConfigurationManager, init=conf: {index: -1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:04,815 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.notification.no-leader.timeout = 60s (default)
2025-12-19 13:34:04,815 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.retrycache.expirytime = 60000ms (default)
2025-12-19 13:34:04,816 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc does not exist. Creating ...
2025-12-19 13:34:04,818 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:04,819 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc has been successfully formatted.
2025-12-19 13:34:04,819 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: initialize group-3149B70783DC
2025-12-19 13:34:04,819 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-173:50ee075d-c1e7-43b2-938b-a7dc0bd7923f:group-3149B70783DC) returns null
2025-12-19 13:34:04,819 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:04,819 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#21751,50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.queue.element-limit = 4096 (default)
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.write.buffer.size = 4194312 (custom)
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: start as a follower, conf=conf: {index: -1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:04,820 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:04,821 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState
2025-12-19 13:34:04,821 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:04,821 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:04,821 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-12-19 13:34:04,821 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.snapshot.retention.file.num = -1 (default)
2025-12-19 13:34:04,821 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: Successfully started.
2025-12-19 13:34:04,821 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.first-election.timeout.min = 5000ms (custom)
2025-12-19 13:34:04,821 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.first-election.timeout.max = 5200ms (custom)
2025-12-19 13:34:04,821 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start RPC server
2025-12-19 13:34:04,822 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: GrpcServicesImpl started, listening on 15493
2025-12-19 13:34:04,823 [JvmPauseMonitor77] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-50ee075d-c1e7-43b2-938b-a7dc0bd7923f: Started
2025-12-19 13:34:05,564 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:05,675 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:05,728 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:06,565 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:06,599 [timer1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - db789b00-552d-47af-82af-a004293aae40: Completed APPEND_ENTRIES, lastRequest: null  (Repeated 6 times in the last 5.000s)
2025-12-19 13:34:06,599 [timer2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - db789b00-552d-47af-82af-a004293aae40: Completed APPEND_ENTRIES, lastReply: serverReply { requestorId: "855ca690-d1ad-4600-b159-013edca2cac7" replyId: "db789b00-552d-47af-82af-a004293aae40" raftGroupId { id: "\r\252\315\351P\252A)\255\230;.\253+n\224" } callId: 53 success: true } term: 1 nextIndex: 1 matchIndex: 18446744073709551615 isHearbeat: true  (Repeated 6 times in the last 5.000s)
2025-12-19 13:34:06,600 [timer3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 855ca690-d1ad-4600-b159-013edca2cac7: Completed APPEND_ENTRIES, lastRequest: null  (Repeated 4 times in the last 5.001s)
2025-12-19 13:34:06,600 [timer4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 855ca690-d1ad-4600-b159-013edca2cac7: Completed APPEND_ENTRIES, lastReply: serverReply { requestorId: "30ebe7c9-7476-496b-b21f-992a4521ab61" replyId: "855ca690-d1ad-4600-b159-013edca2cac7" raftGroupId { id: "\v]{\306\231\024JG\274\221V\022@\2128\006" } callId: 52 success: true } term: 1 nextIndex: 1 matchIndex: 18446744073709551615 isHearbeat: true  (Repeated 4 times in the last 5.000s)
2025-12-19 13:34:06,607 [timer5] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - db789b00-552d-47af-82af-a004293aae40@group-9DFA6617249D->30ebe7c9-7476-496b-b21f-992a4521ab61-AppendLogResponseHandler: Failed appendEntries (Repeated 2 times in the last 5.000s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:34:06,608 [timer6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 855ca690-d1ad-4600-b159-013edca2cac7@group-3B2EAB2B6E94->30ebe7c9-7476-496b-b21f-992a4521ab61-GrpcLogAppender: Follower failed (request=null, errorCount=2); keep nextIndex (1) unchanged and retry. (Repeated 4 times in the last 5.000s)
2025-12-19 13:34:06,608 [timer7] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - 855ca690-d1ad-4600-b159-013edca2cac7@group-3B2EAB2B6E94->30ebe7c9-7476-496b-b21f-992a4521ab61-AppendLogResponseHandler: Failed appendEntries (Repeated 2 times in the last 5.000s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:34:06,675 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:06,728 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:06,734 [timer0] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - db789b00-552d-47af-82af-a004293aae40@group-9DFA6617249D->855ca690-d1ad-4600-b159-013edca2cac7-AppendLogResponseHandler: Failed appendEntries (Repeated 2 times in the last 5.000s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:34:06,734 [timer1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - db789b00-552d-47af-82af-a004293aae40@group-9DFA6617249D->855ca690-d1ad-4600-b159-013edca2cac7-GrpcLogAppender: Follower failed (request=null, errorCount=2); keep nextIndex (1) unchanged and retry. (Repeated 2 times in the last 5.000s)
2025-12-19 13:34:07,565 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:07,676 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:07,729 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:08,566 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:08,676 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:08,729 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:09,566 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:09,677 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:09,730 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:09,825 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5004791568ns, electionTimeout:5004ms
2025-12-19 13:34:09,825 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState
2025-12-19 13:34:09,825 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-19 13:34:09,826 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115
2025-12-19 13:34:09,826 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:09,826 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115 PRE_VOTE round 0: result PASSED (term=0)
2025-12-19 13:34:09,827 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115 ELECTION round 0: result PASSED (term=1)
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.write.element-limit = 4096 (default)
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.watch.timeout = 10s (default)
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: change Leader from null to 50ee075d-c1e7-43b2-938b-a7dc0bd7923f at term 1 for becomeLeader, leader elected after 5012ms
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection115] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 0, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:09,828 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:09,834 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_0
2025-12-19 13:34:09,835 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-19 13:34:10,567 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:10,677 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:10,730 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:10,823 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: close
2025-12-19 13:34:10,823 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown server GrpcServerProtocolService now
2025-12-19 13:34:10,824 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: shutdown
2025-12-19 13:34:10,824 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:10,824 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl
2025-12-19 13:34:10,824 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-PendingRequests: sendNotLeaderResponses
2025-12-19 13:34:10,824 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:34:10,824 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:34:10,824 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:34:10,824 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:34:10,824 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:34:10,825 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:34:10,835 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker close()
2025-12-19 13:34:10,835 [JvmPauseMonitor77] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-50ee075d-c1e7-43b2-938b-a7dc0bd7923f: Stopped
2025-12-19 13:34:10,837 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:initializeRatis(1344)) - Enabled Ratis!
2025-12-19 13:34:10,837 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:scmInit(1293)) - SCM initialization succeeded. Current cluster id for sd=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm; cid=9a5f6a08-7b44-4db9-b4fd-3149b70783dc; layoutVersion=0; scmId=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:10,837 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:10,837 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:10,837 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:10,837 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-1, RPC Address: localhost:15493 and Ratis port: 15493
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-1: 127.0.0.1:15494
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-1: 127.0.0.1:15497
2025-12-19 13:34:10,838 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-1: 127.0.0.1:15495
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-1: 127.0.0.1:15492
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-1: 15493
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-1: 15496
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-1: 127.0.0.1:15490
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-1: 127.0.0.1:15491
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-1: 127.0.0.1
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:10,839 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:10,840 [ForkJoinPool-6-worker-1] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:10,840 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:10,888 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.2.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-12-19 13:34:10,888 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-12-19 13:34:10,903 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:<init>(101)) - starting Raft server for scm:50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:10,904 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:10,905 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:10,905 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:10,905 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:10,905 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:10,905 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:10,905 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:10,905 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:10,905 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.port = 15493 (fallback to raft.grpc.server.port)
2025-12-19 13:34:10,906 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:10,906 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.port = 15493 (fallback to raft.grpc.server.port)
2025-12-19 13:34:10,907 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(273)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:10,907 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: addNew group-3149B70783DC:[] returns group-3149B70783DC:java.util.concurrent.CompletableFuture@924ee3c[Not completed]
2025-12-19 13:34:10,907 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: new RaftServerImpl for group-3149B70783DC:[] with SCMStateMachine-174:uninitialized
2025-12-19 13:34:10,907 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:10,908 [ForkJoinPool-6-worker-1] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:<init>(61)) - Initializing SCM Snapshot Provider
2025-12-19 13:34:10,908 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:10,908 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisSnapshotDirectory(415)) - Snapshot directory for Ratis is not configured. Falling back to ozone.metadata.dirs
2025-12-19 13:34:10,909 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:10,909 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmOnFinalizeActionForDatanodeSchemaV2
2025-12-19 13:34:10,909 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
2025-12-19 13:34:10,909 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ContainerTableSchemaFinalizeAction
2025-12-19 13:34:10,909 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmHAFinalizeUpgradeActionDatanode
2025-12-19 13:34:10,909 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV2FinalizeAction
2025-12-19 13:34:10,910 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(354)) - upgrade localId to 115816896921600000
2025-12-19 13:34:10,911 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(364)) - upgrade delTxnId to 0
2025-12-19 13:34:10,912 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(380)) - upgrade containerId to 0
2025-12-19 13:34:10,913 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(415)) - upgrade CertificateId to 2
2025-12-19 13:34:10,913 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-12-19 13:34:10,913 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:10,913 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:10,914 [ForkJoinPool-6-worker-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(185)) - Entering startup safe mode.
2025-12-19 13:34:10,914 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-12-19 13:34:10,914 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:10,914 [ForkJoinPool-6-worker-1] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-12-19 13:34:10,915 [ForkJoinPool-6-worker-1] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(55)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-19 13:34:10,915 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:10,915 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2025-12-19 13:34:10,915 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:10,915 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(64)) - Starting BackgroundPipelineScrubber Service.
2025-12-19 13:34:10,915 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2025-12-19 13:34:10,916 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(64)) - Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:10,916 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2025-12-19 13:34:10,917 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:10,917 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:10,917 [ForkJoinPool-6-worker-1] INFO  block.SCMDeletedBlockTransactionStatusManager (SCMDeletedBlockTransactionStatusManager.java:loadDeletedBlocksSummary(686)) - Property DeletedBlocksTransactionSummary for service DeletedBlockLogStateManager not found. 
2025-12-19 13:34:10,918 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2025-12-19 13:34:10,918 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:start(288)) - Starting Replication Monitor Thread.
2025-12-19 13:34:10,919 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2025-12-19 13:34:10,919 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed RATIS Containers threshold count to 0.
2025-12-19 13:34:10,919 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed EC Containers threshold count to 0.
2025-12-19 13:34:10,920 [ForkJoinPool-6-worker-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(231)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:10,920 [ForkJoinPool-6-worker-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(190)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-19 13:34:10,920 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(433)) - SCM start with adminUsers: [admin, runner]
2025-12-19 13:34:10,921 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:10,921 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15494
2025-12-19 13:34:10,921 [Socket Reader #1 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15494
2025-12-19 13:34:10,922 [Socket Reader #2 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15494
2025-12-19 13:34:10,922 [Socket Reader #3 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15494
2025-12-19 13:34:10,922 [Socket Reader #4 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15494
2025-12-19 13:34:10,922 [Socket Reader #5 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15494
2025-12-19 13:34:10,922 [Socket Reader #6 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15494
2025-12-19 13:34:10,922 [Socket Reader #7 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15494
2025-12-19 13:34:10,922 [Socket Reader #8 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15494
2025-12-19 13:34:10,922 [Socket Reader #9 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15494
2025-12-19 13:34:10,923 [Socket Reader #10 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15494
2025-12-19 13:34:10,923 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:10,924 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15497
2025-12-19 13:34:10,924 [Socket Reader #1 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15497
2025-12-19 13:34:10,924 [Socket Reader #2 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15497
2025-12-19 13:34:10,924 [Socket Reader #3 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15497
2025-12-19 13:34:10,924 [Socket Reader #4 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15497
2025-12-19 13:34:10,924 [Socket Reader #5 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15497
2025-12-19 13:34:10,925 [Socket Reader #6 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15497
2025-12-19 13:34:10,925 [Socket Reader #7 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15497
2025-12-19 13:34:10,925 [Socket Reader #8 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15497
2025-12-19 13:34:10,925 [Socket Reader #9 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15497
2025-12-19 13:34:10,925 [Socket Reader #10 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15497
2025-12-19 13:34:10,926 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:10,926 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15495
2025-12-19 13:34:10,926 [Socket Reader #1 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15495
2025-12-19 13:34:10,926 [Socket Reader #2 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15495
2025-12-19 13:34:10,926 [Socket Reader #3 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15495
2025-12-19 13:34:10,926 [Socket Reader #4 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15495
2025-12-19 13:34:10,927 [Socket Reader #5 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15495
2025-12-19 13:34:10,927 [Socket Reader #6 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15495
2025-12-19 13:34:10,927 [Socket Reader #7 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15495
2025-12-19 13:34:10,927 [Socket Reader #8 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15495
2025-12-19 13:34:10,927 [Socket Reader #9 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15495
2025-12-19 13:34:10,927 [Socket Reader #10 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15495
2025-12-19 13:34:10,930 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2025-12-19 13:34:10,930 [ForkJoinPool-6-worker-1] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-19 13:34:10,930 [ForkJoinPool-6-worker-1] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(288)) - Running pre-finalized state validations for unfinalized layout features.
2025-12-19 13:34:10,930 [ForkJoinPool-6-worker-1] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(301)) - Running first upgrade commands for unfinalized layout features.
2025-12-19 13:34:10,930 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1522)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15495
2025-12-19 13:34:10,931 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:start(204)) - starting ratis server 0.0.0.0:15493
2025-12-19 13:34:10,931 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:10,932 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:analyzeAndRecoverStorage(118)) - Read RaftStorageMetadata{term=1, votedFor=50ee075d-c1e7-43b2-938b-a7dc0bd7923f} from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/raft-meta
2025-12-19 13:34:10,932 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 0, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:10,932 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: initialize group-3149B70783DC
2025-12-19 13:34:10,932 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-174:50ee075d-c1e7-43b2-938b-a7dc0bd7923f:group-3149B70783DC) returns 0#-1
2025-12-19 13:34:10,932 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:10,933 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#21820,50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:10,933 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:10,933 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 0, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:10,934 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(171)) - Successfully read 1 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_0
2025-12-19 13:34:10,934 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:10,934 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 (append) at position 76
2025-12-19 13:34:10,934 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: start as a follower, conf=conf: {index: 0, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:10,934 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from      null to FOLLOWER at term 1 for startAsFollower
2025-12-19 13:34:10,934 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState
2025-12-19 13:34:10,934 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:10,934 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:10,935 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: Successfully started.
2025-12-19 13:34:10,935 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start RPC server
2025-12-19 13:34:10,935 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: GrpcServicesImpl started, listening on 15493
2025-12-19 13:34:10,935 [ForkJoinPool-6-worker-1] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:start(131)) -  scm role is FOLLOWER peers [50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]
2025-12-19 13:34:10,936 [ForkJoinPool-6-worker-1] INFO  ha.InterSCMGrpcService (InterSCMGrpcProtocolService.java:start(98)) - Starting SCM Grpc Service at port 15496
2025-12-19 13:34:10,936 [JvmPauseMonitor78] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-50ee075d-c1e7-43b2-938b-a7dc0bd7923f: Started
2025-12-19 13:34:10,936 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(64)) - Starting SCMHATransactionMonitor Service.
2025-12-19 13:34:10,936 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMHATransactionMonitor.
2025-12-19 13:34:10,936 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(61)) - SCMHATransactionMonitor Service is already running, skip start.
2025-12-19 13:34:10,944 [ForkJoinPool-6-worker-1] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2025-12-19 13:34:10,972 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(211)) - RPC server for Client  is listening at /0.0.0.0:15495
2025-12-19 13:34:10,973 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:10,973 [IPC Server listener on 15495] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15495: starting
2025-12-19 13:34:10,983 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1535)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15497
2025-12-19 13:34:10,984 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(166)) - RPC server for Block Protocol is listening at /0.0.0.0:15497
2025-12-19 13:34:10,985 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:10,986 [IPC Server listener on 15497] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15497: starting
2025-12-19 13:34:10,995 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(195)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15494
2025-12-19 13:34:10,995 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:10,995 [IPC Server listener on 15494] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15494: starting
2025-12-19 13:34:11,004 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SCMBlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:11,005 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for scm at: http://0.0.0.0:15490
2025-12-19 13:34:11,005 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:11,006 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:11,008 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:11,009 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2025-12-19 13:34:11,009 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:11,009 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:11,009 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/webserver
2025-12-19 13:34:11,009 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15490
2025-12-19 13:34:11,010 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:11,011 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:11,011 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:11,011 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-12-19 13:34:11,011 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@45c4dab2{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:11,012 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@469b90d{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-12-19 13:34:11,015 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3dc87b81{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:11,016 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@34a50daa{HTTP/1.1, (http/1.1)}{0.0.0.0:15490}
2025-12-19 13:34:11,016 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @837204ms
2025-12-19 13:34:11,016 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:11,016 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of scm listening at http://localhost:15490
2025-12-19 13:34:11,016 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createSCMService(622)) - Started SCM RPC server at /0.0.0.0:15495
2025-12-19 13:34:11,017 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:11,017 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:11,017 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-2, RPC Address: localhost:15501 and Ratis port: 15501
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-2: 127.0.0.1:15502
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-2: 127.0.0.1:15505
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-2: 127.0.0.1:15503
2025-12-19 13:34:11,018 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-2: 127.0.0.1:15500
2025-12-19 13:34:11,019 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-2: 15501
2025-12-19 13:34:11,019 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-2: 15504
2025-12-19 13:34:11,019 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-2: 127.0.0.1:15498
2025-12-19 13:34:11,019 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-2: 127.0.0.1:15499
2025-12-19 13:34:11,019 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-2: 127.0.0.1
2025-12-19 13:34:11,019 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:11,019 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:11,019 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:11,020 [ForkJoinPool-6-worker-1] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 2 nodes: [nodeId=scmNode-3,nodeAddress=/127.0.0.1:15513, nodeId=scmNode-1,nodeAddress=/127.0.0.1:15497]
2025-12-19 13:34:11,567 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:11,678 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:11,731 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:12,568 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:12,678 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:12,731 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:13,568 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:13,679 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:13,731 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:14,569 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:14,569 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15432 for past 0 seconds.
java.net.ConnectException: Call From localhost/127.0.0.1 to localhost:15432 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:876)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:639)
	at org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
	at org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
	at org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1435)
	... 12 more
2025-12-19 13:34:14,679 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:14,732 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:15,025 [ForkJoinPool-6-worker-1] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: org.apache.hadoop.ipc_.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): SCM Server:50ee075d-c1e7-43b2-938b-a7dc0bd7923f(localhost) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:249)
	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:111)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:17426)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:539)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:508)
	at org.apache.hadoop.ipc_.RPC$Server.call(RPC.java:1164)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:948)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc_.Server$Handler.run(Server.java:2951)
, while invoking $Proxy53.send over nodeId=scmNode-1,nodeAddress=/127.0.0.1:15497 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2025-12-19 13:34:15,569 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:15,680 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:15,680 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15424 for past 0 seconds.
java.net.ConnectException: Call From localhost/127.0.0.1 to localhost:15424 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:876)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:639)
	at org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
	at org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
	at org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1435)
	... 12 more
2025-12-19 13:34:15,733 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:15,965 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5031412188ns, electionTimeout:5031ms
2025-12-19 13:34:15,965 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState
2025-12-19 13:34:15,966 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2025-12-19 13:34:15,966 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116
2025-12-19 13:34:15,966 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116 PRE_VOTE round 0: submit vote requests at term 1 for conf: {index: 0, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:15,966 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116 PRE_VOTE round 0: result PASSED (term=1)
2025-12-19 13:34:15,967 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116 ELECTION round 0: submit vote requests at term 2 for conf: {index: 0, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:15,967 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116 ELECTION round 0: result PASSED (term=2)
2025-12-19 13:34:15,967 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116
2025-12-19 13:34:15,968 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2025-12-19 13:34:15,968 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:15,968 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl
2025-12-19 13:34:15,968 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:15,968 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(293)) - current SCM becomes leader of term 2.
2025-12-19 13:34:15,968 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(95)) - update <isLeader,term> from <false,0> to <true,2>
2025-12-19 13:34:15,968 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: change Leader from null to 50ee075d-c1e7-43b2-938b-a7dc0bd7923f at term 2 for becomeLeader, leader elected after 5060ms
2025-12-19 13:34:15,968 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(445)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2025-12-19 13:34:15,969 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection116] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:15,969 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(604)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_0 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_0-0
2025-12-19 13:34:15,969 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_1 at position 0
2025-12-19 13:34:15,974 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_1
2025-12-19 13:34:15,976 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl is ready since appliedIndex == startIndex == 1
2025-12-19 13:34:15,976 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMContext (SCMContext.java:setLeaderReady(122)) - update <isLeaderReady> from <false> to <true>
2025-12-19 13:34:15,976 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(268)) - Service BackgroundPipelineCreator transitions to RUNNING.
2025-12-19 13:34:15,977 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:15,977 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:15,977 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:15,977 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:15,977 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:16,570 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:16,680 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:16,733 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:17,026 [ForkJoinPool-6-worker-1] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(426)) - com.google.protobuf.ServiceException: java.net.ConnectException: Call From localhost/127.0.0.1 to localhost:15513 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy53.send over nodeId=scmNode-3,nodeAddress=/127.0.0.1:15513 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2025-12-19 13:34:17,570 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:17,681 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:17,734 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:18,571 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:18,681 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:18,734 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:19,029 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:scmBootstrap(1211)) - SCM BootStrap  is successful for ClusterID 9a5f6a08-7b44-4db9-b4fd-3149b70783dc, SCMID 558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:19,029 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:scmBootstrap(1213)) - Primary SCM Node ID 50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:19,029 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:19,030 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:19,030 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:19,030 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:19,030 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:19,030 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:19,030 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:19,030 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:19,030 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-2, RPC Address: localhost:15501 and Ratis port: 15501
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-2: 127.0.0.1:15502
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-2: 127.0.0.1:15505
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-2: 127.0.0.1:15503
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-2: 127.0.0.1:15500
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-2: 15501
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-2: 15504
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-2: 127.0.0.1:15498
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-2: 127.0.0.1:15499
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-2: 127.0.0.1
2025-12-19 13:34:19,031 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:19,032 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:19,032 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:19,032 [ForkJoinPool-6-worker-1] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:19,032 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:19,086 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.2.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-12-19 13:34:19,086 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-12-19 13:34:19,087 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:19,087 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:19,101 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:<init>(101)) - starting Raft server for scm:558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:19,102 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:19,102 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:19,102 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.port = 15501 (fallback to raft.grpc.server.port)
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.port = 15501 (fallback to raft.grpc.server.port)
2025-12-19 13:34:19,103 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15501 (custom)
2025-12-19 13:34:19,104 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis] (custom)
2025-12-19 13:34:19,105 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: addNew group-3149B70783DC:[] returns group-3149B70783DC:java.util.concurrent.CompletableFuture@7f761b3d[Not completed]
2025-12-19 13:34:19,105 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: new RaftServerImpl for group-3149B70783DC:[] with SCMStateMachine-175:uninitialized
2025-12-19 13:34:19,105 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:19,107 [ForkJoinPool-6-worker-1] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:<init>(61)) - Initializing SCM Snapshot Provider
2025-12-19 13:34:19,107 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:19,107 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisSnapshotDirectory(415)) - Snapshot directory for Ratis is not configured. Falling back to ozone.metadata.dirs
2025-12-19 13:34:19,108 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:19,109 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmOnFinalizeActionForDatanodeSchemaV2
2025-12-19 13:34:19,109 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
2025-12-19 13:34:19,109 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ContainerTableSchemaFinalizeAction
2025-12-19 13:34:19,109 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmHAFinalizeUpgradeActionDatanode
2025-12-19 13:34:19,109 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV2FinalizeAction
2025-12-19 13:34:19,110 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(354)) - upgrade localId to 115816896921600000
2025-12-19 13:34:19,111 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(364)) - upgrade delTxnId to 0
2025-12-19 13:34:19,112 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(380)) - upgrade containerId to 0
2025-12-19 13:34:19,113 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(415)) - upgrade CertificateId to 2
2025-12-19 13:34:19,113 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-12-19 13:34:19,113 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:19,113 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:19,114 [ForkJoinPool-6-worker-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(185)) - Entering startup safe mode.
2025-12-19 13:34:19,114 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-12-19 13:34:19,114 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:19,115 [ForkJoinPool-6-worker-1] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-12-19 13:34:19,115 [ForkJoinPool-6-worker-1] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(55)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-19 13:34:19,115 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:19,115 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2025-12-19 13:34:19,115 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-2-RatisPipelineUtilsThread.
2025-12-19 13:34:19,116 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(64)) - Starting BackgroundPipelineScrubber Service.
2025-12-19 13:34:19,116 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2025-12-19 13:34:19,116 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(64)) - Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:19,116 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2025-12-19 13:34:19,117 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:19,117 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:19,118 [ForkJoinPool-6-worker-1] INFO  block.SCMDeletedBlockTransactionStatusManager (SCMDeletedBlockTransactionStatusManager.java:loadDeletedBlocksSummary(686)) - Property DeletedBlocksTransactionSummary for service DeletedBlockLogStateManager not found. 
2025-12-19 13:34:19,118 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2025-12-19 13:34:19,118 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:start(288)) - Starting Replication Monitor Thread.
2025-12-19 13:34:19,119 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2025-12-19 13:34:19,119 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed RATIS Containers threshold count to 0.
2025-12-19 13:34:19,119 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed EC Containers threshold count to 0.
2025-12-19 13:34:19,120 [ForkJoinPool-6-worker-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(231)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:19,120 [ForkJoinPool-6-worker-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(190)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-19 13:34:19,121 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(433)) - SCM start with adminUsers: [admin, runner]
2025-12-19 13:34:19,121 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:19,121 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15502
2025-12-19 13:34:19,121 [Socket Reader #1 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15502
2025-12-19 13:34:19,122 [Socket Reader #2 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15502
2025-12-19 13:34:19,122 [Socket Reader #3 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15502
2025-12-19 13:34:19,122 [Socket Reader #4 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15502
2025-12-19 13:34:19,122 [Socket Reader #5 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15502
2025-12-19 13:34:19,123 [Socket Reader #7 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15502
2025-12-19 13:34:19,123 [Socket Reader #6 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15502
2025-12-19 13:34:19,123 [Socket Reader #9 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15502
2025-12-19 13:34:19,123 [Socket Reader #10 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15502
2025-12-19 13:34:19,124 [Socket Reader #8 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15502
2025-12-19 13:34:19,124 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:19,124 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15505
2025-12-19 13:34:19,125 [Socket Reader #1 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15505
2025-12-19 13:34:19,125 [Socket Reader #2 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15505
2025-12-19 13:34:19,126 [Socket Reader #3 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15505
2025-12-19 13:34:19,126 [Socket Reader #4 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15505
2025-12-19 13:34:19,126 [Socket Reader #5 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15505
2025-12-19 13:34:19,126 [Socket Reader #6 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15505
2025-12-19 13:34:19,126 [Socket Reader #7 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15505
2025-12-19 13:34:19,127 [Socket Reader #8 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15505
2025-12-19 13:34:19,127 [Socket Reader #9 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15505
2025-12-19 13:34:19,127 [Socket Reader #10 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15505
2025-12-19 13:34:19,127 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:19,127 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15503
2025-12-19 13:34:19,128 [Socket Reader #1 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15503
2025-12-19 13:34:19,128 [Socket Reader #2 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15503
2025-12-19 13:34:19,128 [Socket Reader #3 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15503
2025-12-19 13:34:19,128 [Socket Reader #4 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15503
2025-12-19 13:34:19,128 [Socket Reader #5 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15503
2025-12-19 13:34:19,128 [Socket Reader #6 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15503
2025-12-19 13:34:19,128 [Socket Reader #7 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15503
2025-12-19 13:34:19,129 [Socket Reader #8 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15503
2025-12-19 13:34:19,129 [Socket Reader #9 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15503
2025-12-19 13:34:19,129 [Socket Reader #10 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15503
2025-12-19 13:34:19,132 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2025-12-19 13:34:19,132 [ForkJoinPool-6-worker-1] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-19 13:34:19,132 [ForkJoinPool-6-worker-1] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(288)) - Running pre-finalized state validations for unfinalized layout features.
2025-12-19 13:34:19,132 [ForkJoinPool-6-worker-1] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(301)) - Running first upgrade commands for unfinalized layout features.
2025-12-19 13:34:19,132 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1522)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15503
2025-12-19 13:34:19,132 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:start(204)) - starting ratis server 0.0.0.0:15501
2025-12-19 13:34:19,133 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc does not exist. Creating ...
2025-12-19 13:34:19,134 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:19,135 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc has been successfully formatted.
2025-12-19 13:34:19,135 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: initialize group-3149B70783DC
2025-12-19 13:34:19,135 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-175:558504b9-cfec-4766-96f9-7b6ebb0f3b76:group-3149B70783DC) returns 0#-1
2025-12-19 13:34:19,135 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:19,136 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#22215,558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:19,136 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:19,136 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:19,136 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:19,136 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(412)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: start with initializing state, conf=conf: {index: -1, cur=peers:[]|listeners:[], old=null}
2025-12-19 13:34:19,136 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: changes role from      null to FOLLOWER at term 0 for NOT_IN_CONF
2025-12-19 13:34:19,136 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:19,137 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3149B70783DC,id=558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:19,137 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Successfully started.
2025-12-19 13:34:19,137 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: start RPC server
2025-12-19 13:34:19,137 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: GrpcServicesImpl started, listening on 15501
2025-12-19 13:34:19,138 [JvmPauseMonitor79] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-558504b9-cfec-4766-96f9-7b6ebb0f3b76: Started
2025-12-19 13:34:19,138 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:19,138 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:19,138 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:19,138 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:19,138 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:19,138 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:19,139 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:19,139 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:19,139 [ForkJoinPool-6-worker-1] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 2 nodes: [nodeId=scmNode-3,nodeAddress=/127.0.0.1:15513, nodeId=scmNode-1,nodeAddress=/127.0.0.1:15497]
2025-12-19 13:34:19,140 [IPC Server handler 3 on default port 15497] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:addSCM(329)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: Submitting SetConfiguration request to Ratis server with new SCM peers list: [50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493, 558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501]
2025-12-19 13:34:19,140 [IPC Server handler 3 on default port 15497] INFO  server.RaftServer$Division (RaftServerImpl.java:setConfigurationAsync(1323)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: receive setConfiguration SetConfigurationRequest:client-F6BCC11863EE->50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC, cid=0, seq=null, RW, null, SET_UNCONDITIONALLY, servers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493, 558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501], listeners:[]
2025-12-19 13:34:19,140 [IPC Server handler 3 on default port 15497] INFO  server.RaftServer$Division (LeaderStateImpl.java:startSetConfiguration(483)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-F6BCC11863EE->50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC, cid=0, seq=null, RW, null, SET_UNCONDITIONALLY, servers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493, 558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501], listeners:[]
2025-12-19 13:34:19,141 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$notifyInstallSnapshot$4(807)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: notifyInstallSnapshot with firstAvailable=(t:1, i:0), followerNextIndex=0 
2025-12-19 13:34:19,141 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,142 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501
2025-12-19 13:34:19,145 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$installSnapshot$0(103)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: receive installSnapshot: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0) 
2025-12-19 13:34:19,146 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set firstElectionSinceStartup to false for INSTALL_SNAPSHOT_NOTIFICATION
2025-12-19 13:34:19,146 [grpc-default-executor-0] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(289)) - leader changed, yet current SCM is still follower.
2025-12-19 13:34:19,146 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: change Leader from null to 50ee075d-c1e7-43b2-938b-a7dc0bd7923f at term 2 for INSTALL_SNAPSHOT_NOTIFICATION, leader elected after 41ms
2025-12-19 13:34:19,146 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:notifyStateMachineToInstallSnapshot(262)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Received notification to install snapshot at index 0
2025-12-19 13:34:19,146 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:notifyStateMachineToInstallSnapshot(297)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 0.
2025-12-19 13:34:19,146 [grpc-default-executor-0] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyInstallSnapshotFromLeader(242)) - Received install snapshot notification from SCM leader: localhost:15493 with term index: (t:1, i:0)
2025-12-19 13:34:19,147 [scmNode-2-SCMInstallSnapshot-0] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:getDBCheckpointFromLeader(254)) - Downloading checkpoint from leader SCM scmNode-1 and reloading state from the checkpoint.
2025-12-19 13:34:19,147 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,147 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,148 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$installSnapshot$1(113)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: reply installSnapshot: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:FAIL-t0,IN_PROGRESS,snapshotIndex=0 
2025-12-19 13:34:19,148 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Completed INSTALL_SNAPSHOT, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0) 
2025-12-19 13:34:19,148 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Completed INSTALL_SNAPSHOT, lastReply: null 
2025-12-19 13:34:19,149 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNext$0(667)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-InstallSnapshotNotification: received the first reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:FAIL-t0,IN_PROGRESS,snapshotIndex=0 
2025-12-19 13:34:19,149 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNext$1(684)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-InstallSnapshotNotification: in progress, 
2025-12-19 13:34:19,151 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,151 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,151 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,151 [grpc-default-executor-1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNextImpl$0(531)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0, errorCount=1, request=AppendEntriesRequest:cid=0,entriesCount=0 
2025-12-19 13:34:19,152 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,152 [grpc-default-executor-3] INFO  ha.SCMDBCheckpointProvider (SCMDBCheckpointProvider.java:writeDBCheckPointToSream(48)) - Received request to obtain SCM DB checkpoint snapshot
2025-12-19 13:34:19,152 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,154 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,154 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,154 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,155 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,155 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,156 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,156 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,157 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,157 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,157 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,162 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,162 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,162 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,163 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,164 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,165 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,165 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,165 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,166 [grpc-default-executor-3] INFO  db.RDBCheckpointManager (RDBCheckpointManager.java:createCheckpoint(87)) - Created checkpoint in rocksDB at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/db.checkpoints/scm.db_checkpoint_1766151259163 in 3 milliseconds
2025-12-19 13:34:19,166 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,166 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,168 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,168 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,169 [grpc-default-executor-3] INFO  ha.SCMGrpcOutputStream (SCMGrpcOutputStream.java:close(107)) - Sent 62976 bytes for cluster 9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:19,169 [grpc-default-executor-3] INFO  ha.SCMDBCheckpointProvider (SCMDBCheckpointProvider.java:writeDBCheckPointToSream(73)) - Time taken to write the checkpoint to response output stream: 3 milliseconds
2025-12-19 13:34:19,169 [grpc-default-executor-3] INFO  db.RocksDBCheckpoint (RocksDBCheckpoint.java:cleanupCheckpoint(77)) - Cleaning up RocksDB checkpoint at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/db.checkpoints/scm.db_checkpoint_1766151259163
2025-12-19 13:34:19,169 [grpc-default-executor-1] INFO  ha.InterSCMGrpcClient (InterSCMGrpcClient.java:onCompleted(169)) - Checkpoint is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis.snapshot/scm.db-scmNode-1-1766151259147.tar
2025-12-19 13:34:19,169 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,171 [grpc-default-executor-3] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,171 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,173 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,173 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,173 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,174 [grpc-default-executor-3] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,174 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,176 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,176 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#7:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,176 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,177 [grpc-default-executor-3] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,177 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,179 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,179 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#8:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,179 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,179 [scmNode-2-SCMInstallSnapshot-0] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:getSCMDBSnapshot(126)) - Successfully downloaded latest checkpoint from leader SCM: scmNode-1 path /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis.snapshot/scm.db-scmNode-1-1766151259147
2025-12-19 13:34:19,179 [scmNode-2-SCMInstallSnapshot-0] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:downloadCheckpointFromLeader(189)) - Downloaded checkpoint from Leader scmNode-1 to the location /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis.snapshot/scm.db-scmNode-1-1766151259147
2025-12-19 13:34:19,179 [scmNode-2-SCMInstallSnapshot-0] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$notifyInstallSnapshotFromLeader$2(258)) - Got secret keys from leaders null
2025-12-19 13:34:19,180 [grpc-default-executor-3] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,180 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,181 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,182 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#9:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,182 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,183 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,183 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,184 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,184 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,185 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#10:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,185 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,185 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,187 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,187 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,187 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#11:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,188 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,188 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,189 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,189 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#12:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,189 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,190 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,190 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,191 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,191 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,191 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#13:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,192 [grpc-default-executor-3] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,192 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,196 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,196 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,196 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#14:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,197 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,197 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,199 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,199 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,199 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#15:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,200 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,200 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,202 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,202 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,202 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#16:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,202 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,202 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,204 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,204 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#17:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,205 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,205 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,205 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,207 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,207 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#18:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,207 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,208 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,208 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,208 [scmNode-2-SCMInstallSnapshot-0] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:verifyCheckpointFromLeader(221)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Verify checkpoint 2#2 from leader scmNode-1
2025-12-19 13:34:19,208 [scmNode-2-SCMInstallSnapshot-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$notifyStateMachineToInstallSnapshot$8(320)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: StateMachine successfully installed snapshot index 2. Reloading the StateMachine.
2025-12-19 13:34:19,209 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:19,209 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:19,209 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#19:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  ha.SCMStateMachine (SCMStateMachine.java:pause(395)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Try to pause from current LifeCycle state SCMStateMachine-175:558504b9-cfec-4766-96f9-7b6ebb0f3b76:group-3149B70783DC:RUNNING
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  raftlog.RaftLog (RaftLogBase.java:lambda$new$0(54)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 2
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 2
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 2
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-175:558504b9-cfec-4766-96f9-7b6ebb0f3b76:group-3149B70783DC) returns 0#-1
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  raftlog.RaftLog (RaftLogBase.java:lambda$new$0(54)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog: purgeIndex: updateToMax old=-1, new=2, updated? true
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:notifyStateMachineToInstallSnapshot(365)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: (t:2, i:2)
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set new configuration index: 1 configurationEntry { peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:19,210 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:19,212 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onNext(706)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-InstallSnapshotNotification: Follower installed snapshot at index 2
2025-12-19 13:34:19,212 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:info(64)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76: snapshotIndex: setUnconditionally 0 -> 2
2025-12-19 13:34:19,213 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:info(64)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76: matchIndex: setUnconditionally -1 -> 2
2025-12-19 13:34:19,213 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:info(64)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76: nextIndex: setUnconditionally 0 -> 3
2025-12-19 13:34:19,213 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:setAttemptedToInstallSnapshot(154)) - Follower 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76 acknowledged installing snapshot
2025-12-19 13:34:19,213 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:increaseNextIndex(468)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: updateNextIndex 3 for SNAPSHOT_INSTALLED
2025-12-19 13:34:19,213 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onFollowerCatchup(633)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-InstallSnapshotNotification: follower nextIndex = 3 >= leader startIndex = 0
2025-12-19 13:34:19,234 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:installCheckpoint(273)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Install checkpoint 2#2
2025-12-19 13:34:19,241 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:installCheckpoint(311)) - Replaced DB with checkpoint, term: 2, index: 2
2025-12-19 13:34:19,241 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:19,241 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:19,264 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:reinitialize(177)) - reinitialize SequenceIdGenerator.
2025-12-19 13:34:19,265 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-12-19 13:34:19,265 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  block.SCMDeletedBlockTransactionStatusManager (SCMDeletedBlockTransactionStatusManager.java:loadDeletedBlocksSummary(686)) - Property DeletedBlocksTransactionSummary for service DeletedBlockLogStateManager not found. 
2025-12-19 13:34:19,266 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:installCheckpoint(326)) - Reloaded SCM state with Term: 2 and Index: 2
2025-12-19 13:34:19,266 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:reinitialize(421)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: SCMStateMachine is reinitializing. newTermIndex = (t:2, i:2)
2025-12-19 13:34:19,267 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 2
2025-12-19 13:34:19,267 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 2
2025-12-19 13:34:19,571 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:19,682 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:19,734 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:20,572 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:20,682 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:20,735 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:21,175 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 3, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:21,176 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: start 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState
2025-12-19 13:34:21,177 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 3, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:21,177 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: Starting segment from index:3
2025-12-19 13:34:21,177 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1624)) -  FOLLOWER (RUNNING): 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC:t2, leader=50ee075d-c1e7-43b2-938b-a7dc0bd7923f, voted=null, raftlog=Memoized:558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog:OPENED:c2:last(t:2, i:3), conf=conf: {index: 3, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}: Follower has completed install the snapshot 2.
2025-12-19 13:34:21,177 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_3 at position 0
2025-12-19 13:34:21,183 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_3
2025-12-19 13:34:21,184 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,184 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,185 [IPC Server handler 3 on default port 15497] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:addSCM(340)) - Successfully added new SCM: 558504b9-cfec-4766-96f9-7b6ebb0f3b76.
2025-12-19 13:34:21,186 [ForkJoinPool-6-worker-1] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:start(127)) - Successfully added SCM scmNode-2 to group group-3149B70783DC:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]
2025-12-19 13:34:21,186 [ForkJoinPool-6-worker-1] INFO  ha.InterSCMGrpcService (InterSCMGrpcProtocolService.java:start(98)) - Starting SCM Grpc Service at port 15504
2025-12-19 13:34:21,187 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(64)) - Starting SCMHATransactionMonitor Service.
2025-12-19 13:34:21,187 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:21,187 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:21,187 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:21,187 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:21,187 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:21,187 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMHATransactionMonitor.
2025-12-19 13:34:21,187 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(61)) - SCMHATransactionMonitor Service is already running, skip start.
2025-12-19 13:34:21,208 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(211)) - RPC server for Client  is listening at /0.0.0.0:15503
2025-12-19 13:34:21,209 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:21,209 [IPC Server listener on 15503] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15503: starting
2025-12-19 13:34:21,221 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1535)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15505
2025-12-19 13:34:21,221 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(166)) - RPC server for Block Protocol is listening at /0.0.0.0:15505
2025-12-19 13:34:21,222 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:21,222 [IPC Server listener on 15505] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15505: starting
2025-12-19 13:34:21,233 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(195)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15502
2025-12-19 13:34:21,234 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:21,234 [IPC Server listener on 15502] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15502: starting
2025-12-19 13:34:21,245 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SCMBlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:21,246 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for scm at: http://0.0.0.0:15498
2025-12-19 13:34:21,247 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:21,248 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:21,249 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:21,250 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2025-12-19 13:34:21,250 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:21,250 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:21,250 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/webserver
2025-12-19 13:34:21,251 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15498
2025-12-19 13:34:21,251 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:21,252 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:21,252 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:21,252 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-12-19 13:34:21,253 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5a9bbbe8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:21,253 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@28ca55a{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-12-19 13:34:21,257 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@58bf4cf4{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:21,257 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4028cf0{HTTP/1.1, (http/1.1)}{0.0.0.0:15498}
2025-12-19 13:34:21,257 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @847446ms
2025-12-19 13:34:21,258 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:21,258 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of scm listening at http://localhost:15498
2025-12-19 13:34:21,258 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createSCMService(622)) - Started SCM RPC server at /0.0.0.0:15503
2025-12-19 13:34:21,259 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:21,259 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:21,259 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:21,260 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:21,260 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:21,260 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:21,260 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:21,260 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:21,260 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:21,260 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-3, RPC Address: localhost:15509 and Ratis port: 15509
2025-12-19 13:34:21,260 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-3: 127.0.0.1:15510
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-3: 127.0.0.1:15513
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-3: 127.0.0.1:15511
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-3: 127.0.0.1:15508
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-3: 15509
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-3: 15512
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-3: 127.0.0.1:15506
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-3: 127.0.0.1:15507
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-3: 127.0.0.1
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:21,261 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:21,262 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:21,263 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:21,263 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:21,263 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:21,263 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:21,263 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:21,263 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:21,263 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:21,264 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:21,264 [ForkJoinPool-6-worker-1] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 2 nodes: [nodeId=scmNode-2,nodeAddress=/127.0.0.1:15505, nodeId=scmNode-1,nodeAddress=/127.0.0.1:15497]
2025-12-19 13:34:21,267 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:scmBootstrap(1211)) - SCM BootStrap  is successful for ClusterID 9a5f6a08-7b44-4db9-b4fd-3149b70783dc, SCMID 6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:21,267 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:scmBootstrap(1213)) - Primary SCM Node ID 50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:21,267 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:21,267 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:21,267 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:21,268 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:21,268 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:21,268 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:21,268 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:21,268 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:21,268 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:21,268 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-3, RPC Address: localhost:15509 and Ratis port: 15509
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-3: 127.0.0.1:15510
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-3: 127.0.0.1:15513
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-3: 127.0.0.1:15511
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-3: 127.0.0.1:15508
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-3: 15509
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-3: 15512
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-3: 127.0.0.1:15506
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-3: 127.0.0.1:15507
2025-12-19 13:34:21,269 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-3: 127.0.0.1
2025-12-19 13:34:21,270 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:21,270 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:21,270 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:21,270 [ForkJoinPool-6-worker-1] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:21,271 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:21,323 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.2.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-12-19 13:34:21,323 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-12-19 13:34:21,325 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:21,325 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:21,342 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:<init>(101)) - starting Raft server for scm:6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:21,342 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:21,343 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:21,343 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:21,343 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:21,343 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:21,343 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:21,343 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:21,344 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:21,344 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.port = 15509 (fallback to raft.grpc.server.port)
2025-12-19 13:34:21,344 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:21,344 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.port = 15509 (fallback to raft.grpc.server.port)
2025-12-19 13:34:21,344 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15509 (custom)
2025-12-19 13:34:21,345 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis] (custom)
2025-12-19 13:34:21,345 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 6a054400-8896-4262-aa80-3995e76ba098: addNew group-3149B70783DC:[] returns group-3149B70783DC:java.util.concurrent.CompletableFuture@2cc6e4c9[Not completed]
2025-12-19 13:34:21,346 [6a054400-8896-4262-aa80-3995e76ba098-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 6a054400-8896-4262-aa80-3995e76ba098: new RaftServerImpl for group-3149B70783DC:[] with SCMStateMachine-176:uninitialized
2025-12-19 13:34:21,346 [6a054400-8896-4262-aa80-3995e76ba098-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:21,347 [ForkJoinPool-6-worker-1] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:<init>(61)) - Initializing SCM Snapshot Provider
2025-12-19 13:34:21,347 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:21,347 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisSnapshotDirectory(415)) - Snapshot directory for Ratis is not configured. Falling back to ozone.metadata.dirs
2025-12-19 13:34:21,348 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:21,348 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmOnFinalizeActionForDatanodeSchemaV2
2025-12-19 13:34:21,348 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
2025-12-19 13:34:21,348 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ContainerTableSchemaFinalizeAction
2025-12-19 13:34:21,349 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmHAFinalizeUpgradeActionDatanode
2025-12-19 13:34:21,349 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV2FinalizeAction
2025-12-19 13:34:21,350 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(354)) - upgrade localId to 115816896921600000
2025-12-19 13:34:21,350 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(364)) - upgrade delTxnId to 0
2025-12-19 13:34:21,351 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(380)) - upgrade containerId to 0
2025-12-19 13:34:21,352 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(415)) - upgrade CertificateId to 2
2025-12-19 13:34:21,352 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-12-19 13:34:21,352 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:21,352 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:21,353 [ForkJoinPool-6-worker-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(185)) - Entering startup safe mode.
2025-12-19 13:34:21,353 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-12-19 13:34:21,353 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:21,353 [ForkJoinPool-6-worker-1] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-12-19 13:34:21,354 [ForkJoinPool-6-worker-1] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(55)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-19 13:34:21,354 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:21,354 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2025-12-19 13:34:21,354 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-3-RatisPipelineUtilsThread.
2025-12-19 13:34:21,354 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(64)) - Starting BackgroundPipelineScrubber Service.
2025-12-19 13:34:21,354 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2025-12-19 13:34:21,355 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(64)) - Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:21,355 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2025-12-19 13:34:21,355 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:21,356 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:21,356 [ForkJoinPool-6-worker-1] INFO  block.SCMDeletedBlockTransactionStatusManager (SCMDeletedBlockTransactionStatusManager.java:loadDeletedBlocksSummary(686)) - Property DeletedBlocksTransactionSummary for service DeletedBlockLogStateManager not found. 
2025-12-19 13:34:21,356 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2025-12-19 13:34:21,357 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:start(288)) - Starting Replication Monitor Thread.
2025-12-19 13:34:21,357 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2025-12-19 13:34:21,357 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed RATIS Containers threshold count to 0.
2025-12-19 13:34:21,358 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed EC Containers threshold count to 0.
2025-12-19 13:34:21,358 [ForkJoinPool-6-worker-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(231)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:21,358 [ForkJoinPool-6-worker-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(190)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-19 13:34:21,359 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(433)) - SCM start with adminUsers: [admin, runner]
2025-12-19 13:34:21,359 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:21,359 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15510
2025-12-19 13:34:21,359 [Socket Reader #1 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15510
2025-12-19 13:34:21,359 [Socket Reader #2 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15510
2025-12-19 13:34:21,360 [Socket Reader #3 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15510
2025-12-19 13:34:21,360 [Socket Reader #4 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15510
2025-12-19 13:34:21,360 [Socket Reader #5 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15510
2025-12-19 13:34:21,360 [Socket Reader #6 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15510
2025-12-19 13:34:21,360 [Socket Reader #7 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15510
2025-12-19 13:34:21,360 [Socket Reader #8 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15510
2025-12-19 13:34:21,360 [Socket Reader #9 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15510
2025-12-19 13:34:21,361 [Socket Reader #10 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15510
2025-12-19 13:34:21,361 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:21,362 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15513
2025-12-19 13:34:21,362 [Socket Reader #1 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15513
2025-12-19 13:34:21,362 [Socket Reader #2 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15513
2025-12-19 13:34:21,362 [Socket Reader #3 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15513
2025-12-19 13:34:21,362 [Socket Reader #4 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15513
2025-12-19 13:34:21,362 [Socket Reader #5 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15513
2025-12-19 13:34:21,363 [Socket Reader #6 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15513
2025-12-19 13:34:21,363 [Socket Reader #7 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15513
2025-12-19 13:34:21,363 [Socket Reader #8 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15513
2025-12-19 13:34:21,363 [Socket Reader #9 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15513
2025-12-19 13:34:21,363 [Socket Reader #10 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15513
2025-12-19 13:34:21,364 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:21,364 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15511
2025-12-19 13:34:21,364 [Socket Reader #1 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15511
2025-12-19 13:34:21,365 [Socket Reader #2 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15511
2025-12-19 13:34:21,365 [Socket Reader #3 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15511
2025-12-19 13:34:21,365 [Socket Reader #4 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15511
2025-12-19 13:34:21,365 [Socket Reader #5 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15511
2025-12-19 13:34:21,365 [Socket Reader #6 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15511
2025-12-19 13:34:21,365 [Socket Reader #7 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15511
2025-12-19 13:34:21,366 [Socket Reader #8 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15511
2025-12-19 13:34:21,366 [Socket Reader #9 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15511
2025-12-19 13:34:21,366 [Socket Reader #10 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15511
2025-12-19 13:34:21,369 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2025-12-19 13:34:21,369 [ForkJoinPool-6-worker-1] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-19 13:34:21,369 [ForkJoinPool-6-worker-1] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(288)) - Running pre-finalized state validations for unfinalized layout features.
2025-12-19 13:34:21,370 [ForkJoinPool-6-worker-1] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(301)) - Running first upgrade commands for unfinalized layout features.
2025-12-19 13:34:21,370 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1522)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15511
2025-12-19 13:34:21,370 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:start(204)) - starting ratis server 0.0.0.0:15509
2025-12-19 13:34:21,370 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc does not exist. Creating ...
2025-12-19 13:34:21,371 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:21,373 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc has been successfully formatted.
2025-12-19 13:34:21,373 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 6a054400-8896-4262-aa80-3995e76ba098: initialize group-3149B70783DC
2025-12-19 13:34:21,373 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-176:6a054400-8896-4262-aa80-3995e76ba098:group-3149B70783DC) returns 0#-1
2025-12-19 13:34:21,373 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:21,374 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#22608,6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:21,374 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:21,375 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:21,375 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:21,375 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(412)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: start with initializing state, conf=conf: {index: -1, cur=peers:[]|listeners:[], old=null}
2025-12-19 13:34:21,375 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: changes role from      null to FOLLOWER at term 0 for NOT_IN_CONF
2025-12-19 13:34:21,376 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:21,376 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3149B70783DC,id=6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:21,376 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Successfully started.
2025-12-19 13:34:21,376 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 6a054400-8896-4262-aa80-3995e76ba098: start RPC server
2025-12-19 13:34:21,376 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 6a054400-8896-4262-aa80-3995e76ba098: GrpcServicesImpl started, listening on 15509
2025-12-19 13:34:21,377 [JvmPauseMonitor80] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-6a054400-8896-4262-aa80-3995e76ba098: Started
2025-12-19 13:34:21,377 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:21,377 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:21,378 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:21,378 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:21,378 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:21,378 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:21,378 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:21,378 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:21,378 [ForkJoinPool-6-worker-1] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 2 nodes: [nodeId=scmNode-2,nodeAddress=/127.0.0.1:15505, nodeId=scmNode-1,nodeAddress=/127.0.0.1:15497]
2025-12-19 13:34:21,379 [IPC Server handler 5 on default port 15497] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:addSCM(329)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: Submitting SetConfiguration request to Ratis server with new SCM peers list: [558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509]
2025-12-19 13:34:21,380 [IPC Server handler 5 on default port 15497] INFO  server.RaftServer$Division (RaftServerImpl.java:setConfigurationAsync(1323)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: receive setConfiguration SetConfigurationRequest:client-F6BCC11863EE->50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC, cid=1, seq=null, RW, null, SET_UNCONDITIONALLY, servers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509], listeners:[]
2025-12-19 13:34:21,380 [IPC Server handler 5 on default port 15497] INFO  server.RaftServer$Division (LeaderStateImpl.java:startSetConfiguration(483)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-F6BCC11863EE->50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC, cid=1, seq=null, RW, null, SET_UNCONDITIONALLY, servers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509], listeners:[]
2025-12-19 13:34:21,380 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$notifyInstallSnapshot$4(807)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: notifyInstallSnapshot with firstAvailable=(t:1, i:0), followerNextIndex=0 
2025-12-19 13:34:21,381 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,381 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509
2025-12-19 13:34:21,383 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$installSnapshot$0(103)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: receive installSnapshot: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0) 
2025-12-19 13:34:21,387 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set firstElectionSinceStartup to false for INSTALL_SNAPSHOT_NOTIFICATION
2025-12-19 13:34:21,387 [grpc-default-executor-1] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(289)) - leader changed, yet current SCM is still follower.
2025-12-19 13:34:21,387 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: change Leader from null to 50ee075d-c1e7-43b2-938b-a7dc0bd7923f at term 2 for INSTALL_SNAPSHOT_NOTIFICATION, leader elected after 40ms
2025-12-19 13:34:21,387 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:notifyStateMachineToInstallSnapshot(262)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Received notification to install snapshot at index 0
2025-12-19 13:34:21,387 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:notifyStateMachineToInstallSnapshot(297)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: notifyInstallSnapshot: nextIndex is 0 but the leader's first available index is 0.
2025-12-19 13:34:21,387 [grpc-default-executor-1] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyInstallSnapshotFromLeader(242)) - Received install snapshot notification from SCM leader: localhost:15493 with term index: (t:1, i:0)
2025-12-19 13:34:21,387 [scmNode-3-SCMInstallSnapshot-0] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:getDBCheckpointFromLeader(254)) - Downloading checkpoint from leader SCM scmNode-1 and reloading state from the checkpoint.
2025-12-19 13:34:21,387 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,388 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,388 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$installSnapshot$1(113)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: reply installSnapshot: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#0:FAIL-t0,IN_PROGRESS,snapshotIndex=0 
2025-12-19 13:34:21,389 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 6a054400-8896-4262-aa80-3995e76ba098: Completed INSTALL_SNAPSHOT, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0) 
2025-12-19 13:34:21,389 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 6a054400-8896-4262-aa80-3995e76ba098: Completed INSTALL_SNAPSHOT, lastReply: null 
2025-12-19 13:34:21,389 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNext$0(667)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-InstallSnapshotNotification: received the first reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#0:FAIL-t0,IN_PROGRESS,snapshotIndex=0 
2025-12-19 13:34:21,389 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNext$1(684)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-InstallSnapshotNotification: in progress, 
2025-12-19 13:34:21,391 [grpc-default-executor-1] INFO  ha.SCMDBCheckpointProvider (SCMDBCheckpointProvider.java:writeDBCheckPointToSream(48)) - Received request to obtain SCM DB checkpoint snapshot
2025-12-19 13:34:21,392 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,392 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,393 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNextImpl$0(531)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0, errorCount=1, request=AppendEntriesRequest:cid=0,entriesCount=0 
2025-12-19 13:34:21,393 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,393 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,394 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,395 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,396 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,396 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,396 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,396 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,397 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,398 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,398 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,398 [grpc-default-executor-3] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,398 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,398 [grpc-default-executor-1] INFO  db.RDBCheckpointManager (RDBCheckpointManager.java:createCheckpoint(87)) - Created checkpoint in rocksDB at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/db.checkpoints/scm.db_checkpoint_1766151261395 in 2 milliseconds
2025-12-19 13:34:21,399 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,399 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,399 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,400 [grpc-default-executor-3] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,400 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,401 [grpc-default-executor-1] INFO  ha.SCMGrpcOutputStream (SCMGrpcOutputStream.java:close(107)) - Sent 66560 bytes for cluster 9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:21,401 [grpc-default-executor-1] INFO  ha.SCMDBCheckpointProvider (SCMDBCheckpointProvider.java:writeDBCheckPointToSream(73)) - Time taken to write the checkpoint to response output stream: 3 milliseconds
2025-12-19 13:34:21,402 [grpc-default-executor-1] INFO  db.RocksDBCheckpoint (RocksDBCheckpoint.java:cleanupCheckpoint(77)) - Cleaning up RocksDB checkpoint at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/db.checkpoints/scm.db_checkpoint_1766151261395
2025-12-19 13:34:21,402 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,403 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,403 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,403 [grpc-default-executor-1] INFO  ha.InterSCMGrpcClient (InterSCMGrpcClient.java:onCompleted(169)) - Checkpoint is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis.snapshot/scm.db-scmNode-1-1766151261387.tar
2025-12-19 13:34:21,404 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,404 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,405 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,406 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,406 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,407 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,407 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,408 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,409 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,409 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,410 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,410 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,412 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,412 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,413 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#7:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,413 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,413 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,414 [scmNode-3-SCMInstallSnapshot-0] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:getSCMDBSnapshot(126)) - Successfully downloaded latest checkpoint from leader SCM: scmNode-1 path /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis.snapshot/scm.db-scmNode-1-1766151261387
2025-12-19 13:34:21,414 [scmNode-3-SCMInstallSnapshot-0] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:downloadCheckpointFromLeader(189)) - Downloaded checkpoint from Leader scmNode-1 to the location /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis.snapshot/scm.db-scmNode-1-1766151261387
2025-12-19 13:34:21,414 [scmNode-3-SCMInstallSnapshot-0] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$notifyInstallSnapshotFromLeader$2(258)) - Got secret keys from leaders null
2025-12-19 13:34:21,415 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,415 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#8:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,415 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,416 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,417 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,418 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,418 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,418 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#9:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,419 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,419 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,420 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,420 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#10:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,421 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,422 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,422 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,423 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,423 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,423 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#11:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,424 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,424 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,425 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,426 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#12:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,426 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,426 [grpc-default-executor-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,426 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,428 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,429 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#13:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,429 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,429 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,429 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,431 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,431 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#14:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,431 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,432 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,432 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,434 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,434 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,434 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#15:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,435 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,435 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,437 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,437 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,437 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#16:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,438 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,438 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,439 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,439 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,440 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#17:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,441 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,441 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,443 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,443 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,443 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#18:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,444 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,444 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,446 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,446 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#19:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,447 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,448 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,448 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,450 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,450 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,450 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#20:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,450 [grpc-default-executor-1] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,451 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,452 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,452 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,452 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#21:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,453 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,453 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,454 [scmNode-3-SCMInstallSnapshot-0] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:verifyCheckpointFromLeader(221)) - 6a054400-8896-4262-aa80-3995e76ba098: Verify checkpoint 2#6 from leader scmNode-1
2025-12-19 13:34:21,454 [scmNode-3-SCMInstallSnapshot-0] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$notifyStateMachineToInstallSnapshot$8(320)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: StateMachine successfully installed snapshot index 6. Reloading the StateMachine.
2025-12-19 13:34:21,454 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1665)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as snapshot (0) installation is in progress
2025-12-19 13:34:21,454 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#22:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2025-12-19 13:34:21,454 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] INFO  server.GrpcLogAppender (GrpcLogAppender.java:notifyInstallSnapshot(815)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: send 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  ha.SCMStateMachine (SCMStateMachine.java:pause(395)) - 6a054400-8896-4262-aa80-3995e76ba098: Try to pause from current LifeCycle state SCMStateMachine-176:6a054400-8896-4262-aa80-3995e76ba098:group-3149B70783DC:RUNNING
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  raftlog.RaftLog (RaftLogBase.java:lambda$new$0(54)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLog: snapshotIndex: updateIncreasingly -1 -> 6
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally -1 -> 6
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally -1 -> 6
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-176:6a054400-8896-4262-aa80-3995e76ba098:group-3149B70783DC) returns 0#-1
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  raftlog.RaftLog (RaftLogBase.java:lambda$new$0(54)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLog: purgeIndex: updateToMax old=-1, new=6, updated? true
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:notifyStateMachineToInstallSnapshot(365)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: InstallSnapshot notification result: SNAPSHOT_INSTALLED, at index: (t:2, i:6)
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:installSnapshotImpl(147)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set new configuration index: 5 configurationEntry { peers { id: "558504b9-cfec-4766-96f9-7b6ebb0f3b76" address: "localhost:15501" startupRole: FOLLOWER } peers { id: "50ee075d-c1e7-43b2-938b-a7dc0bd7923f" address: "localhost:15493" startupRole: FOLLOWER } } from snapshot
2025-12-19 13:34:21,455 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:21,457 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onNext(706)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-InstallSnapshotNotification: Follower installed snapshot at index 6
2025-12-19 13:34:21,457 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:info(64)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098: snapshotIndex: setUnconditionally 0 -> 6
2025-12-19 13:34:21,457 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:info(64)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098: matchIndex: setUnconditionally -1 -> 6
2025-12-19 13:34:21,457 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:info(64)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098: nextIndex: setUnconditionally 0 -> 7
2025-12-19 13:34:21,457 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:setAttemptedToInstallSnapshot(154)) - Follower 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098 acknowledged installing snapshot
2025-12-19 13:34:21,457 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:increaseNextIndex(468)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: updateNextIndex 7 for SNAPSHOT_INSTALLED
2025-12-19 13:34:21,457 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onFollowerCatchup(633)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-InstallSnapshotNotification: follower nextIndex = 7 >= leader startIndex = 0
2025-12-19 13:34:21,475 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:installCheckpoint(273)) - 6a054400-8896-4262-aa80-3995e76ba098: Install checkpoint 2#6
2025-12-19 13:34:21,482 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:installCheckpoint(311)) - Replaced DB with checkpoint, term: 2, index: 6
2025-12-19 13:34:21,482 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:21,482 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:21,504 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:reinitialize(177)) - reinitialize SequenceIdGenerator.
2025-12-19 13:34:21,505 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(75)) - No pipeline exists in current db
2025-12-19 13:34:21,505 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  block.SCMDeletedBlockTransactionStatusManager (SCMDeletedBlockTransactionStatusManager.java:loadDeletedBlocksSummary(686)) - Property DeletedBlocksTransactionSummary for service DeletedBlockLogStateManager not found. 
2025-12-19 13:34:21,505 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:installCheckpoint(326)) - Reloaded SCM state with Term: 2 and Index: 6
2025-12-19 13:34:21,506 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:reinitialize(421)) - 6a054400-8896-4262-aa80-3995e76ba098: SCMStateMachine is reinitializing. newTermIndex = (t:2, i:6)
2025-12-19 13:34:21,506 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: snapshotIndex: setUnconditionally -1 -> 6
2025-12-19 13:34:21,506 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: appliedIndex: setUnconditionally -1 -> 6
2025-12-19 13:34:21,572 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:21,683 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:21,735 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:22,573 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:22,683 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:22,736 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:23,573 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:23,683 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:23,736 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:24,141 [timer3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$notifyInstallSnapshot$4(807)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: notifyInstallSnapshot with firstAvailable=(t:1, i:0), followerNextIndex=7  (Repeated 21 times in the last 5.000s)
2025-12-19 13:34:24,145 [timer5] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$installSnapshot$0(103)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: receive installSnapshot: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)  (Repeated 21 times in the last 5.000s)
2025-12-19 13:34:24,148 [timer6] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$installSnapshot$1(113)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: reply installSnapshot: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:OK-t2,SNAPSHOT_INSTALLED,snapshotIndex=2  (Repeated 21 times in the last 5.000s)
2025-12-19 13:34:24,148 [timer0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Completed INSTALL_SNAPSHOT, lastReply: null  (Repeated 21 times in the last 5.000s)
2025-12-19 13:34:24,148 [timer7] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Completed INSTALL_SNAPSHOT, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#0-t2,notify:(t:1, i:0)  (Repeated 21 times in the last 5.000s)
2025-12-19 13:34:24,149 [timer1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNext$0(667)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-InstallSnapshotNotification: received a reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:OK-t2,SNAPSHOT_INSTALLED,snapshotIndex=2  (Repeated 21 times in the last 5.000s)
2025-12-19 13:34:24,149 [timer2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNext$1(684)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-InstallSnapshotNotification: in progress,  (Repeated 20 times in the last 5.000s)
2025-12-19 13:34:24,151 [timer5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNextImpl$0(531)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0, errorCount=1, request=AppendEntriesRequest:cid=19,entriesCount=0  (Repeated 20 times in the last 5.000s)
2025-12-19 13:34:24,574 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:24,684 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:24,737 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:25,574 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:25,684 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:25,737 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:26,380 [timer2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$notifyInstallSnapshot$4(807)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: notifyInstallSnapshot with firstAvailable=(t:1, i:0), followerNextIndex=7  (Repeated 24 times in the last 5.000s)
2025-12-19 13:34:26,384 [timer4] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$installSnapshot$0(103)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: receive installSnapshot: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)  (Repeated 24 times in the last 5.000s)
2025-12-19 13:34:26,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 7, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:26,387 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 7, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:26,387 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 6a054400-8896-4262-aa80-3995e76ba098: start 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState
2025-12-19 13:34:26,388 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 7, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:26,388 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1624)) -  FOLLOWER (RUNNING): 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC:t2, leader=50ee075d-c1e7-43b2-938b-a7dc0bd7923f, voted=null, raftlog=Memoized:6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLog:OPENED:c6:lastnull, conf=conf: {index: 7, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}: Follower has completed install the snapshot 6.
2025-12-19 13:34:26,388 [6a054400-8896-4262-aa80-3995e76ba098-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: Starting segment from index:7
2025-12-19 13:34:26,388 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_7 at position 0
2025-12-19 13:34:26,388 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:26,389 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:26,389 [timer1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNext$1(684)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-InstallSnapshotNotification: in progress,  (Repeated 23 times in the last 5.000s)
2025-12-19 13:34:26,389 [timer7] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 6a054400-8896-4262-aa80-3995e76ba098: Completed INSTALL_SNAPSHOT, lastReply: null  (Repeated 24 times in the last 5.001s)
2025-12-19 13:34:26,389 [timer5] INFO  impl.SnapshotInstallationHandler (SnapshotInstallationHandler.java:lambda$installSnapshot$1(113)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: reply installSnapshot: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#0:OK-t2,SNAPSHOT_INSTALLED,snapshotIndex=6  (Repeated 24 times in the last 5.001s)
2025-12-19 13:34:26,390 [timer6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 6a054400-8896-4262-aa80-3995e76ba098: Completed INSTALL_SNAPSHOT, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#0-t2,notify:(t:1, i:0)  (Repeated 24 times in the last 5.001s)
2025-12-19 13:34:26,390 [timer0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNext$0(667)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-InstallSnapshotNotification: received a reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#0:OK-t2,SNAPSHOT_INSTALLED,snapshotIndex=6  (Repeated 24 times in the last 5.001s)
2025-12-19 13:34:26,390 [grpc-default-executor-2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:26,391 [IPC Server handler 5 on default port 15497] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:addSCM(340)) - Successfully added new SCM: 6a054400-8896-4262-aa80-3995e76ba098.
2025-12-19 13:34:26,391 [ForkJoinPool-6-worker-1] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:start(127)) - Successfully added SCM scmNode-3 to group group-3149B70783DC:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]
2025-12-19 13:34:26,392 [ForkJoinPool-6-worker-1] INFO  ha.InterSCMGrpcService (InterSCMGrpcProtocolService.java:start(98)) - Starting SCM Grpc Service at port 15512
2025-12-19 13:34:26,393 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(64)) - Starting SCMHATransactionMonitor Service.
2025-12-19 13:34:26,393 [timer3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNextImpl$0(531)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0, errorCount=1, request=AppendEntriesRequest:cid=22,entriesCount=0  (Repeated 23 times in the last 5.000s)
2025-12-19 13:34:26,393 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMHATransactionMonitor.
2025-12-19 13:34:26,393 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(61)) - SCMHATransactionMonitor Service is already running, skip start.
2025-12-19 13:34:26,395 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_7
2025-12-19 13:34:26,397 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:26,397 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:26,397 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:26,397 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:26,397 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:26,411 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(211)) - RPC server for Client  is listening at /0.0.0.0:15511
2025-12-19 13:34:26,412 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:26,412 [IPC Server listener on 15511] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15511: starting
2025-12-19 13:34:26,422 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1535)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15513
2025-12-19 13:34:26,422 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(166)) - RPC server for Block Protocol is listening at /0.0.0.0:15513
2025-12-19 13:34:26,422 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:26,422 [IPC Server listener on 15513] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15513: starting
2025-12-19 13:34:26,432 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(195)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15510
2025-12-19 13:34:26,433 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:26,433 [IPC Server listener on 15510] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15510: starting
2025-12-19 13:34:26,443 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SCMBlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:26,444 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for scm at: http://0.0.0.0:15506
2025-12-19 13:34:26,444 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:26,445 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:26,446 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:26,447 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2025-12-19 13:34:26,447 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:26,447 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:26,448 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/webserver
2025-12-19 13:34:26,448 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15506
2025-12-19 13:34:26,448 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:26,449 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:26,449 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:26,450 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-12-19 13:34:26,450 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@fffefd{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:26,450 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@88d2769{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-12-19 13:34:26,454 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@774a16b2{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:26,454 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@b158f39{HTTP/1.1, (http/1.1)}{0.0.0.0:15506}
2025-12-19 13:34:26,454 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @852643ms
2025-12-19 13:34:26,455 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:26,455 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of scm listening at http://localhost:15506
2025-12-19 13:34:26,455 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:createSCMService(622)) - Started SCM RPC server at /0.0.0.0:15511
2025-12-19 13:34:26,457 [ForkJoinPool-6-worker-1] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(114)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2025-12-19 13:34:26,457 [ForkJoinPool-6-worker-1] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(228)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15532
2025-12-19 13:34:26,457 [ForkJoinPool-6-worker-1] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(262)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2025-12-19 13:34:26,457 [ForkJoinPool-6-worker-1] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(269)) - OM Node ID is not set. Setting it to the default ID: om1
2025-12-19 13:34:26,459 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = SNAPSHOT_DEFRAG (version = 9), software layout = SNAPSHOT_DEFRAG (version = 9)
2025-12-19 13:34:26,525 [ForkJoinPool-6-worker-1] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 65 ms to scan 2 urls, producing 227 keys and 665 values
2025-12-19 13:34:26,525 [ForkJoinPool-6-worker-1] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(110)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2025-12-19 13:34:26,525 [ForkJoinPool-6-worker-1] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(110)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2025-12-19 13:34:26,526 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:setReplicationFromConfig(4778)) - Set default replication in OM: RATIS/3 -> RATIS/THREE
2025-12-19 13:34:26,526 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,526 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,526 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,526 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,526 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,527 [ForkJoinPool-6-worker-1] INFO  proxy.SCMContainerLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 3 nodes: [nodeId=scmNode-2,nodeAddress=/127.0.0.1:15503, nodeId=scmNode-3,nodeAddress=/127.0.0.1:15511, nodeId=scmNode-1,nodeAddress=/127.0.0.1:15495]
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,529 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,529 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,529 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,529 [ForkJoinPool-6-worker-1] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 3 nodes: [nodeId=scmNode-2,nodeAddress=/127.0.0.1:15505, nodeId=scmNode-3,nodeAddress=/127.0.0.1:15513, nodeId=scmNode-1,nodeAddress=/127.0.0.1:15497]
2025-12-19 13:34:26,530 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,530 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,530 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,530 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,530 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,531 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,531 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,531 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,531 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,531 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:26,531 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:26,531 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:26,531 [ForkJoinPool-6-worker-1] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 3 nodes: [nodeId=scmNode-2,nodeAddress=/127.0.0.1:15505, nodeId=scmNode-3,nodeAddress=/127.0.0.1:15513, nodeId=scmNode-1,nodeAddress=/127.0.0.1:15497]
2025-12-19 13:34:26,534 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:<init>(683)) - OM start with adminUsers: [admin, runner]
2025-12-19 13:34:26,575 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:26,683 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(920)) - S3 Multi-Tenancy is disabled
2025-12-19 13:34:26,683 [ForkJoinPool-6-worker-1] INFO  acl.OzoneAuthorizerFactory (OzoneAuthorizerFactory.java:create(69)) - om1: Authorizer for OM is class org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer
2025-12-19 13:34:26,683 [ForkJoinPool-6-worker-1] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(164)) - Ozone filesystem snapshot feature is enabled.
2025-12-19 13:34:26,685 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:26,702 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SnapshotDiffCleanupService with interval 60000 milliseconds
2025-12-19 13:34:26,713 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4836)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2025-12-19 13:34:26,713 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:26,714 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:26,714 [ForkJoinPool-6-worker-1] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(172)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15535
2025-12-19 13:34:26,715 [ForkJoinPool-6-worker-1] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(649)) - TransactionInfo not found in OM DB.
2025-12-19 13:34:26,715 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy om1
2025-12-19 13:34:26,715 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:26,715 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.port = 15535 (fallback to raft.grpc.server.port)
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.port = 15535 (fallback to raft.grpc.server.port)
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15535 (custom)
2025-12-19 13:34:26,716 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.request.timeout = 3000ms (default)
2025-12-19 13:34:26,717 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ratis] (custom)
2025-12-19 13:34:26,718 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - om1: addNew group-C5BA1605619E:[om1|localhost:15535] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@b82d21e[Not completed]
2025-12-19 13:34:26,718 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2334)) - OzoneManager Ratis server initialized at port 15535
2025-12-19 13:34:26,718 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|localhost:15535] with OzoneManagerStateMachine-177:uninitialized
2025-12-19 13:34:26,718 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1383)) - Creating RPC Server
2025-12-19 13:34:26,718 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.timeout.min = 1s (custom)
2025-12-19 13:34:26,718 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.timeout.max = 1200ms (custom)
2025-12-19 13:34:26,718 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.slowness.timeout = 2s (custom)
2025-12-19 13:34:26,718 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - om1@group-C5BA1605619E: ConfigurationManager, init=conf: {index: -1, cur=peers:[om1|localhost:15535]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:26,718 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.notification.no-leader.timeout = 2s (custom)
2025-12-19 13:34:26,718 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.retrycache.expirytime = 300s (custom)
2025-12-19 13:34:26,738 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:27,067 [ForkJoinPool-6-worker-1] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 348 ms to scan 25 urls, producing 61 keys and 7898 values
2025-12-19 13:34:27,069 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:27,070 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 127.0.0.1:15532
2025-12-19 13:34:27,070 [Socket Reader #1 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15532
2025-12-19 13:34:27,071 [Socket Reader #2 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15532
2025-12-19 13:34:27,071 [Socket Reader #3 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15532
2025-12-19 13:34:27,071 [Socket Reader #4 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15532
2025-12-19 13:34:27,072 [Socket Reader #5 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15532
2025-12-19 13:34:27,072 [Socket Reader #6 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15532
2025-12-19 13:34:27,072 [Socket Reader #7 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15532
2025-12-19 13:34:27,072 [Socket Reader #8 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15532
2025-12-19 13:34:27,073 [Socket Reader #9 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15532
2025-12-19 13:34:27,073 [Socket Reader #10 for port 15532] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15532
2025-12-19 13:34:27,111 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:start(1818)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15532
2025-12-19 13:34:27,112 [ForkJoinPool-6-worker-1] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(682)) - Starting OzoneManagerRatisServer om1 at port 15535
2025-12-19 13:34:27,113 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2025-12-19 13:34:27,115 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:27,116 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2025-12-19 13:34:27,117 [om1-impl-thread1] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:lambda$0(147)) - om1: initialize group-C5BA1605619E with <INITIAL_VALUE>
2025-12-19 13:34:27,117 [om1-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - om1@group-C5BA1605619E: getLatestSnapshot(OzoneManagerStateMachine-177:om1:group-C5BA1605619E) returns 0#-1
2025-12-19 13:34:27,117 [om1-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - om1@group-C5BA1605619E-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:27,120 [om1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#22960,om1@group-C5BA1605619E-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:27,120 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2025-12-19 13:34:27,123 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:27,123 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:27,123 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - om1@group-C5BA1605619E: start as a follower, conf=conf: {index: -1, cur=peers:[om1|localhost:15535]|listeners:[], old=null}
2025-12-19 13:34:27,123 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:27,123 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-FollowerState
2025-12-19 13:34:27,124 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2025-12-19 13:34:27,124 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:27,124 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-12-19 13:34:27,124 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-12-19 13:34:27,124 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2025-12-19 13:34:27,124 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2025-12-19 13:34:27,125 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - om1@group-C5BA1605619E: Successfully started.
2025-12-19 13:34:27,125 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - om1: start RPC server
2025-12-19 13:34:27,126 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - om1: GrpcServicesImpl started, listening on 15535
2025-12-19 13:34:27,127 [JvmPauseMonitor81] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-om1: Started
2025-12-19 13:34:27,127 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:start(1833)) - Version File has different layout version (9) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2025-12-19 13:34:27,130 [ForkJoinPool-6-worker-1] INFO  client.ScmTopologyClient (ScmTopologyClient.java:start(70)) - Initial network topology fetched from SCM: /.
2025-12-19 13:34:27,130 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.2.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-12-19 13:34:27,131 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-12-19 13:34:27,133 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service KeyDeletingService with interval 60000 milliseconds
2025-12-19 13:34:27,133 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service DirectoryDeletingService with interval 120000 milliseconds
2025-12-19 13:34:27,134 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service OpenKeyCleanupService with interval 86400000 milliseconds
2025-12-19 13:34:27,134 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SstFilteringService with interval 60000 milliseconds
2025-12-19 13:34:27,135 [ForkJoinPool-6-worker-1] INFO  om.KeyManagerImpl (KeyManagerImpl.java:startSnapshotDefragService(433)) - SnapshotDefragService is disabled. Snapshot defragmentation will not run periodically.
2025-12-19 13:34:27,135 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SnapshotDeletingService with interval 30000 milliseconds
2025-12-19 13:34:27,136 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service MultipartUploadCleanupService with interval 86400000 milliseconds
2025-12-19 13:34:27,137 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15533
2025-12-19 13:34:27,137 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:27,138 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:27,140 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:27,141 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2025-12-19 13:34:27,141 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:27,141 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:27,142 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ozone-metadata/webserver
2025-12-19 13:34:27,142 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15533
2025-12-19 13:34:27,142 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:27,144 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:27,144 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:27,144 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-12-19 13:34:27,145 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6fbbd780{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:27,145 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7773eff3{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-12-19 13:34:27,149 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@182bb838{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2025-12-19 13:34:27,149 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@35a6583d{HTTP/1.1, (http/1.1)}{0.0.0.0:15533}
2025-12-19 13:34:27,149 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @853338ms
2025-12-19 13:34:27,149 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:27,150 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of ozoneManager listening at http://localhost:15533
2025-12-19 13:34:27,150 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:27,150 [IPC Server listener on 15532] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15532: starting
2025-12-19 13:34:27,152 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2288)) - Trash Interval set to 0. Files deleted won't move to trash
2025-12-19 13:34:27,164 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:27,164 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:27,178 [ForkJoinPool-6-worker-1] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(198)) - Updating IP address of datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/null) to 127.0.0.1
2025-12-19 13:34:27,178 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(253)) - HddsDatanodeService b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1)
2025-12-19 13:34:27,179 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:27,179 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmOnFinalizeActionForDatanodeSchemaV2
2025-12-19 13:34:27,179 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
2025-12-19 13:34:27,179 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ContainerTableSchemaFinalizeAction
2025-12-19 13:34:27,179 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmHAFinalizeUpgradeActionDatanode
2025-12-19 13:34:27,179 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV2FinalizeAction
2025-12-19 13:34:27,179 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,180 [ForkJoinPool-6-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(322)) - Datanode State Machine Task Thread Pool size 4
2025-12-19 13:34:27,182 [ForkJoinPool-6-worker-1] INFO  volume.HddsVolume (HddsVolume.java:<init>(166)) - HddsVolume: { id=DS-b52c7263-3844-4832-8c57-01b9f7328f97 dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=184448985434423296 committed=0 }
2025-12-19 13:34:27,182 [ForkJoinPool-6-worker-1] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds to VolumeSet
2025-12-19 13:34:27,183 [ForkJoinPool-6-worker-1] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis to VolumeSet
2025-12-19 13:34:27,184 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:27,184 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:27,206 [ForkJoinPool-6-worker-1] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(80)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-12-19 13:34:27,206 [ForkJoinPool-6-worker-1] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(89)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-12-19 13:34:27,207 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-19 13:34:27,208 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:27,208 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:27,208 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:27,208 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:27,208 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:27,208 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:27,208 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:27,208 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.admin.port = 15540 (custom)
2025-12-19 13:34:27,209 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:27,209 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.client.port = 15539 (custom)
2025-12-19 13:34:27,209 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15541 (custom)
2025-12-19 13:34:27,209 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (ConfUtils.java:logGet(62)) - raft.grpc.message.size.max = 34603008 (custom)
2025-12-19 13:34:27,209 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (ConfUtils.java:logGet(62)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2025-12-19 13:34:27,209 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.request.timeout = 60s (custom)
2025-12-19 13:34:27,211 [ForkJoinPool-6-worker-1] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(62)) - raft.datastream.type = NETTY (custom)
2025-12-19 13:34:27,211 [ForkJoinPool-6-worker-1] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for b8c29964-8a98-47a9-8b1d-466622f5f9c1-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-12-19 13:34:27,211 [ForkJoinPool-6-worker-1] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for b8c29964-8a98-47a9-8b1d-466622f5f9c1-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-12-19 13:34:27,212 [ForkJoinPool-6-worker-1] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(62)) - raft.netty.dataStream.port = 15542 (custom)
2025-12-19 13:34:27,212 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis] (custom)
2025-12-19 13:34:27,212 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9bc55302] REGISTERED
2025-12-19 13:34:27,213 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9bc55302] BIND: 0.0.0.0/0.0.0.0:15542
2025-12-19 13:34:27,213 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9bc55302, L:/0.0.0.0:15542] ACTIVE
2025-12-19 13:34:27,213 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(273)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/tmp
2025-12-19 13:34:27,213 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(278)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/tmp is not a group directory; ignoring it. 
2025-12-19 13:34:27,213 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(85)) - Initializing replication server with thread count = 10 queue length = 4096
2025-12-19 13:34:27,214 [ForkJoinPool-6-worker-1] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(129)) - GrpcServer channel type EpollServerSocketChannel
2025-12-19 13:34:27,215 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-12-19 13:34:27,215 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-12-19 13:34:27,217 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15536
2025-12-19 13:34:27,217 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:27,218 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:27,219 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:27,220 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-12-19 13:34:27,220 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:27,220 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:27,221 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ozone-metadata/webserver
2025-12-19 13:34:27,221 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15536
2025-12-19 13:34:27,221 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:27,222 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:27,222 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:27,222 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-12-19 13:34:27,223 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@30d9246d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:27,223 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@112eecc8{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-12-19 13:34:27,259 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3c009dff{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ozone-metadata/webserver/jetty-0_0_0_0-15536-hdds-container-service-2_2_0-SNAPSHOT_jar-_-any-15245521250652141047/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-12-19 13:34:27,259 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6f559a9c{HTTP/1.1, (http/1.1)}{0.0.0.0:15536}
2025-12-19 13:34:27,259 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @853448ms
2025-12-19 13:34:27,259 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:27,260 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of hddsDatanode listening at http://localhost:15536
2025-12-19 13:34:27,260 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:27,260 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15537
2025-12-19 13:34:27,261 [Socket Reader #1 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15537
2025-12-19 13:34:27,261 [Socket Reader #3 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15537
2025-12-19 13:34:27,261 [Socket Reader #2 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15537
2025-12-19 13:34:27,261 [Socket Reader #4 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15537
2025-12-19 13:34:27,262 [Socket Reader #5 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15537
2025-12-19 13:34:27,262 [Socket Reader #6 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15537
2025-12-19 13:34:27,262 [Socket Reader #7 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15537
2025-12-19 13:34:27,263 [Socket Reader #8 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15537
2025-12-19 13:34:27,263 [Socket Reader #9 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15537
2025-12-19 13:34:27,263 [Socket Reader #10 for port 15537] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15537
2025-12-19 13:34:27,264 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(356)) - Datanode start with admins: [admin, runner]
2025-12-19 13:34:27,264 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15537
2025-12-19 13:34:27,265 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:27,265 [IPC Server listener on 15537] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15537: starting
2025-12-19 13:34:27,267 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:27,267 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:27,268 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineDaemonThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(288)) - Running pre-finalized state validations for unfinalized layout features.
2025-12-19 13:34:27,268 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineDaemonThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(301)) - Running first upgrade commands for unfinalized layout features.
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(364)) - Ozone container server started.
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,269 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,273 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ozone-metadata/datanode.id
2025-12-19 13:34:27,284 [ForkJoinPool-6-worker-1] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(198)) - Updating IP address of datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/null) to 127.0.0.1
2025-12-19 13:34:27,284 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(253)) - HddsDatanodeService 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1)
2025-12-19 13:34:27,285 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:27,285 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmOnFinalizeActionForDatanodeSchemaV2
2025-12-19 13:34:27,285 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
2025-12-19 13:34:27,285 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ContainerTableSchemaFinalizeAction
2025-12-19 13:34:27,285 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmHAFinalizeUpgradeActionDatanode
2025-12-19 13:34:27,285 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV2FinalizeAction
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,286 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,287 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,287 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,287 [ForkJoinPool-6-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(322)) - Datanode State Machine Task Thread Pool size 4
2025-12-19 13:34:27,289 [ForkJoinPool-6-worker-1] INFO  volume.HddsVolume (HddsVolume.java:<init>(166)) - HddsVolume: { id=DS-7ea3176d-9d2e-4e60-ac24-82da7dc7254b dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=184448985434423296 committed=0 }
2025-12-19 13:34:27,289 [ForkJoinPool-6-worker-1] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds to VolumeSet
2025-12-19 13:34:27,289 [ForkJoinPool-6-worker-1] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis to VolumeSet
2025-12-19 13:34:27,290 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:27,290 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:27,309 [ForkJoinPool-6-worker-1] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(80)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-12-19 13:34:27,310 [ForkJoinPool-6-worker-1] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(89)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-12-19 13:34:27,311 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:27,311 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:27,311 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:27,312 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:27,312 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:27,312 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:27,312 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:27,312 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.admin.port = 15548 (custom)
2025-12-19 13:34:27,312 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:27,312 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.client.port = 15547 (custom)
2025-12-19 13:34:27,312 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15549 (custom)
2025-12-19 13:34:27,314 [ForkJoinPool-6-worker-1] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 57412301-a084-4aa6-8e22-91ecff01c376-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-12-19 13:34:27,314 [ForkJoinPool-6-worker-1] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 57412301-a084-4aa6-8e22-91ecff01c376-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-12-19 13:34:27,314 [ForkJoinPool-6-worker-1] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(62)) - raft.netty.dataStream.port = 15550 (custom)
2025-12-19 13:34:27,315 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis] (custom)
2025-12-19 13:34:27,315 [57412301-a084-4aa6-8e22-91ecff01c376-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x39a12701] REGISTERED
2025-12-19 13:34:27,315 [57412301-a084-4aa6-8e22-91ecff01c376-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x39a12701] BIND: 0.0.0.0/0.0.0.0:15550
2025-12-19 13:34:27,315 [57412301-a084-4aa6-8e22-91ecff01c376-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x39a12701, L:/0.0.0.0:15550] ACTIVE
2025-12-19 13:34:27,316 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(273)) - 57412301-a084-4aa6-8e22-91ecff01c376: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/tmp
2025-12-19 13:34:27,316 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(278)) - 57412301-a084-4aa6-8e22-91ecff01c376: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2025-12-19 13:34:27,316 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(85)) - Initializing replication server with thread count = 10 queue length = 4096
2025-12-19 13:34:27,317 [ForkJoinPool-6-worker-1] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(129)) - GrpcServer channel type EpollServerSocketChannel
2025-12-19 13:34:27,317 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-12-19 13:34:27,318 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-12-19 13:34:27,319 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15544
2025-12-19 13:34:27,319 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:27,320 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:27,321 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:27,322 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-12-19 13:34:27,322 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:27,322 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:27,322 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ozone-metadata/webserver
2025-12-19 13:34:27,323 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15544
2025-12-19 13:34:27,323 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:27,324 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:27,324 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:27,325 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-12-19 13:34:27,325 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@925d524{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:27,325 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6ef86c04{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-12-19 13:34:27,359 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@e46e6bf{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ozone-metadata/webserver/jetty-0_0_0_0-15544-hdds-container-service-2_2_0-SNAPSHOT_jar-_-any-8013334643845325839/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-12-19 13:34:27,360 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@262483d3{HTTP/1.1, (http/1.1)}{0.0.0.0:15544}
2025-12-19 13:34:27,360 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @853548ms
2025-12-19 13:34:27,360 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:27,360 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of hddsDatanode listening at http://localhost:15544
2025-12-19 13:34:27,361 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:27,361 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15545
2025-12-19 13:34:27,361 [Socket Reader #1 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15545
2025-12-19 13:34:27,362 [Socket Reader #2 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15545
2025-12-19 13:34:27,362 [Socket Reader #3 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15545
2025-12-19 13:34:27,362 [Socket Reader #4 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15545
2025-12-19 13:34:27,363 [Socket Reader #5 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15545
2025-12-19 13:34:27,363 [Socket Reader #6 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15545
2025-12-19 13:34:27,363 [Socket Reader #7 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15545
2025-12-19 13:34:27,363 [Socket Reader #8 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15545
2025-12-19 13:34:27,363 [Socket Reader #9 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15545
2025-12-19 13:34:27,363 [Socket Reader #10 for port 15545] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15545
2025-12-19 13:34:27,364 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(356)) - Datanode start with admins: [admin, runner]
2025-12-19 13:34:27,364 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15545
2025-12-19 13:34:27,365 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:27,365 [IPC Server listener on 15545] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15545: starting
2025-12-19 13:34:27,366 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:27,366 [ForkJoinPool-6-worker-1] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(114)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineDaemonThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(288)) - Running pre-finalized state validations for unfinalized layout features.
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineDaemonThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(301)) - Running first upgrade commands for unfinalized layout features.
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(364)) - Ozone container server started.
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,367 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,368 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,368 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,368 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,368 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,368 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,368 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,371 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ozone-metadata/datanode.id
2025-12-19 13:34:27,382 [ForkJoinPool-6-worker-1] INFO  protocol.DatanodeDetails (DatanodeDetails.java:validateDatanodeIpAddress(198)) - Updating IP address of datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/null) to 127.0.0.1
2025-12-19 13:34:27,382 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(253)) - HddsDatanodeService 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1)
2025-12-19 13:34:27,383 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = INITIAL_VERSION (version = 0), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:27,383 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmOnFinalizeActionForDatanodeSchemaV2
2025-12-19 13:34:27,383 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV3FinalizeAction
2025-12-19 13:34:27,383 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ContainerTableSchemaFinalizeAction
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : ScmHAFinalizeUpgradeActionDatanode
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  upgrade.HDDSLayoutVersionManager (HDDSLayoutVersionManager.java:lambda$registerUpgradeActions$0(81)) - Registering Upgrade Action : DatanodeSchemaV2FinalizeAction
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,384 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,385 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,385 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,385 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,385 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,385 [ForkJoinPool-6-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(322)) - Datanode State Machine Task Thread Pool size 4
2025-12-19 13:34:27,386 [ForkJoinPool-6-worker-1] INFO  volume.HddsVolume (HddsVolume.java:<init>(166)) - HddsVolume: { id=DS-18810e72-649e-4d83-a1ea-af2c86e8441f dir=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds type=DISK capacity=9222449699674390527 used=0 available=9222449699674390527 minFree=184448985434423296 committed=0 }
2025-12-19 13:34:27,386 [ForkJoinPool-6-worker-1] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds to VolumeSet
2025-12-19 13:34:27,387 [ForkJoinPool-6-worker-1] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis to VolumeSet
2025-12-19 13:34:27,387 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:27,388 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.datanode.id.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:27,405 [ForkJoinPool-6-worker-1] INFO  impl.FilePerChunkStrategy (FilePerChunkStrategy.java:<init>(80)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-12-19 13:34:27,405 [ForkJoinPool-6-worker-1] INFO  impl.FilePerBlockStrategy (FilePerBlockStrategy.java:<init>(89)) - ozone.chunk.read.mapped.buffer.max.count is load with 0
2025-12-19 13:34:27,406 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:27,406 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:27,406 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:27,406 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:27,407 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:27,407 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:27,407 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:27,407 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.admin.port = 15556 (custom)
2025-12-19 13:34:27,407 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:27,407 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.client.port = 15555 (custom)
2025-12-19 13:34:27,407 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15557 (custom)
2025-12-19 13:34:27,408 [ForkJoinPool-6-worker-1] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 9f85a268-b54d-42c0-89e3-0f143f429527-NettyServerStreamRpc-bossGroup; Thread size is 0.
2025-12-19 13:34:27,409 [ForkJoinPool-6-worker-1] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(74)) - Create EpollEventLoopGroup for 9f85a268-b54d-42c0-89e3-0f143f429527-NettyServerStreamRpc-workerGroup; Thread size is 0.
2025-12-19 13:34:27,409 [ForkJoinPool-6-worker-1] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(62)) - raft.netty.dataStream.port = 15558 (custom)
2025-12-19 13:34:27,410 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis] (custom)
2025-12-19 13:34:27,410 [9f85a268-b54d-42c0-89e3-0f143f429527-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa70ed6a6] REGISTERED
2025-12-19 13:34:27,410 [9f85a268-b54d-42c0-89e3-0f143f429527-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa70ed6a6] BIND: 0.0.0.0/0.0.0.0:15558
2025-12-19 13:34:27,410 [9f85a268-b54d-42c0-89e3-0f143f429527-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa70ed6a6, L:/0.0.0.0:15558] ACTIVE
2025-12-19 13:34:27,410 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(273)) - 9f85a268-b54d-42c0-89e3-0f143f429527: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/tmp
2025-12-19 13:34:27,410 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(278)) - 9f85a268-b54d-42c0-89e3-0f143f429527: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/tmp is not a group directory; ignoring it. 
2025-12-19 13:34:27,410 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(85)) - Initializing replication server with thread count = 10 queue length = 4096
2025-12-19 13:34:27,411 [ForkJoinPool-6-worker-1] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(129)) - GrpcServer channel type EpollServerSocketChannel
2025-12-19 13:34:27,412 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(169)) - Initializing replication supervisor with thread count = 10
2025-12-19 13:34:27,412 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(358)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2025-12-19 13:34:27,413 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15552
2025-12-19 13:34:27,414 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:27,414 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:27,416 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:27,416 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2025-12-19 13:34:27,417 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:27,417 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:27,417 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ozone-metadata/webserver
2025-12-19 13:34:27,417 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15552
2025-12-19 13:34:27,417 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:27,419 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:27,419 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:27,419 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-12-19 13:34:27,420 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@23cfa901{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:27,420 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7ed2ebe1{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2025-12-19 13:34:27,455 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3bdc0d08{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ozone-metadata/webserver/jetty-0_0_0_0-15552-hdds-container-service-2_2_0-SNAPSHOT_jar-_-any-5542166325308716921/webapp/,AVAILABLE}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-12-19 13:34:27,456 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3f52fd39{HTTP/1.1, (http/1.1)}{0.0.0.0:15552}
2025-12-19 13:34:27,456 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @853644ms
2025-12-19 13:34:27,456 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:27,456 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of hddsDatanode listening at http://localhost:15552
2025-12-19 13:34:27,457 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:27,457 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15553
2025-12-19 13:34:27,457 [Socket Reader #1 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15553
2025-12-19 13:34:27,458 [Socket Reader #2 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15553
2025-12-19 13:34:27,458 [Socket Reader #3 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15553
2025-12-19 13:34:27,458 [Socket Reader #4 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15553
2025-12-19 13:34:27,458 [Socket Reader #5 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15553
2025-12-19 13:34:27,459 [Socket Reader #6 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15553
2025-12-19 13:34:27,459 [Socket Reader #7 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15553
2025-12-19 13:34:27,459 [Socket Reader #8 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15553
2025-12-19 13:34:27,459 [Socket Reader #9 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15553
2025-12-19 13:34:27,460 [Socket Reader #10 for port 15553] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15553
2025-12-19 13:34:27,460 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(356)) - Datanode start with admins: [admin, runner]
2025-12-19 13:34:27,460 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(76)) - RPC server for Client /0.0.0.0:15553
2025-12-19 13:34:27,461 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:27,461 [IPC Server listener on 15553] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15553: starting
2025-12-19 13:34:27,463 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,463 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,463 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,463 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineDaemonThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(288)) - Running pre-finalized state validations for unfinalized layout features.
2025-12-19 13:34:27,464 [ForkJoinPool-6-worker-1] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,464 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineDaemonThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runPrefinalizeStateActions(301)) - Running first upgrade commands for unfinalized layout features.
2025-12-19 13:34:27,465 [ForkJoinPool-6-worker-1] INFO  proxy.SCMContainerLocationFailoverProxyProvider (SCMFailoverProxyProviderBase.java:<init>(120)) - Created fail-over proxy for protocol StorageContainerLocationProtocolPB with 3 nodes: [nodeId=scmNode-2,nodeAddress=/127.0.0.1:15503, nodeId=scmNode-3,nodeAddress=/127.0.0.1:15511, nodeId=scmNode-1,nodeAddress=/127.0.0.1:15495]
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:startStateMachineThread(364)) - Ozone container server started.
2025-12-19 13:34:27,465 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2025-12-19 13:34:27,465 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:27,465 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.security.service.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.security.service.port appended with serviceId and nodeId
2025-12-19 13:34:27,465 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  ha.SCMNodeInfo (SCMNodeInfo.java:getPort(196)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
2025-12-19 13:34:27,468 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ozone-metadata/datanode.id
2025-12-19 13:34:27,575 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:27,685 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:27,759 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:27,776 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(146)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds
2025-12-19 13:34:27,776 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(176)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds
2025-12-19 13:34:27,776 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(359)) - Build ContainerSet costs 0s
2025-12-19 13:34:27,776 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds
2025-12-19 13:34:27,777 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(231)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds
2025-12-19 13:34:27,778 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis
2025-12-19 13:34:27,778 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(231)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis
2025-12-19 13:34:27,779 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(544)) - Attempting to start container services.
2025-12-19 13:34:27,780 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-12-19 13:34:27,780 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-12-19 13:34:27,780 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(138)) - ReplicationServer is started using port 15543
2025-12-19 13:34:27,780 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(b8c29964-8a98-47a9-8b1d-466622f5f9c1)
2025-12-19 13:34:27,781 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start RPC server
2025-12-19 13:34:27,782 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: GrpcServicesImpl started, listening on 15539
2025-12-19 13:34:27,782 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: GrpcServicesImpl started, listening on 15541
2025-12-19 13:34:27,782 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: GrpcServicesImpl started, listening on 15540
2025-12-19 13:34:27,782 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(b8c29964-8a98-47a9-8b1d-466622f5f9c1) is started using port RATIS=15539
2025-12-19 13:34:27,782 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(b8c29964-8a98-47a9-8b1d-466622f5f9c1) is started using port RATIS_ADMIN=15540
2025-12-19 13:34:27,782 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(b8c29964-8a98-47a9-8b1d-466622f5f9c1) is started using port RATIS_SERVER=15541
2025-12-19 13:34:27,782 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(b8c29964-8a98-47a9-8b1d-466622f5f9c1) is started using port RATIS_DATASTREAM=15542
2025-12-19 13:34:27,782 [JvmPauseMonitor82] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-b8c29964-8a98-47a9-8b1d-466622f5f9c1: Started
2025-12-19 13:34:27,783 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service BlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:27,783 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service StaleRecoveringContainerScrubbingService with interval 60000 milliseconds
2025-12-19 13:34:27,783 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:27,784 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:27,785 [IPC Server handler 1 on default port 15494] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:27,785 [IPC Server handler 1 on default port 15502] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:27,786 [IPC Server handler 1 on default port 15494] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: b8c29964-8a98-47a9-8b1d-466622f5f9c1{ip: 127.0.0.1, host: localhost, ports: [HTTP=15536, CLIENT_RPC=15537, REPLICATION=15543, RATIS=15539, RATIS_ADMIN=15540, RATIS_SERVER=15541, RATIS_DATASTREAM=15542, STANDALONE=15538], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,786 [IPC Server handler 1 on default port 15502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: b8c29964-8a98-47a9-8b1d-466622f5f9c1{ip: 127.0.0.1, host: localhost, ports: [HTTP=15536, CLIENT_RPC=15537, REPLICATION=15543, RATIS=15539, RATIS_ADMIN=15540, RATIS_SERVER=15541, RATIS_DATASTREAM=15542, STANDALONE=15538], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,786 [IPC Server handler 1 on default port 15510] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:27,786 [IPC Server handler 1 on default port 15510] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: b8c29964-8a98-47a9-8b1d-466622f5f9c1{ip: 127.0.0.1, host: localhost, ports: [HTTP=15536, CLIENT_RPC=15537, REPLICATION=15543, RATIS=15539, RATIS_ADMIN=15540, RATIS_SERVER=15541, RATIS_DATASTREAM=15542, STANDALONE=15538], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,786 [scmNode-1-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:27,787 [scmNode-2-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:27,787 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2025-12-19 13:34:27,787 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-e9c493b0-d510-4c9a-94da-ff0630b18160 to datanode:b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1)
2025-12-19 13:34:27,788 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,788 [scmNode-3-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:27,788 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2025-12-19 13:34:27,789 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,789 [scmNode-2-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,789 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2025-12-19 13:34:27,789 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,790 [scmNode-1-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,790 [scmNode-2-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,791 [scmNode-1-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,791 [scmNode-3-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,791 [scmNode-3-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,796 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,796 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,796 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,796 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,796 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,796 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,796 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,797 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: e9c493b0-d510-4c9a-94da-ff0630b18160, Nodes: [ {b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-19T13:34:27.787615388Z[Etc/UTC]}
2025-12-19 13:34:27,872 [57412301-a084-4aa6-8e22-91ecff01c376-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(146)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds
2025-12-19 13:34:27,872 [57412301-a084-4aa6-8e22-91ecff01c376-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(176)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds
2025-12-19 13:34:27,873 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(359)) - Build ContainerSet costs 0s
2025-12-19 13:34:27,873 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds
2025-12-19 13:34:27,873 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(231)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds
2025-12-19 13:34:27,874 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis
2025-12-19 13:34:27,874 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(231)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis
2025-12-19 13:34:27,875 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(544)) - Attempting to start container services.
2025-12-19 13:34:27,876 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-12-19 13:34:27,876 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-12-19 13:34:27,876 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(138)) - ReplicationServer is started using port 15551
2025-12-19 13:34:27,876 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(57412301-a084-4aa6-8e22-91ecff01c376)
2025-12-19 13:34:27,877 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 57412301-a084-4aa6-8e22-91ecff01c376: start RPC server
2025-12-19 13:34:27,877 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 57412301-a084-4aa6-8e22-91ecff01c376: GrpcServicesImpl started, listening on 15547
2025-12-19 13:34:27,877 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 57412301-a084-4aa6-8e22-91ecff01c376: GrpcServicesImpl started, listening on 15549
2025-12-19 13:34:27,878 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 57412301-a084-4aa6-8e22-91ecff01c376: GrpcServicesImpl started, listening on 15548
2025-12-19 13:34:27,878 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(57412301-a084-4aa6-8e22-91ecff01c376) is started using port RATIS=15547
2025-12-19 13:34:27,878 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(57412301-a084-4aa6-8e22-91ecff01c376) is started using port RATIS_ADMIN=15548
2025-12-19 13:34:27,878 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(57412301-a084-4aa6-8e22-91ecff01c376) is started using port RATIS_SERVER=15549
2025-12-19 13:34:27,878 [JvmPauseMonitor83] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-57412301-a084-4aa6-8e22-91ecff01c376: Started
2025-12-19 13:34:27,878 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(57412301-a084-4aa6-8e22-91ecff01c376) is started using port RATIS_DATASTREAM=15550
2025-12-19 13:34:27,878 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service BlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:27,879 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service StaleRecoveringContainerScrubbingService with interval 60000 milliseconds
2025-12-19 13:34:27,879 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:27,879 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:27,880 [IPC Server handler 3 on default port 15502] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:27,880 [IPC Server handler 3 on default port 15502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 57412301-a084-4aa6-8e22-91ecff01c376{ip: 127.0.0.1, host: localhost, ports: [HTTP=15544, CLIENT_RPC=15545, REPLICATION=15551, RATIS=15547, RATIS_ADMIN=15548, RATIS_SERVER=15549, RATIS_DATASTREAM=15550, STANDALONE=15546], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,880 [IPC Server handler 3 on default port 15494] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:27,880 [IPC Server handler 3 on default port 15494] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 57412301-a084-4aa6-8e22-91ecff01c376{ip: 127.0.0.1, host: localhost, ports: [HTTP=15544, CLIENT_RPC=15545, REPLICATION=15551, RATIS=15547, RATIS_ADMIN=15548, RATIS_SERVER=15549, RATIS_DATASTREAM=15550, STANDALONE=15546], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,880 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,881 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2025-12-19 13:34:27,881 [IPC Server handler 3 on default port 15510] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:27,881 [IPC Server handler 3 on default port 15510] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 57412301-a084-4aa6-8e22-91ecff01c376{ip: 127.0.0.1, host: localhost, ports: [HTTP=15544, CLIENT_RPC=15545, REPLICATION=15551, RATIS=15547, RATIS_ADMIN=15548, RATIS_SERVER=15549, RATIS_DATASTREAM=15550, STANDALONE=15546], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,881 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2025-12-19 13:34:27,881 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,881 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,881 [scmNode-3-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,881 [scmNode-3-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:27,881 [scmNode-2-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:27,881 [scmNode-1-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:27,881 [scmNode-2-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,881 [scmNode-2-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,881 [scmNode-3-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,881 [scmNode-1-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,881 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2025-12-19 13:34:27,881 [scmNode-1-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,882 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-099e5e47-f620-4042-9012-1603dfd1d8ca to datanode:57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1)
2025-12-19 13:34:27,884 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,884 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,884 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,884 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,884 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,884 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,884 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,885 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,885 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,885 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,885 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 099e5e47-f620-4042-9012-1603dfd1d8ca, Nodes: [ {57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-19T13:34:27.882060467Z[Etc/UTC]}
2025-12-19 13:34:27,969 [9f85a268-b54d-42c0-89e3-0f143f429527-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(146)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds
2025-12-19 13:34:27,969 [9f85a268-b54d-42c0-89e3-0f143f429527-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(176)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds
2025-12-19 13:34:27,970 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(359)) - Build ContainerSet costs 0s
2025-12-19 13:34:27,970 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds
2025-12-19 13:34:27,970 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(231)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds
2025-12-19 13:34:27,974 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(138)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis
2025-12-19 13:34:27,974 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(231)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis
2025-12-19 13:34:27,975 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(544)) - Attempting to start container services.
2025-12-19 13:34:27,975 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-12-19 13:34:27,976 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(89)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2025-12-19 13:34:27,976 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(138)) - ReplicationServer is started using port 15559
2025-12-19 13:34:27,976 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(559)) - Starting XceiverServerRatis(9f85a268-b54d-42c0-89e3-0f143f429527)
2025-12-19 13:34:27,977 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start RPC server
2025-12-19 13:34:27,977 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 9f85a268-b54d-42c0-89e3-0f143f429527: GrpcServicesImpl started, listening on 15555
2025-12-19 13:34:27,978 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 9f85a268-b54d-42c0-89e3-0f143f429527: GrpcServicesImpl started, listening on 15557
2025-12-19 13:34:27,978 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 9f85a268-b54d-42c0-89e3-0f143f429527: GrpcServicesImpl started, listening on 15556
2025-12-19 13:34:27,978 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(9f85a268-b54d-42c0-89e3-0f143f429527) is started using port RATIS=15555
2025-12-19 13:34:27,978 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(9f85a268-b54d-42c0-89e3-0f143f429527) is started using port RATIS_ADMIN=15556
2025-12-19 13:34:27,978 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(9f85a268-b54d-42c0-89e3-0f143f429527) is started using port RATIS_SERVER=15557
2025-12-19 13:34:27,978 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(586)) - XceiverServerRatis(9f85a268-b54d-42c0-89e3-0f143f429527) is started using port RATIS_DATASTREAM=15558
2025-12-19 13:34:27,978 [JvmPauseMonitor84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-9f85a268-b54d-42c0-89e3-0f143f429527: Started
2025-12-19 13:34:27,979 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service BlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:27,979 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service StaleRecoveringContainerScrubbingService with interval 60000 milliseconds
2025-12-19 13:34:27,980 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:27,980 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:27,981 [IPC Server handler 5 on default port 15494] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:27,981 [IPC Server handler 5 on default port 15494] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 9f85a268-b54d-42c0-89e3-0f143f429527{ip: 127.0.0.1, host: localhost, ports: [HTTP=15552, CLIENT_RPC=15553, REPLICATION=15559, RATIS=15555, RATIS_ADMIN=15556, RATIS_SERVER=15557, RATIS_DATASTREAM=15558, STANDALONE=15554], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,982 [scmNode-1-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,982 [scmNode-1-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,982 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,982 [scmNode-1-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:27,983 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-06657f59-31dc-40a9-89f4-b70a942b69e2 to datanode:9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1)
2025-12-19 13:34:27,982 [IPC Server handler 5 on default port 15510] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:27,983 [IPC Server handler 5 on default port 15510] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 9f85a268-b54d-42c0-89e3-0f143f429527{ip: 127.0.0.1, host: localhost, ports: [HTTP=15552, CLIENT_RPC=15553, REPLICATION=15559, RATIS=15555, RATIS_ADMIN=15556, RATIS_SERVER=15557, RATIS_DATASTREAM=15558, STANDALONE=15554], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,982 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2025-12-19 13:34:27,983 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,983 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(151)) - All SCM safe mode pre check rules have passed
2025-12-19 13:34:27,983 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-19 13:34:27,983 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,983 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2025-12-19 13:34:27,983 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,983 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(151)) - All SCM safe mode pre check rules have passed
2025-12-19 13:34:27,983 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-19 13:34:27,982 [IPC Server handler 5 on default port 15502] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:27,984 [IPC Server handler 5 on default port 15502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 9f85a268-b54d-42c0-89e3-0f143f429527{ip: 127.0.0.1, host: localhost, ports: [HTTP=15552, CLIENT_RPC=15553, REPLICATION=15559, RATIS=15555, RATIS_ADMIN=15556, RATIS_SERVER=15557, RATIS_DATASTREAM=15558, STANDALONE=15554], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(151)) - All SCM safe mode pre check rules have passed
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,984 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,983 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:27,983 [scmNode-3-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:27,984 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:27,984 [scmNode-3-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,984 [scmNode-3-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,986 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,986 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,986 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,986 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,986 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,986 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,986 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 06657f59-31dc-40a9-89f4-b70a942b69e2, Nodes: [ {9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-19T13:34:27.983156813Z[Etc/UTC]}
2025-12-19 13:34:27,987 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 to datanode:b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1)
2025-12-19 13:34:27,987 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 to datanode:9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1)
2025-12-19 13:34:27,987 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 to datanode:57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1)
2025-12-19 13:34:27,987 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,987 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,987 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,987 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,987 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,988 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,989 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,989 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,989 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,989 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,989 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,989 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,990 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,990 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,990 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,990 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,990 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,990 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,991 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61, Nodes: [ {b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1), ReplicaIndex: 0}, {9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1), ReplicaIndex: 0}, {57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-19T13:34:27.987069322Z[Etc/UTC]}
2025-12-19 13:34:27,991 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-83edabe4-a852-4d54-beae-579d88baa401 to datanode:9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1)
2025-12-19 13:34:27,991 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-83edabe4-a852-4d54-beae-579d88baa401 to datanode:57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1)
2025-12-19 13:34:27,991 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-83edabe4-a852-4d54-beae-579d88baa401 to datanode:b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1)
2025-12-19 13:34:27,991 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,992 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,992 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,992 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,992 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,992 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,993 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,993 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,993 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,993 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,993 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,993 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,994 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,994 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,994 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,995 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,995 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,995 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,995 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:27,995 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:27,995 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:27,995 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:recordMetricsForPipeline(922)) - Pipeline-83edabe4-a852-4d54-beae-579d88baa401 and Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 have exactly the same set of datanodes: [9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1), 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1), b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1)]
2025-12-19 13:34:27,996 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 83edabe4-a852-4d54-beae-579d88baa401, Nodes: [ {9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1), ReplicaIndex: 0}, {57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1), ReplicaIndex: 0}, {b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-19T13:34:27.991731055Z[Etc/UTC]}
2025-12-19 13:34:28,188 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1064809658ns, electionTimeout:1064ms
2025-12-19 13:34:28,188 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2025-12-19 13:34:28,188 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-19 13:34:28,189 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-LeaderElection117
2025-12-19 13:34:28,189 [om1@group-C5BA1605619E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - om1@group-C5BA1605619E-LeaderElection117 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[om1|localhost:15535]|listeners:[], old=null}
2025-12-19 13:34:28,189 [om1@group-C5BA1605619E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - om1@group-C5BA1605619E-LeaderElection117 PRE_VOTE round 0: result PASSED (term=0)
2025-12-19 13:34:28,190 [om1@group-C5BA1605619E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - om1@group-C5BA1605619E-LeaderElection117 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[om1|localhost:15535]|listeners:[], old=null}
2025-12-19 13:34:28,190 [om1@group-C5BA1605619E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - om1@group-C5BA1605619E-LeaderElection117 ELECTION round 0: result PASSED (term=1)
2025-12-19 13:34:28,190 [om1@group-C5BA1605619E-LeaderElection117] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection117
2025-12-19 13:34:28,190 [om1@group-C5BA1605619E-LeaderElection117] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-19 13:34:28,190 [om1@group-C5BA1605619E-LeaderElection117] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 3600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:28,191 [om1@group-C5BA1605619E-LeaderElection117] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.log-metadata.enabled = false (custom)
2025-12-19 13:34:28,191 [om1@group-C5BA1605619E-LeaderElection117] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2025-12-19 13:34:28,191 [om1@group-C5BA1605619E-LeaderElection117] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - om1@group-C5BA1605619E: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:28,191 [om1@group-C5BA1605619E-LeaderElection117] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyLeaderChanged(195)) - om1@group-C5BA1605619E: leader changed to om1
2025-12-19 13:34:28,191 [om1@group-C5BA1605619E-LeaderElection117] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1472ms
2025-12-19 13:34:28,192 [om1@group-C5BA1605619E-LeaderElection117] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:28,192 [om1@group-C5BA1605619E-LeaderElection117] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - om1@group-C5BA1605619E: set configuration conf: {index: 0, cur=peers:[om1|localhost:15535]|listeners:[], old=null}
2025-12-19 13:34:28,192 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:28,199 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/om/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2025-12-19 13:34:28,200 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(264)) - notifyConfigurationChanged from Ratis: term=1, index=0, New Peer list: om1(localhost:15535), New Listener list
2025-12-19 13:34:28,200 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader om1@group-C5BA1605619E-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-19 13:34:28,465 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:28,466 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:28,466 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:28,576 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:28,686 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:28,759 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:28,770 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: addNew group-FF0630B18160:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541] returns group-FF0630B18160:java.util.concurrent.CompletableFuture@6413fa22[Not completed]
2025-12-19 13:34:28,771 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: new RaftServerImpl for group-FF0630B18160:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541] with ContainerStateMachine-178:uninitialized
2025-12-19 13:34:28,771 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.timeout.min = 5s (custom)
2025-12-19 13:34:28,771 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.timeout.max = 5200ms (custom)
2025-12-19 13:34:28,771 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.slowness.timeout = 300s (custom)
2025-12-19 13:34:28,771 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: ConfigurationManager, init=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,771 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.notification.no-leader.timeout = 300s (custom)
2025-12-19 13:34:28,771 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.retrycache.expirytime = 600000ms (custom)
2025-12-19 13:34:28,774 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis] (custom)
2025-12-19 13:34:28,774 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/e9c493b0-d510-4c9a-94da-ff0630b18160 does not exist. Creating ...
2025-12-19 13:34:28,775 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/e9c493b0-d510-4c9a-94da-ff0630b18160/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,776 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/e9c493b0-d510-4c9a-94da-ff0630b18160 has been successfully formatted.
2025-12-19 13:34:28,776 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: initialize group-FF0630B18160
2025-12-19 13:34:28,776 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-FF0630B18160: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,777 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: getLatestSnapshot(ContainerStateMachine-178:b8c29964-8a98-47a9-8b1d-466622f5f9c1:group-FF0630B18160) returns null
2025-12-19 13:34:28,777 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,778 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,778 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23241,b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,778 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/e9c493b0-d510-4c9a-94da-ff0630b18160
2025-12-19 13:34:28,778 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2025-12-19 13:34:28,778 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.queue.element-limit = 1024 (custom)
2025-12-19 13:34:28,778 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,779 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2025-12-19 13:34:28,779 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,779 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.write.buffer.size = 33554440 (custom)
2025-12-19 13:34:28,783 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,784 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,784 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,784 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,784 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,784 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,784 [scmNode-1-EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(132)) - Opened pipeline Pipeline-e9c493b0-d510-4c9a-94da-ff0630b18160
2025-12-19 13:34:28,785 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2025-12-19 13:34:28,786 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,786 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,786 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,786 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,786 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,786 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,786 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,787 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,785 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,787 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,787 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,787 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,787 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,787 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,787 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: start as a follower, conf=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541]|listeners:[], old=null}
2025-12-19 13:34:28,787 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,787 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState
2025-12-19 13:34:28,788 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF0630B18160,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:28,788 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-FF0630B18160,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:28,788 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.snapshot.auto.trigger.threshold = 100000 (custom)
2025-12-19 13:34:28,788 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.snapshot.retention.file.num = 5 (custom)
2025-12-19 13:34:28,788 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.purge.upto.snapshot.index = false (default)
2025-12-19 13:34:28,788 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.first-election.timeout.min = 1000ms (custom)
2025-12-19 13:34:28,788 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.first-election.timeout.max = 1200ms (custom)
2025-12-19 13:34:28,789 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: Successfully started.
2025-12-19 13:34:28,789 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(839)) - Created group Pipeline-e9c493b0-d510-4c9a-94da-ff0630b18160
2025-12-19 13:34:28,789 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(141)) - Created Pipeline RATIS ONE Pipeline-e9c493b0-d510-4c9a-94da-ff0630b18160.
2025-12-19 13:34:28,789 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: addNew group-6AA3D4F57C61:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] returns group-6AA3D4F57C61:java.util.concurrent.CompletableFuture@7c17c0f[Not completed]
2025-12-19 13:34:28,790 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: new RaftServerImpl for group-6AA3D4F57C61:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] with ContainerStateMachine-179:uninitialized
2025-12-19 13:34:28,790 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: ConfigurationManager, init=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,793 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 does not exist. Creating ...
2025-12-19 13:34:28,794 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,795 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 has been successfully formatted.
2025-12-19 13:34:28,795 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: initialize group-6AA3D4F57C61
2025-12-19 13:34:28,795 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-6AA3D4F57C61: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,795 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: getLatestSnapshot(ContainerStateMachine-179:b8c29964-8a98-47a9-8b1d-466622f5f9c1:group-6AA3D4F57C61) returns null
2025-12-19 13:34:28,795 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,796 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,796 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,797 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,797 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23249,b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,797 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61
2025-12-19 13:34:28,802 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,802 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,803 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: start as a follower, conf=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:28,803 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,803 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FollowerState
2025-12-19 13:34:28,803 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:28,803 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:28,804 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: Successfully started.
2025-12-19 13:34:28,804 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(839)) - Created group Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61
2025-12-19 13:34:28,810 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 9f85a268-b54d-42c0-89e3-0f143f429527: addNew group-6AA3D4F57C61:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] returns group-6AA3D4F57C61:java.util.concurrent.CompletableFuture@886463c[Not completed]
2025-12-19 13:34:28,811 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 9f85a268-b54d-42c0-89e3-0f143f429527: new RaftServerImpl for group-6AA3D4F57C61:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] with ContainerStateMachine-180:uninitialized
2025-12-19 13:34:28,811 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: ConfigurationManager, init=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,814 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis] (custom)
2025-12-19 13:34:28,814 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 does not exist. Creating ...
2025-12-19 13:34:28,815 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,816 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 has been successfully formatted.
2025-12-19 13:34:28,817 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 9f85a268-b54d-42c0-89e3-0f143f429527: initialize group-6AA3D4F57C61
2025-12-19 13:34:28,817 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-6AA3D4F57C61: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,817 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: getLatestSnapshot(ContainerStateMachine-180:9f85a268-b54d-42c0-89e3-0f143f429527:group-6AA3D4F57C61) returns null
2025-12-19 13:34:28,817 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,818 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,818 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,819 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23254,9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,819 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61
2025-12-19 13:34:28,819 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,825 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,825 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,826 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: start as a follower, conf=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:28,826 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,826 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-FollowerState
2025-12-19 13:34:28,826 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:28,826 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:28,827 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: Successfully started.
2025-12-19 13:34:28,834 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 57412301-a084-4aa6-8e22-91ecff01c376: addNew group-6AA3D4F57C61:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] returns group-6AA3D4F57C61:java.util.concurrent.CompletableFuture@7b6aaf9a[Not completed]
2025-12-19 13:34:28,835 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 57412301-a084-4aa6-8e22-91ecff01c376: new RaftServerImpl for group-6AA3D4F57C61:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] with ContainerStateMachine-181:uninitialized
2025-12-19 13:34:28,835 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: ConfigurationManager, init=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,837 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis] (custom)
2025-12-19 13:34:28,838 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 does not exist. Creating ...
2025-12-19 13:34:28,839 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,841 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 has been successfully formatted.
2025-12-19 13:34:28,841 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 57412301-a084-4aa6-8e22-91ecff01c376: initialize group-6AA3D4F57C61
2025-12-19 13:34:28,841 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-6AA3D4F57C61: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,841 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: getLatestSnapshot(ContainerStateMachine-181:57412301-a084-4aa6-8e22-91ecff01c376:group-6AA3D4F57C61) returns null
2025-12-19 13:34:28,841 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,842 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,842 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,843 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,843 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23262,57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,843 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61
2025-12-19 13:34:28,848 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,849 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,849 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: start as a follower, conf=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:28,849 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,849 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 57412301-a084-4aa6-8e22-91ecff01c376: start 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FollowerState
2025-12-19 13:34:28,849 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:28,849 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:28,850 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: Successfully started.
2025-12-19 13:34:28,852 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(141)) - Created Pipeline RATIS THREE Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61.
2025-12-19 13:34:28,852 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: addNew group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] returns group-579D88BAA401:java.util.concurrent.CompletableFuture@180d6f8c[Not completed]
2025-12-19 13:34:28,853 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: new RaftServerImpl for group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] with ContainerStateMachine-182:uninitialized
2025-12-19 13:34:28,853 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: ConfigurationManager, init=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,855 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis] (custom)
2025-12-19 13:34:28,856 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/83edabe4-a852-4d54-beae-579d88baa401 does not exist. Creating ...
2025-12-19 13:34:28,857 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/83edabe4-a852-4d54-beae-579d88baa401/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,858 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/83edabe4-a852-4d54-beae-579d88baa401 has been successfully formatted.
2025-12-19 13:34:28,858 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: initialize group-579D88BAA401
2025-12-19 13:34:28,858 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-579D88BAA401: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,858 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: getLatestSnapshot(ContainerStateMachine-182:b8c29964-8a98-47a9-8b1d-466622f5f9c1:group-579D88BAA401) returns null
2025-12-19 13:34:28,858 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,859 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,860 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,860 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,860 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23269,b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,861 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/83edabe4-a852-4d54-beae-579d88baa401
2025-12-19 13:34:28,866 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,866 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,867 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: start as a follower, conf=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:28,867 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,867 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-FollowerState
2025-12-19 13:34:28,867 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-579D88BAA401,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:28,867 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-579D88BAA401,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:28,868 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: Successfully started.
2025-12-19 13:34:28,868 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(839)) - Created group Pipeline-83edabe4-a852-4d54-beae-579d88baa401
2025-12-19 13:34:28,868 [57412301-a084-4aa6-8e22-91ecff01c376-CreatePipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 57412301-a084-4aa6-8e22-91ecff01c376: addNew group-1603DFD1D8CA:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549] returns group-1603DFD1D8CA:java.util.concurrent.CompletableFuture@53eb88d4[Not completed]
2025-12-19 13:34:28,869 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 57412301-a084-4aa6-8e22-91ecff01c376: new RaftServerImpl for group-1603DFD1D8CA:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549] with ContainerStateMachine-183:uninitialized
2025-12-19 13:34:28,870 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: ConfigurationManager, init=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,873 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis] (custom)
2025-12-19 13:34:28,874 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/099e5e47-f620-4042-9012-1603dfd1d8ca does not exist. Creating ...
2025-12-19 13:34:28,874 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 9f85a268-b54d-42c0-89e3-0f143f429527: addNew group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] returns group-579D88BAA401:java.util.concurrent.CompletableFuture@79d041e[Not completed]
2025-12-19 13:34:28,875 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/099e5e47-f620-4042-9012-1603dfd1d8ca/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,876 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 9f85a268-b54d-42c0-89e3-0f143f429527: new RaftServerImpl for group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] with ContainerStateMachine-184:uninitialized
2025-12-19 13:34:28,876 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: ConfigurationManager, init=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,877 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/099e5e47-f620-4042-9012-1603dfd1d8ca has been successfully formatted.
2025-12-19 13:34:28,877 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 57412301-a084-4aa6-8e22-91ecff01c376: initialize group-1603DFD1D8CA
2025-12-19 13:34:28,877 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-1603DFD1D8CA: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,877 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: getLatestSnapshot(ContainerStateMachine-183:57412301-a084-4aa6-8e22-91ecff01c376:group-1603DFD1D8CA) returns null
2025-12-19 13:34:28,878 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,879 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,880 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,880 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,882 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,883 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,883 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,883 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,883 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,883 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,884 [scmNode-1-EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(132)) - Opened pipeline Pipeline-099e5e47-f620-4042-9012-1603dfd1d8ca
2025-12-19 13:34:28,883 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,884 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,885 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis] (custom)
2025-12-19 13:34:28,885 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/83edabe4-a852-4d54-beae-579d88baa401 does not exist. Creating ...
2025-12-19 13:34:28,885 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23274,57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,886 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/099e5e47-f620-4042-9012-1603dfd1d8ca
2025-12-19 13:34:28,886 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,886 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,886 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,888 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,888 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,888 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,889 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/83edabe4-a852-4d54-beae-579d88baa401/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,891 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/83edabe4-a852-4d54-beae-579d88baa401 has been successfully formatted.
2025-12-19 13:34:28,891 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 9f85a268-b54d-42c0-89e3-0f143f429527: initialize group-579D88BAA401
2025-12-19 13:34:28,891 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-579D88BAA401: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,891 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: getLatestSnapshot(ContainerStateMachine-184:9f85a268-b54d-42c0-89e3-0f143f429527:group-579D88BAA401) returns null
2025-12-19 13:34:28,892 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,892 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,892 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,893 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: start as a follower, conf=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549]|listeners:[], old=null}
2025-12-19 13:34:28,893 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,893 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 57412301-a084-4aa6-8e22-91ecff01c376: start 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-FollowerState
2025-12-19 13:34:28,893 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23277,9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,893 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/83edabe4-a852-4d54-beae-579d88baa401
2025-12-19 13:34:28,894 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,895 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1603DFD1D8CA,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:28,895 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-1603DFD1D8CA,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:28,895 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: Successfully started.
2025-12-19 13:34:28,895 [57412301-a084-4aa6-8e22-91ecff01c376-CreatePipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(839)) - Created group Pipeline-099e5e47-f620-4042-9012-1603dfd1d8ca
2025-12-19 13:34:28,895 [57412301-a084-4aa6-8e22-91ecff01c376-CreatePipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(141)) - Created Pipeline RATIS ONE Pipeline-099e5e47-f620-4042-9012-1603dfd1d8ca.
2025-12-19 13:34:28,896 [57412301-a084-4aa6-8e22-91ecff01c376-CreatePipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 57412301-a084-4aa6-8e22-91ecff01c376: addNew group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] returns group-579D88BAA401:java.util.concurrent.CompletableFuture@5d2c7cd9[Not completed]
2025-12-19 13:34:28,897 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 57412301-a084-4aa6-8e22-91ecff01c376: new RaftServerImpl for group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] with ContainerStateMachine-185:uninitialized
2025-12-19 13:34:28,897 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,897 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,897 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: ConfigurationManager, init=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,900 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,901 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,901 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis] (custom)
2025-12-19 13:34:28,901 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/83edabe4-a852-4d54-beae-579d88baa401 does not exist. Creating ...
2025-12-19 13:34:28,902 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: start as a follower, conf=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:28,902 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,902 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FollowerState
2025-12-19 13:34:28,902 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-579D88BAA401,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:28,902 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-579D88BAA401,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:28,902 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: Successfully started.
2025-12-19 13:34:28,903 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/83edabe4-a852-4d54-beae-579d88baa401/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,904 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/83edabe4-a852-4d54-beae-579d88baa401 has been successfully formatted.
2025-12-19 13:34:28,904 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 57412301-a084-4aa6-8e22-91ecff01c376: initialize group-579D88BAA401
2025-12-19 13:34:28,904 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-579D88BAA401: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,904 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: getLatestSnapshot(ContainerStateMachine-185:57412301-a084-4aa6-8e22-91ecff01c376:group-579D88BAA401) returns null
2025-12-19 13:34:28,904 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,907 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23285,57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,907 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/83edabe4-a852-4d54-beae-579d88baa401
2025-12-19 13:34:28,907 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,908 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,908 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,914 [grpc-default-executor-0] WARN  server.GrpcAdminProtocolService (GrpcAdminProtocolService.java:lambda$groupManagement$1(53)) - Failed groupManagement: GROUPADD, GroupManagementRequest:client-BAAABCCBCB41->57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401, cid=68, seq=null, RW, null, Add:group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.AlreadyExistsException: 57412301-a084-4aa6-8e22-91ecff01c376: Failed to add group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] since the group already exists in the map.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:674)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:662)
	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2210)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:516)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:498)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:51)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:180)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:51)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:698)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:356)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:861)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.ratis.protocol.exceptions.AlreadyExistsException: 57412301-a084-4aa6-8e22-91ecff01c376: Failed to add group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:100)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:515)
	... 13 more
2025-12-19 13:34:28,915 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,916 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,916 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: start as a follower, conf=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:28,916 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,916 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 57412301-a084-4aa6-8e22-91ecff01c376: start 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FollowerState
2025-12-19 13:34:28,916 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-579D88BAA401,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:28,916 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-579D88BAA401,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:28,917 [57412301-a084-4aa6-8e22-91ecff01c376-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: Successfully started.
2025-12-19 13:34:28,917 [57412301-a084-4aa6-8e22-91ecff01c376-CreatePipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(839)) - Created group Pipeline-83edabe4-a852-4d54-beae-579d88baa401
2025-12-19 13:34:28,921 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CreatePipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(141)) - Created Pipeline RATIS THREE Pipeline-83edabe4-a852-4d54-beae-579d88baa401.
2025-12-19 13:34:28,924 [grpc-default-executor-0] WARN  server.GrpcAdminProtocolService (GrpcAdminProtocolService.java:lambda$groupManagement$1(53)) - Failed groupManagement: GROUPADD, GroupManagementRequest:client-35D15E79A572->9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401, cid=69, seq=null, RW, null, Add:group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.AlreadyExistsException: 9f85a268-b54d-42c0-89e3-0f143f429527: Failed to add group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] since the group already exists in the map.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:674)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:662)
	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2210)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:516)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:498)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:51)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:180)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:51)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:698)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:356)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:861)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.ratis.protocol.exceptions.AlreadyExistsException: 9f85a268-b54d-42c0-89e3-0f143f429527: Failed to add group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:100)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:515)
	... 13 more
2025-12-19 13:34:28,932 [grpc-default-executor-0] WARN  server.GrpcAdminProtocolService (GrpcAdminProtocolService.java:lambda$groupManagement$1(53)) - Failed groupManagement: GROUPADD, GroupManagementRequest:client-D314A5FD2957->b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401, cid=70, seq=null, RW, null, Add:group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.AlreadyExistsException: b8c29964-8a98-47a9-8b1d-466622f5f9c1: Failed to add group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] since the group already exists in the map.
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:674)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:662)
	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2210)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:516)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:498)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:51)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:180)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:51)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:698)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:356)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:861)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.ratis.protocol.exceptions.AlreadyExistsException: b8c29964-8a98-47a9-8b1d-466622f5f9c1: Failed to add group-579D88BAA401:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:100)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:515)
	... 13 more
2025-12-19 13:34:28,938 [57412301-a084-4aa6-8e22-91ecff01c376-CreatePipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(141)) - Created Pipeline RATIS THREE Pipeline-83edabe4-a852-4d54-beae-579d88baa401.
2025-12-19 13:34:28,966 [9f85a268-b54d-42c0-89e3-0f143f429527-CreatePipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 9f85a268-b54d-42c0-89e3-0f143f429527: addNew group-B70A942B69E2:[9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] returns group-B70A942B69E2:java.util.concurrent.CompletableFuture@47110aeb[Not completed]
2025-12-19 13:34:28,967 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 9f85a268-b54d-42c0-89e3-0f143f429527: new RaftServerImpl for group-B70A942B69E2:[9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557] with ContainerStateMachine-186:uninitialized
2025-12-19 13:34:28,967 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: ConfigurationManager, init=conf: {index: -1, cur=peers:[9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:28,969 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis] (custom)
2025-12-19 13:34:28,970 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/06657f59-31dc-40a9-89f4-b70a942b69e2 does not exist. Creating ...
2025-12-19 13:34:28,971 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/06657f59-31dc-40a9-89f4-b70a942b69e2/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:28,972 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(98)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/06657f59-31dc-40a9-89f4-b70a942b69e2 has been successfully formatted.
2025-12-19 13:34:28,973 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:initialize(339)) - 9f85a268-b54d-42c0-89e3-0f143f429527: initialize group-B70A942B69E2
2025-12-19 13:34:28,973 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(347)) - group-B70A942B69E2: The snapshot info is null. Setting the last applied index to:<INITIAL_VALUE>
2025-12-19 13:34:28,974 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,974 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: getLatestSnapshot(ContainerStateMachine-186:9f85a268-b54d-42c0-89e3-0f143f429527:group-B70A942B69E2) returns null
2025-12-19 13:34:28,974 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLog: snapshotIndexFromStateMachine = -1
2025-12-19 13:34:28,975 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,975 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,977 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23299,9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:28,977 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/06657f59-31dc-40a9-89f4-b70a942b69e2
2025-12-19 13:34:28,977 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,977 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,977 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,978 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,978 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,978 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,980 [scmNode-1-EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(132)) - Opened pipeline Pipeline-06657f59-31dc-40a9-89f4-b70a942b69e2
2025-12-19 13:34:28,979 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,980 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,980 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,980 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,980 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,980 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,978 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:28,980 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,980 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:28,980 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:28,980 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:28,980 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:28,984 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,985 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:28,985 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: start as a follower, conf=conf: {index: -1, cur=peers:[9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:28,985 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-19 13:34:28,985 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-FollowerState
2025-12-19 13:34:28,986 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B70A942B69E2,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:28,986 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-B70A942B69E2,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:28,987 [9f85a268-b54d-42c0-89e3-0f143f429527-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: Successfully started.
2025-12-19 13:34:28,987 [9f85a268-b54d-42c0-89e3-0f143f429527-CreatePipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(839)) - Created group Pipeline-06657f59-31dc-40a9-89f4-b70a942b69e2
2025-12-19 13:34:28,987 [9f85a268-b54d-42c0-89e3-0f143f429527-CreatePipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(141)) - Created Pipeline RATIS ONE Pipeline-06657f59-31dc-40a9-89f4-b70a942b69e2.
2025-12-19 13:34:29,466 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:29,466 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:29,466 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:29,577 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:29,686 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:29,760 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:29,760 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15440 for past 0 seconds.
java.net.ConnectException: Call From localhost/127.0.0.1 to localhost:15440 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:876)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:639)
	at org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
	at org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
	at org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1435)
	... 12 more
2025-12-19 13:34:29,842 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1016585316ns, electionTimeout:1016ms
2025-12-19 13:34:29,842 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-FollowerState
2025-12-19 13:34:29,843 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-19 13:34:29,843 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118
2025-12-19 13:34:29,843 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,844 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541
2025-12-19 13:34:29,844 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549
2025-12-19 13:34:29,847 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: receive requestVote(PRE_VOTE, 9f85a268-b54d-42c0-89e3-0f143f429527, group-6AA3D4F57C61, 0, <PROTO_DEFAULT>)
2025-12-19 13:34:29,847 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: receive requestVote(PRE_VOTE, 9f85a268-b54d-42c0-89e3-0f143f429527, group-6AA3D4F57C61, 0, <PROTO_DEFAULT>)
2025-12-19 13:34:29,847 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FOLLOWER: accept PRE_VOTE from 9f85a268-b54d-42c0-89e3-0f143f429527: our priority 0 <= candidate's priority 1
2025-12-19 13:34:29,847 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FOLLOWER: accept PRE_VOTE from 9f85a268-b54d-42c0-89e3-0f143f429527: our priority 0 <= candidate's priority 1
2025-12-19 13:34:29,847 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61 replies to PRE_VOTE vote request: 9f85a268-b54d-42c0-89e3-0f143f429527<-57412301-a084-4aa6-8e22-91ecff01c376#0:OK-t0-last:<INITIAL_VALUE>. Peer's state: 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61:t0, leader=null, voted=, raftlog=Memoized:57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,847 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61 replies to PRE_VOTE vote request: 9f85a268-b54d-42c0-89e3-0f143f429527<-b8c29964-8a98-47a9-8b1d-466622f5f9c1#0:OK-t0-last:<INITIAL_VALUE>. Peer's state: b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61:t0, leader=null, voted=, raftlog=Memoized:b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,848 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(206)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2025-12-19 13:34:29,848 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(210)) -   Response 0: 9f85a268-b54d-42c0-89e3-0f143f429527<-57412301-a084-4aa6-8e22-91ecff01c376#0:OK-t0-last:<INITIAL_VALUE>
2025-12-19 13:34:29,848 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118 PRE_VOTE round 0: result PASSED
2025-12-19 13:34:29,849 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,850 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: receive requestVote(ELECTION, 9f85a268-b54d-42c0-89e3-0f143f429527, group-6AA3D4F57C61, 1, <PROTO_DEFAULT>)
2025-12-19 13:34:29,850 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: receive requestVote(ELECTION, 9f85a268-b54d-42c0-89e3-0f143f429527, group-6AA3D4F57C61, 1, <PROTO_DEFAULT>)
2025-12-19 13:34:29,850 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FOLLOWER: accept ELECTION from 9f85a268-b54d-42c0-89e3-0f143f429527: our priority 0 <= candidate's priority 1
2025-12-19 13:34:29,850 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FOLLOWER: accept ELECTION from 9f85a268-b54d-42c0-89e3-0f143f429527: our priority 0 <= candidate's priority 1
2025-12-19 13:34:29,850 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: changes role from  FOLLOWER to FOLLOWER at term 0 for candidate:9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:29,850 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FollowerState
2025-12-19 13:34:29,850 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: changes role from  FOLLOWER to FOLLOWER at term 0 for candidate:9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:29,850 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FollowerState
2025-12-19 13:34:29,850 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FollowerState was interrupted
2025-12-19 13:34:29,850 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FollowerState was interrupted
2025-12-19 13:34:29,850 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FollowerState
2025-12-19 13:34:29,850 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 57412301-a084-4aa6-8e22-91ecff01c376: start 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FollowerState
2025-12-19 13:34:29,850 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: set firstElectionSinceStartup to false for candidate:9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:29,851 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: set firstElectionSinceStartup to false for candidate:9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:29,852 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61 replies to ELECTION vote request: 9f85a268-b54d-42c0-89e3-0f143f429527<-b8c29964-8a98-47a9-8b1d-466622f5f9c1#0:OK-t1-last:<INITIAL_VALUE>. Peer's state: b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61:t1, leader=null, voted=9f85a268-b54d-42c0-89e3-0f143f429527, raftlog=Memoized:b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,852 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61 replies to ELECTION vote request: 9f85a268-b54d-42c0-89e3-0f143f429527<-57412301-a084-4aa6-8e22-91ecff01c376#0:OK-t1-last:<INITIAL_VALUE>. Peer's state: 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61:t1, leader=null, voted=9f85a268-b54d-42c0-89e3-0f143f429527, raftlog=Memoized:57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,852 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(206)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118: ELECTION PASSED received 1 response(s) and 0 exception(s):
2025-12-19 13:34:29,852 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(210)) -   Response 0: 9f85a268-b54d-42c0-89e3-0f143f429527<-b8c29964-8a98-47a9-8b1d-466622f5f9c1#0:OK-t1-last:<INITIAL_VALUE>
2025-12-19 13:34:29,852 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118 ELECTION round 0: result PASSED
2025-12-19 13:34:29,852 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118
2025-12-19 13:34:29,852 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-19 13:34:29,852 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:29,852 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.write.element-limit = 1024 (custom)
2025-12-19 13:34:29,852 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2025-12-19 13:34:29,853 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.watch.timeout = 30s (custom)
2025-12-19 13:34:29,853 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.log-metadata.enabled = true (default)
2025-12-19 13:34:29,854 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderStateImpl
2025-12-19 13:34:29,854 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:29,854 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-6AA3D4F57C61 with new leaderId: 9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:29,854 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: change Leader from null to 9f85a268-b54d-42c0-89e3-0f143f429527 at term 1 for becomeLeader, leader elected after 1042ms
2025-12-19 13:34:29,854 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:29,854 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderElection118] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: set configuration conf: {index: 0, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,855 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:29,855 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,857 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,859 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,860 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:29,861 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:29,861 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:29,861 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:29,861 [grpc-default-executor-4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-6AA3D4F57C61 with new leaderId: 9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:29,861 [grpc-default-executor-5] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-6AA3D4F57C61 with new leaderId: 9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:29,861 [grpc-default-executor-4] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: change Leader from null to 9f85a268-b54d-42c0-89e3-0f143f429527 at term 1 for APPEND_ENTRIES, leader elected after 1070ms
2025-12-19 13:34:29,862 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:29,862 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:29,862 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2025-12-19 13:34:29,862 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:29,862 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,862 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:29,861 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2025-12-19 13:34:29,862 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:29,862 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,862 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:29,862 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: set configuration conf: {index: 0, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,862 [scmNode-1-EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(132)) - Opened pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61
2025-12-19 13:34:29,861 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2025-12-19 13:34:29,862 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:29,862 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,862 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:29,862 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(195)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - HealthyPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(158)) - ScmSafeModeManager, all rules are successfully validated
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(159)) - SCM exiting safe mode.
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(78)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(78)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(265)) - notifyStatusChanged:RUNNING
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1411)) - Service ReplicationManager transitions to RUNNING.
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(136)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2025-12-19 13:34:29,863 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:notifyStatusChanged(78)) - Service SCMHATransactionMonitor transitions to RUNNING.
2025-12-19 13:34:29,863 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:29,861 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: change Leader from null to 9f85a268-b54d-42c0-89e3-0f143f429527 at term 1 for APPEND_ENTRIES, leader elected after 1025ms
2025-12-19 13:34:29,864 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: set configuration conf: {index: 0, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,864 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:29,864 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/current/log_inprogress_0
2025-12-19 13:34:29,865 [57412301-a084-4aa6-8e22-91ecff01c376-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:29,865 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:29,871 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/current/log_inprogress_0
2025-12-19 13:34:29,872 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/current/log_inprogress_0
2025-12-19 13:34:29,873 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-19 13:34:29,930 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1063052097ns, electionTimeout:1062ms
2025-12-19 13:34:29,930 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-FollowerState
2025-12-19 13:34:29,930 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-19 13:34:29,930 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119
2025-12-19 13:34:29,930 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,931 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549
2025-12-19 13:34:29,931 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557
2025-12-19 13:34:29,934 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: receive requestVote(PRE_VOTE, b8c29964-8a98-47a9-8b1d-466622f5f9c1, group-579D88BAA401, 0, <PROTO_DEFAULT>)
2025-12-19 13:34:29,934 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: receive requestVote(PRE_VOTE, b8c29964-8a98-47a9-8b1d-466622f5f9c1, group-579D88BAA401, 0, <PROTO_DEFAULT>)
2025-12-19 13:34:29,934 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FOLLOWER: accept PRE_VOTE from b8c29964-8a98-47a9-8b1d-466622f5f9c1: our priority 0 <= candidate's priority 1
2025-12-19 13:34:29,934 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FOLLOWER: accept PRE_VOTE from b8c29964-8a98-47a9-8b1d-466622f5f9c1: our priority 0 <= candidate's priority 1
2025-12-19 13:34:29,934 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401 replies to PRE_VOTE vote request: b8c29964-8a98-47a9-8b1d-466622f5f9c1<-57412301-a084-4aa6-8e22-91ecff01c376#0:OK-t0-last:<INITIAL_VALUE>. Peer's state: 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401:t0, leader=null, voted=, raftlog=Memoized:57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,934 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401 replies to PRE_VOTE vote request: b8c29964-8a98-47a9-8b1d-466622f5f9c1<-9f85a268-b54d-42c0-89e3-0f143f429527#0:OK-t0-last:<INITIAL_VALUE>. Peer's state: 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401:t0, leader=null, voted=, raftlog=Memoized:9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,934 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(206)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2025-12-19 13:34:29,934 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(210)) -   Response 0: b8c29964-8a98-47a9-8b1d-466622f5f9c1<-9f85a268-b54d-42c0-89e3-0f143f429527#0:OK-t0-last:<INITIAL_VALUE>
2025-12-19 13:34:29,934 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119 PRE_VOTE round 0: result PASSED
2025-12-19 13:34:29,936 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,936 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: receive requestVote(ELECTION, b8c29964-8a98-47a9-8b1d-466622f5f9c1, group-579D88BAA401, 1, <PROTO_DEFAULT>)
2025-12-19 13:34:29,936 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: receive requestVote(ELECTION, b8c29964-8a98-47a9-8b1d-466622f5f9c1, group-579D88BAA401, 1, <PROTO_DEFAULT>)
2025-12-19 13:34:29,936 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FOLLOWER: accept ELECTION from b8c29964-8a98-47a9-8b1d-466622f5f9c1: our priority 0 <= candidate's priority 1
2025-12-19 13:34:29,936 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: changes role from  FOLLOWER to FOLLOWER at term 0 for candidate:b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:29,936 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FollowerState
2025-12-19 13:34:29,936 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FOLLOWER: accept ELECTION from b8c29964-8a98-47a9-8b1d-466622f5f9c1: our priority 0 <= candidate's priority 1
2025-12-19 13:34:29,937 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FollowerState was interrupted
2025-12-19 13:34:29,937 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 57412301-a084-4aa6-8e22-91ecff01c376: start 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FollowerState
2025-12-19 13:34:29,937 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: changes role from  FOLLOWER to FOLLOWER at term 0 for candidate:b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:29,937 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FollowerState
2025-12-19 13:34:29,937 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FollowerState
2025-12-19 13:34:29,937 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: set firstElectionSinceStartup to false for candidate:b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:29,937 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FollowerState was interrupted
2025-12-19 13:34:29,937 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: set firstElectionSinceStartup to false for candidate:b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:29,938 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401 replies to ELECTION vote request: b8c29964-8a98-47a9-8b1d-466622f5f9c1<-9f85a268-b54d-42c0-89e3-0f143f429527#0:OK-t1-last:<INITIAL_VALUE>. Peer's state: 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401:t1, leader=null, voted=b8c29964-8a98-47a9-8b1d-466622f5f9c1, raftlog=Memoized:9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,938 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401 replies to ELECTION vote request: b8c29964-8a98-47a9-8b1d-466622f5f9c1<-57412301-a084-4aa6-8e22-91ecff01c376#0:OK-t1-last:<INITIAL_VALUE>. Peer's state: 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401:t1, leader=null, voted=b8c29964-8a98-47a9-8b1d-466622f5f9c1, raftlog=Memoized:57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLog:OPENED:c-1:lastnull, conf=conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,939 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(206)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119: ELECTION PASSED received 1 response(s) and 0 exception(s):
2025-12-19 13:34:29,939 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(210)) -   Response 0: b8c29964-8a98-47a9-8b1d-466622f5f9c1<-57412301-a084-4aa6-8e22-91ecff01c376#0:OK-t1-last:<INITIAL_VALUE>
2025-12-19 13:34:29,939 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119 ELECTION round 0: result PASSED
2025-12-19 13:34:29,939 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119
2025-12-19 13:34:29,939 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-19 13:34:29,939 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:29,940 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderStateImpl
2025-12-19 13:34:29,940 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:29,940 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-579D88BAA401 with new leaderId: b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:29,940 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: change Leader from null to b8c29964-8a98-47a9-8b1d-466622f5f9c1 at term 1 for becomeLeader, leader elected after 1086ms
2025-12-19 13:34:29,940 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:29,941 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderElection119] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: set configuration conf: {index: 0, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,941 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:29,941 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(195)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-19 13:34:29,941 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - HealthyPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,941 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(158)) - ScmSafeModeManager, all rules are successfully validated
2025-12-19 13:34:29,941 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(159)) - SCM exiting safe mode.
2025-12-19 13:34:29,941 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-19 13:34:29,942 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,942 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(195)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-19 13:34:29,942 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - HealthyPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:29,942 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(158)) - ScmSafeModeManager, all rules are successfully validated
2025-12-19 13:34:29,942 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(159)) - SCM exiting safe mode.
2025-12-19 13:34:29,942 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-19 13:34:29,945 [scmNode-1-EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(132)) - Opened pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401
2025-12-19 13:34:29,946 [grpc-default-executor-5] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-579D88BAA401 with new leaderId: b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:29,946 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: change Leader from null to b8c29964-8a98-47a9-8b1d-466622f5f9c1 at term 1 for APPEND_ENTRIES, leader elected after 1069ms
2025-12-19 13:34:29,947 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: set configuration conf: {index: 0, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,948 [9f85a268-b54d-42c0-89e3-0f143f429527-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:29,948 [grpc-default-executor-3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-579D88BAA401 with new leaderId: b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:29,948 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: change Leader from null to b8c29964-8a98-47a9-8b1d-466622f5f9c1 at term 1 for APPEND_ENTRIES, leader elected after 1050ms
2025-12-19 13:34:29,948 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:29,948 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: set configuration conf: {index: 0, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549, b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541, 9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:29,949 [57412301-a084-4aa6-8e22-91ecff01c376-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:29,949 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:29,949 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/83edabe4-a852-4d54-beae-579d88baa401/current/log_inprogress_0
2025-12-19 13:34:29,955 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/83edabe4-a852-4d54-beae-579d88baa401/current/log_inprogress_0
2025-12-19 13:34:29,955 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/83edabe4-a852-4d54-beae-579d88baa401/current/log_inprogress_0
2025-12-19 13:34:29,957 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-19 13:34:29,982 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1195122724ns, electionTimeout:1194ms
2025-12-19 13:34:29,983 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState
2025-12-19 13:34:29,983 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-19 13:34:29,983 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120
2025-12-19 13:34:29,983 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541]|listeners:[], old=null}
2025-12-19 13:34:29,983 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120 PRE_VOTE round 0: result PASSED (term=0)
2025-12-19 13:34:29,984 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541]|listeners:[], old=null}
2025-12-19 13:34:29,984 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120 ELECTION round 0: result PASSED (term=1)
2025-12-19 13:34:29,984 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120
2025-12-19 13:34:29,984 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-19 13:34:29,984 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:29,985 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: start b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderStateImpl
2025-12-19 13:34:29,985 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:29,985 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-FF0630B18160 with new leaderId: b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:29,985 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: change Leader from null to b8c29964-8a98-47a9-8b1d-466622f5f9c1 at term 1 for becomeLeader, leader elected after 1214ms
2025-12-19 13:34:29,986 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:29,986 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderElection120] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: set configuration conf: {index: 0, cur=peers:[b8c29964-8a98-47a9-8b1d-466622f5f9c1|127.0.0.1:15541]|listeners:[], old=null}
2025-12-19 13:34:29,986 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:29,992 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/e9c493b0-d510-4c9a-94da-ff0630b18160/current/log_inprogress_0
2025-12-19 13:34:29,994 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-19 13:34:30,092 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1199086100ns, electionTimeout:1197ms
2025-12-19 13:34:30,092 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-FollowerState
2025-12-19 13:34:30,092 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-19 13:34:30,093 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 57412301-a084-4aa6-8e22-91ecff01c376: start 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121
2025-12-19 13:34:30,093 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549]|listeners:[], old=null}
2025-12-19 13:34:30,093 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121 PRE_VOTE round 0: result PASSED (term=0)
2025-12-19 13:34:30,094 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549]|listeners:[], old=null}
2025-12-19 13:34:30,094 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121 ELECTION round 0: result PASSED (term=1)
2025-12-19 13:34:30,094 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121
2025-12-19 13:34:30,094 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-19 13:34:30,094 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:30,095 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 57412301-a084-4aa6-8e22-91ecff01c376: start 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderStateImpl
2025-12-19 13:34:30,095 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:30,095 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-1603DFD1D8CA with new leaderId: 57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:30,095 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: change Leader from null to 57412301-a084-4aa6-8e22-91ecff01c376 at term 1 for becomeLeader, leader elected after 1224ms
2025-12-19 13:34:30,095 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:30,095 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderElection121] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: set configuration conf: {index: 0, cur=peers:[57412301-a084-4aa6-8e22-91ecff01c376|127.0.0.1:15549]|listeners:[], old=null}
2025-12-19 13:34:30,096 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:30,105 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/099e5e47-f620-4042-9012-1603dfd1d8ca/current/log_inprogress_0
2025-12-19 13:34:30,106 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-19 13:34:30,181 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1195791817ns, electionTimeout:1195ms
2025-12-19 13:34:30,181 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-FollowerState
2025-12-19 13:34:30,181 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-19 13:34:30,181 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122
2025-12-19 13:34:30,182 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:30,182 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122 PRE_VOTE round 0: result PASSED (term=0)
2025-12-19 13:34:30,183 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:30,183 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122 ELECTION round 0: result PASSED (term=1)
2025-12-19 13:34:30,183 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122
2025-12-19 13:34:30,183 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-19 13:34:30,183 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:30,184 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 9f85a268-b54d-42c0-89e3-0f143f429527: start 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderStateImpl
2025-12-19 13:34:30,184 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:30,184 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(940)) - Leader change notification received for group: group-B70A942B69E2 with new leaderId: 9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:30,184 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: change Leader from null to 9f85a268-b54d-42c0-89e3-0f143f429527 at term 1 for becomeLeader, leader elected after 1216ms
2025-12-19 13:34:30,184 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(440)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-19 13:34:30,184 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderElection122] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: set configuration conf: {index: 0, cur=peers:[9f85a268-b54d-42c0-89e3-0f143f429527|127.0.0.1:15557]|listeners:[], old=null}
2025-12-19 13:34:30,184 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_0 at position 0
2025-12-19 13:34:30,191 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/06657f59-31dc-40a9-89f4-b70a942b69e2/current/log_inprogress_0
2025-12-19 13:34:30,192 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-19 13:34:30,466 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:30,467 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Cluster exits safe mode
2025-12-19 13:34:30,467 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:30,469 [IPC Server handler 1 on default port 15495] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - Finalization started.
2025-12-19 13:34:30,471 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:30,471 [scmNode-1-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-1-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:34:30,471 [IPC Server handler 1 on default port 15495] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:logCheckpointCrossed(58)) - SCM Finalization has crossed checkpoint FINALIZATION_STARTED
2025-12-19 13:34:30,471 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-3-RatisPipelineUtilsThread.
2025-12-19 13:34:30,471 [scmNode-3-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-3-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:34:30,471 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-2-RatisPipelineUtilsThread.
2025-12-19 13:34:30,472 [scmNode-2-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-2-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:34:30,473 [IPC Server handler 1 on default port 15495] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(511)) - Pipeline Pipeline-099e5e47-f620-4042-9012-1603dfd1d8ca moved to CLOSED state
2025-12-19 13:34:30,475 [IPC Server handler 1 on default port 15495] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(511)) - Pipeline Pipeline-e9c493b0-d510-4c9a-94da-ff0630b18160 moved to CLOSED state
2025-12-19 13:34:30,476 [IPC Server handler 1 on default port 15495] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(511)) - Pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 moved to CLOSED state
2025-12-19 13:34:30,478 [IPC Server handler 1 on default port 15495] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(511)) - Pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 moved to CLOSED state
2025-12-19 13:34:30,481 [IPC Server handler 1 on default port 15495] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(511)) - Pipeline Pipeline-06657f59-31dc-40a9-89f4-b70a942b69e2 moved to CLOSED state
2025-12-19 13:34:30,481 [IPC Server handler 1 on default port 15495] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) -   Existing pipelines and containers will be closed during Upgrade.
  New pipelines creation will remain frozen until Upgrade is finalized.
2025-12-19 13:34:30,482 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V2
2025-12-19 13:34:30,482 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.ScmOnFinalizeActionForDatanodeSchemaV2 (ScmOnFinalizeActionForDatanodeSchemaV2.java:execute(41)) - Executing SCM On Finalize action for layout feature DATANODE_SCHEMA_V2
2025-12-19 13:34:30,483 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V2
2025-12-19 13:34:30,483 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.ScmOnFinalizeActionForDatanodeSchemaV2 (ScmOnFinalizeActionForDatanodeSchemaV2.java:execute(41)) - Executing SCM On Finalize action for layout feature DATANODE_SCHEMA_V2
2025-12-19 13:34:30,483 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V2
2025-12-19 13:34:30,483 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.ScmOnFinalizeActionForDatanodeSchemaV2 (ScmOnFinalizeActionForDatanodeSchemaV2.java:execute(41)) - Executing SCM On Finalize action for layout feature DATANODE_SCHEMA_V2
2025-12-19 13:34:30,484 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V2 has been finalized.
2025-12-19 13:34:30,484 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V2 has been finalized.
2025-12-19 13:34:30,485 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V2 has been finalized.
2025-12-19 13:34:30,485 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: SCM_HA.
2025-12-19 13:34:30,486 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: SCM_HA.
2025-12-19 13:34:30,486 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: SCM_HA.
2025-12-19 13:34:30,487 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature SCM_HA has been finalized.
2025-12-19 13:34:30,487 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature SCM_HA has been finalized.
2025-12-19 13:34:30,487 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature SCM_HA has been finalized.
2025-12-19 13:34:30,488 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
2025-12-19 13:34:30,489 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
2025-12-19 13:34:30,489 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
2025-12-19 13:34:30,489 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
2025-12-19 13:34:30,490 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
2025-12-19 13:34:30,490 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: DATANODE_SCHEMA_V3.
2025-12-19 13:34:30,491 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
2025-12-19 13:34:30,492 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V3 has been finalized.
2025-12-19 13:34:30,492 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: DATANODE_SCHEMA_V3.
2025-12-19 13:34:30,492 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: DATANODE_SCHEMA_V3.
2025-12-19 13:34:30,493 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V3 has been finalized.
2025-12-19 13:34:30,493 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V3 has been finalized.
2025-12-19 13:34:30,494 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS.
2025-12-19 13:34:30,494 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS.
2025-12-19 13:34:30,495 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS.
2025-12-19 13:34:30,496 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,496 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,496 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,498 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WEBUI_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:30,498 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WEBUI_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:30,499 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WEBUI_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:30,499 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WEBUI_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,500 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WEBUI_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,500 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WEBUI_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,501 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HADOOP_PRC_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:30,502 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HADOOP_PRC_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:30,502 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HADOOP_PRC_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,502 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HADOOP_PRC_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:30,503 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HADOOP_PRC_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,504 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HADOOP_PRC_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:30,504 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HBASE_SUPPORT.
2025-12-19 13:34:30,505 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HBASE_SUPPORT.
2025-12-19 13:34:30,505 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HBASE_SUPPORT.
2025-12-19 13:34:30,505 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HBASE_SUPPORT has been finalized.
2025-12-19 13:34:30,506 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HBASE_SUPPORT has been finalized.
2025-12-19 13:34:30,507 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WITNESSED_CONTAINER_DB_PROTO_VALUE.
2025-12-19 13:34:30,507 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HBASE_SUPPORT has been finalized.
2025-12-19 13:34:30,507 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WITNESSED_CONTAINER_DB_PROTO_VALUE.
2025-12-19 13:34:30,508 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WITNESSED_CONTAINER_DB_PROTO_VALUE.
2025-12-19 13:34:30,508 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WITNESSED_CONTAINER_DB_PROTO_VALUE has been finalized.
2025-12-19 13:34:30,508 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WITNESSED_CONTAINER_DB_PROTO_VALUE has been finalized.
2025-12-19 13:34:30,509 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: STORAGE_SPACE_DISTRIBUTION.
2025-12-19 13:34:30,510 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: STORAGE_SPACE_DISTRIBUTION.
2025-12-19 13:34:30,510 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WITNESSED_CONTAINER_DB_PROTO_VALUE has been finalized.
2025-12-19 13:34:30,510 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: STORAGE_SPACE_DISTRIBUTION.
2025-12-19 13:34:30,510 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature STORAGE_SPACE_DISTRIBUTION has been finalized.
2025-12-19 13:34:30,510 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(126)) - Finalization is complete.
2025-12-19 13:34:30,511 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature STORAGE_SPACE_DISTRIBUTION has been finalized.
2025-12-19 13:34:30,511 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(126)) - Finalization is complete.
2025-12-19 13:34:30,511 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,511 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,511 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-3-RatisPipelineUtilsThread.
2025-12-19 13:34:30,511 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:30,511 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,511 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,511 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-06657f59-31dc-40a9-89f4-b70a942b69e2 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,511 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,511 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-06657f59-31dc-40a9-89f4-b70a942b69e2 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature STORAGE_SPACE_DISTRIBUTION has been finalized.
2025-12-19 13:34:30,512 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(126)) - Finalization is complete.
2025-12-19 13:34:30,511 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,512 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-e9c493b0-d510-4c9a-94da-ff0630b18160 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,512 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-099e5e47-f620-4042-9012-1603dfd1d8ca in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [scmNode-1-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,512 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-e9c493b0-d510-4c9a-94da-ff0630b18160 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [IPC Server handler 1 on default port 15495] INFO  upgrade.TestScmHAFinalization (UpgradeTestUtils.java:lambda$newTerminatingFinalizationExecutor$2(116)) - Terminating upgrade finalization at point: AFTER_COMPLETE_FINALIZATION. This is expected test execution.
2025-12-19 13:34:30,512 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,512 [ForkJoinPool-6-worker-1] INFO  upgrade.TestScmHAFinalization (TestScmHAFinalization.java:testFinalizationWithRestart(210)) - Restarting all SCMs during upgrade finalization.
2025-12-19 13:34:30,512 [IPC Server handler 1 on default port 15495] WARN  upgrade.InjectedUpgradeFinalizationExecutor (InjectedUpgradeFinalizationExecutor.java:execute(86)) - Upgrade Finalization failed with following Exception.
org.apache.hadoop.ozone.upgrade.InjectedUpgradeFinalizationExecutor$UpgradeTestInjectionAbort
	at org.apache.hadoop.ozone.upgrade.InjectedUpgradeFinalizationExecutor.injectTestFunctionAtThisPoint(InjectedUpgradeFinalizationExecutor.java:120)
	at org.apache.hadoop.ozone.upgrade.InjectedUpgradeFinalizationExecutor.execute(InjectedUpgradeFinalizationExecutor.java:79)
	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:104)
	at org.apache.hadoop.hdds.scm.server.upgrade.FinalizationManagerImpl.finalizeUpgrade(FinalizationManagerImpl.java:115)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.finalizeScmUpgrade(SCMClientProtocolServer.java:1113)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getFinalizeScmUpgrade(StorageContainerLocationProtocolServerSideTranslatorPB.java:1054)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:660)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:238)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:539)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:508)
	at org.apache.hadoop.ipc_.RPC$Server.call(RPC.java:1164)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc_.Server$RpcCall.run(Server.java:948)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc_.Server$Handler.run(Server.java:2951)
2025-12-19 13:34:30,513 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:restartStorageContainerManager(260)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneHAClusterImpl
2025-12-19 13:34:30,513 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:shutdownStorageContainerManager(250)) - Shutting down StorageContainerManager 558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:30,513 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1621)) - Container Balancer is not running.
2025-12-19 13:34:30,513 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1754)) - Stopping Replication Manager Service.
2025-12-19 13:34:30,513 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(319)) - Stopping Replication Monitor Thread.
2025-12-19 13:34:30,513 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1630)) - Stopping the Datanode Admin Monitor.
2025-12-19 13:34:30,513 [scmNode-2-OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-2-OverReplicatedProcessor interrupted. Exiting...
2025-12-19 13:34:30,514 [scmNode-2-ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(940)) - Replication Monitor Thread is stopped
2025-12-19 13:34:30,512 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-2-RatisPipelineUtilsThread.
2025-12-19 13:34:30,512 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,514 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-099e5e47-f620-4042-9012-1603dfd1d8ca in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,514 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,514 [scmNode-3-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,513 [scmNode-2-UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-2-UnderReplicatedProcessor interrupted. Exiting...
2025-12-19 13:34:30,514 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1637)) - Stopping datanode service RPC server
2025-12-19 13:34:30,514 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(455)) - Stopping the RPC server for DataNodes
2025-12-19 13:34:30,514 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15502
2025-12-19 13:34:30,514 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,514 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,514 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-06657f59-31dc-40a9-89f4-b70a942b69e2 in state CLOSED which uses HEALTHY_READONLY datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-e9c493b0-d510-4c9a-94da-ff0630b18160 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(54)) - Datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1) moved to HEALTHY READONLY state.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-099e5e47-f620-4042-9012-1603dfd1d8ca in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,515 [scmNode-2-EventQueue-HealthyReadonlyNodeForHealthyReadOnlyNodeHandler] INFO  node.HealthyReadOnlyNodeHandler (HealthyReadOnlyNodeHandler.java:onMessage(86)) - Sending close command for pipeline Pipeline-83edabe4-a852-4d54-beae-579d88baa401 in state CLOSED which uses HEALTHY_READONLY datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). This will send close commands for its containers.
2025-12-19 13:34:30,519 [IPC Server listener on 15502] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15502
2025-12-19 13:34:30,519 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:30,526 [scmNode-2-SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(913)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-12-19 13:34:30,526 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1645)) - Stopping block service RPC server
2025-12-19 13:34:30,526 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(175)) - Stopping the RPC server for Block Protocol
2025-12-19 13:34:30,526 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15505
2025-12-19 13:34:30,532 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1652)) - Stopping the StorageContainerLocationProtocol RPC server
2025-12-19 13:34:30,532 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(220)) - Stopping the RPC server for Client Protocol
2025-12-19 13:34:30,532 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15503
2025-12-19 13:34:30,532 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:30,532 [IPC Server listener on 15505] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15505
2025-12-19 13:34:30,537 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1659)) - Stopping Storage Container Manager HTTP server.
2025-12-19 13:34:30,537 [IPC Server listener on 15503] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15503
2025-12-19 13:34:30,537 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@58bf4cf4{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:30,538 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:30,538 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4028cf0{HTTP/1.1, (http/1.1)}{0.0.0.0:15498}
2025-12-19 13:34:30,539 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:34:30,539 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@28ca55a{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-12-19 13:34:30,539 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5a9bbbe8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:34:30,540 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1667)) - Stopping SCM LayoutVersionManager Service.
2025-12-19 13:34:30,540 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1679)) - Stopping Block Manager Service.
2025-12-19 13:34:30,540 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:30,541 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:30,542 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1704)) - Stopping SCM Event Queue.
2025-12-19 13:34:30,542 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping SCM HA services.
2025-12-19 13:34:30,542 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:stop(267)) - stopping ratis server 0.0.0.0:15501
2025-12-19 13:34:30,542 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: close
2025-12-19 13:34:30,543 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: shutdown server GrpcServerProtocolService now
2025-12-19 13:34:30,543 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: shutdown
2025-12-19 13:34:30,544 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:30,544 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: shutdown 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState
2025-12-19 13:34:30,544 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: set stopIndex = 61
2025-12-19 13:34:30,545 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: APPEND_ENTRIES onError, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#158-t2,previous=(t:2, i:61),leaderCommit=61,initializing? false,entries: size=1, first=(t:2, i:62), METADATAENTRY(c:61): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:34:30,545 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:34:30,545 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState was interrupted
2025-12-19 13:34:30,545 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:takeSnapshot(332)) - Current Snapshot Index 61, takeSnapshot took 1 ms
2025-12-19 13:34:30,545 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: Took a snapshot at index 61
2025-12-19 13:34:30,545 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: snapshotIndex: updateIncreasingly 2 -> 61
2025-12-19 13:34:30,545 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:34:30,546 [grpc-default-executor-4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (63) unchanged and retry.
2025-12-19 13:34:30,546 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:2, i:61)
2025-12-19 13:34:30,547 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:34:30,551 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:34:30,577 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:30,687 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15424. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:30,687 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15424-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15424 for past 0 seconds.
java.net.ConnectException: Call From localhost/127.0.0.1 to localhost:15424 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:876)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:639)
	at org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
	at org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
	at org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1435)
	... 12 more
2025-12-19 13:34:30,761 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:30,987 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15502 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "localhost/127.0.0.1"; destination host is: "localhost":15502; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:910)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)
	at org.apache.hadoop.ipc_.Client$IpcStreams.readResponse(Client.java:1873)
	at org.apache.hadoop.ipc_.Client$Connection.receiveRpcResponse(Client.java:1165)
	at org.apache.hadoop.ipc_.Client$Connection.run(Client.java:1056)
2025-12-19 13:34:30,987 [IPC Server handler 10 on default port 15510] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:30,988 [IPC Server handler 13 on default port 15494] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:31,096 [IPC Server handler 11 on default port 15510] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:31,096 [IPC Server handler 0 on default port 15494] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:31,185 [IPC Server handler 12 on default port 15510] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:31,185 [IPC Server handler 1 on default port 15494] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:31,511 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker close()
2025-12-19 13:34:31,511 [JvmPauseMonitor79] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-558504b9-cfec-4766-96f9-7b6ebb0f3b76: Stopped
2025-12-19 13:34:31,512 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(127)) - Stopping SCMHATransactionMonitor Service.
2025-12-19 13:34:31,512 [scmNode-2-SCMHATransactionMonitor] WARN  SCMHATransactionMonitor (BackgroundSCMService.java:run(111)) - SCMHATransactionMonitor is interrupted, exit
2025-12-19 13:34:31,512 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-2-RatisPipelineUtilsThread.
2025-12-19 13:34:31,512 [scmNode-2-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-2-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:34:31,513 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(127)) - Stopping BackgroundPipelineScrubber Service.
2025-12-19 13:34:31,513 [scmNode-2-BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(111)) - BackgroundPipelineScrubber is interrupted, exit
2025-12-19 13:34:31,516 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2025-12-19 13:34:31,516 [ForkJoinPool-6-worker-1] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - scmNode-2-RatisPipelineUtilsThread is not running, just ignore.
2025-12-19 13:34:31,516 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(122)) - BackgroundPipelineScrubber Service is not running, skip stop.
2025-12-19 13:34:31,516 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(127)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:31,516 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:31,516 [scmNode-2-ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(111)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2025-12-19 13:34:31,517 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(326)) - Replication Monitor Thread is not running.
2025-12-19 13:34:31,517 [ForkJoinPool-6-worker-1] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(362)) - Cannot stop Container Balancer because it's not running or stopping
2025-12-19 13:34:31,517 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(122)) - SCMHATransactionMonitor Service is not running, skip stop.
2025-12-19 13:34:31,517 [scmNode-2-LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(285)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1167)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:283)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:34:31,517 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1745)) - Stopping SCM MetadataStore.
2025-12-19 13:34:31,526 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:31,526 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:31,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:31,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:31,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:31,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:31,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:31,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:31,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-2, RPC Address: localhost:15501 and Ratis port: 15501
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-2: 0.0.0.0:15502
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-2: 0.0.0.0:15505
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-2: 0.0.0.0:15503
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-2: 127.0.0.1:15500
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-2: 15501
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-2: 15504
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-2: 127.0.0.1:15498
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-2: 127.0.0.1:15499
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-2: 127.0.0.1
2025-12-19 13:34:31,528 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:31,529 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:31,529 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:31,529 [ForkJoinPool-6-worker-1] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:31,529 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:31,550 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.2.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-12-19 13:34:31,551 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-12-19 13:34:31,566 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:<init>(101)) - starting Raft server for scm:558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:31,566 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:31,567 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.appender.buffer.byte-limit = 4194304 (default)
2025-12-19 13:34:31,567 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:31,567 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:31,567 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.port = 15501 (fallback to raft.grpc.server.port)
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.port = 15501 (fallback to raft.grpc.server.port)
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15501 (custom)
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (ConfUtils.java:logGet(62)) - raft.grpc.message.size.max = 5242880 (custom)
2025-12-19 13:34:31,568 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (ConfUtils.java:logGet(62)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-12-19 13:34:31,569 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-19 13:34:31,569 [ForkJoinPool-6-worker-1] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(62)) - raft.datastream.type = DISABLED (default)
2025-12-19 13:34:31,570 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis] (custom)
2025-12-19 13:34:31,570 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(273)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:31,570 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: addNew group-3149B70783DC:[] returns group-3149B70783DC:java.util.concurrent.CompletableFuture@68c2a111[Not completed]
2025-12-19 13:34:31,570 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-groupManagement] INFO  ha.SCMStateMachine (SCMStateMachine.java:<init>(100)) - Updated lastAppliedTermIndex 2#61 with transactionInfo term andIndex
2025-12-19 13:34:31,571 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: new RaftServerImpl for group-3149B70783DC:[] with SCMStateMachine-187:uninitialized
2025-12-19 13:34:31,571 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-19 13:34:31,571 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:31,571 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.notification.no-leader.timeout = 60s (default)
2025-12-19 13:34:31,571 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.retrycache.expirytime = 60000ms (default)
2025-12-19 13:34:31,573 [ForkJoinPool-6-worker-1] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:<init>(61)) - Initializing SCM Snapshot Provider
2025-12-19 13:34:31,573 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:31,573 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisSnapshotDirectory(415)) - Snapshot directory for Ratis is not configured. Falling back to ozone.metadata.dirs
2025-12-19 13:34:31,574 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = STORAGE_SPACE_DISTRIBUTION (version = 10), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:31,575 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-12-19 13:34:31,575 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:31,575 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:31,576 [ForkJoinPool-6-worker-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(185)) - Entering startup safe mode.
2025-12-19 13:34:31,576 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-12-19 13:34:31,576 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:31,577 [ForkJoinPool-6-worker-1] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(55)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-19 13:34:31,577 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:31,578 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2025-12-19 13:34:31,578 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-2-RatisPipelineUtilsThread.
2025-12-19 13:34:31,578 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:31,578 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(64)) - Starting BackgroundPipelineScrubber Service.
2025-12-19 13:34:31,578 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2025-12-19 13:34:31,579 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(64)) - Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:31,579 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2025-12-19 13:34:31,579 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:31,580 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:31,580 [ForkJoinPool-6-worker-1] INFO  block.SCMDeletedBlockTransactionStatusManager (SCMDeletedBlockTransactionStatusManager.java:loadDeletedBlocksSummary(686)) - Property DeletedBlocksTransactionSummary for service DeletedBlockLogStateManager not found. 
2025-12-19 13:34:31,580 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2025-12-19 13:34:31,581 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:start(288)) - Starting Replication Monitor Thread.
2025-12-19 13:34:31,581 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2025-12-19 13:34:31,582 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed RATIS Containers threshold count to 0.
2025-12-19 13:34:31,582 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed EC Containers threshold count to 0.
2025-12-19 13:34:31,582 [ForkJoinPool-6-worker-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(231)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:31,582 [ForkJoinPool-6-worker-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(190)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-19 13:34:31,582 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(433)) - SCM start with adminUsers: [admin, runner]
2025-12-19 13:34:31,583 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:31,583 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15502
2025-12-19 13:34:31,583 [Socket Reader #1 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15502
2025-12-19 13:34:31,583 [Socket Reader #2 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15502
2025-12-19 13:34:31,584 [Socket Reader #3 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15502
2025-12-19 13:34:31,584 [Socket Reader #4 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15502
2025-12-19 13:34:31,584 [Socket Reader #5 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15502
2025-12-19 13:34:31,584 [Socket Reader #6 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15502
2025-12-19 13:34:31,584 [Socket Reader #7 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15502
2025-12-19 13:34:31,584 [Socket Reader #8 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15502
2025-12-19 13:34:31,584 [Socket Reader #9 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15502
2025-12-19 13:34:31,585 [Socket Reader #10 for port 15502] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15502
2025-12-19 13:34:31,585 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:31,585 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15505
2025-12-19 13:34:31,586 [Socket Reader #1 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15505
2025-12-19 13:34:31,586 [Socket Reader #2 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15505
2025-12-19 13:34:31,586 [Socket Reader #3 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15505
2025-12-19 13:34:31,586 [Socket Reader #4 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15505
2025-12-19 13:34:31,586 [Socket Reader #5 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15505
2025-12-19 13:34:31,586 [Socket Reader #6 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15505
2025-12-19 13:34:31,586 [Socket Reader #7 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15505
2025-12-19 13:34:31,587 [Socket Reader #8 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15505
2025-12-19 13:34:31,587 [Socket Reader #9 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15505
2025-12-19 13:34:31,587 [Socket Reader #10 for port 15505] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15505
2025-12-19 13:34:31,587 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:31,587 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15503
2025-12-19 13:34:31,588 [Socket Reader #1 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15503
2025-12-19 13:34:31,588 [Socket Reader #2 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15503
2025-12-19 13:34:31,588 [Socket Reader #3 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15503
2025-12-19 13:34:31,588 [Socket Reader #4 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15503
2025-12-19 13:34:31,588 [Socket Reader #5 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15503
2025-12-19 13:34:31,588 [Socket Reader #6 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15503
2025-12-19 13:34:31,589 [Socket Reader #7 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15503
2025-12-19 13:34:31,589 [Socket Reader #8 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15503
2025-12-19 13:34:31,589 [Socket Reader #9 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15503
2025-12-19 13:34:31,589 [Socket Reader #10 for port 15503] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15503
2025-12-19 13:34:31,592 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2025-12-19 13:34:31,592 [ForkJoinPool-6-worker-1] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-19 13:34:31,592 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1522)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15503
2025-12-19 13:34:31,592 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:start(204)) - starting ratis server 0.0.0.0:15501
2025-12-19 13:34:31,593 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:31,594 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:analyzeAndRecoverStorage(118)) - Read RaftStorageMetadata{term=2, votedFor=} from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/raft-meta
2025-12-19 13:34:31,594 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:31,594 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: initialize group-3149B70783DC
2025-12-19 13:34:31,594 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-187:558504b9-cfec-4766-96f9-7b6ebb0f3b76:group-3149B70783DC) returns 2#61
2025-12-19 13:34:31,594 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog: snapshotIndexFromStateMachine = 61
2025-12-19 13:34:31,596 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23416,558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:31,596 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:31,596 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-12-19 13:34:31,596 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.queue.element-limit = 4096 (default)
2025-12-19 13:34:31,596 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-12-19 13:34:31,596 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.write.buffer.size = 4194312 (custom)
2025-12-19 13:34:31,596 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2025-12-19 13:34:31,597 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 3, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:31,597 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:31,597 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 7, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:31,597 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(171)) - Successfully read 60 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_3
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 62
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_3 (append) at position 8704
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:lambda$new$0(54)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog: purgeIndex: updateToMax old=-1, new=2, updated? true
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: start as a follower, conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: changes role from      null to FOLLOWER at term 2 for startAsFollower
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: start 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState
2025-12-19 13:34:31,598 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.first-election.timeout.min = 5000ms (custom)
2025-12-19 13:34:31,599 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.rpc.first-election.timeout.max = 5200ms (custom)
2025-12-19 13:34:31,599 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:31,599 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3149B70783DC,id=558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:34:31,599 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-12-19 13:34:31,599 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.snapshot.retention.file.num = -1 (default)
2025-12-19 13:34:31,599 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: Successfully started.
2025-12-19 13:34:31,599 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: start RPC server
2025-12-19 13:34:31,600 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: GrpcServicesImpl started, listening on 15501
2025-12-19 13:34:31,601 [ForkJoinPool-6-worker-1] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:start(131)) -  scm role is FOLLOWER peers [558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]
2025-12-19 13:34:31,601 [ForkJoinPool-6-worker-1] INFO  ha.InterSCMGrpcService (InterSCMGrpcProtocolService.java:start(98)) - Starting SCM Grpc Service at port 15504
2025-12-19 13:34:31,601 [JvmPauseMonitor85] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-558504b9-cfec-4766-96f9-7b6ebb0f3b76: Started
2025-12-19 13:34:31,601 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(64)) - Starting SCMHATransactionMonitor Service.
2025-12-19 13:34:31,602 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMHATransactionMonitor.
2025-12-19 13:34:31,602 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(61)) - SCMHATransactionMonitor Service is already running, skip start.
2025-12-19 13:34:31,614 [ForkJoinPool-6-worker-1] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2025-12-19 13:34:31,653 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(211)) - RPC server for Client  is listening at /0.0.0.0:15503
2025-12-19 13:34:31,654 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:31,654 [IPC Server listener on 15503] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15503: starting
2025-12-19 13:34:31,663 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1535)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15505
2025-12-19 13:34:31,664 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(166)) - RPC server for Block Protocol is listening at /0.0.0.0:15505
2025-12-19 13:34:31,664 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:31,664 [IPC Server listener on 15505] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15505: starting
2025-12-19 13:34:31,674 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(195)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15502
2025-12-19 13:34:31,675 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:31,675 [IPC Server listener on 15502] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15502: starting
2025-12-19 13:34:31,686 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SCMBlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:31,686 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for scm at: http://0.0.0.0:15498
2025-12-19 13:34:31,687 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:31,687 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:31,689 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:31,690 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2025-12-19 13:34:31,690 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:31,690 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:31,690 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/webserver
2025-12-19 13:34:31,691 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15498
2025-12-19 13:34:31,691 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:31,692 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:31,692 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:31,692 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2025-12-19 13:34:31,693 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@730d0914{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:31,693 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@17f1e008{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-12-19 13:34:31,698 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5cefe85c{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:31,698 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@41b04bc3{HTTP/1.1, (http/1.1)}{0.0.0.0:15498}
2025-12-19 13:34:31,698 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @857886ms
2025-12-19 13:34:31,698 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:31,698 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of scm listening at http://localhost:15498
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:restartStorageContainerManager(260)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneHAClusterImpl
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:shutdownStorageContainerManager(250)) - Shutting down StorageContainerManager 6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1621)) - Container Balancer is not running.
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1754)) - Stopping Replication Manager Service.
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(319)) - Stopping Replication Monitor Thread.
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1630)) - Stopping the Datanode Admin Monitor.
2025-12-19 13:34:31,699 [scmNode-3-OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-3-OverReplicatedProcessor interrupted. Exiting...
2025-12-19 13:34:31,699 [scmNode-3-ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(940)) - Replication Monitor Thread is stopped
2025-12-19 13:34:31,699 [scmNode-3-UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-3-UnderReplicatedProcessor interrupted. Exiting...
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1637)) - Stopping datanode service RPC server
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(455)) - Stopping the RPC server for DataNodes
2025-12-19 13:34:31,699 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15510
2025-12-19 13:34:31,704 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:31,704 [IPC Server listener on 15510] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15510
2025-12-19 13:34:31,761 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:31,768 [scmNode-3-SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(913)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-12-19 13:34:31,768 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1645)) - Stopping block service RPC server
2025-12-19 13:34:31,768 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(175)) - Stopping the RPC server for Block Protocol
2025-12-19 13:34:31,768 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15513
2025-12-19 13:34:31,771 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1652)) - Stopping the StorageContainerLocationProtocol RPC server
2025-12-19 13:34:31,771 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(220)) - Stopping the RPC server for Client Protocol
2025-12-19 13:34:31,771 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:31,772 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15511
2025-12-19 13:34:31,771 [IPC Server listener on 15513] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15513
2025-12-19 13:34:31,776 [IPC Server listener on 15511] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15511
2025-12-19 13:34:31,776 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1659)) - Stopping Storage Container Manager HTTP server.
2025-12-19 13:34:31,776 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:31,777 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@774a16b2{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:31,778 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@b158f39{HTTP/1.1, (http/1.1)}{0.0.0.0:15506}
2025-12-19 13:34:31,778 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:34:31,779 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@88d2769{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-12-19 13:34:31,779 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@fffefd{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:34:31,780 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1667)) - Stopping SCM LayoutVersionManager Service.
2025-12-19 13:34:31,780 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1679)) - Stopping Block Manager Service.
2025-12-19 13:34:31,781 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:31,781 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:31,782 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1704)) - Stopping SCM Event Queue.
2025-12-19 13:34:31,783 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping SCM HA services.
2025-12-19 13:34:31,783 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:stop(267)) - stopping ratis server 0.0.0.0:15509
2025-12-19 13:34:31,783 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 6a054400-8896-4262-aa80-3995e76ba098: close
2025-12-19 13:34:31,784 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown server GrpcServerProtocolService now
2025-12-19 13:34:31,784 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: shutdown
2025-12-19 13:34:31,784 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:31,784 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState
2025-12-19 13:34:31,784 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: set stopIndex = 61
2025-12-19 13:34:31,784 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState was interrupted
2025-12-19 13:34:31,785 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:takeSnapshot(332)) - Current Snapshot Index 61, takeSnapshot took 1 ms
2025-12-19 13:34:31,785 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: Took a snapshot at index 61
2025-12-19 13:34:31,785 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: snapshotIndex: updateIncreasingly 6 -> 61
2025-12-19 13:34:31,785 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:2, i:61)
2025-12-19 13:34:31,786 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - 6a054400-8896-4262-aa80-3995e76ba098: APPEND_ENTRIES onError, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#147-t2,previous=(t:2, i:61),leaderCommit=61,initializing? false,entries: size=1, first=(t:2, i:62), METADATAENTRY(c:61): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:34:31,786 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:34:31,786 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - 6a054400-8896-4262-aa80-3995e76ba098: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:34:31,786 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:34:31,786 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (63) unchanged and retry.
2025-12-19 13:34:31,791 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:34:31,985 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(68)) - Processing FinalizeNewLayoutVersionCommandHandler command.
2025-12-19 13:34:31,985 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(81)) - Finalize Upgrade called!
2025-12-19 13:34:31,985 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - Finalization started.
2025-12-19 13:34:31,986 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V2
2025-12-19 13:34:31,986 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV2FinalizeAction (DatanodeSchemaV2FinalizeAction.java:execute(43)) - Executing datanode 'onFinalize' action for the first version with upgrade support. New containers will be created with Schema Version 2 henceforth.
2025-12-19 13:34:31,986 [IPC Server handler 12 on default port 15494] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:31,986 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15510 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "localhost/127.0.0.1"; destination host is: "localhost":15510; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:910)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)
	at org.apache.hadoop.ipc_.Client$IpcStreams.readResponse(Client.java:1873)
	at org.apache.hadoop.ipc_.Client$Connection.receiveRpcResponse(Client.java:1165)
	at org.apache.hadoop.ipc_.Client$Connection.run(Client.java:1056)
2025-12-19 13:34:31,987 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V2 has been finalized.
2025-12-19 13:34:31,987 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: SCM_HA
2025-12-19 13:34:31,987 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.ScmHAFinalizeUpgradeActionDatanode (ScmHAFinalizeUpgradeActionDatanode.java:execute(50)) - Upgrading Datanode volume layout for SCM HA support.
2025-12-19 13:34:31,988 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.ScmHAFinalizeUpgradeActionDatanode (ScmHAFinalizeUpgradeActionDatanode.java:upgradeVolume(108)) - Volume already contains cluster ID directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc. No action required for SCM HA finalization.
2025-12-19 13:34:31,988 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature SCM_HA has been finalized.
2025-12-19 13:34:31,988 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
2025-12-19 13:34:31,989 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
2025-12-19 13:34:31,989 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V3
2025-12-19 13:34:31,989 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV3FinalizeAction (DatanodeSchemaV3FinalizeAction.java:execute(49)) - Upgrading Datanode volume layout for Schema V3 support.
2025-12-19 13:34:32,019 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-66019413-eed9-4305-abd0-b794a6497ecc/container.db to cache
2025-12-19 13:34:32,019 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(602)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-66019413-eed9-4305-abd0-b794a6497ecc/container.db for volume DS-66019413-eed9-4305-abd0-b794a6497ecc
2025-12-19 13:34:32,019 [ForkJoinPool.commonPool-worker-3] WARN  volume.HddsVolume (HddsVolume.java:loadDbStore(492)) - Schema V3 db is already loaded from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-66019413-eed9-4305-abd0-b794a6497ecc for volume DS-66019413-eed9-4305-abd0-b794a6497ecc
2025-12-19 13:34:32,020 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV3FinalizeAction (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-12-19 13:34:32,021 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V3 has been finalized.
2025-12-19 13:34:32,021 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS.
2025-12-19 13:34:32,022 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:32,022 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WEBUI_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:32,023 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WEBUI_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:32,023 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HADOOP_PRC_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:32,023 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HADOOP_PRC_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:32,023 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HBASE_SUPPORT.
2025-12-19 13:34:32,024 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HBASE_SUPPORT has been finalized.
2025-12-19 13:34:32,024 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: WITNESSED_CONTAINER_DB_PROTO_VALUE
2025-12-19 13:34:32,025 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.ContainerTableSchemaFinalizeAction (ContainerTableSchemaFinalizeAction.java:execute(71)) - Finished copy to containerIdsTable from previous table
2025-12-19 13:34:32,026 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WITNESSED_CONTAINER_DB_PROTO_VALUE has been finalized.
2025-12-19 13:34:32,026 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: STORAGE_SPACE_DISTRIBUTION.
2025-12-19 13:34:32,026 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature STORAGE_SPACE_DISTRIBUTION has been finalized.
2025-12-19 13:34:32,026 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(126)) - Finalization is complete.
2025-12-19 13:34:32,026 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - Finalization is done.
2025-12-19 13:34:32,096 [57412301-a084-4aa6-8e22-91ecff01c376-DatanodeStateMachineDaemonThread] WARN  datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(194)) - Detected timeout: Timeout occurred on endpoint: localhost/127.0.0.1:15502
2025-12-19 13:34:32,096 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15502. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:32,097 [IPC Server handler 0 on default port 15494] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:32,097 [IPC Server handler 0 on default port 15502] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:32,097 [IPC Server handler 2 on default port 15502] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:32,097 [IPC Server handler 1 on default port 15502] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:32,098 [IPC Server handler 3 on default port 15502] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:32,099 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:32,099 [IPC Server handler 2 on default port 15494] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 0, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:32,100 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:32,133 [scmNode-1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(46)) - Datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1) moved to HEALTHY state.
2025-12-19 13:34:32,133 [scmNode-1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(290)) - trigger a one-shot run on scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:32,134 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(208)) - Sending CreatePipelineCommand for pipeline:Pipeline-03820fd6-9aec-4969-af0e-4128bda6f024 to datanode:b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1)
2025-12-19 13:34:32,137 [grpc-default-executor-0] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Follower failed (request=null, errorCount=3); keep nextIndex (64) unchanged and retry.
2025-12-19 13:34:32,138 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set firstElectionSinceStartup to false for APPEND_ENTRIES
2025-12-19 13:34:32,138 [grpc-default-executor-0] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(289)) - leader changed, yet current SCM is still follower.
2025-12-19 13:34:32,138 [grpc-default-executor-0] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: change Leader from null to 50ee075d-c1e7-43b2-938b-a7dc0bd7923f at term 2 for APPEND_ENTRIES, leader elected after 566ms
2025-12-19 13:34:32,145 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:32,145 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:32,145 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:32,145 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:32,146 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:32,146 [scmNode-1-RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(246)) - Created new pipeline Pipeline{ Id: 03820fd6-9aec-4969-af0e-4128bda6f024, Nodes: [ {b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-19T13:34:32.134257839Z[Etc/UTC]}
2025-12-19 13:34:32,147 [grpc-default-executor-0] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Follower failed (request=null, errorCount=5); keep nextIndex (65) unchanged and retry.
2025-12-19 13:34:32,148 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:32,148 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:32,148 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:32,148 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:32,148 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:32,185 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(68)) - Processing FinalizeNewLayoutVersionCommandHandler command.
2025-12-19 13:34:32,185 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(81)) - Finalize Upgrade called!
2025-12-19 13:34:32,185 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - Finalization started.
2025-12-19 13:34:32,185 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V2
2025-12-19 13:34:32,185 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV2FinalizeAction (DatanodeSchemaV2FinalizeAction.java:execute(43)) - Executing datanode 'onFinalize' action for the first version with upgrade support. New containers will be created with Schema Version 2 henceforth.
2025-12-19 13:34:32,187 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V2 has been finalized.
2025-12-19 13:34:32,187 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: SCM_HA
2025-12-19 13:34:32,187 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.ScmHAFinalizeUpgradeActionDatanode (ScmHAFinalizeUpgradeActionDatanode.java:execute(50)) - Upgrading Datanode volume layout for SCM HA support.
2025-12-19 13:34:32,187 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.ScmHAFinalizeUpgradeActionDatanode (ScmHAFinalizeUpgradeActionDatanode.java:upgradeVolume(108)) - Volume already contains cluster ID directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc. No action required for SCM HA finalization.
2025-12-19 13:34:32,188 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature SCM_HA has been finalized.
2025-12-19 13:34:32,188 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
2025-12-19 13:34:32,189 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
2025-12-19 13:34:32,189 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V3
2025-12-19 13:34:32,189 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV3FinalizeAction (DatanodeSchemaV3FinalizeAction.java:execute(49)) - Upgrading Datanode volume layout for Schema V3 support.
2025-12-19 13:34:32,216 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d/container.db to cache
2025-12-19 13:34:32,216 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(602)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d/container.db for volume DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d
2025-12-19 13:34:32,216 [ForkJoinPool.commonPool-worker-3] WARN  volume.HddsVolume (HddsVolume.java:loadDbStore(492)) - Schema V3 db is already loaded from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d for volume DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d
2025-12-19 13:34:32,216 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV3FinalizeAction (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-12-19 13:34:32,217 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V3 has been finalized.
2025-12-19 13:34:32,217 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS.
2025-12-19 13:34:32,218 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:32,218 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WEBUI_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:32,219 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WEBUI_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:32,219 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HADOOP_PRC_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:32,220 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HADOOP_PRC_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:32,220 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HBASE_SUPPORT.
2025-12-19 13:34:32,221 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HBASE_SUPPORT has been finalized.
2025-12-19 13:34:32,221 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: WITNESSED_CONTAINER_DB_PROTO_VALUE
2025-12-19 13:34:32,221 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.ContainerTableSchemaFinalizeAction (ContainerTableSchemaFinalizeAction.java:execute(71)) - Finished copy to containerIdsTable from previous table
2025-12-19 13:34:32,222 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WITNESSED_CONTAINER_DB_PROTO_VALUE has been finalized.
2025-12-19 13:34:32,222 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: STORAGE_SPACE_DISTRIBUTION.
2025-12-19 13:34:32,223 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature STORAGE_SPACE_DISTRIBUTION has been finalized.
2025-12-19 13:34:32,223 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(126)) - Finalization is complete.
2025-12-19 13:34:32,223 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - Finalization is done.
2025-12-19 13:34:32,223 [9f85a268-b54d-42c0-89e3-0f143f429527-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(68)) - Processing FinalizeNewLayoutVersionCommandHandler command.
2025-12-19 13:34:32,511 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker close()
2025-12-19 13:34:32,511 [JvmPauseMonitor80] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-6a054400-8896-4262-aa80-3995e76ba098: Stopped
2025-12-19 13:34:32,512 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(127)) - Stopping SCMHATransactionMonitor Service.
2025-12-19 13:34:32,512 [scmNode-3-SCMHATransactionMonitor] WARN  SCMHATransactionMonitor (BackgroundSCMService.java:run(111)) - SCMHATransactionMonitor is interrupted, exit
2025-12-19 13:34:32,512 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-3-RatisPipelineUtilsThread.
2025-12-19 13:34:32,513 [scmNode-3-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-3-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:34:32,513 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(127)) - Stopping BackgroundPipelineScrubber Service.
2025-12-19 13:34:32,513 [scmNode-3-BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(111)) - BackgroundPipelineScrubber is interrupted, exit
2025-12-19 13:34:32,517 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2025-12-19 13:34:32,517 [ForkJoinPool-6-worker-1] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - scmNode-3-RatisPipelineUtilsThread is not running, just ignore.
2025-12-19 13:34:32,517 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(122)) - BackgroundPipelineScrubber Service is not running, skip stop.
2025-12-19 13:34:32,517 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(127)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:32,517 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:32,518 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(326)) - Replication Monitor Thread is not running.
2025-12-19 13:34:32,518 [ForkJoinPool-6-worker-1] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(362)) - Cannot stop Container Balancer because it's not running or stopping
2025-12-19 13:34:32,518 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(122)) - SCMHATransactionMonitor Service is not running, skip stop.
2025-12-19 13:34:32,518 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1745)) - Stopping SCM MetadataStore.
2025-12-19 13:34:32,518 [scmNode-3-LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(285)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1167)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:283)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:34:32,519 [scmNode-3-ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(111)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2025-12-19 13:34:32,526 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:32,526 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:32,526 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:32,526 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:32,526 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:32,526 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-3, RPC Address: localhost:15509 and Ratis port: 15509
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-3: 0.0.0.0:15510
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-3: 0.0.0.0:15513
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-3: 0.0.0.0:15511
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-3: 127.0.0.1:15508
2025-12-19 13:34:32,527 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-3: 15509
2025-12-19 13:34:32,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-3: 15512
2025-12-19 13:34:32,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-3: 127.0.0.1:15506
2025-12-19 13:34:32,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-3: 127.0.0.1:15507
2025-12-19 13:34:32,528 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-3: 127.0.0.1
2025-12-19 13:34:32,528 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:32,528 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:32,528 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:32,528 [ForkJoinPool-6-worker-1] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:32,529 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:32,552 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.2.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-12-19 13:34:32,552 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-12-19 13:34:32,568 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:<init>(101)) - starting Raft server for scm:6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:32,569 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:32,570 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:32,570 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:32,570 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:32,570 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:32,570 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:32,570 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:32,570 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:32,570 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.port = 15509 (fallback to raft.grpc.server.port)
2025-12-19 13:34:32,571 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:32,571 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.port = 15509 (fallback to raft.grpc.server.port)
2025-12-19 13:34:32,571 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15509 (custom)
2025-12-19 13:34:32,572 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis] (custom)
2025-12-19 13:34:32,572 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(273)) - 6a054400-8896-4262-aa80-3995e76ba098: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:32,573 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 6a054400-8896-4262-aa80-3995e76ba098: addNew group-3149B70783DC:[] returns group-3149B70783DC:java.util.concurrent.CompletableFuture@2bc07754[Not completed]
2025-12-19 13:34:32,573 [6a054400-8896-4262-aa80-3995e76ba098-groupManagement] INFO  ha.SCMStateMachine (SCMStateMachine.java:<init>(100)) - Updated lastAppliedTermIndex 2#61 with transactionInfo term andIndex
2025-12-19 13:34:32,573 [6a054400-8896-4262-aa80-3995e76ba098-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 6a054400-8896-4262-aa80-3995e76ba098: new RaftServerImpl for group-3149B70783DC:[] with SCMStateMachine-188:uninitialized
2025-12-19 13:34:32,573 [6a054400-8896-4262-aa80-3995e76ba098-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:32,575 [ForkJoinPool-6-worker-1] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:<init>(61)) - Initializing SCM Snapshot Provider
2025-12-19 13:34:32,575 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:32,575 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisSnapshotDirectory(415)) - Snapshot directory for Ratis is not configured. Falling back to ozone.metadata.dirs
2025-12-19 13:34:32,576 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = STORAGE_SPACE_DISTRIBUTION (version = 10), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:32,577 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-12-19 13:34:32,578 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:32,578 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:32,578 [ForkJoinPool-6-worker-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(185)) - Entering startup safe mode.
2025-12-19 13:34:32,578 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-12-19 13:34:32,578 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:32,578 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:32,580 [ForkJoinPool-6-worker-1] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(55)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-19 13:34:32,580 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:32,580 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2025-12-19 13:34:32,580 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-3-RatisPipelineUtilsThread.
2025-12-19 13:34:32,580 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(64)) - Starting BackgroundPipelineScrubber Service.
2025-12-19 13:34:32,581 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2025-12-19 13:34:32,581 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(64)) - Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:32,581 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2025-12-19 13:34:32,582 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:32,582 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:32,582 [ForkJoinPool-6-worker-1] INFO  block.SCMDeletedBlockTransactionStatusManager (SCMDeletedBlockTransactionStatusManager.java:loadDeletedBlocksSummary(686)) - Property DeletedBlocksTransactionSummary for service DeletedBlockLogStateManager not found. 
2025-12-19 13:34:32,583 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2025-12-19 13:34:32,583 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:start(288)) - Starting Replication Monitor Thread.
2025-12-19 13:34:32,583 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2025-12-19 13:34:32,584 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed RATIS Containers threshold count to 0.
2025-12-19 13:34:32,584 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed EC Containers threshold count to 0.
2025-12-19 13:34:32,584 [ForkJoinPool-6-worker-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(231)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:32,584 [ForkJoinPool-6-worker-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(190)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-19 13:34:32,585 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(433)) - SCM start with adminUsers: [admin, runner]
2025-12-19 13:34:32,585 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:32,585 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15510
2025-12-19 13:34:32,585 [Socket Reader #1 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15510
2025-12-19 13:34:32,586 [Socket Reader #2 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15510
2025-12-19 13:34:32,586 [Socket Reader #3 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15510
2025-12-19 13:34:32,586 [Socket Reader #4 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15510
2025-12-19 13:34:32,586 [Socket Reader #5 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15510
2025-12-19 13:34:32,586 [Socket Reader #6 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15510
2025-12-19 13:34:32,586 [Socket Reader #7 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15510
2025-12-19 13:34:32,587 [Socket Reader #8 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15510
2025-12-19 13:34:32,587 [Socket Reader #9 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15510
2025-12-19 13:34:32,587 [Socket Reader #10 for port 15510] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15510
2025-12-19 13:34:32,587 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:32,588 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15513
2025-12-19 13:34:32,588 [Socket Reader #1 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15513
2025-12-19 13:34:32,588 [Socket Reader #2 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15513
2025-12-19 13:34:32,588 [Socket Reader #3 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15513
2025-12-19 13:34:32,588 [Socket Reader #4 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15513
2025-12-19 13:34:32,589 [Socket Reader #5 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15513
2025-12-19 13:34:32,589 [Socket Reader #6 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15513
2025-12-19 13:34:32,589 [Socket Reader #7 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15513
2025-12-19 13:34:32,589 [Socket Reader #8 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15513
2025-12-19 13:34:32,589 [Socket Reader #9 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15513
2025-12-19 13:34:32,589 [Socket Reader #10 for port 15513] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15513
2025-12-19 13:34:32,590 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:32,590 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15511
2025-12-19 13:34:32,590 [Socket Reader #1 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15511
2025-12-19 13:34:32,591 [Socket Reader #2 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15511
2025-12-19 13:34:32,591 [Socket Reader #3 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15511
2025-12-19 13:34:32,591 [Socket Reader #4 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15511
2025-12-19 13:34:32,591 [Socket Reader #5 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15511
2025-12-19 13:34:32,591 [Socket Reader #6 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15511
2025-12-19 13:34:32,591 [Socket Reader #7 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15511
2025-12-19 13:34:32,591 [Socket Reader #8 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15511
2025-12-19 13:34:32,592 [Socket Reader #9 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15511
2025-12-19 13:34:32,592 [Socket Reader #10 for port 15511] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15511
2025-12-19 13:34:32,595 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2025-12-19 13:34:32,595 [ForkJoinPool-6-worker-1] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-19 13:34:32,595 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1522)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15511
2025-12-19 13:34:32,596 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:start(204)) - starting ratis server 0.0.0.0:15509
2025-12-19 13:34:32,597 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:32,597 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:analyzeAndRecoverStorage(118)) - Read RaftStorageMetadata{term=2, votedFor=} from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/raft-meta
2025-12-19 13:34:32,597 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:32,597 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 6a054400-8896-4262-aa80-3995e76ba098: initialize group-3149B70783DC
2025-12-19 13:34:32,597 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-188:6a054400-8896-4262-aa80-3995e76ba098:group-3149B70783DC) returns 2#61
2025-12-19 13:34:32,597 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLog: snapshotIndexFromStateMachine = 61
2025-12-19 13:34:32,599 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#23802,6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:32,599 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:32,600 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 7, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:32,600 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:32,600 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(171)) - Successfully read 56 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_7
2025-12-19 13:34:32,600 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 62
2025-12-19 13:34:32,600 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-19 13:34:32,600 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_7 (append) at position 8359
2025-12-19 13:34:32,602 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:lambda$new$0(54)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLog: purgeIndex: updateToMax old=-1, new=6, updated? true
2025-12-19 13:34:32,602 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: start as a follower, conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:32,602 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: changes role from      null to FOLLOWER at term 2 for startAsFollower
2025-12-19 13:34:32,602 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 6a054400-8896-4262-aa80-3995e76ba098: start 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState
2025-12-19 13:34:32,603 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:32,603 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3149B70783DC,id=6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:34:32,603 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Successfully started.
2025-12-19 13:34:32,603 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 6a054400-8896-4262-aa80-3995e76ba098: start RPC server
2025-12-19 13:34:32,604 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 6a054400-8896-4262-aa80-3995e76ba098: GrpcServicesImpl started, listening on 15509
2025-12-19 13:34:32,604 [ForkJoinPool-6-worker-1] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:start(131)) -  scm role is FOLLOWER peers [558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]
2025-12-19 13:34:32,604 [JvmPauseMonitor86] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-6a054400-8896-4262-aa80-3995e76ba098: Started
2025-12-19 13:34:32,605 [ForkJoinPool-6-worker-1] INFO  ha.InterSCMGrpcService (InterSCMGrpcProtocolService.java:start(98)) - Starting SCM Grpc Service at port 15512
2025-12-19 13:34:32,605 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(64)) - Starting SCMHATransactionMonitor Service.
2025-12-19 13:34:32,605 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMHATransactionMonitor.
2025-12-19 13:34:32,605 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(61)) - SCMHATransactionMonitor Service is already running, skip start.
2025-12-19 13:34:32,625 [ForkJoinPool-6-worker-1] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2025-12-19 13:34:32,683 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(211)) - RPC server for Client  is listening at /0.0.0.0:15511
2025-12-19 13:34:32,683 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:32,683 [IPC Server listener on 15511] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15511: starting
2025-12-19 13:34:32,696 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1535)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15513
2025-12-19 13:34:32,696 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(166)) - RPC server for Block Protocol is listening at /0.0.0.0:15513
2025-12-19 13:34:32,696 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:32,697 [IPC Server listener on 15513] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15513: starting
2025-12-19 13:34:32,709 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(195)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15510
2025-12-19 13:34:32,710 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:32,710 [IPC Server listener on 15510] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15510: starting
2025-12-19 13:34:32,722 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SCMBlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:32,723 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for scm at: http://0.0.0.0:15506
2025-12-19 13:34:32,723 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:32,724 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:32,727 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:32,728 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2025-12-19 13:34:32,728 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:32,728 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:32,729 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/webserver
2025-12-19 13:34:32,729 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15506
2025-12-19 13:34:32,729 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:32,730 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:32,731 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:32,731 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-12-19 13:34:32,731 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1aaa059d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:32,732 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1836ac04{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-12-19 13:34:32,736 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@34cc9b51{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2414bc13{HTTP/1.1, (http/1.1)}{0.0.0.0:15506}
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @858925ms
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of scm listening at http://localhost:15506
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:restartStorageContainerManager(260)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneHAClusterImpl
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:shutdownStorageContainerManager(250)) - Shutting down StorageContainerManager 50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1621)) - Container Balancer is not running.
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1754)) - Stopping Replication Manager Service.
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(319)) - Stopping Replication Monitor Thread.
2025-12-19 13:34:32,737 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1630)) - Stopping the Datanode Admin Monitor.
2025-12-19 13:34:32,738 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1637)) - Stopping datanode service RPC server
2025-12-19 13:34:32,738 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(455)) - Stopping the RPC server for DataNodes
2025-12-19 13:34:32,738 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15494
2025-12-19 13:34:32,738 [scmNode-1-OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-1-OverReplicatedProcessor interrupted. Exiting...
2025-12-19 13:34:32,738 [scmNode-1-UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-1-UnderReplicatedProcessor interrupted. Exiting...
2025-12-19 13:34:32,738 [scmNode-1-ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(940)) - Replication Monitor Thread is stopped
2025-12-19 13:34:32,743 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:32,743 [IPC Server listener on 15494] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15494
2025-12-19 13:34:32,747 [scmNode-1-SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(913)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-12-19 13:34:32,748 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1645)) - Stopping block service RPC server
2025-12-19 13:34:32,748 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(175)) - Stopping the RPC server for Block Protocol
2025-12-19 13:34:32,748 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15497
2025-12-19 13:34:32,753 [IPC Server listener on 15497] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15497
2025-12-19 13:34:32,753 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:32,753 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1652)) - Stopping the StorageContainerLocationProtocol RPC server
2025-12-19 13:34:32,753 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(220)) - Stopping the RPC server for Client Protocol
2025-12-19 13:34:32,753 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15495
2025-12-19 13:34:32,760 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:34:32,760 [IPC Server listener on 15495] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15495
2025-12-19 13:34:32,760 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1659)) - Stopping Storage Container Manager HTTP server.
2025-12-19 13:34:32,760 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3dc87b81{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:32,762 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@34a50daa{HTTP/1.1, (http/1.1)}{0.0.0.0:15490}
2025-12-19 13:34:32,762 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:34:32,762 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:32,762 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@469b90d{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-12-19 13:34:32,762 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@45c4dab2{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:34:32,764 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1667)) - Stopping SCM LayoutVersionManager Service.
2025-12-19 13:34:32,764 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1679)) - Stopping Block Manager Service.
2025-12-19 13:34:32,764 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:32,765 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:32,765 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1704)) - Stopping SCM Event Queue.
2025-12-19 13:34:32,766 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping SCM HA services.
2025-12-19 13:34:32,767 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:stop(267)) - stopping ratis server 0.0.0.0:15493
2025-12-19 13:34:32,767 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: close
2025-12-19 13:34:32,768 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown server GrpcServerProtocolService now
2025-12-19 13:34:32,768 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: shutdown
2025-12-19 13:34:32,769 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:32,769 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl
2025-12-19 13:34:32,768 [Thread-20476] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76 Close channels
2025-12-19 13:34:32,769 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(304)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-12-19 13:34:32,769 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(304)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-12-19 13:34:32,769 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-PendingRequests: sendNotLeaderResponses
2025-12-19 13:34:32,770 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyNotLeader(213)) - current leader SCM steps down.
2025-12-19 13:34:32,770 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(95)) - update <isLeader,term> from <true,2> to <false,0>
2025-12-19 13:34:32,770 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(101)) - update <isLeaderReady> from <true> to <false>
2025-12-19 13:34:32,770 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Completed APPEND_ENTRIES, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#162-t2,previous=(t:2, i:63),leaderCommit=63,initializing? false,entries: size=1, first=(t:2, i:64), METADATAENTRY(c:63) 
2025-12-19 13:34:32,770 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Completed APPEND_ENTRIES, lastReply: null 
2025-12-19 13:34:32,771 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(84)) - Service BackgroundPipelineScrubber transitions to PAUSING.
2025-12-19 13:34:32,771 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(84)) - Service ExpiredContainerReplicaOpScrubber transitions to PAUSING.
2025-12-19 13:34:32,771 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:notifyStatusChanged(84)) - Service SCMHATransactionMonitor transitions to PAUSING.
2025-12-19 13:34:32,771 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(562)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-12-19 13:34:32,771 [grpc-default-executor-1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(241)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: Failed to resetClient for 558504b9-cfec-4766-96f9-7b6ebb0f3b76
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:70)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:127)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:211)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:216)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:70)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:563)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:579)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:565)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:72)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:733)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:714)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:34:32,771 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: set stopIndex = 64
2025-12-19 13:34:32,772 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(562)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-12-19 13:34:32,772 [grpc-default-executor-0] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(241)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: Failed to resetClient for 558504b9-cfec-4766-96f9-7b6ebb0f3b76
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:70)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:127)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:211)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:216)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:70)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:563)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:579)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:565)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:72)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:733)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:714)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:34:32,773 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:takeSnapshot(332)) - Current Snapshot Index 64, takeSnapshot took 2 ms
2025-12-19 13:34:32,773 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: Took a snapshot at index 64
2025-12-19 13:34:32,773 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 64
2025-12-19 13:34:32,773 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:2, i:64)
2025-12-19 13:34:32,774 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:34:32,778 [Thread-20477] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 6a054400-8896-4262-aa80-3995e76ba098 Close channels
2025-12-19 13:34:32,778 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:34:33,097 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15510. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:33,097 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15494 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "localhost/127.0.0.1"; destination host is: "localhost":15494; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:910)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)
	at org.apache.hadoop.ipc_.Client$IpcStreams.readResponse(Client.java:1873)
	at org.apache.hadoop.ipc_.Client$Connection.receiveRpcResponse(Client.java:1165)
	at org.apache.hadoop.ipc_.Client$Connection.run(Client.java:1056)
2025-12-19 13:34:33,098 [9f85a268-b54d-42c0-89e3-0f143f429527-DatanodeStateMachineDaemonThread] WARN  datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(194)) - Detected timeout: Timeout occurred on endpoint: localhost/127.0.0.1:15510
2025-12-19 13:34:33,099 [IPC Server handler 0 on default port 15510] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:33,099 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:33,100 [IPC Server handler 1 on default port 15510] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:33,099 [IPC Server handler 0 on default port 15510] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:33,100 [IPC Server handler 6 on default port 15502] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:33,100 [IPC Server handler 6 on default port 15502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 9f85a268-b54d-42c0-89e3-0f143f429527{ip: 127.0.0.1, host: localhost, ports: [HTTP=15552, CLIENT_RPC=15553, REPLICATION=15559, RATIS=15555, RATIS_ADMIN=15556, RATIS_SERVER=15557, RATIS_DATASTREAM=15558, STANDALONE=15554], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:33,101 [IPC Server handler 7 on default port 15502] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:33,101 [IPC Server handler 7 on default port 15502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: b8c29964-8a98-47a9-8b1d-466622f5f9c1{ip: 127.0.0.1, host: localhost, ports: [HTTP=15536, CLIENT_RPC=15537, REPLICATION=15543, RATIS=15539, RATIS_ADMIN=15540, RATIS_SERVER=15541, RATIS_DATASTREAM=15542, STANDALONE=15538], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:33,102 [scmNode-2-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:33,102 [scmNode-2-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:33,102 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2025-12-19 13:34:33,102 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2025-12-19 13:34:33,102 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:33,102 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:33,102 [IPC Server handler 3 on default port 15510] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:33,102 [IPC Server handler 5 on default port 15510] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:33,102 [IPC Server handler 4 on default port 15510] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:33,103 [scmNode-2-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:33,103 [scmNode-2-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:33,103 [IPC Server handler 8 on default port 15502] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:33,103 [IPC Server handler 8 on default port 15502] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 57412301-a084-4aa6-8e22-91ecff01c376{ip: 127.0.0.1, host: localhost, ports: [HTTP=15544, CLIENT_RPC=15545, REPLICATION=15551, RATIS=15547, RATIS_ADMIN=15548, RATIS_SERVER=15549, RATIS_DATASTREAM=15550, STANDALONE=15546], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:33,103 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(151)) - All SCM safe mode pre check rules have passed
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:33,103 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:process(184)) - Below DNs reported by Pipeline: Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 are either in bad health or un-registered with SCMs. Details: DN 57412301-a084-4aa6-8e22-91ecff01c376: Health: HEALTHY_READONLY, Operational State: IN_SERVICE
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:process(184)) - Below DNs reported by Pipeline: Pipeline-83edabe4-a852-4d54-beae-579d88baa401 are either in bad health or un-registered with SCMs. Details: DN 57412301-a084-4aa6-8e22-91ecff01c376: Health: HEALTHY_READONLY, Operational State: IN_SERVICE
2025-12-19 13:34:33,103 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:33,104 [scmNode-2-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:33,147 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker close()
2025-12-19 13:34:33,147 [JvmPauseMonitor78] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-50ee075d-c1e7-43b2-938b-a7dc0bd7923f: Stopped
2025-12-19 13:34:33,148 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(127)) - Stopping SCMHATransactionMonitor Service.
2025-12-19 13:34:33,148 [scmNode-1-SCMHATransactionMonitor] WARN  SCMHATransactionMonitor (BackgroundSCMService.java:run(111)) - SCMHATransactionMonitor is interrupted, exit
2025-12-19 13:34:33,148 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:33,148 [scmNode-1-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-1-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:34:33,148 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(127)) - Stopping BackgroundPipelineScrubber Service.
2025-12-19 13:34:33,148 [scmNode-1-BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(111)) - BackgroundPipelineScrubber is interrupted, exit
2025-12-19 13:34:33,151 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2025-12-19 13:34:33,152 [ForkJoinPool-6-worker-1] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - scmNode-1-RatisPipelineUtilsThread is not running, just ignore.
2025-12-19 13:34:33,152 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(122)) - BackgroundPipelineScrubber Service is not running, skip stop.
2025-12-19 13:34:33,152 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(127)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:33,152 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:34:33,152 [scmNode-1-ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(111)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2025-12-19 13:34:33,153 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(326)) - Replication Monitor Thread is not running.
2025-12-19 13:34:33,153 [ForkJoinPool-6-worker-1] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(362)) - Cannot stop Container Balancer because it's not running or stopping
2025-12-19 13:34:33,153 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(122)) - SCMHATransactionMonitor Service is not running, skip stop.
2025-12-19 13:34:33,153 [scmNode-1-LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(285)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1167)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:283)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:34:33,153 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1745)) - Stopping SCM MetadataStore.
2025-12-19 13:34:33,161 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(141)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:33,161 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(162)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:33,162 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(172)) - ServiceID for StorageContainerManager is scmservice
2025-12-19 13:34:33,162 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:33,162 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:33,162 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:33,162 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(259)) - Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scmNode-1, RPC Address: localhost:15493 and Ratis port: 15493
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.datanode.address with value of key ozone.scm.datanode.address.scmservice.scmNode-1: 0.0.0.0:15494
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.block.client.address with value of key ozone.scm.block.client.address.scmservice.scmNode-1: 0.0.0.0:15497
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.client.address with value of key ozone.scm.client.address.scmservice.scmNode-1: 0.0.0.0:15495
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.security.service.address with value of key ozone.scm.security.service.address.scmservice.scmNode-1: 127.0.0.1:15492
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.ratis.port with value of key ozone.scm.ratis.port.scmservice.scmNode-1: 15493
2025-12-19 13:34:33,163 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.grpc.port with value of key ozone.scm.grpc.port.scmservice.scmNode-1: 15496
2025-12-19 13:34:33,164 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.http-address with value of key ozone.scm.http-address.scmservice.scmNode-1: 127.0.0.1:15490
2025-12-19 13:34:33,164 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.https-address with value of key ozone.scm.https-address.scmservice.scmNode-1: 127.0.0.1:15491
2025-12-19 13:34:33,164 [ForkJoinPool-6-worker-1] INFO  ha.SCMHANodeDetails (ConfUtils.java:setNodeSpecificConfigs(98)) - Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scmNode-1: 127.0.0.1
2025-12-19 13:34:33,164 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.block.client.port
2025-12-19 13:34:33,164 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.client.port
2025-12-19 13:34:33,164 [ForkJoinPool-6-worker-1] WARN  scm.ScmUtils (ScmUtils.java:logWarn(162)) - ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId. If want to configure same port configure ozone.scm.datanode.port
2025-12-19 13:34:33,164 [ForkJoinPool-6-worker-1] WARN  utils.HAUtils (HAUtils.java:getMetaDir(311)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:33,165 [ForkJoinPool-6-worker-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:getDBDirPath(160)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-19 13:34:33,186 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(128)) - Loading schema from [jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.2.0-SNAPSHOT.jar!/network-topology-default.xml]
2025-12-19 13:34:33,187 [ForkJoinPool-6-worker-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(175)) - Loading network topology layer schema file
2025-12-19 13:34:33,202 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:<init>(101)) - starting Raft server for scm:50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:33,202 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:33,203 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(132)) - Starting Apache Ratis Netty Support -- RaftServerProxy 50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:33,203 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                version: 3.2.1
2025-12-19 13:34:33,203 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -                    url: git@github.com:onesizefitsquorum/ratis.git
2025-12-19 13:34:33,203 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(136)) -               revision: 07a340e37662b1f0c9fd2dfde79fccb728060d34
2025-12-19 13:34:33,204 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   java: OpenJDK 64-Bit Server VM 21.0.9+10-LTS
2025-12-19 13:34:33,204 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (VersionInfo.java:printStartupMessages(139)) -                   user: runner
2025-12-19 13:34:33,204 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:33,204 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.admin.port = 15493 (fallback to raft.grpc.server.port)
2025-12-19 13:34:33,204 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-19 13:34:33,204 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(69)) - raft.grpc.client.port = 15493 (fallback to raft.grpc.server.port)
2025-12-19 13:34:33,204 [ForkJoinPool-6-worker-1] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(62)) - raft.grpc.server.port = 15493 (custom)
2025-12-19 13:34:33,205 [ForkJoinPool-6-worker-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis] (custom)
2025-12-19 13:34:33,206 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(273)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:33,206 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(106)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: addNew group-3149B70783DC:[] returns group-3149B70783DC:java.util.concurrent.CompletableFuture@cc73b7b[Not completed]
2025-12-19 13:34:33,206 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  ha.SCMStateMachine (SCMStateMachine.java:<init>(100)) - Updated lastAppliedTermIndex 2#64 with transactionInfo term andIndex
2025-12-19 13:34:33,206 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(269)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: new RaftServerImpl for group-3149B70783DC:[] with SCMStateMachine-189:uninitialized
2025-12-19 13:34:33,206 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(115)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-19 13:34:33,208 [ForkJoinPool-6-worker-1] INFO  ha.SCMSnapshotProvider (SCMSnapshotProvider.java:<init>(61)) - Initializing SCM Snapshot Provider
2025-12-19 13:34:33,208 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(322)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-19 13:34:33,209 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisSnapshotDirectory(415)) - Snapshot directory for Ratis is not configured. Falling back to ozone.metadata.dirs
2025-12-19 13:34:33,209 [ForkJoinPool-6-worker-1] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(80)) - Initializing Layout version manager with metadata layout = STORAGE_SPACE_DISTRIBUTION (version = 10), software layout = STORAGE_SPACE_DISTRIBUTION (version = 10)
2025-12-19 13:34:33,211 [ForkJoinPool-6-worker-1] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(232)) - Init the HA SequenceIdGenerator.
2025-12-19 13:34:33,211 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:33,211 [ForkJoinPool-6-worker-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(79)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2025-12-19 13:34:33,211 [ForkJoinPool-6-worker-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(185)) - Entering startup safe mode.
2025-12-19 13:34:33,212 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-12-19 13:34:33,212 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:33,213 [ForkJoinPool-6-worker-1] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(55)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-19 13:34:33,213 [ForkJoinPool-6-worker-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(83)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-19 13:34:33,214 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2025-12-19 13:34:33,214 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(126)) - Starting scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:34:33,214 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(64)) - Starting BackgroundPipelineScrubber Service.
2025-12-19 13:34:33,214 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2025-12-19 13:34:33,214 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(64)) - Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:34:33,215 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2025-12-19 13:34:33,215 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:33,215 [ForkJoinPool-6-worker-1] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(78)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-19 13:34:33,216 [ForkJoinPool-6-worker-1] INFO  block.SCMDeletedBlockTransactionStatusManager (SCMDeletedBlockTransactionStatusManager.java:loadDeletedBlocksSummary(686)) - Property DeletedBlocksTransactionSummary for service DeletedBlockLogStateManager not found. 
2025-12-19 13:34:33,216 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2025-12-19 13:34:33,217 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:start(288)) - Starting Replication Monitor Thread.
2025-12-19 13:34:33,217 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2025-12-19 13:34:33,218 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed RATIS Containers threshold count to 0.
2025-12-19 13:34:33,218 [ForkJoinPool-6-worker-1] INFO  safemode.SCMSafeModeManager (AbstractContainerSafeModeRule.java:initializeRule(83)) - Refreshed EC Containers threshold count to 0.
2025-12-19 13:34:33,218 [ForkJoinPool-6-worker-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(231)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:33,218 [ForkJoinPool-6-worker-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(190)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-19 13:34:33,219 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(433)) - SCM start with adminUsers: [admin, runner]
2025-12-19 13:34:33,219 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:33,219 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15494
2025-12-19 13:34:33,219 [Socket Reader #1 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15494
2025-12-19 13:34:33,220 [Socket Reader #2 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15494
2025-12-19 13:34:33,220 [Socket Reader #3 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15494
2025-12-19 13:34:33,220 [Socket Reader #4 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15494
2025-12-19 13:34:33,220 [Socket Reader #5 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15494
2025-12-19 13:34:33,220 [Socket Reader #6 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15494
2025-12-19 13:34:33,220 [Socket Reader #7 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15494
2025-12-19 13:34:33,221 [Socket Reader #8 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15494
2025-12-19 13:34:33,221 [Socket Reader #9 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15494
2025-12-19 13:34:33,221 [Socket Reader #10 for port 15494] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15494
2025-12-19 13:34:33,221 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:33,222 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15497
2025-12-19 13:34:33,222 [Socket Reader #1 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15497
2025-12-19 13:34:33,222 [Socket Reader #2 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15497
2025-12-19 13:34:33,222 [Socket Reader #3 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15497
2025-12-19 13:34:33,222 [Socket Reader #4 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15497
2025-12-19 13:34:33,222 [Socket Reader #5 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15497
2025-12-19 13:34:33,223 [Socket Reader #6 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15497
2025-12-19 13:34:33,223 [Socket Reader #7 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15497
2025-12-19 13:34:33,223 [Socket Reader #8 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15497
2025-12-19 13:34:33,223 [Socket Reader #9 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15497
2025-12-19 13:34:33,223 [Socket Reader #10 for port 15497] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15497
2025-12-19 13:34:33,224 [ForkJoinPool-6-worker-1] INFO  ipc_.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc_.DefaultRpcScheduler, ipcBackoff: false.
2025-12-19 13:34:33,224 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:<init>(1209)) - Listener at 0.0.0.0:15495
2025-12-19 13:34:33,224 [Socket Reader #1 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #1 for port 15495
2025-12-19 13:34:33,224 [Socket Reader #2 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #2 for port 15495
2025-12-19 13:34:33,224 [Socket Reader #3 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #3 for port 15495
2025-12-19 13:34:33,224 [Socket Reader #4 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #4 for port 15495
2025-12-19 13:34:33,225 [Socket Reader #5 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #5 for port 15495
2025-12-19 13:34:33,225 [Socket Reader #6 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #6 for port 15495
2025-12-19 13:34:33,225 [Socket Reader #7 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #7 for port 15495
2025-12-19 13:34:33,225 [Socket Reader #8 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #8 for port 15495
2025-12-19 13:34:33,225 [Socket Reader #9 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #9 for port 15495
2025-12-19 13:34:33,225 [Socket Reader #10 for port 15495] INFO  ipc_.Server (Server.java:run(1245)) - Starting Socket Reader #10 for port 15495
2025-12-19 13:34:33,228 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2025-12-19 13:34:33,228 [ForkJoinPool-6-worker-1] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-19 13:34:33,228 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1522)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15495
2025-12-19 13:34:33,229 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:start(204)) - starting ratis server 0.0.0.0:15493
2025-12-19 13:34:33,230 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(229)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/in_use.lock acquired by nodename 49142@localhost
2025-12-19 13:34:33,230 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:analyzeAndRecoverStorage(118)) - Read RaftStorageMetadata{term=2, votedFor=50ee075d-c1e7-43b2-938b-a7dc0bd7923f} from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/raft-meta
2025-12-19 13:34:33,230 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:33,230 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  ha.SCMStateMachine (SCMStateMachine.java:lambda$initialize$0(135)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: initialize group-3149B70783DC
2025-12-19 13:34:33,231 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:getSnapshotIndexFromStateMachine(155)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: getLatestSnapshot(SCMStateMachine-189:50ee075d-c1e7-43b2-938b-a7dc0bd7923f:group-3149B70783DC) returns 2#64
2025-12-19 13:34:33,231 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  raftlog.RaftLog (RaftLogBase.java:<init>(90)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLog: snapshotIndexFromStateMachine = 64
2025-12-19 13:34:33,232 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[#24193,50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun,5,main] started
2025-12-19 13:34:33,232 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(190)) - new 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc
2025-12-19 13:34:33,233 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 0, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:33,233 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(171)) - Successfully read 1 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_0-0
2025-12-19 13:34:33,233 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 1, cur=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:33,233 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 3, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:33,234 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 5, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:33,234 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 7, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[]}
2025-12-19 13:34:33,234 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:33,234 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.LogSegment (LogSegment.java:loadSegment(171)) - Successfully read 64 entries from segment file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_1
2025-12-19 13:34:33,234 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(141)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 64
2025-12-19 13:34:33,234 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_1 (append) at position 9339
2025-12-19 13:34:33,235 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(406)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: start as a follower, conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:33,235 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from      null to FOLLOWER at term 2 for startAsFollower
2025-12-19 13:34:33,235 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState
2025-12-19 13:34:33,235 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:33,235 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:register(58)) - register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:33,236 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(420)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: Successfully started.
2025-12-19 13:34:33,236 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:startImpl(415)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start RPC server
2025-12-19 13:34:33,236 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:startImpl(336)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: GrpcServicesImpl started, listening on 15493
2025-12-19 13:34:33,237 [ForkJoinPool-6-worker-1] INFO  ha.SCMHAManagerImpl (SCMHAManagerImpl.java:start(131)) -  scm role is FOLLOWER peers [558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]
2025-12-19 13:34:33,237 [ForkJoinPool-6-worker-1] INFO  ha.InterSCMGrpcService (InterSCMGrpcProtocolService.java:start(98)) - Starting SCM Grpc Service at port 15496
2025-12-19 13:34:33,237 [JvmPauseMonitor87] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-50ee075d-c1e7-43b2-938b-a7dc0bd7923f: Started
2025-12-19 13:34:33,237 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(64)) - Starting SCMHATransactionMonitor Service.
2025-12-19 13:34:33,238 [ForkJoinPool-6-worker-1] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMHATransactionMonitor.
2025-12-19 13:34:33,238 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:start(61)) - SCMHATransactionMonitor Service is already running, skip start.
2025-12-19 13:34:33,250 [ForkJoinPool-6-worker-1] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2025-12-19 13:34:33,283 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(211)) - RPC server for Client  is listening at /0.0.0.0:15495
2025-12-19 13:34:33,284 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:33,284 [IPC Server listener on 15495] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15495: starting
2025-12-19 13:34:33,294 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1535)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15497
2025-12-19 13:34:33,294 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(166)) - RPC server for Block Protocol is listening at /0.0.0.0:15497
2025-12-19 13:34:33,294 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:33,294 [IPC Server listener on 15497] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15497: starting
2025-12-19 13:34:33,304 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(195)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15494
2025-12-19 13:34:33,305 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1484)) - IPC Server Responder: starting
2025-12-19 13:34:33,305 [IPC Server listener on 15494] INFO  ipc_.Server (Server.java:run(1324)) - IPC Server listener on 15494: starting
2025-12-19 13:34:33,315 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:start(119)) - Starting service SCMBlockDeletingService with interval 60000 milliseconds
2025-12-19 13:34:33,316 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(227)) - Starting Web-server for scm at: http://0.0.0.0:15490
2025-12-19 13:34:33,316 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(105)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2025-12-19 13:34:33,317 [ForkJoinPool-6-worker-1] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2025-12-19 13:34:33,318 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1041)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-19 13:34:33,319 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1017)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2025-12-19 13:34:33,319 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-19 13:34:33,319 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1025)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-19 13:34:33,319 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(193)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/webserver
2025-12-19 13:34:33,319 [ForkJoinPool-6-worker-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1241)) - Jetty bound to port 15490
2025-12-19 13:34:33,320 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 21.0.9+10-LTS
2025-12-19 13:34:33,321 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2025-12-19 13:34:33,321 [ForkJoinPool-6-worker-1] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2025-12-19 13:34:33,321 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2025-12-19 13:34:33,321 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2e597b23{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2025-12-19 13:34:33,322 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@698f943d{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2025-12-19 13:34:33,325 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2131f4bc{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:34:33,326 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@bdd6cf{HTTP/1.1, (http/1.1)}{0.0.0.0:15490}
2025-12-19 13:34:33,326 [ForkJoinPool-6-worker-1] INFO  server.Server (Server.java:doStart(415)) - Started @859514ms
2025-12-19 13:34:33,326 [ForkJoinPool-6-worker-1] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2025-12-19 13:34:33,326 [ForkJoinPool-6-worker-1] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(357)) - HTTP server of scm listening at http://localhost:15490
2025-12-19 13:34:33,579 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:33,763 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:33,985 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(68)) - Processing FinalizeNewLayoutVersionCommandHandler command.
2025-12-19 13:34:34,096 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(68)) - Processing FinalizeNewLayoutVersionCommandHandler command.
2025-12-19 13:34:34,096 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(81)) - Finalize Upgrade called!
2025-12-19 13:34:34,096 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - Finalization started.
2025-12-19 13:34:34,096 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V2
2025-12-19 13:34:34,097 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV2FinalizeAction (DatanodeSchemaV2FinalizeAction.java:execute(43)) - Executing datanode 'onFinalize' action for the first version with upgrade support. New containers will be created with Schema Version 2 henceforth.
2025-12-19 13:34:34,098 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V2 has been finalized.
2025-12-19 13:34:34,098 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: SCM_HA
2025-12-19 13:34:34,098 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.ScmHAFinalizeUpgradeActionDatanode (ScmHAFinalizeUpgradeActionDatanode.java:execute(50)) - Upgrading Datanode volume layout for SCM HA support.
2025-12-19 13:34:34,098 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.ScmHAFinalizeUpgradeActionDatanode (ScmHAFinalizeUpgradeActionDatanode.java:upgradeVolume(108)) - Volume already contains cluster ID directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc. No action required for SCM HA finalization.
2025-12-19 13:34:34,100 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature SCM_HA has been finalized.
2025-12-19 13:34:34,100 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: ERASURE_CODED_STORAGE_SUPPORT.
2025-12-19 13:34:34,100 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15494. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:34,100 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:34,100 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:34,101 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature ERASURE_CODED_STORAGE_SUPPORT has been finalized.
2025-12-19 13:34:34,101 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: DATANODE_SCHEMA_V3
2025-12-19 13:34:34,101 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV3FinalizeAction (DatanodeSchemaV3FinalizeAction.java:execute(49)) - Upgrading Datanode volume layout for Schema V3 support.
2025-12-19 13:34:34,101 [IPC Server handler 0 on default port 15494] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:34,101 [IPC Server handler 2 on default port 15494] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:34,101 [IPC Server handler 1 on default port 15494] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:34,102 [IPC Server handler 3 on default port 15494] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode b8c29964-8a98-47a9-8b1d-466622f5f9c1(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:34,102 [IPC Server handler 4 on default port 15494] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(91)) - SCM received heartbeat from an unregistered datanode 9f85a268-b54d-42c0-89e3-0f143f429527(localhost/127.0.0.1). Asking datanode to re-register.
2025-12-19 13:34:34,102 [IPC Server handler 6 on default port 15502] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 3, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:34,104 [IPC Server handler 2 on default port 15510] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:34,104 [IPC Server handler 2 on default port 15510] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: b8c29964-8a98-47a9-8b1d-466622f5f9c1{ip: 127.0.0.1, host: localhost, ports: [HTTP=15536, CLIENT_RPC=15537, REPLICATION=15543, RATIS=15539, RATIS_ADMIN=15540, RATIS_SERVER=15541, RATIS_DATASTREAM=15542, STANDALONE=15538], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:34,104 [IPC Server handler 7 on default port 15510] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:34,104 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:34,104 [IPC Server handler 7 on default port 15510] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 9f85a268-b54d-42c0-89e3-0f143f429527{ip: 127.0.0.1, host: localhost, ports: [HTTP=15552, CLIENT_RPC=15553, REPLICATION=15559, RATIS=15555, RATIS_ADMIN=15556, RATIS_SERVER=15557, RATIS_DATASTREAM=15558, STANDALONE=15554], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:34,105 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:34,105 [scmNode-3-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:34,105 [scmNode-3-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:34,105 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:34,105 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2025-12-19 13:34:34,105 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:34,106 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2025-12-19 13:34:34,106 [scmNode-3-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,106 [scmNode-3-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,106 [scmNode-3-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,106 [scmNode-3-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,107 [IPC Server handler 8 on default port 15494] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:34:34,107 [IPC Server handler 8 on default port 15494] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: b8c29964-8a98-47a9-8b1d-466622f5f9c1{ip: 127.0.0.1, host: localhost, ports: [HTTP=15536, CLIENT_RPC=15537, REPLICATION=15543, RATIS=15539, RATIS_ADMIN=15540, RATIS_SERVER=15541, RATIS_DATASTREAM=15542, STANDALONE=15538], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:34,108 [IPC Server handler 9 on default port 15494] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:34:34,108 [IPC Server handler 9 on default port 15494] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 9f85a268-b54d-42c0-89e3-0f143f429527{ip: 127.0.0.1, host: localhost, ports: [HTTP=15552, CLIENT_RPC=15553, REPLICATION=15559, RATIS=15555, RATIS_ADMIN=15556, RATIS_SERVER=15557, RATIS_DATASTREAM=15558, STANDALONE=15554], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:34,108 [scmNode-1-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:34,108 [scmNode-1-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:34,109 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2025-12-19 13:34:34,109 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2025-12-19 13:34:34,109 [scmNode-1-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,109 [scmNode-1-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,109 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:34,109 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:34,111 [scmNode-1-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,111 [scmNode-1-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,143 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(70)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4/container.db to cache
2025-12-19 13:34:34,143 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(602)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4/container.db for volume DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4
2025-12-19 13:34:34,144 [ForkJoinPool.commonPool-worker-3] WARN  volume.HddsVolume (HddsVolume.java:loadDbStore(492)) - Schema V3 db is already loaded from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4 for volume DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4
2025-12-19 13:34:34,144 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.DatanodeSchemaV3FinalizeAction (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(102)) - Load 1 volumes DbStore cost: 0ms
2025-12-19 13:34:34,144 [57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(519)) - Ignore. OzoneContainer already started.
2025-12-19 13:34:34,145 [IPC Server handler 10 on default port 15510] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:34,145 [IPC Server handler 10 on default port 15510] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 57412301-a084-4aa6-8e22-91ecff01c376{ip: 127.0.0.1, host: localhost, ports: [HTTP=15544, CLIENT_RPC=15545, REPLICATION=15551, RATIS=15547, RATIS_ADMIN=15548, RATIS_SERVER=15549, RATIS_DATASTREAM=15550, STANDALONE=15546], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:34,145 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:34,145 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(151)) - All SCM safe mode pre check rules have passed
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:process(184)) - Below DNs reported by Pipeline: Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 are either in bad health or un-registered with SCMs. Details: DN 57412301-a084-4aa6-8e22-91ecff01c376: Health: HEALTHY_READONLY, Operational State: IN_SERVICE
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:process(184)) - Below DNs reported by Pipeline: Pipeline-83edabe4-a852-4d54-beae-579d88baa401 are either in bad health or un-registered with SCMs. Details: DN 57412301-a084-4aa6-8e22-91ecff01c376: Health: HEALTHY_READONLY, Operational State: IN_SERVICE
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,146 [scmNode-3-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,146 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature DATANODE_SCHEMA_V3 has been finalized.
2025-12-19 13:34:34,147 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS.
2025-12-19 13:34:34,147 [IPC Server handler 11 on default port 15510] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:34,147 [IPC Server handler 12 on default port 15502] WARN  node.SCMNodeManager (SCMNodeManager.java:sendFinalizeToDatanodeIfNeeded(769)) - Data node localhost can not be used in any pipeline in the cluster. DataNode MetadataLayoutVersion = 4, SCM MetadataLayoutVersion = 10
2025-12-19 13:34:34,148 [IPC Server handler 10 on default port 15494] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:34:34,148 [IPC Server handler 10 on default port 15494] INFO  node.SCMNodeManager (SCMNodeManager.java:register(428)) - Registered datanode: 57412301-a084-4aa6-8e22-91ecff01c376{ip: 127.0.0.1, host: localhost, ports: [HTTP=15544, CLIENT_RPC=15545, REPLICATION=15551, RATIS=15547, RATIS_ADMIN=15548, RATIS_SERVER=15549, RATIS_DATASTREAM=15550, STANDALONE=15546], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-ContainerRegistrationReportForECContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-ContainerRegistrationReportForRatisContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(78)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(151)) - All SCM safe mode pre check rules have passed
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:process(184)) - Below DNs reported by Pipeline: Pipeline-b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61 are either in bad health or un-registered with SCMs. Details: DN 57412301-a084-4aa6-8e22-91ecff01c376: Health: HEALTHY_READONLY, Operational State: IN_SERVICE
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:34,148 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:process(184)) - Below DNs reported by Pipeline: Pipeline-83edabe4-a852-4d54-beae-579d88baa401 are either in bad health or un-registered with SCMs. Details: DN 57412301-a084-4aa6-8e22-91ecff01c376: Health: HEALTHY_READONLY, Operational State: IN_SERVICE
2025-12-19 13:34:34,149 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature RATIS_DATASTREAM_PORT_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:34,149 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: WEBUI_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:34,150 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WEBUI_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:34,150 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HADOOP_PRC_PORTS_IN_DATANODEDETAILS.
2025-12-19 13:34:34,151 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HADOOP_PRC_PORTS_IN_DATANODEDETAILS has been finalized.
2025-12-19 13:34:34,151 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: HBASE_SUPPORT.
2025-12-19 13:34:34,152 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature HBASE_SUPPORT has been finalized.
2025-12-19 13:34:34,152 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:runFinalizationAction(270)) - Running finalization actions for layout feature: WITNESSED_CONTAINER_DB_PROTO_VALUE
2025-12-19 13:34:34,153 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.ContainerTableSchemaFinalizeAction (ContainerTableSchemaFinalizeAction.java:execute(71)) - Finished copy to containerIdsTable from previous table
2025-12-19 13:34:34,154 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature WITNESSED_CONTAINER_DB_PROTO_VALUE has been finalized.
2025-12-19 13:34:34,154 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - No onFinalize work defined for feature: STORAGE_SPACE_DISTRIBUTION.
2025-12-19 13:34:34,155 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(124)) - Layout feature STORAGE_SPACE_DISTRIBUTION has been finalized.
2025-12-19 13:34:34,155 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:finalized(126)) - Finalization is complete.
2025-12-19 13:34:34,155 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - Finalization is done.
2025-12-19 13:34:34,155 [57412301-a084-4aa6-8e22-91ecff01c376-CommandProcessorThread] INFO  commandhandler.FinalizeNewLayoutVersionCommandHandler (FinalizeNewLayoutVersionCommandHandler.java:handle(68)) - Processing FinalizeNewLayoutVersionCommandHandler command.
2025-12-19 13:34:34,579 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:34,763 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:35,179 [scmNode-2-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(46)) - Datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1) moved to HEALTHY state.
2025-12-19 13:34:35,179 [scmNode-2-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:35,180 [scmNode-3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(46)) - Datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1) moved to HEALTHY state.
2025-12-19 13:34:35,180 [scmNode-3-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:35,213 [scmNode-1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(46)) - Datanode 57412301-a084-4aa6-8e22-91ecff01c376(localhost/127.0.0.1) moved to HEALTHY state.
2025-12-19 13:34:35,214 [scmNode-1-EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(283)) - ignore, not leader SCM.
2025-12-19 13:34:35,546 [timer3] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-AppendLogResponseHandler: Failed appendEntries (Repeated 2 times in the last 5.001s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:34:35,547 [timer4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: Follower failed (request=null, errorCount=2); keep nextIndex (63) unchanged and retry. (Repeated 2 times in the last 5.001s)
2025-12-19 13:34:35,580 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:35,764 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:36,580 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:36,764 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:36,786 [timer1] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-AppendLogResponseHandler: Failed appendEntries (Repeated 6 times in the last 4.999s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
  Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: connect(..) failed: Address family not supported by protocol: localhost/[0:0:0:0:0:0:0:1]:15509
  Caused by: java.net.ConnectException: connect(..) failed: Address family not supported by protocol
2025-12-19 13:34:36,787 [timer2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Follower failed (request=null, errorCount=2); keep nextIndex (63) unchanged and retry. (Repeated 2 times in the last 5.000s)
2025-12-19 13:34:37,137 [timer4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Follower failed (request=null, errorCount=4); keep nextIndex (64) unchanged and retry. (Repeated 2 times in the last 5.000s)
2025-12-19 13:34:37,148 [timer7] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Follower failed (request=null, errorCount=6); keep nextIndex (65) unchanged and retry. (Repeated 2 times in the last 5.000s)
2025-12-19 13:34:37,581 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:37,651 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5048371651ns, electionTimeout:5048ms
2025-12-19 13:34:37,651 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState
2025-12-19 13:34:37,651 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2025-12-19 13:34:37,651 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 6a054400-8896-4262-aa80-3995e76ba098: start 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123
2025-12-19 13:34:37,652 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123 PRE_VOTE round 0: submit vote requests at term 2 for conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:37,652 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501
2025-12-19 13:34:37,652 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493
2025-12-19 13:34:37,655 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: receive requestVote(PRE_VOTE, 6a054400-8896-4262-aa80-3995e76ba098, group-3149B70783DC, 2, (t:2, i:62))
2025-12-19 13:34:37,655 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: receive requestVote(PRE_VOTE, 6a054400-8896-4262-aa80-3995e76ba098, group-3149B70783DC, 2, (t:2, i:62))
2025-12-19 13:34:37,655 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FOLLOWER: reject PRE_VOTE from 6a054400-8896-4262-aa80-3995e76ba098: our last entry (t:2, i:64) > candidate's last entry (t:2, i:62)
2025-12-19 13:34:37,655 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FOLLOWER: reject PRE_VOTE from 6a054400-8896-4262-aa80-3995e76ba098: our last entry (t:2, i:64) > candidate's last entry (t:2, i:62)
2025-12-19 13:34:37,655 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC replies to PRE_VOTE vote request: 6a054400-8896-4262-aa80-3995e76ba098<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:FAIL-t2-last:(t:2, i:64). Peer's state: 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC:t2, leader=50ee075d-c1e7-43b2-938b-a7dc0bd7923f, voted=, raftlog=Memoized:558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog:OPENED:c63:last(t:2, i:64), conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:37,655 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC replies to PRE_VOTE vote request: 6a054400-8896-4262-aa80-3995e76ba098<-50ee075d-c1e7-43b2-938b-a7dc0bd7923f#0:FAIL-t2-last:(t:2, i:64). Peer's state: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC:t2, leader=null, voted=50ee075d-c1e7-43b2-938b-a7dc0bd7923f, raftlog=Memoized:50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLog:OPENED:c64:last(t:2, i:64), conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:37,656 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  impl.LeaderElection (LeaderElection.java:waitForResults(573)) - rejectedPeers: [50ee075d-c1e7-43b2-938b-a7dc0bd7923f, 558504b9-cfec-4766-96f9-7b6ebb0f3b76], emptyCommit? false
2025-12-19 13:34:37,656 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(206)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2025-12-19 13:34:37,656 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(210)) -   Response 0: 6a054400-8896-4262-aa80-3995e76ba098<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:FAIL-t2-last:(t:2, i:64)
2025-12-19 13:34:37,656 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(210)) -   Response 1: 6a054400-8896-4262-aa80-3995e76ba098<-50ee075d-c1e7-43b2-938b-a7dc0bd7923f#0:FAIL-t2-last:(t:2, i:64)
2025-12-19 13:34:37,656 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123 PRE_VOTE round 0: result REJECTED
2025-12-19 13:34:37,656 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2025-12-19 13:34:37,656 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123
2025-12-19 13:34:37,656 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 6a054400-8896-4262-aa80-3995e76ba098: start 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState
2025-12-19 13:34:37,657 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-LeaderElection123] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set firstElectionSinceStartup to false for REJECTED
2025-12-19 13:34:37,764 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:37,770 [timer5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Completed APPEND_ENTRIES, lastRequest: null  (Repeated 2 times in the last 5.001s)
2025-12-19 13:34:37,771 [timer6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: Completed APPEND_ENTRIES, lastReply: null  (Repeated 2 times in the last 5.001s)
2025-12-19 13:34:38,376 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(161)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5140854495ns, electionTimeout:5140ms
2025-12-19 13:34:38,376 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState
2025-12-19 13:34:38,376 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2025-12-19 13:34:38,376 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124
2025-12-19 13:34:38,376 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124 PRE_VOTE round 0: submit vote requests at term 2 for conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,377 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501
2025-12-19 13:34:38,377 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509
2025-12-19 13:34:38,380 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: receive requestVote(PRE_VOTE, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f, group-3149B70783DC, 2, (t:2, i:64))
2025-12-19 13:34:38,380 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FOLLOWER: accept PRE_VOTE from 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: our priority 0 <= candidate's priority 0
2025-12-19 13:34:38,380 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: receive requestVote(PRE_VOTE, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f, group-3149B70783DC, 2, (t:2, i:64))
2025-12-19 13:34:38,380 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FOLLOWER: accept PRE_VOTE from 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: our last entry (t:2, i:62) < candidate's last entry (t:2, i:64)
2025-12-19 13:34:38,380 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC replies to PRE_VOTE vote request: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#0:OK-t2-last:(t:2, i:62). Peer's state: 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC:t2, leader=null, voted=, raftlog=Memoized:6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLog:OPENED:c61:last(t:2, i:62), conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,380 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC replies to PRE_VOTE vote request: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:OK-t2-last:(t:2, i:64). Peer's state: 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC:t2, leader=50ee075d-c1e7-43b2-938b-a7dc0bd7923f, voted=, raftlog=Memoized:558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog:OPENED:c63:last(t:2, i:64), conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,381 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(206)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2025-12-19 13:34:38,381 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(210)) -   Response 0: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:OK-t2-last:(t:2, i:64)
2025-12-19 13:34:38,381 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124 PRE_VOTE round 0: result PASSED
2025-12-19 13:34:38,382 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(448)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124 ELECTION round 0: submit vote requests at term 3 for conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,383 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: receive requestVote(ELECTION, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f, group-3149B70783DC, 3, (t:2, i:64))
2025-12-19 13:34:38,383 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FOLLOWER: accept ELECTION from 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: our priority 0 <= candidate's priority 0
2025-12-19 13:34:38,384 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:38,384 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: shutdown 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState
2025-12-19 13:34:38,384 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: change Leader from 50ee075d-c1e7-43b2-938b-a7dc0bd7923f to null at term 3 for updateCurrentTerm
2025-12-19 13:34:38,384 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1434)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: receive requestVote(ELECTION, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f, group-3149B70783DC, 3, (t:2, i:64))
2025-12-19 13:34:38,384 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: start 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState
2025-12-19 13:34:38,384 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FOLLOWER: accept ELECTION from 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: our last entry (t:2, i:62) < candidate's last entry (t:2, i:64)
2025-12-19 13:34:38,384 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:34:38,384 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState
2025-12-19 13:34:38,384 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 6a054400-8896-4262-aa80-3995e76ba098: start 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState
2025-12-19 13:34:38,384 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState was interrupted
2025-12-19 13:34:38,385 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState was interrupted
2025-12-19 13:34:38,385 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC replies to ELECTION vote request: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:OK-t3-last:(t:2, i:64). Peer's state: 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC:t3, leader=null, voted=50ee075d-c1e7-43b2-938b-a7dc0bd7923f, raftlog=Memoized:558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLog:OPENED:c63:last(t:2, i:64), conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,385 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1468)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC replies to ELECTION vote request: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#0:OK-t3-last:(t:2, i:62). Peer's state: 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC:t3, leader=null, voted=50ee075d-c1e7-43b2-938b-a7dc0bd7923f, raftlog=Memoized:6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLog:OPENED:c61:last(t:2, i:62), conf=conf: {index: 9, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(206)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124: ELECTION PASSED received 1 response(s) and 0 exception(s):
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(210)) -   Response 0: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-558504b9-cfec-4766-96f9-7b6ebb0f3b76#0:OK-t3-last:(t:2, i:64)
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(450)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124 ELECTION round 0: result PASSED
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(141)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(393)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(69)) - raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.write.element-limit = 4096 (default)
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-12-19 13:34:38,386 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(62)) - raft.server.watch.timeout = 10s (default)
2025-12-19 13:34:38,388 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(148)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: start 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl
2025-12-19 13:34:38,388 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(577)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set firstElectionSinceStartup to false for becomeLeader
2025-12-19 13:34:38,388 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(293)) - current SCM becomes leader of term 3.
2025-12-19 13:34:38,388 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(95)) - update <isLeader,term> from <false,0> to <true,3>
2025-12-19 13:34:38,388 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: change Leader from null to 50ee075d-c1e7-43b2-938b-a7dc0bd7923f at term 3 for becomeLeader, leader elected after 5181ms
2025-12-19 13:34:38,388 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(445)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: Rolling segment log-1_64 to index:64
2025-12-19 13:34:38,389 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderElection124] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: set configuration conf: {index: 65, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,389 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(604)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_1 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_1-64
2025-12-19 13:34:38,389 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_65 at position 0
2025-12-19 13:34:38,396 [grpc-default-executor-1] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(289)) - leader changed, yet current SCM is still follower.
2025-12-19 13:34:38,396 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: change Leader from null to 50ee075d-c1e7-43b2-938b-a7dc0bd7923f at term 3 for APPEND_ENTRIES, leader elected after 5822ms
2025-12-19 13:34:38,396 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1687)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as previous log entry ((t:2, i:64)) is not found
2025-12-19 13:34:38,396 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#1:FAIL-t3,INCONSISTENCY,nextIndex=63,followerCommit=61,matchIndex=-1
2025-12-19 13:34:38,396 [grpc-default-executor-3] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyLeaderChanged(289)) - leader changed, yet current SCM is still follower.
2025-12-19 13:34:38,396 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setLeader(278)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: change Leader from null to 50ee075d-c1e7-43b2-938b-a7dc0bd7923f at term 3 for APPEND_ENTRIES, leader elected after 12ms
2025-12-19 13:34:38,396 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:checkInconsistentAppendEntries(1687)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: Failed appendEntries as previous log entry ((t:2, i:64)) is not found
2025-12-19 13:34:38,396 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:appendEntriesAsync(1607)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: appendEntries* reply 50ee075d-c1e7-43b2-938b-a7dc0bd7923f<-6a054400-8896-4262-aa80-3995e76ba098#0:FAIL-t3,INCONSISTENCY,nextIndex=63,followerCommit=61,matchIndex=-1
2025-12-19 13:34:38,396 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: set configuration conf: {index: 65, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,397 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(445)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: Rolling segment log-3_64 to index:64
2025-12-19 13:34:38,397 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-1/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_65
2025-12-19 13:34:38,397 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNextImpl$0(531)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 63, errorCount=1, request=AppendEntriesRequest:cid=1,entriesCount=1,entry=(t:3, i:65) 
2025-12-19 13:34:38,398 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:info(70)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098: setNextIndex nextIndex: updateUnconditionally 66 -> 63
2025-12-19 13:34:38,398 [grpc-default-executor-1] INFO  leader.FollowerInfo (FollowerInfoImpl.java:info(70)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098: setNextIndex nextIndex: updateUnconditionally 66 -> 63
2025-12-19 13:34:38,398 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 65, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,399 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(604)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_3 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_3-64
2025-12-19 13:34:38,399 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_65 at position 0
2025-12-19 13:34:38,400 [6a054400-8896-4262-aa80-3995e76ba098-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(445)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: Rolling segment log-7_64 to index:64
2025-12-19 13:34:38,400 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(392)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: set configuration conf: {index: 65, cur=peers:[558504b9-cfec-4766-96f9-7b6ebb0f3b76|localhost:15501, 6a054400-8896-4262-aa80-3995e76ba098|localhost:15509, 50ee075d-c1e7-43b2-938b-a7dc0bd7923f|localhost:15493]|listeners:[], old=null}
2025-12-19 13:34:38,407 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-2/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_65
2025-12-19 13:34:38,407 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(604)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_7 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_7-64
2025-12-19 13:34:38,407 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(61)) - open log_inprogress_65 at position 0
2025-12-19 13:34:38,411 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:checkStartIndex(309)) - Leader 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl is ready since appliedIndex == startIndex == 65
2025-12-19 13:34:38,411 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMContext (SCMContext.java:setLeaderReady(122)) - update <isLeaderReady> from <false> to <true>
2025-12-19 13:34:38,411 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(268)) - Service BackgroundPipelineCreator transitions to RUNNING.
2025-12-19 13:34:38,412 [scmNode-1-FinalizationManager-0] INFO  upgrade.FinalizationManagerImpl (FinalizationManagerImpl.java:lambda$onLeaderReady$0(165)) - SCM became leader. Resuming upgrade finalization from current checkpoint MLV_EQUALS_SLV.
2025-12-19 13:34:38,412 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (BasicUpgradeFinalizer.java:logAndEmit(395)) - Finalization started.
2025-12-19 13:34:38,412 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:38,412 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:38,412 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:38,412 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:38,412 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:38,412 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:38,413 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:logCheckpointCrossed(58)) - SCM Finalization has crossed checkpoint FINALIZATION_STARTED
2025-12-19 13:34:38,413 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:logCheckpointCrossed(58)) - SCM Finalization has crossed checkpoint MLV_EQUALS_SLV
2025-12-19 13:34:38,413 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:34:38,414 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(647)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/scmNode-3/scm.ratis/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/current/log_inprogress_65
2025-12-19 13:34:38,416 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - DataNodeSafeModeRule rule is successfully validated
2025-12-19 13:34:38,416 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - RatisContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:38,417 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(227)) - Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-19 13:34:38,417 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - StateMachineReadyRule rule is successfully validated
2025-12-19 13:34:38,417 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:34:38,417 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - ECContainerSafeModeRule rule is successfully validated
2025-12-19 13:34:38,581 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:38,765 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:39,327 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:39,327 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:39,327 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:39,582 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:39,765 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:40,328 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:40,328 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:40,328 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:40,582 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:40,766 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:41,328 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:41,329 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:41,329 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:41,583 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:41,766 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:42,329 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:42,329 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:42,329 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:42,583 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:42,767 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:43,329 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:43,330 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:43,330 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:43,397 [timer7] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$onNextImpl$0(531)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 63, errorCount=2, request=null  (Repeated 2 times in the last 5.000s)
2025-12-19 13:34:43,413 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:34:43,584 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:43,767 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:44,330 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:44,331 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:44,331 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:44,584 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:44,768 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:44,768 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15440 for past 0 seconds.
java.net.ConnectException: Call From localhost/127.0.0.1 to localhost:15440 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:876)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:639)
	at org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
	at org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
	at org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1435)
	... 12 more
2025-12-19 13:34:45,331 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:45,331 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:45,331 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:45,585 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:45,769 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:46,331 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:46,332 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:46,332 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:46,585 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:46,769 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:47,332 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:47,332 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:47,332 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:47,586 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:47,769 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:48,332 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:48,333 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:48,333 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:48,413 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:34:48,586 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:48,770 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:49,333 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:49,333 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:49,333 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:49,587 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:49,770 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:50,333 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:50,334 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:50,334 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:50,587 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:50,771 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:51,334 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:51,334 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:51,334 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:51,588 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:51,771 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:52,334 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:52,335 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:52,335 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:52,588 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:52,772 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:53,335 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:53,335 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:53,335 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:53,413 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:34:53,589 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:53,772 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:54,335 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:54,336 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:54,336 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:54,589 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:54,773 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:55,336 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:55,336 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:55,336 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:55,590 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:55,773 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:56,336 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:56,337 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:56,337 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:56,590 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:56,774 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:57,337 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:57,337 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:57,337 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:57,591 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:57,774 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:58,338 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:58,338 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:58,338 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:58,414 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:34:58,591 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:58,775 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:59,338 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:34:59,338 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:34:59,338 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:34:59,592 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:34:59,775 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:00,339 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:00,339 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:00,339 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:00,593 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:00,776 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:01,339 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:01,339 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:01,339 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:01,593 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:01,776 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:02,340 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:02,340 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:02,340 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:02,594 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:02,777 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:03,340 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:03,340 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:03,340 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:03,414 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:03,594 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:03,777 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:04,341 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:04,341 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:04,341 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:04,595 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:04,778 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:05,341 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:05,341 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:05,341 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:05,595 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:05,778 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:06,342 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:06,342 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:06,342 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:06,596 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:06,779 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:07,342 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:07,342 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:07,343 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:07,596 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:07,779 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:08,343 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:08,343 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:08,343 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:08,414 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:08,597 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:08,780 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:09,344 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:09,344 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:09,344 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:09,597 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:09,780 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:10,344 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:10,344 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:10,344 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:10,598 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:10,781 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:11,345 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:11,345 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:11,345 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:11,598 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:11,781 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:12,345 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:12,345 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:12,345 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:12,599 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:12,782 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:13,346 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:13,346 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:13,346 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:13,414 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:13,599 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:13,782 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:14,346 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:14,347 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:14,347 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:14,599 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:14,600 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15432 for past 0 seconds.
java.net.ConnectException: Call From localhost/127.0.0.1 to localhost:15432 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:876)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:973)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:614)
	at org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:639)
	at org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
	at org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
	at org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1435)
	... 12 more
2025-12-19 13:35:14,783 [db789b00-552d-47af-82af-a004293aae40-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:15,347 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:15,347 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:15,347 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:15,600 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:15,783 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:16,348 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:16,348 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:16,348 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:16,601 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:16,784 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:17,348 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:17,348 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:17,349 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:17,601 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:17,784 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:18,349 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:18,349 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:18,349 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:18,415 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:18,602 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:18,785 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:19,349 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:19,350 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:19,350 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:19,602 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:19,785 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:20,350 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:20,350 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:20,350 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:20,602 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:20,786 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:21,351 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:21,351 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:21,351 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:21,603 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:21,786 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:22,351 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:22,351 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:22,351 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:22,603 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:22,787 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:23,352 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:23,352 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:23,352 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:23,415 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:23,604 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:23,787 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:24,352 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:24,352 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:24,352 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:24,604 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:24,788 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:25,353 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:25,353 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:25,353 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:25,605 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:25,788 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:26,353 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:26,353 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:26,353 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:26,605 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:26,788 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:27,354 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:27,354 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:27,354 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:27,606 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:27,789 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:28,354 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:28,354 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:28,354 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:28,415 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:28,606 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:28,789 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:29,355 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:29,355 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:29,355 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:29,607 [30ebe7c9-7476-496b-b21f-992a4521ab61-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:29,790 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15440-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15440. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:30,355 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:30,355 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Waiting for cluster to exit safe mode
2025-12-19 13:35:30,355 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:30,608 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:31,151 [scmNode-2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:35:31,151 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(195)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-19 13:35:31,151 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(195)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-19 13:35:31,151 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(195)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-19 13:35:31,151 [scmNode-1-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:35:31,151 [scmNode-3-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - OneReplicaPipelineSafeModeRule rule is successfully validated
2025-12-19 13:35:31,152 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - HealthyPipelineSafeModeRule rule is successfully validated
2025-12-19 13:35:31,152 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(158)) - ScmSafeModeManager, all rules are successfully validated
2025-12-19 13:35:31,151 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - HealthyPipelineSafeModeRule rule is successfully validated
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(138)) - HealthyPipelineSafeModeRule rule is successfully validated
2025-12-19 13:35:31,152 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(158)) - ScmSafeModeManager, all rules are successfully validated
2025-12-19 13:35:31,152 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(159)) - SCM exiting safe mode.
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(158)) - ScmSafeModeManager, all rules are successfully validated
2025-12-19 13:35:31,152 [scmNode-2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(159)) - SCM exiting safe mode.
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(78)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(78)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(265)) - notifyStatusChanged:RUNNING
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1411)) - Service ReplicationManager transitions to RUNNING.
2025-12-19 13:35:31,152 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(159)) - SCM exiting safe mode.
2025-12-19 13:35:31,152 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(136)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2025-12-19 13:35:31,152 [scmNode-3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(224)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-19 13:35:31,153 [scmNode-1-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:notifyStatusChanged(78)) - Service SCMHATransactionMonitor transitions to RUNNING.
2025-12-19 13:35:31,356 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(181)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2025-12-19 13:35:31,356 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(184)) - Cluster exits safe mode
2025-12-19 13:35:31,356 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(186)) - SCM became leader
2025-12-19 13:35:31,357 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:31,608 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:32,358 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:32,609 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:33,359 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:33,415 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:33,609 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:34,360 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:34,610 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:35,361 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:35,610 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:36,362 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:36,611 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:37,363 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:37,611 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:38,364 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:38,415 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:38,612 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:39,365 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:39,612 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:40,367 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:40,613 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:41,368 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:41,613 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:42,369 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:42,613 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:43,370 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:43,416 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:43,614 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:44,371 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:44,614 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:45,372 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:45,615 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:46,373 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:46,616 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:47,374 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:47,616 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:48,375 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:48,416 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:48,617 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:49,376 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:49,617 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:50,377 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:50,618 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:51,378 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:51,618 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:52,379 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:52,619 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:53,381 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:53,416 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:53,619 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:54,383 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:54,620 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:55,384 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:55,620 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:56,385 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:56,621 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:57,386 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:57,621 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:58,387 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:58,416 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:35:58,622 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:35:59,388 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:35:59,623 [855ca690-d1ad-4600-b159-013edca2cac7-EndpointStateMachineTaskThread-/127.0.0.1:15432-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15432. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:00,389 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:01,390 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:02,391 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:03,392 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:03,417 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:36:04,393 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:05,394 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:06,395 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:07,396 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:08,397 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:08,417 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:36:09,398 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:10,399 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:11,400 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:12,401 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:13,402 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:13,417 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:36:14,403 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:15,404 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:16,405 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:17,406 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:18,407 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:18,417 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:36:19,408 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:20,409 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:21,410 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:22,411 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:23,412 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:23,418 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:36:24,413 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:25,414 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:26,415 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:27,416 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:28,417 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:28,418 [scmNode-1-FinalizationManager-0] INFO  upgrade.UpgradeFinalizer (SCMUpgradeFinalizer.java:createPipelinesAfterFinalization(199)) - Waiting for at least one open Ratis 3 pipeline after SCM finalization.
2025-12-19 13:36:29,418 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:30,419 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:31,420 [ForkJoinPool-6-worker-1] INFO  upgrade.TestHddsUpgradeUtils (TestHddsUpgradeUtils.java:lambda$waitForFinalizationFromClient$0(76)) - Waiting for upgrade finalization to complete from client. Current status is FINALIZATION_IN_PROGRESS.
2025-12-19 13:36:31,421 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(373)) - Shutting down the Mini Ozone Cluster
2025-12-19 13:36:31,421 [ForkJoinPool-6-worker-1] INFO  db.CodecTestUtil (CodecTestUtil.java:gc(50)) - gc 0
2025-12-19 13:36:31,647 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(307)) - Stopping the OzoneManager om1
2025-12-19 13:36:31,647 [ForkJoinPool-6-worker-1] INFO  om.OzoneManager (OzoneManager.java:stop(2378)) - om1[localhost:15532]: Stopping Ozone Manager
2025-12-19 13:36:31,647 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15532
2025-12-19 13:36:31,649 [IPC Server listener on 15532] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15532
2025-12-19 13:36:31,649 [ForkJoinPool-6-worker-1] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:stop(688)) - Stopping org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer@7c2fa8b8 at port 15535
2025-12-19 13:36:31,649 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:31,649 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - om1: close
2025-12-19 13:36:31,650 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - om1: shutdown server GrpcServerProtocolService now
2025-12-19 13:36:31,650 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - om1@group-C5BA1605619E: shutdown
2025-12-19 13:36:31,650 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2025-12-19 13:36:31,651 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2025-12-19 13:36:31,651 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2025-12-19 13:36:31,651 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - om1: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:36:31,651 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:31,662 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(546)) - om1: taking snapshot. applied = (t:1, i:0), skipped = -1, notified = (t:1, i:0), current snapshot index = (t:1, i:0), took 10 ms
2025-12-19 13:36:31,662 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:31,662 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:31,662 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - om1@group-C5BA1605619E-StateMachineUpdater: closing OzoneManagerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:31,662 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(586)) - Stopping OzoneManagerStateMachine-177:om1:group-C5BA1605619E.
2025-12-19 13:36:31,662 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(528)) - Stopping OMDoubleBuffer flush thread
2025-12-19 13:36:31,662 [om1-OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(587)) - OMDoubleBuffer flush thread om1-OMDoubleBufferFlushThread is interrupted and will exit.
2025-12-19 13:36:31,662 [om1@group-C5BA1605619E-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - om1@group-C5BA1605619E-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:32,211 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2025-12-19 13:36:32,211 [JvmPauseMonitor81] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-om1: Stopped
2025-12-19 13:36:32,211 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service KeyDeletingService
2025-12-19 13:36:32,213 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service DirectoryDeletingService
2025-12-19 13:36:32,213 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service OpenKeyCleanupService
2025-12-19 13:36:32,214 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SstFilteringService
2025-12-19 13:36:32,214 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SnapshotDeletingService
2025-12-19 13:36:32,214 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service MultipartUploadCleanupService
2025-12-19 13:36:32,216 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@182bb838{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2025-12-19 13:36:32,216 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@35a6583d{HTTP/1.1, (http/1.1)}{0.0.0.0:15533}
2025-12-19 13:36:32,216 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:36:32,217 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7773eff3{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-12-19 13:36:32,217 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6fbbd780{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:36:32,217 [ForkJoinPool-6-worker-1] INFO  rocksdiff.RocksDBCheckpointDiffer (RocksDBCheckpointDiffer.java:close(346)) - Shutting down CompactionDagPruningService.
2025-12-19 13:36:32,219 [ForkJoinPool-6-worker-1] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1557)) - Shutting down executorService: 'SnapDiffExecutor'
2025-12-19 13:36:32,219 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SnapshotDiffCleanupService
2025-12-19 13:36:32,220 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(314)) - Stopping the StorageContainerManager 558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:36:32,220 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1621)) - Container Balancer is not running.
2025-12-19 13:36:32,221 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1754)) - Stopping Replication Manager Service.
2025-12-19 13:36:32,221 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(319)) - Stopping Replication Monitor Thread.
2025-12-19 13:36:32,221 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1630)) - Stopping the Datanode Admin Monitor.
2025-12-19 13:36:32,221 [scmNode-2-UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-2-UnderReplicatedProcessor interrupted. Exiting...
2025-12-19 13:36:32,221 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1637)) - Stopping datanode service RPC server
2025-12-19 13:36:32,221 [scmNode-2-OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-2-OverReplicatedProcessor interrupted. Exiting...
2025-12-19 13:36:32,221 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(455)) - Stopping the RPC server for DataNodes
2025-12-19 13:36:32,221 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15502
2025-12-19 13:36:32,221 [scmNode-2-ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(940)) - Replication Monitor Thread is stopped
2025-12-19 13:36:32,226 [IPC Server listener on 15502] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15502
2025-12-19 13:36:32,226 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,247 [scmNode-2-SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(913)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-12-19 13:36:32,247 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1645)) - Stopping block service RPC server
2025-12-19 13:36:32,247 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(175)) - Stopping the RPC server for Block Protocol
2025-12-19 13:36:32,247 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15505
2025-12-19 13:36:32,250 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1652)) - Stopping the StorageContainerLocationProtocol RPC server
2025-12-19 13:36:32,251 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(220)) - Stopping the RPC server for Client Protocol
2025-12-19 13:36:32,251 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15503
2025-12-19 13:36:32,250 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,251 [IPC Server listener on 15505] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15505
2025-12-19 13:36:32,254 [IPC Server listener on 15503] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15503
2025-12-19 13:36:32,254 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,254 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1659)) - Stopping Storage Container Manager HTTP server.
2025-12-19 13:36:32,255 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5cefe85c{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:36:32,256 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@41b04bc3{HTTP/1.1, (http/1.1)}{0.0.0.0:15498}
2025-12-19 13:36:32,256 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:36:32,257 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@17f1e008{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-12-19 13:36:32,257 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@730d0914{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:36:32,258 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1667)) - Stopping SCM LayoutVersionManager Service.
2025-12-19 13:36:32,258 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1679)) - Stopping Block Manager Service.
2025-12-19 13:36:32,258 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:32,258 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:32,259 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1704)) - Stopping SCM Event Queue.
2025-12-19 13:36:32,260 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping SCM HA services.
2025-12-19 13:36:32,260 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:stop(267)) - stopping ratis server 0.0.0.0:15501
2025-12-19 13:36:32,260 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: close
2025-12-19 13:36:32,262 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: shutdown server GrpcServerProtocolService now
2025-12-19 13:36:32,262 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC: shutdown
2025-12-19 13:36:32,262 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=558504b9-cfec-4766-96f9-7b6ebb0f3b76
2025-12-19 13:36:32,262 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: shutdown 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState
2025-12-19 13:36:32,262 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: set stopIndex = 66
2025-12-19 13:36:32,263 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-FollowerState was interrupted
2025-12-19 13:36:32,263 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:36:32,264 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:takeSnapshot(332)) - Current Snapshot Index 66, takeSnapshot took 1 ms
2025-12-19 13:36:32,264 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: Took a snapshot at index 66
2025-12-19 13:36:32,264 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: snapshotIndex: updateIncreasingly 61 -> 66
2025-12-19 13:36:32,265 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:3, i:66)
2025-12-19 13:36:32,265 [558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:32,275 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: APPEND_ENTRIES onError, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->558504b9-cfec-4766-96f9-7b6ebb0f3b76#3-t3,previous=(t:3, i:65),leaderCommit=65,initializing? false,entries: size=1, first=(t:3, i:66), METADATAENTRY(c:65): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:36:32,275 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:36:32,275 [grpc-default-executor-6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (67) unchanged and retry.
2025-12-19 13:36:32,275 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:36:32,419 [558504b9-cfec-4766-96f9-7b6ebb0f3b76-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76@group-3149B70783DC-SegmentedRaftLogWorker close()
2025-12-19 13:36:32,419 [JvmPauseMonitor85] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-558504b9-cfec-4766-96f9-7b6ebb0f3b76: Stopped
2025-12-19 13:36:32,419 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(127)) - Stopping SCMHATransactionMonitor Service.
2025-12-19 13:36:32,419 [scmNode-2-SCMHATransactionMonitor] WARN  SCMHATransactionMonitor (BackgroundSCMService.java:run(111)) - SCMHATransactionMonitor is interrupted, exit
2025-12-19 13:36:32,420 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-2-RatisPipelineUtilsThread.
2025-12-19 13:36:32,420 [scmNode-2-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-2-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:36:32,420 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(127)) - Stopping BackgroundPipelineScrubber Service.
2025-12-19 13:36:32,420 [scmNode-2-BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(111)) - BackgroundPipelineScrubber is interrupted, exit
2025-12-19 13:36:32,423 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2025-12-19 13:36:32,423 [ForkJoinPool-6-worker-1] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - scmNode-2-RatisPipelineUtilsThread is not running, just ignore.
2025-12-19 13:36:32,423 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(122)) - BackgroundPipelineScrubber Service is not running, skip stop.
2025-12-19 13:36:32,423 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(127)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:36:32,423 [scmNode-2-ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(111)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2025-12-19 13:36:32,423 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:32,424 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(326)) - Replication Monitor Thread is not running.
2025-12-19 13:36:32,424 [ForkJoinPool-6-worker-1] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(362)) - Cannot stop Container Balancer because it's not running or stopping
2025-12-19 13:36:32,424 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(122)) - SCMHATransactionMonitor Service is not running, skip stop.
2025-12-19 13:36:32,424 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1745)) - Stopping SCM MetadataStore.
2025-12-19 13:36:32,424 [scmNode-2-LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(285)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1167)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:283)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:32,429 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(314)) - Stopping the StorageContainerManager 6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:36:32,429 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1621)) - Container Balancer is not running.
2025-12-19 13:36:32,429 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1754)) - Stopping Replication Manager Service.
2025-12-19 13:36:32,430 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(319)) - Stopping Replication Monitor Thread.
2025-12-19 13:36:32,430 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1630)) - Stopping the Datanode Admin Monitor.
2025-12-19 13:36:32,430 [scmNode-3-ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(940)) - Replication Monitor Thread is stopped
2025-12-19 13:36:32,430 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1637)) - Stopping datanode service RPC server
2025-12-19 13:36:32,430 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(455)) - Stopping the RPC server for DataNodes
2025-12-19 13:36:32,430 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15510
2025-12-19 13:36:32,430 [scmNode-3-OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-3-OverReplicatedProcessor interrupted. Exiting...
2025-12-19 13:36:32,430 [scmNode-3-UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-3-UnderReplicatedProcessor interrupted. Exiting...
2025-12-19 13:36:32,434 [IPC Server listener on 15510] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15510
2025-12-19 13:36:32,434 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,447 [scmNode-3-SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(913)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-12-19 13:36:32,447 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1645)) - Stopping block service RPC server
2025-12-19 13:36:32,447 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(175)) - Stopping the RPC server for Block Protocol
2025-12-19 13:36:32,447 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15513
2025-12-19 13:36:32,451 [IPC Server listener on 15513] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15513
2025-12-19 13:36:32,451 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1652)) - Stopping the StorageContainerLocationProtocol RPC server
2025-12-19 13:36:32,451 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(220)) - Stopping the RPC server for Client Protocol
2025-12-19 13:36:32,452 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15511
2025-12-19 13:36:32,451 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,455 [IPC Server listener on 15511] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15511
2025-12-19 13:36:32,455 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,455 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1659)) - Stopping Storage Container Manager HTTP server.
2025-12-19 13:36:32,456 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@34cc9b51{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:36:32,457 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@2414bc13{HTTP/1.1, (http/1.1)}{0.0.0.0:15506}
2025-12-19 13:36:32,457 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:36:32,458 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1836ac04{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-12-19 13:36:32,458 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1aaa059d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:36:32,459 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1667)) - Stopping SCM LayoutVersionManager Service.
2025-12-19 13:36:32,459 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1679)) - Stopping Block Manager Service.
2025-12-19 13:36:32,459 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:32,460 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:32,460 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1704)) - Stopping SCM Event Queue.
2025-12-19 13:36:32,460 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping SCM HA services.
2025-12-19 13:36:32,461 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:stop(267)) - stopping ratis server 0.0.0.0:15509
2025-12-19 13:36:32,461 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 6a054400-8896-4262-aa80-3995e76ba098: close
2025-12-19 13:36:32,464 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown server GrpcServerProtocolService now
2025-12-19 13:36:32,464 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC: shutdown
2025-12-19 13:36:32,464 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=6a054400-8896-4262-aa80-3995e76ba098
2025-12-19 13:36:32,464 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState
2025-12-19 13:36:32,464 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: set stopIndex = 66
2025-12-19 13:36:32,464 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-FollowerState was interrupted
2025-12-19 13:36:32,465 [Thread-20930] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76 Close channels
2025-12-19 13:36:32,465 [Thread-20932] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f Close channels
2025-12-19 13:36:32,465 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:takeSnapshot(332)) - Current Snapshot Index 66, takeSnapshot took 1 ms
2025-12-19 13:36:32,466 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: Took a snapshot at index 66
2025-12-19 13:36:32,466 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: snapshotIndex: updateIncreasingly 61 -> 66
2025-12-19 13:36:32,466 [grpc-default-executor-7] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - 6a054400-8896-4262-aa80-3995e76ba098: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:36:32,466 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:3, i:66)
2025-12-19 13:36:32,466 [6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:32,467 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 6a054400-8896-4262-aa80-3995e76ba098: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:36:32,466 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - 6a054400-8896-4262-aa80-3995e76ba098: APPEND_ENTRIES onError, lastRequest: 50ee075d-c1e7-43b2-938b-a7dc0bd7923f->6a054400-8896-4262-aa80-3995e76ba098#4-t3,previous=(t:3, i:65),leaderCommit=65,initializing? false,entries: size=1, first=(t:3, i:66), METADATAENTRY(c:65): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:36:32,470 [grpc-default-executor-9] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:36:32,470 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (67) unchanged and retry.
2025-12-19 13:36:32,548 [6a054400-8896-4262-aa80-3995e76ba098-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 6a054400-8896-4262-aa80-3995e76ba098@group-3149B70783DC-SegmentedRaftLogWorker close()
2025-12-19 13:36:32,548 [JvmPauseMonitor86] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-6a054400-8896-4262-aa80-3995e76ba098: Stopped
2025-12-19 13:36:32,548 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(127)) - Stopping SCMHATransactionMonitor Service.
2025-12-19 13:36:32,548 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-3-RatisPipelineUtilsThread.
2025-12-19 13:36:32,548 [scmNode-3-SCMHATransactionMonitor] WARN  SCMHATransactionMonitor (BackgroundSCMService.java:run(111)) - SCMHATransactionMonitor is interrupted, exit
2025-12-19 13:36:32,548 [scmNode-3-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-3-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:36:32,549 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(127)) - Stopping BackgroundPipelineScrubber Service.
2025-12-19 13:36:32,549 [scmNode-3-BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(111)) - BackgroundPipelineScrubber is interrupted, exit
2025-12-19 13:36:32,549 [ForkJoinPool-6-worker-1] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - scmNode-3-RatisPipelineUtilsThread is not running, just ignore.
2025-12-19 13:36:32,549 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(122)) - BackgroundPipelineScrubber Service is not running, skip stop.
2025-12-19 13:36:32,549 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(127)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:36:32,549 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:32,549 [scmNode-3-ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(111)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2025-12-19 13:36:32,549 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(326)) - Replication Monitor Thread is not running.
2025-12-19 13:36:32,550 [ForkJoinPool-6-worker-1] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(362)) - Cannot stop Container Balancer because it's not running or stopping
2025-12-19 13:36:32,550 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(122)) - SCMHATransactionMonitor Service is not running, skip stop.
2025-12-19 13:36:32,550 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1745)) - Stopping SCM MetadataStore.
2025-12-19 13:36:32,550 [scmNode-3-LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(285)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1167)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:283)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:32,557 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneHAClusterImpl (MiniOzoneHAClusterImpl.java:stop(314)) - Stopping the StorageContainerManager 50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:36:32,557 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1621)) - Container Balancer is not running.
2025-12-19 13:36:32,557 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1754)) - Stopping Replication Manager Service.
2025-12-19 13:36:32,557 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(319)) - Stopping Replication Monitor Thread.
2025-12-19 13:36:32,557 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1630)) - Stopping the Datanode Admin Monitor.
2025-12-19 13:36:32,557 [scmNode-1-ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(940)) - Replication Monitor Thread is stopped
2025-12-19 13:36:32,557 [scmNode-1-OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-1-OverReplicatedProcessor interrupted. Exiting...
2025-12-19 13:36:32,557 [scmNode-1-UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(178)) - scmNode-1-UnderReplicatedProcessor interrupted. Exiting...
2025-12-19 13:36:32,557 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1637)) - Stopping datanode service RPC server
2025-12-19 13:36:32,557 [ForkJoinPool-6-worker-1] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(455)) - Stopping the RPC server for DataNodes
2025-12-19 13:36:32,557 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15494
2025-12-19 13:36:32,560 [IPC Server listener on 15494] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15494
2025-12-19 13:36:32,560 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,647 [scmNode-1-SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(913)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2025-12-19 13:36:32,647 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1645)) - Stopping block service RPC server
2025-12-19 13:36:32,647 [ForkJoinPool-6-worker-1] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(175)) - Stopping the RPC server for Block Protocol
2025-12-19 13:36:32,647 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15497
2025-12-19 13:36:32,651 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1652)) - Stopping the StorageContainerLocationProtocol RPC server
2025-12-19 13:36:32,651 [ForkJoinPool-6-worker-1] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(220)) - Stopping the RPC server for Client Protocol
2025-12-19 13:36:32,651 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15495
2025-12-19 13:36:32,651 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,651 [IPC Server listener on 15497] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15497
2025-12-19 13:36:32,655 [IPC Server listener on 15495] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15495
2025-12-19 13:36:32,655 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1659)) - Stopping Storage Container Manager HTTP server.
2025-12-19 13:36:32,655 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2131f4bc{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2025-12-19 13:36:32,656 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:32,656 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@bdd6cf{HTTP/1.1, (http/1.1)}{0.0.0.0:15490}
2025-12-19 13:36:32,656 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:36:32,656 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@698f943d{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2025-12-19 13:36:32,656 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2e597b23{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:36:32,657 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1667)) - Stopping SCM LayoutVersionManager Service.
2025-12-19 13:36:32,657 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1679)) - Stopping Block Manager Service.
2025-12-19 13:36:32,657 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:32,658 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:32,658 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1704)) - Stopping SCM Event Queue.
2025-12-19 13:36:32,658 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping SCM HA services.
2025-12-19 13:36:32,658 [ForkJoinPool-6-worker-1] INFO  ha.SCMRatisServerImpl (SCMRatisServerImpl.java:stop(267)) - stopping ratis server 0.0.0.0:15493
2025-12-19 13:36:32,659 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: close
2025-12-19 13:36:32,662 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown server GrpcServerProtocolService now
2025-12-19 13:36:32,662 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC: shutdown
2025-12-19 13:36:32,662 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3149B70783DC,id=50ee075d-c1e7-43b2-938b-a7dc0bd7923f
2025-12-19 13:36:32,663 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-LeaderStateImpl
2025-12-19 13:36:32,663 [Thread-20934] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 558504b9-cfec-4766-96f9-7b6ebb0f3b76 Close channels
2025-12-19 13:36:32,663 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-PendingRequests: sendNotLeaderResponses
2025-12-19 13:36:32,663 [Thread-20935] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 6a054400-8896-4262-aa80-3995e76ba098 Close channels
2025-12-19 13:36:32,663 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(304)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->6a054400-8896-4262-aa80-3995e76ba098-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-12-19 13:36:32,663 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(304)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC->558504b9-cfec-4766-96f9-7b6ebb0f3b76-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-12-19 13:36:32,663 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:36:32,663 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  ha.SCMStateMachine (SCMStateMachine.java:notifyNotLeader(213)) - current leader SCM steps down.
2025-12-19 13:36:32,664 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(95)) - update <isLeader,term> from <true,3> to <false,0>
2025-12-19 13:36:32,664 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  ha.SCMContext (SCMContext.java:updateLeaderAndTerm(101)) - update <isLeaderReady> from <true> to <false>
2025-12-19 13:36:32,664 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(84)) - Service BackgroundPipelineScrubber transitions to PAUSING.
2025-12-19 13:36:32,664 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(84)) - Service ExpiredContainerReplicaOpScrubber transitions to PAUSING.
2025-12-19 13:36:32,664 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:notifyStatusChanged(84)) - Service SCMHATransactionMonitor transitions to PAUSING.
2025-12-19 13:36:32,664 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: set stopIndex = 66
2025-12-19 13:36:32,666 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  ha.SCMStateMachine (SCMStateMachine.java:takeSnapshot(332)) - Current Snapshot Index 66, takeSnapshot took 1 ms
2025-12-19 13:36:32,666 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: Took a snapshot at index 66
2025-12-19 13:36:32,666 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: snapshotIndex: updateIncreasingly 64 -> 66
2025-12-19 13:36:32,666 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:3, i:66)
2025-12-19 13:36:32,666 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:33,119 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15494 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "localhost/127.0.0.1"; destination host is: "localhost":15494; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:910)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)
	at org.apache.hadoop.ipc_.Client$IpcStreams.readResponse(Client.java:1873)
	at org.apache.hadoop.ipc_.Client$Connection.receiveRpcResponse(Client.java:1165)
	at org.apache.hadoop.ipc_.Client$Connection.run(Client.java:1056)
2025-12-19 13:36:33,119 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15510 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "localhost/127.0.0.1"; destination host is: "localhost":15510; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:910)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)
	at org.apache.hadoop.ipc_.Client$IpcStreams.readResponse(Client.java:1873)
	at org.apache.hadoop.ipc_.Client$Connection.receiveRpcResponse(Client.java:1165)
	at org.apache.hadoop.ipc_.Client$Connection.run(Client.java:1056)
2025-12-19 13:36:33,119 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(239)) - Unable to communicate to SCM server at localhost/127.0.0.1:15502 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "localhost/127.0.0.1"; destination host is: "localhost":15502; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:62)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:961)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:910)
	at org.apache.hadoop.ipc_.Client.getRpcResponse(Client.java:1546)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc_.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
	at jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readFully(DataInputStream.java:210)
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:385)
	at org.apache.hadoop.ipc_.Client$IpcStreams.readResponse(Client.java:1873)
	at org.apache.hadoop.ipc_.Client$Connection.receiveRpcResponse(Client.java:1165)
	at org.apache.hadoop.ipc_.Client$Connection.run(Client.java:1056)
2025-12-19 13:36:33,418 [scmNode-1-FinalizationManager-0] WARN  ha.SCMContext (SCMContext.java:getTermOfLeader(203)) - getTerm is invoked when not leader.
2025-12-19 13:36:33,418 [scmNode-1-FinalizationManager-0] WARN  upgrade.DefaultUpgradeFinalizationExecutor (DefaultUpgradeFinalizationExecutor.java:execute(54)) - Upgrade Finalization failed with following Exception. 
org.apache.ratis.protocol.exceptions.NotLeaderException: Server 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC is not the leader
	at org.apache.hadoop.hdds.scm.ha.SCMRatisServerImpl.triggerNotLeaderException(SCMRatisServerImpl.java:316)
	at org.apache.hadoop.hdds.scm.ha.SCMContext.getTermOfLeader(SCMContext.java:209)
	at org.apache.hadoop.hdds.scm.server.upgrade.SCMUpgradeFinalizer.createPipelinesAfterFinalization(SCMUpgradeFinalizer.java:187)
	at org.apache.hadoop.hdds.scm.server.upgrade.SCMUpgradeFinalizer.postFinalizeUpgrade(SCMUpgradeFinalizer.java:119)
	at org.apache.hadoop.hdds.scm.server.upgrade.SCMUpgradeFinalizer.postFinalizeUpgrade(SCMUpgradeFinalizer.java:44)
	at org.apache.hadoop.ozone.upgrade.DefaultUpgradeFinalizationExecutor.execute(DefaultUpgradeFinalizationExecutor.java:50)
	at org.apache.hadoop.ozone.upgrade.BasicUpgradeFinalizer.finalize(BasicUpgradeFinalizer.java:104)
	at org.apache.hadoop.hdds.scm.server.upgrade.FinalizationManagerImpl.finalizeUpgrade(FinalizationManagerImpl.java:115)
	at org.apache.hadoop.hdds.scm.server.upgrade.FinalizationManagerImpl.lambda$onLeaderReady$0(FinalizationManagerImpl.java:168)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:33,419 [50ee075d-c1e7-43b2-938b-a7dc0bd7923f-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 50ee075d-c1e7-43b2-938b-a7dc0bd7923f@group-3149B70783DC-SegmentedRaftLogWorker close()
2025-12-19 13:36:33,419 [JvmPauseMonitor87] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-50ee075d-c1e7-43b2-938b-a7dc0bd7923f: Stopped
2025-12-19 13:36:33,419 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(127)) - Stopping SCMHATransactionMonitor Service.
2025-12-19 13:36:33,419 [scmNode-1-SCMHATransactionMonitor] WARN  SCMHATransactionMonitor (BackgroundSCMService.java:run(111)) - SCMHATransactionMonitor is interrupted, exit
2025-12-19 13:36:33,420 [ForkJoinPool-6-worker-1] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(154)) - Stopping scmNode-1-RatisPipelineUtilsThread.
2025-12-19 13:36:33,420 [scmNode-1-RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(185)) - scmNode-1-RatisPipelineUtilsThread is interrupted.
2025-12-19 13:36:33,420 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(127)) - Stopping BackgroundPipelineScrubber Service.
2025-12-19 13:36:33,420 [scmNode-1-BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(111)) - BackgroundPipelineScrubber is interrupted, exit
2025-12-19 13:36:33,420 [ForkJoinPool-6-worker-1] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(150)) - scmNode-1-RatisPipelineUtilsThread is not running, just ignore.
2025-12-19 13:36:33,420 [ForkJoinPool-6-worker-1] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(122)) - BackgroundPipelineScrubber Service is not running, skip stop.
2025-12-19 13:36:33,420 [ForkJoinPool-6-worker-1] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(127)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2025-12-19 13:36:33,420 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service SCMBlockDeletingService
2025-12-19 13:36:33,420 [scmNode-1-ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(111)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2025-12-19 13:36:33,420 [ForkJoinPool-6-worker-1] INFO  replication.ReplicationManager (ReplicationManager.java:stop(326)) - Replication Monitor Thread is not running.
2025-12-19 13:36:33,421 [ForkJoinPool-6-worker-1] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(362)) - Cannot stop Container Balancer because it's not running or stopping
2025-12-19 13:36:33,421 [ForkJoinPool-6-worker-1] INFO  SCMHATransactionMonitor (BackgroundSCMService.java:stop(122)) - SCMHATransactionMonitor Service is not running, skip stop.
2025-12-19 13:36:33,421 [ForkJoinPool-6-worker-1] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1745)) - Stopping SCM MetadataStore.
2025-12-19 13:36:33,421 [scmNode-1-LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(285)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1167)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:283)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:33,426 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(389)) - Stopping the Mini Ozone Cluster
2025-12-19 13:36:33,426 [ForkJoinPool-6-worker-1] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(443)) - Stopping the HddsDatanodes
2025-12-19 13:36:33,427 [ForkJoinPool-6-worker-4] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(568)) - Attempting to stop container services.
2025-12-19 13:36:33,427 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-12-19 13:36:33,427 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@3999f569 exiting.
2025-12-19 13:36:33,427 [ForkJoinPool-6-worker-4] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(87)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds) is shutting down. 
2025-12-19 13:36:33,427 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-12-19 13:36:33,428 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds, DS-66019413-eed9-4305-abd0-b794a6497ecc) exiting.
2025-12-19 13:36:33,428 [ForkJoinPool-6-worker-4] INFO  ozoneimpl.OnDemandContainerScanner (OnDemandContainerScanner.java:shutdown(141)) - On-demand container scanner is shutting down.
2025-12-19 13:36:33,428 [ForkJoinPool-6-worker-4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(b8c29964-8a98-47a9-8b1d-466622f5f9c1)
2025-12-19 13:36:33,428 [ForkJoinPool-6-worker-4] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: close
2025-12-19 13:36:33,429 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160: shutdown
2025-12-19 13:36:33,429 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF0630B18160,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:36:33,429 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61: shutdown
2025-12-19 13:36:33,429 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-LeaderStateImpl
2025-12-19 13:36:33,429 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-PendingRequests: sendNotLeaderResponses
2025-12-19 13:36:33,429 [ForkJoinPool-6-worker-4] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-12-19 13:36:33,429 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FollowerState
2025-12-19 13:36:33,429 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread4] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401: shutdown
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-FollowerState was interrupted
2025-12-19 13:36:33,430 [Thread-20943] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 57412301-a084-4aa6-8e22-91ecff01c376 Close channels
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-6AA3D4F57C61: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/sm/snapshot.1_0
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread4] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-579D88BAA401,id=b8c29964-8a98-47a9-8b1d-466622f5f9c1
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-LeaderStateImpl
2025-12-19 13:36:33,430 [Thread-20945] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 9f85a268-b54d-42c0-89e3-0f143f429527 Close channels
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread4] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-PendingRequests: sendNotLeaderResponses
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->9f85a268-b54d-42c0-89e3-0f143f429527-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(304)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->9f85a268-b54d-42c0-89e3-0f143f429527-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-12-19 13:36:33,431 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->57412301-a084-4aa6-8e22-91ecff01c376-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(304)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->57412301-a084-4aa6-8e22-91ecff01c376-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-12-19 13:36:33,431 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:33,430 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-FF0630B18160: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/e9c493b0-d510-4c9a-94da-ff0630b18160/sm/snapshot.1_0
2025-12-19 13:36:33,431 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-579D88BAA401: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/83edabe4-a852-4d54-beae-579d88baa401/sm/snapshot.1_0
2025-12-19 13:36:33,431 [grpc-default-executor-8] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 9f85a268-b54d-42c0-89e3-0f143f429527: Completed APPEND_ENTRIES, lastRequest: b8c29964-8a98-47a9-8b1d-466622f5f9c1->9f85a268-b54d-42c0-89e3-0f143f429527#1-t1,previous=<PROTO_DEFAULT>,leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id:"57412301-a084-4aa6-8e22-91ecff01c376"address:"127.0.0.1:15549"dataStreamAddress:"127.0.0.1:15550"clientAddress:"127.0.0.1:15547"adminAddress:"127.0.0.1:15548"startupRole:FOLLOWER, id:"b8c29964-8a98-47a9-8b1d-466622f5f9c1"address:"127.0.0.1:15541"priority:1dataStreamAddress:"127.0.0.1:15542"clientAddress:"127.0.0.1:15539"adminAddress:"127.0.0.1:15540"startupRole:FOLLOWER, id:"9f85a268-b54d-42c0-89e3-0f143f429527"address:"127.0.0.1:15557"dataStreamAddress:"127.0.0.1:15558"clientAddress:"127.0.0.1:15555"adminAddress:"127.0.0.1:15556"startupRole:FOLLOWER, old:) 
2025-12-19 13:36:33,431 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$6(173)) - 57412301-a084-4aa6-8e22-91ecff01c376: Completed APPEND_ENTRIES, lastRequest: b8c29964-8a98-47a9-8b1d-466622f5f9c1->57412301-a084-4aa6-8e22-91ecff01c376#1-t1,previous=<PROTO_DEFAULT>,leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id:"57412301-a084-4aa6-8e22-91ecff01c376"address:"127.0.0.1:15549"dataStreamAddress:"127.0.0.1:15550"clientAddress:"127.0.0.1:15547"adminAddress:"127.0.0.1:15548"startupRole:FOLLOWER, id:"b8c29964-8a98-47a9-8b1d-466622f5f9c1"address:"127.0.0.1:15541"priority:1dataStreamAddress:"127.0.0.1:15542"clientAddress:"127.0.0.1:15539"adminAddress:"127.0.0.1:15540"startupRole:FOLLOWER, id:"9f85a268-b54d-42c0-89e3-0f143f429527"address:"127.0.0.1:15557"dataStreamAddress:"127.0.0.1:15558"clientAddress:"127.0.0.1:15555"adminAddress:"127.0.0.1:15556"startupRole:FOLLOWER, old:) 
2025-12-19 13:36:33,431 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 57412301-a084-4aa6-8e22-91ecff01c376: Completed APPEND_ENTRIES, lastReply: null 
2025-12-19 13:36:33,432 [grpc-default-executor-9] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$null$7(177)) - 9f85a268-b54d-42c0-89e3-0f143f429527: Completed APPEND_ENTRIES, lastReply: serverReply { requestorId: "b8c29964-8a98-47a9-8b1d-466622f5f9c1" replyId: "9f85a268-b54d-42c0-89e3-0f143f429527" raftGroupId { id: "\203\355\253\344\250RMT\276\256W\235\210\272\244\001" } callId: 52 success: true } term: 1 nextIndex: 1 matchIndex: 18446744073709551615 isHearbeat: true 
2025-12-19 13:36:33,432 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(562)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->57412301-a084-4aa6-8e22-91ecff01c376-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-12-19 13:36:33,432 [grpc-default-executor-9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(562)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->9f85a268-b54d-42c0-89e3-0f143f429527-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-12-19 13:36:33,432 [grpc-default-executor-6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(241)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->57412301-a084-4aa6-8e22-91ecff01c376-GrpcLogAppender: Failed to resetClient for 57412301-a084-4aa6-8e22-91ecff01c376
org.apache.ratis.protocol.exceptions.AlreadyClosedException: b8c29964-8a98-47a9-8b1d-466622f5f9c1 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:70)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:127)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:211)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:216)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:70)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:563)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:579)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:565)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:72)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:733)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:714)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:33,432 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(241)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->9f85a268-b54d-42c0-89e3-0f143f429527-GrpcLogAppender: Failed to resetClient for 9f85a268-b54d-42c0-89e3-0f143f429527
org.apache.ratis.protocol.exceptions.AlreadyClosedException: b8c29964-8a98-47a9-8b1d-466622f5f9c1 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:70)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:127)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:211)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:216)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:70)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:563)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:579)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:565)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:72)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:733)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:714)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:33,433 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(562)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->57412301-a084-4aa6-8e22-91ecff01c376-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-12-19 13:36:33,433 [grpc-default-executor-6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(241)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->57412301-a084-4aa6-8e22-91ecff01c376-GrpcLogAppender: Failed to resetClient for 57412301-a084-4aa6-8e22-91ecff01c376
org.apache.ratis.protocol.exceptions.AlreadyClosedException: b8c29964-8a98-47a9-8b1d-466622f5f9c1 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:70)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:127)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:211)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:216)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:70)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:563)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:579)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:487)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:451)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:484)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:565)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:72)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:733)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:714)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:33,433 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-6AA3D4F57C61: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/sm/snapshot.1_0 took: 4 ms
2025-12-19 13:36:33,433 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-579D88BAA401: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/83edabe4-a852-4d54-beae-579d88baa401/sm/snapshot.1_0 took: 2 ms
2025-12-19 13:36:33,433 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:33,433 [grpc-default-executor-9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(562)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->9f85a268-b54d-42c0-89e3-0f143f429527-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-12-19 13:36:33,433 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:33,433 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:33,433 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:33,434 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:33,433 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(241)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401->9f85a268-b54d-42c0-89e3-0f143f429527-GrpcLogAppender: Failed to resetClient for 9f85a268-b54d-42c0-89e3-0f143f429527
org.apache.ratis.protocol.exceptions.AlreadyClosedException: b8c29964-8a98-47a9-8b1d-466622f5f9c1 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:70)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:127)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:211)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:216)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:70)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:563)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:579)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:565)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:72)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:733)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:714)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:33,434 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-FF0630B18160: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/ratis/e9c493b0-d510-4c9a-94da-ff0630b18160/sm/snapshot.1_0 took: 4 ms
2025-12-19 13:36:33,434 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:33,434 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:33,434 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:33,434 [ForkJoinPool-6-worker-4] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-12-19 13:36:33,434 [ForkJoinPool-6-worker-4] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown server GrpcServerProtocolService now
2025-12-19 13:36:33,434 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:33,434 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:33,434 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:33,435 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(127)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->b8c29964-8a98-47a9-8b1d-466622f5f9c1-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2025-12-19 13:36:33,435 [grpc-default-executor-8] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(232)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->b8c29964-8a98-47a9-8b1d-466622f5f9c1-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (1) unchanged and retry.
2025-12-19 13:36:33,435 [b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:33,435 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: APPEND_ENTRIES onError, lastRequest: 9f85a268-b54d-42c0-89e3-0f143f429527->b8c29964-8a98-47a9-8b1d-466622f5f9c1#1-t1,previous=<PROTO_DEFAULT>,leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id:"b8c29964-8a98-47a9-8b1d-466622f5f9c1"address:"127.0.0.1:15541"dataStreamAddress:"127.0.0.1:15542"clientAddress:"127.0.0.1:15539"adminAddress:"127.0.0.1:15540"startupRole:FOLLOWER, id:"57412301-a084-4aa6-8e22-91ecff01c376"address:"127.0.0.1:15549"dataStreamAddress:"127.0.0.1:15550"clientAddress:"127.0.0.1:15547"adminAddress:"127.0.0.1:15548"startupRole:FOLLOWER, id:"9f85a268-b54d-42c0-89e3-0f143f429527"address:"127.0.0.1:15557"priority:1dataStreamAddress:"127.0.0.1:15558"clientAddress:"127.0.0.1:15555"adminAddress:"127.0.0.1:15556"startupRole:FOLLOWER, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:36:33,435 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(127)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2025-12-19 13:36:33,435 [ForkJoinPool-6-worker-4] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:36:33,435 [ForkJoinPool-6-worker-4] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-12-19 13:36:33,436 [ForkJoinPool-6-worker-4] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-12-19 13:36:33,438 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9bc55302, L:/0.0.0.0:15542] CLOSE
2025-12-19 13:36:33,438 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9bc55302, L:/0.0.0.0:15542] INACTIVE
2025-12-19 13:36:33,438 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9bc55302, L:/0.0.0.0:15542] UNREGISTERED
2025-12-19 13:36:33,881 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-6AA3D4F57C61-SegmentedRaftLogWorker close()
2025-12-19 13:36:33,882 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread3] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-6AA3D4F57C61 is closed by HddsDatanodeService
2025-12-19 13:36:33,961 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-579D88BAA401-SegmentedRaftLogWorker close()
2025-12-19 13:36:33,961 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread4] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-579D88BAA401 is closed by HddsDatanodeService
2025-12-19 13:36:34,002 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1@group-FF0630B18160-SegmentedRaftLogWorker close()
2025-12-19 13:36:34,003 [b8c29964-8a98-47a9-8b1d-466622f5f9c1-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-FF0630B18160 is closed by HddsDatanodeService
2025-12-19 13:36:34,003 [JvmPauseMonitor82] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-b8c29964-8a98-47a9-8b1d-466622f5f9c1: Stopped
2025-12-19 13:36:34,123 [ForkJoinPool-6-worker-3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(568)) - Attempting to stop container services.
2025-12-19 13:36:34,123 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15494. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:34,123 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15510. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:34,123 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15502. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:34,123 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-12-19 13:36:34,124 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@60df7f24 exiting.
2025-12-19 13:36:34,124 [ForkJoinPool-6-worker-3] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(87)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds) is shutting down. 
2025-12-19 13:36:34,124 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-12-19 13:36:34,124 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds, DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d) exiting.
2025-12-19 13:36:34,124 [ForkJoinPool-6-worker-3] INFO  ozoneimpl.OnDemandContainerScanner (OnDemandContainerScanner.java:shutdown(141)) - On-demand container scanner is shutting down.
2025-12-19 13:36:34,124 [ForkJoinPool-6-worker-3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(9f85a268-b54d-42c0-89e3-0f143f429527)
2025-12-19 13:36:34,124 [ForkJoinPool-6-worker-3] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 9f85a268-b54d-42c0-89e3-0f143f429527: close
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61: shutdown
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:36:34,125 [ForkJoinPool-6-worker-3] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread4] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2: shutdown
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread4] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B70A942B69E2,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-LeaderStateImpl
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401: shutdown
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread4] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-PendingRequests: sendNotLeaderResponses
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-LeaderStateImpl
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-PendingRequests: sendNotLeaderResponses
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->57412301-a084-4aa6-8e22-91ecff01c376-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(304)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->57412301-a084-4aa6-8e22-91ecff01c376-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-579D88BAA401,id=9f85a268-b54d-42c0-89e3-0f143f429527
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FollowerState
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->b8c29964-8a98-47a9-8b1d-466622f5f9c1-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(304)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->b8c29964-8a98-47a9-8b1d-466622f5f9c1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2025-12-19 13:36:34,125 [Thread-20985] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - 57412301-a084-4aa6-8e22-91ecff01c376 Close channels
2025-12-19 13:36:34,126 [Thread-20984] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(92)) - b8c29964-8a98-47a9-8b1d-466622f5f9c1 Close channels
2025-12-19 13:36:34,125 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-579D88BAA401: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/83edabe4-a852-4d54-beae-579d88baa401/sm/snapshot.1_0
2025-12-19 13:36:34,126 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-6AA3D4F57C61: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/sm/snapshot.1_0
2025-12-19 13:36:34,126 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:34,126 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-FollowerState was interrupted
2025-12-19 13:36:34,126 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-B70A942B69E2: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/06657f59-31dc-40a9-89f4-b70a942b69e2/sm/snapshot.1_0
2025-12-19 13:36:34,126 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(562)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->57412301-a084-4aa6-8e22-91ecff01c376-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-12-19 13:36:34,127 [grpc-default-executor-8] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(241)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->57412301-a084-4aa6-8e22-91ecff01c376-GrpcLogAppender: Failed to resetClient for 57412301-a084-4aa6-8e22-91ecff01c376
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 9f85a268-b54d-42c0-89e3-0f143f429527 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:70)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:127)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:211)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:216)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:70)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:563)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:579)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:487)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:451)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:484)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:565)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:72)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:733)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:714)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:34,127 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-579D88BAA401: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/83edabe4-a852-4d54-beae-579d88baa401/sm/snapshot.1_0 took: 1 ms
2025-12-19 13:36:34,127 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:34,127 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:34,127 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(562)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->57412301-a084-4aa6-8e22-91ecff01c376-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2025-12-19 13:36:34,127 [grpc-default-executor-6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(241)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61->57412301-a084-4aa6-8e22-91ecff01c376-GrpcLogAppender: Failed to resetClient for 57412301-a084-4aa6-8e22-91ecff01c376
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 9f85a268-b54d-42c0-89e3-0f143f429527 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:70)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:127)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:211)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:216)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:70)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:563)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:579)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:565)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:72)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:733)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:714)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2025-12-19 13:36:34,127 [ForkJoinPool-6-worker-3] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-12-19 13:36:34,127 [ForkJoinPool-6-worker-3] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown server GrpcServerProtocolService now
2025-12-19 13:36:34,127 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-6AA3D4F57C61: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/sm/snapshot.1_0 took: 1 ms
2025-12-19 13:36:34,127 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-B70A942B69E2: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/ratis/06657f59-31dc-40a9-89f4-b70a942b69e2/sm/snapshot.1_0 took: 0 ms
2025-12-19 13:36:34,128 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:34,128 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:34,128 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:34,128 [ForkJoinPool-6-worker-3] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:36:34,128 [ForkJoinPool-6-worker-3] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-12-19 13:36:34,128 [9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:34,128 [ForkJoinPool-6-worker-3] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 9f85a268-b54d-42c0-89e3-0f143f429527: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-12-19 13:36:34,127 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:34,128 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:34,128 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:34,128 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:34,128 [9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:34,129 [9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:34,131 [9f85a268-b54d-42c0-89e3-0f143f429527-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa70ed6a6, L:/0.0.0.0:15558] CLOSE
2025-12-19 13:36:34,131 [9f85a268-b54d-42c0-89e3-0f143f429527-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa70ed6a6, L:/0.0.0.0:15558] INACTIVE
2025-12-19 13:36:34,131 [9f85a268-b54d-42c0-89e3-0f143f429527-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa70ed6a6, L:/0.0.0.0:15558] UNREGISTERED
2025-12-19 13:36:34,159 [ForkJoinPool-6-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(568)) - Attempting to stop container services.
2025-12-19 13:36:34,159 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-12-19 13:36:34,159 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - org.apache.hadoop.ozone.container.ozoneimpl.BackgroundContainerMetadataScanner@7acf4ab1 exiting.
2025-12-19 13:36:34,159 [ForkJoinPool-6-worker-1] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(87)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds) is shutting down. 
2025-12-19 13:36:34,159 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(136)) - Background container scan was interrupted.
2025-12-19 13:36:34,159 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(63)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds, DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4) exiting.
2025-12-19 13:36:34,160 [ForkJoinPool-6-worker-1] INFO  ozoneimpl.OnDemandContainerScanner (OnDemandContainerScanner.java:shutdown(141)) - On-demand container scanner is shutting down.
2025-12-19 13:36:34,160 [ForkJoinPool-6-worker-1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:stop(594)) - Closing XceiverServerRatis(57412301-a084-4aa6-8e22-91ecff01c376)
2025-12-19 13:36:34,160 [ForkJoinPool-6-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(425)) - 57412301-a084-4aa6-8e22-91ecff01c376: close
2025-12-19 13:36:34,160 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA: shutdown
2025-12-19 13:36:34,160 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1603DFD1D8CA,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:36:34,160 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61: shutdown
2025-12-19 13:36:34,161 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2025-12-19 13:36:34,160 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(103)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-LeaderStateImpl
2025-12-19 13:36:34,161 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(281)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-PendingRequests: sendNotLeaderResponses
2025-12-19 13:36:34,161 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6AA3D4F57C61,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:36:34,161 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread4] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$1(528)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401: shutdown
2025-12-19 13:36:34,161 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:34,161 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2025-12-19 13:36:34,161 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown server GrpcServerProtocolService now
2025-12-19 13:36:34,161 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FollowerState
2025-12-19 13:36:34,161 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread4] INFO  util.JmxRegister (JmxRegister.java:unregister(74)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-579D88BAA401,id=57412301-a084-4aa6-8e22-91ecff01c376
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FollowerState
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-6AA3D4F57C61: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/sm/snapshot.1_0
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-579D88BAA401: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/83edabe4-a852-4d54-beae-579d88baa401/sm/snapshot.1_0
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:34,161 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(427)) - group-1603DFD1D8CA: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/099e5e47-f620-4042-9012-1603dfd1d8ca/sm/snapshot.1_0
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-FollowerState was interrupted
2025-12-19 13:36:34,162 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown server GrpcServerProtocolService successfully
2025-12-19 13:36:34,162 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(345)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(163)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater: set stopIndex = 0
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FollowerState] INFO  impl.FollowerState (FollowerState.java:runImpl(170)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-FollowerState was interrupted
2025-12-19 13:36:34,163 [ForkJoinPool-6-worker-1] INFO  server.GrpcServicesImpl (GrpcServicesImpl.java:closeImpl(354)) - 57412301-a084-4aa6-8e22-91ecff01c376: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-6AA3D4F57C61: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/b9e0bfa2-a183-4cf0-ba13-6aa3d4f57c61/sm/snapshot.1_0 took: 1 ms
2025-12-19 13:36:34,162 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-579D88BAA401: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/83edabe4-a852-4d54-beae-579d88baa401/sm/snapshot.1_0 took: 1 ms
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(436)) - group-1603DFD1D8CA: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/ratis/099e5e47-f620-4042-9012-1603dfd1d8ca/sm/snapshot.1_0 took: 1 ms
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(307)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater: Took a snapshot at index 0
2025-12-19 13:36:34,164 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(101)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-19 13:36:34,164 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stop(140)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-StateMachineUpdater: closing ContainerStateMachine, lastApplied=(t:1, i:0)
2025-12-19 13:36:34,163 [57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:34,164 [57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-19 13:36:34,166 [57412301-a084-4aa6-8e22-91ecff01c376-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x39a12701, L:/0.0.0.0:15550] CLOSE
2025-12-19 13:36:34,166 [57412301-a084-4aa6-8e22-91ecff01c376-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x39a12701, L:/0.0.0.0:15550] INACTIVE
2025-12-19 13:36:34,166 [57412301-a084-4aa6-8e22-91ecff01c376-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x39a12701, L:/0.0.0.0:15550] UNREGISTERED
2025-12-19 13:36:34,201 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-B70A942B69E2-SegmentedRaftLogWorker close()
2025-12-19 13:36:34,201 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread4] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-B70A942B69E2 is closed by HddsDatanodeService
2025-12-19 13:36:34,876 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-6AA3D4F57C61-SegmentedRaftLogWorker close()
2025-12-19 13:36:34,877 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-6AA3D4F57C61 is closed by HddsDatanodeService
2025-12-19 13:36:34,882 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-6AA3D4F57C61-SegmentedRaftLogWorker close()
2025-12-19 13:36:34,882 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread3] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-6AA3D4F57C61 is closed by HddsDatanodeService
2025-12-19 13:36:34,965 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 9f85a268-b54d-42c0-89e3-0f143f429527@group-579D88BAA401-SegmentedRaftLogWorker close()
2025-12-19 13:36:34,966 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-579D88BAA401-SegmentedRaftLogWorker close()
2025-12-19 13:36:34,966 [9f85a268-b54d-42c0-89e3-0f143f429527-impl-thread3] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-579D88BAA401 is closed by HddsDatanodeService
2025-12-19 13:36:34,966 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread4] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-579D88BAA401 is closed by HddsDatanodeService
2025-12-19 13:36:34,966 [JvmPauseMonitor84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-9f85a268-b54d-42c0-89e3-0f143f429527: Stopped
2025-12-19 13:36:35,115 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(254)) - 57412301-a084-4aa6-8e22-91ecff01c376@group-1603DFD1D8CA-SegmentedRaftLogWorker close()
2025-12-19 13:36:35,116 [57412301-a084-4aa6-8e22-91ecff01c376-impl-thread2] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:notifyServerShutdown(1038)) - group-1603DFD1D8CA is closed by HddsDatanodeService
2025-12-19 13:36:35,116 [JvmPauseMonitor83] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-57412301-a084-4aa6-8e22-91ecff01c376: Stopped
2025-12-19 13:36:35,124 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15494. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:35,124 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15502. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:35,124 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15510. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:36,006 [ForkJoinPool-6-worker-4] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(110)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-66019413-eed9-4305-abd0-b794a6497ecc/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d/container.db]
2025-12-19 13:36:36,007 [ForkJoinPool-6-worker-4] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(104)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-66019413-eed9-4305-abd0-b794a6497ecc/container.db from cache
2025-12-19 13:36:36,007 [ForkJoinPool-6-worker-4] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(635)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-1/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-66019413-eed9-4305-abd0-b794a6497ecc/container.db for volume DS-66019413-eed9-4305-abd0-b794a6497ecc
2025-12-19 13:36:36,007 [ForkJoinPool-6-worker-4] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service BlockDeletingService
2025-12-19 13:36:36,007 [ForkJoinPool-6-worker-4] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-12-19 13:36:36,008 [ForkJoinPool-6-worker-4] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(653)) - Ozone container server stopped.
2025-12-19 13:36:36,009 [ForkJoinPool-6-worker-4] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3c009dff{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-12-19 13:36:36,009 [ForkJoinPool-6-worker-4] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6f559a9c{HTTP/1.1, (http/1.1)}{0.0.0.0:15536}
2025-12-19 13:36:36,010 [ForkJoinPool-6-worker-4] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:36:36,010 [ForkJoinPool-6-worker-4] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@112eecc8{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-12-19 13:36:36,010 [ForkJoinPool-6-worker-4] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@30d9246d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:36:36,010 [ForkJoinPool-6-worker-4] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-12-19 13:36:36,010 [ForkJoinPool-6-worker-4] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15537
2025-12-19 13:36:36,011 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:36,011 [IPC Server listener on 15537] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15537
2025-12-19 13:36:36,124 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15494. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:36,124 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15510. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:36,124 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15502. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:36,969 [ForkJoinPool-6-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(110)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d/container.db]
2025-12-19 13:36:36,971 [ForkJoinPool-6-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(104)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d/container.db from cache
2025-12-19 13:36:36,971 [ForkJoinPool-6-worker-3] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(635)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-3/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d/container.db for volume DS-3e4d6844-9e04-4a91-b6f9-a5e7b469515d
2025-12-19 13:36:36,971 [ForkJoinPool-6-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service BlockDeletingService
2025-12-19 13:36:36,971 [ForkJoinPool-6-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-12-19 13:36:36,972 [ForkJoinPool-6-worker-3] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(653)) - Ozone container server stopped.
2025-12-19 13:36:36,973 [ForkJoinPool-6-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3bdc0d08{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-12-19 13:36:36,973 [ForkJoinPool-6-worker-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3f52fd39{HTTP/1.1, (http/1.1)}{0.0.0.0:15552}
2025-12-19 13:36:36,973 [ForkJoinPool-6-worker-3] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:36:36,973 [ForkJoinPool-6-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7ed2ebe1{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-12-19 13:36:36,973 [ForkJoinPool-6-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@23cfa901{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:36:36,974 [ForkJoinPool-6-worker-3] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-12-19 13:36:36,974 [ForkJoinPool-6-worker-3] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15553
2025-12-19 13:36:36,975 [IPC Server listener on 15553] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15553
2025-12-19 13:36:36,975 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
2025-12-19 13:36:37,119 [ForkJoinPool-6-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(110)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4/container.db]
2025-12-19 13:36:37,120 [ForkJoinPool-6-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(104)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4/container.db from cache
2025-12-19 13:36:37,120 [ForkJoinPool-6-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(635)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9a5f6a08-7b44-4db9-b4fd-3149b70783dc/ozone-metadata/datanode-2/data-0/hdds/9a5f6a08-7b44-4db9-b4fd-3149b70783dc/DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4/container.db for volume DS-ebf3c6c9-4ad8-4651-9777-55d956ac77a4
2025-12-19 13:36:37,120 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service BlockDeletingService
2025-12-19 13:36:37,120 [ForkJoinPool-6-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(195)) - Shutting down service StaleRecoveringContainerScrubbingService
2025-12-19 13:36:37,122 [ForkJoinPool-6-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(653)) - Ozone container server stopped.
2025-12-19 13:36:37,122 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@e46e6bf{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2025-12-19 13:36:37,123 [ForkJoinPool-6-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@262483d3{HTTP/1.1, (http/1.1)}{0.0.0.0:15544}
2025-12-19 13:36:37,123 [ForkJoinPool-6-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2025-12-19 13:36:37,123 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6ef86c04{static,/static,jar:file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/hdds-container-service-2.2.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2025-12-19 13:36:37,123 [ForkJoinPool-6-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@925d524{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2025-12-19 13:36:37,124 [ForkJoinPool-6-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(82)) - Stopping the RPC server for Client Protocol
2025-12-19 13:36:37,124 [ForkJoinPool-6-worker-1] INFO  ipc_.Server (Server.java:stop(3422)) - Stopping server on 15545
2025-12-19 13:36:37,124 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15494. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:37,125 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15510. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:37,125 [9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 ] INFO  ipc_.Client (Client.java:handleConnectionFailure(928)) - Retrying connect to server: localhost/127.0.0.1:15502. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2025-12-19 13:36:37,125 [IPC Server listener on 15545] INFO  ipc_.Server (Server.java:run(1356)) - Stopping IPC Server listener on 15545
2025-12-19 13:36:37,125 [IPC Server Responder] INFO  ipc_.Server (Server.java:run(1489)) - Stopping IPC Server Responder
====> [2] AFTER_COMPLETE_FINALIZATION TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2025-12-19 01:36:37,127

"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=4321 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 "  prio=5 tid=23193 blocked
java.lang.Thread.State: BLOCKED
        at app//org.apache.hadoop.ipc_.Client$Connection.addCall(Client.java:449)
        at app//org.apache.hadoop.ipc_.Client$Connection.access$3700(Client.java:336)
        at app//org.apache.hadoop.ipc_.Client.getConnection(Client.java:1592)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1435)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1388)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
        at app/jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
        at java.base@21.0.9/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"gradle-enterprise-test-client-gradle-enterprise-test-listener"  prio=5 tid=31 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/sun.nio.ch.SocketDispatcher.write0(Native Method)
        at java.base@21.0.9/sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:62)
        at java.base@21.0.9/sun.nio.ch.NioSocketImpl.tryWrite(NioSocketImpl.java:394)
        at java.base@21.0.9/sun.nio.ch.NioSocketImpl.implWrite(NioSocketImpl.java:410)
        at java.base@21.0.9/sun.nio.ch.NioSocketImpl.write(NioSocketImpl.java:440)
        at java.base@21.0.9/sun.nio.ch.NioSocketImpl$2.write(NioSocketImpl.java:819)
        at java.base@21.0.9/java.net.Socket$SocketOutputStream.write(Socket.java:1195)
        at java.base@21.0.9/java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1899)
        at java.base@21.0.9/java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1863)
        at java.base@21.0.9/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1568)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1542)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1451)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1194)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1394)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1190)
        at java.base@21.0.9/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1585)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1542)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1451)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1194)
        at java.base@21.0.9/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1585)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1542)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1451)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1194)
        at java.base@21.0.9/java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1585)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1542)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1451)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1194)
        at java.base@21.0.9/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:358)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.a(SourceFile:141)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.b(SourceFile:93)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a$$Lambda/0x00007f1420145d78.run(Unknown Source)
        at java.base@21.0.9/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
        at java.base@21.0.9/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool-6-worker-2" daemon prio=5 tid=21749 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.9/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 "  prio=5 tid=23191 blocked
java.lang.Thread.State: BLOCKED
        at app//org.apache.hadoop.ipc_.Client$Connection.addCall(Client.java:449)
        at app//org.apache.hadoop.ipc_.Client$Connection.access$3700(Client.java:336)
        at app//org.apache.hadoop.ipc_.Client.getConnection(Client.java:1592)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1435)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1388)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
        at app/jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
        at java.base@21.0.9/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"surefire-process-checker" daemon prio=5 tid=26 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=7440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=25 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.9/java.io.FileInputStream.readBytes(Native Method)
        at java.base@21.0.9/java.io.FileInputStream.read(FileInputStream.java:287)
        at java.base@21.0.9/java.io.BufferedInputStream.read1(BufferedInputStream.java:345)
        at java.base@21.0.9/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)
        at java.base@21.0.9/java.io.BufferedInputStream.read(BufferedInputStream.java:399)
        at java.base@21.0.9/java.io.BufferedInputStream.fill(BufferedInputStream.java:291)
        at java.base@21.0.9/java.io.BufferedInputStream.read1(BufferedInputStream.java:347)
        at java.base@21.0.9/java.io.BufferedInputStream.implRead(BufferedInputStream.java:420)
        at java.base@21.0.9/java.io.BufferedInputStream.read(BufferedInputStream.java:399)
        at app//org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:169)
        at app//org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:50)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.read(AbstractStreamDecoder.java:430)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.read(AbstractStreamDecoder.java:419)
        at app//org.apache.maven.surefire.api.stream.AbstractStreamDecoder.readMessageType(AbstractStreamDecoder.java:116)
        at app//org.apache.maven.surefire.booter.stream.CommandDecoder.decode(CommandDecoder.java:77)
        at app//org.apache.maven.surefire.booter.spi.CommandChannelDecoder.decode(CommandChannelDecoder.java:60)
        at app//org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:290)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool-6-worker-1" daemon prio=5 tid=21746 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.9/java.lang.Thread.dumpThreads(Native Method)
        at java.base@21.0.9/java.lang.Thread.getAllStackTraces(Thread.java:2522)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:81)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:67)
        at app//org.apache.ozone.test.TimedOutTestsListener.lambda$executionFinished$0(TimedOutTestsListener.java:53)
        at app//org.apache.ozone.test.TimedOutTestsListener$$Lambda/0x00007f1420b6c460.accept(Unknown Source)
        at java.base@21.0.9/java.util.Optional.ifPresent(Optional.java:178)
        at app//org.apache.ozone.test.TimedOutTestsListener.executionFinished(TimedOutTestsListener.java:49)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$executionFinished$10(CompositeTestExecutionListener.java:74)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda/0x00007f1420b4a3a8.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$notifyEach$21(CompositeTestExecutionListener.java:110)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda/0x00007f142013e460.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:262)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.notifyEach(CompositeTestExecutionListener.java:108)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.executionFinished(CompositeTestExecutionListener.java:73)
        at app//org.junit.platform.launcher.core.ExecutionListenerAdapter.executionFinished(ExecutionListenerAdapter.java:57)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$executionFinished$6(CompositeEngineExecutionListener.java:60)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda/0x00007f1420b48fd0.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$notifyEach$13(CompositeEngineExecutionListener.java:82)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda/0x00007f1420167110.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:262)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.notifyEach(CompositeEngineExecutionListener.java:80)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.executionFinished(CompositeEngineExecutionListener.java:59)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:47)
        at app//org.junit.platform.launcher.core.StackTracePruningEngineExecutionListener.executionFinished(StackTracePruningEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:47)
        at app//org.junit.platform.launcher.core.OutcomeDelayingEngineExecutionListener.executionFinished(OutcomeDelayingEngineExecutionListener.java:63)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion(NodeTestTask.java:201)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:106)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.exec(ForkJoinPoolHierarchicalTestExecutorService.java:274)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.execSync(ForkJoinPoolHierarchicalTestExecutorService.java:247)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.submit(ForkJoinPoolHierarchicalTestExecutorService.java:148)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:232)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:210)
        at app//org.junit.jupiter.engine.descriptor.TemplateExecutor.execute(TemplateExecutor.java:98)
        at app//org.junit.jupiter.engine.descriptor.TemplateExecutor.lambda$executeForProvider$0(TemplateExecutor.java:61)
        at app//org.junit.jupiter.engine.descriptor.TemplateExecutor$$Lambda/0x00007f14201a1b80.accept(Unknown Source)
        at java.base@21.0.9/java.util.Optional.ifPresent(Optional.java:178)
        at app//org.junit.jupiter.engine.descriptor.TemplateExecutor.lambda$executeForProvider$1(TemplateExecutor.java:61)
        at app//org.junit.jupiter.engine.descriptor.TemplateExecutor$$Lambda/0x00007f1420183c70.accept(Unknown Source)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@21.0.9/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@21.0.9/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@21.0.9/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@21.0.9/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@21.0.9/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@21.0.9/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@21.0.9/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
        at java.base@21.0.9/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
        at java.base@21.0.9/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@21.0.9/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at app//org.junit.jupiter.engine.descriptor.TemplateExecutor.executeForProvider(TemplateExecutor.java:59)
        at app//org.junit.jupiter.engine.descriptor.TemplateExecutor.execute(TemplateExecutor.java:48)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:112)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:40)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:157)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016ee78.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:147)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016ec50.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:145)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016e828.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:144)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:101)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.exec(ForkJoinPoolHierarchicalTestExecutorService.java:274)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.execSync(ForkJoinPoolHierarchicalTestExecutorService.java:247)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:159)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:161)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016ee78.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:147)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016ec50.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:145)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016e828.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:144)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:101)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.exec(ForkJoinPoolHierarchicalTestExecutorService.java:274)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.execSync(ForkJoinPoolHierarchicalTestExecutorService.java:247)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:159)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:161)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016ee78.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:147)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016ec50.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:145)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda/0x00007f142016e828.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:144)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:101)
        at app//org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.exec(ForkJoinPoolHierarchicalTestExecutorService.java:274)
        at java.base@21.0.9/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:387)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1312)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1843)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1808)
        at java.base@21.0.9/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 "  prio=5 tid=23216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.9/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ipc_.Client$Connection.handleConnectionFailure(Client.java:923)
        at app//org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:662)
        at app//org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
        at app//org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
        at app//org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1435)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1388)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
        at app/jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
        at java.base@21.0.9/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=7439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15494-0 "  prio=5 tid=23213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.9/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ipc_.Client$Connection.handleConnectionFailure(Client.java:923)
        at app//org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:662)
        at app//org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
        at app//org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
        at app//org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1435)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1388)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
        at app/jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
        at java.base@21.0.9/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"Finalizer" daemon prio=8 tid=10 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:339)
        at java.base@21.0.9/java.lang.ref.NativeReferenceQueue.await(NativeReferenceQueue.java:48)
        at java.base@21.0.9/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:158)
        at java.base@21.0.9/java.lang.ref.NativeReferenceQueue.remove(NativeReferenceQueue.java:89)
        at java.base@21.0.9/java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:173)
"timer0" daemon prio=5 tid=522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.9/java.util.TimerThread.run(Timer.java:516)
"9f85a268-b54d-42c0-89e3-0f143f429527-EndpointStateMachineTaskThread-/127.0.0.1:15510-0 "  prio=5 tid=23215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Thread.sleep0(Native Method)
        at java.base@21.0.9/java.lang.Thread.sleep(Thread.java:509)
        at app//org.apache.hadoop.ipc_.Client$Connection.handleConnectionFailure(Client.java:923)
        at app//org.apache.hadoop.ipc_.Client$Connection.setupConnection(Client.java:662)
        at app//org.apache.hadoop.ipc_.Client$Connection.setupIOstreams(Client.java:756)
        at app//org.apache.hadoop.ipc_.Client$Connection.access$3800(Client.java:336)
        at app//org.apache.hadoop.ipc_.Client.getConnection(Client.java:1605)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1435)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1388)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
        at app/jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
        at java.base@21.0.9/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool.commonPool-worker-1" daemon prio=5 tid=1505 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.9/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"57412301-a084-4aa6-8e22-91ecff01c376-EndpointStateMachineTaskThread-/127.0.0.1:15502-0 "  prio=5 tid=23194 blocked
java.lang.Thread.State: BLOCKED
        at app//org.apache.hadoop.ipc_.Client$Connection.addCall(Client.java:449)
        at app//org.apache.hadoop.ipc_.Client$Connection.access$3700(Client.java:336)
        at app//org.apache.hadoop.ipc_.Client.getConnection(Client.java:1592)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1435)
        at app//org.apache.hadoop.ipc_.Client.call(Client.java:1388)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
        at app//org.apache.hadoop.ipc_.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:120)
        at app/jdk.proxy2/jdk.proxy2.$Proxy61.submitRequest(Unknown Source)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:105)
        at app//org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:136)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:151)
        at app//org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:71)
        at java.base@21.0.9/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"IPC Parameter Sending Thread for localhost/127.0.0.1:15495" daemon prio=5 tid=24576 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.9/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.9/java.util.concurrent.LinkedTransferQueue.xfer(LinkedTransferQueue.java:613)
        at java.base@21.0.9/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.9/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at app//org.apache.hadoop.ipc_.Client$Connection$RpcRequestSender.run(Client.java:1083)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"process reaper" daemon prio=10 tid=29 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:410)
        at java.base@21.0.9/java.util.concurrent.LinkedTransferQueue$DualNode.await(LinkedTransferQueue.java:452)
        at java.base@21.0.9/java.util.concurrent.SynchronousQueue$Transferer.xferLifo(SynchronousQueue.java:194)
        at java.base@21.0.9/java.util.concurrent.SynchronousQueue.xfer(SynchronousQueue.java:235)
        at java.base@21.0.9/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:338)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1069)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
        at java.base@21.0.9/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:186)
"timer3" daemon prio=5 tid=514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.9/java.util.TimerThread.run(Timer.java:516)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=4320 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=10524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"junit-jupiter-timeout-watcher" daemon prio=10 tid=21747 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"timer5" daemon prio=5 tid=519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.9/java.util.TimerThread.run(Timer.java:516)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=16680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-stream-flusher" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=16681 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"timer2" daemon prio=5 tid=509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.9/java.util.TimerThread.run(Timer.java:516)
"ForkJoinPool.commonPool-worker-3" daemon prio=5 tid=12141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkUntil(LockSupport.java:449)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1891)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.9/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"timer7" daemon prio=5 tid=521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.9/java.util.TimerThread.run(Timer.java:516)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=1229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"globalEventExecutor-2-37"  prio=5 tid=24777 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.GlobalEventExecutor.takeTask(GlobalEventExecutor.java:118)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.GlobalEventExecutor$TaskRunner.run(GlobalEventExecutor.java:281)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool.commonPool-worker-2" daemon prio=5 tid=1528 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.9/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=22936 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"MutableQuantiles-0" daemon prio=5 tid=1301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=13663 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=19808 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"ForkJoinPool-6-worker-3" daemon prio=5 tid=21828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.9/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=10523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"IPC Client (2019482172) connection to localhost/127.0.0.1:15495 from runner" daemon prio=5 tid=24575 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at app//org.apache.hadoop.ipc_.Client$Connection.waitForWork(Client.java:1004)
        at app//org.apache.hadoop.ipc_.Client$Connection.run(Client.java:1055)
"Common-Cleaner" daemon prio=8 tid=17 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1886)
        at java.base@21.0.9/java.lang.ref.ReferenceQueue.await(ReferenceQueue.java:71)
        at java.base@21.0.9/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:143)
        at java.base@21.0.9/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:218)
        at java.base@21.0.9/jdk.internal.ref.CleanerImpl.run(CleanerImpl.java:140)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
        at java.base@21.0.9/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:186)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=22937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"LeakDetector-ManagedRocksObject0" daemon prio=5 tid=49 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:519)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3780)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3725)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1746)
        at java.base@21.0.9/java.lang.ref.ReferenceQueue.await(ReferenceQueue.java:67)
        at java.base@21.0.9/java.lang.ref.ReferenceQueue.remove0(ReferenceQueue.java:158)
        at java.base@21.0.9/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:234)
        at app//org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:79)
        at app//org.apache.hadoop.hdds.utils.LeakDetector$$Lambda/0x00007f142049aff8.run(Unknown Source)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"main"  prio=5 tid=1 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.9/java.util.concurrent.ForkJoinTask.awaitDone(ForkJoinTask.java:461)
        at java.base@21.0.9/java.util.concurrent.ForkJoinTask.get(ForkJoinTask.java:991)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.executeEngine(EngineExecutionOrchestrator.java:230)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.failOrExecuteEngine(EngineExecutionOrchestrator.java:204)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:172)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:101)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:64)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda/0x00007f1420139170.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:150)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:63)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:109)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:91)
        at app//org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at app//org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39)
        at app//org.junit.platform.launcher.core.InterceptingLauncher$$Lambda/0x00007f14200a0000.proceed(Unknown Source)
        at app//org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25)
        at app//org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38)
        at app//org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at app//org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:56)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:162)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:120)
        at app//org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
        at app//org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at app//org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
        at app//org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
"Signal Dispatcher" daemon prio=9 tid=11 runnable
java.lang.Thread.State: RUNNABLE
"ForkJoinPool-6-worker-4" daemon prio=5 tid=22945 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.9/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"ForkJoinPool-6-worker-5" daemon prio=5 tid=22946 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.park(LockSupport.java:371)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1893)
        at java.base@21.0.9/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1809)
        at java.base@21.0.9/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:188)
"Reference Handler" daemon prio=10 tid=9 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@21.0.9/java.lang.ref.Reference.waitForReferencePendingList(Native Method)
        at java.base@21.0.9/java.lang.ref.Reference.processPendingReferences(Reference.java:246)
        at java.base@21.0.9/java.lang.ref.Reference$ReferenceHandler.run(Reference.java:208)
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=1230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"timer6" daemon prio=5 tid=520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.9/java.util.TimerThread.run(Timer.java:516)
"timer1" daemon prio=5 tid=506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.9/java.util.TimerThread.run(Timer.java:516)
"volumeTable_FullTableCache-Cleanup-0" daemon prio=5 tid=13662 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)
"timer4" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/java.lang.Object.wait0(Native Method)
        at java.base@21.0.9/java.lang.Object.wait(Object.java:366)
        at java.base@21.0.9/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@21.0.9/java.util.TimerThread.run(Timer.java:516)
"Notification Thread" daemon prio=9 tid=22 runnable
java.lang.Thread.State: RUNNABLE
"bucketTable_FullTableCache-Cleanup-0" daemon prio=5 tid=19809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@21.0.9/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@21.0.9/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:269)
        at java.base@21.0.9/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1797)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@21.0.9/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1070)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
        at java.base@21.0.9/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base@21.0.9/java.lang.Thread.runWith(Thread.java:1596)
        at java.base@21.0.9/java.lang.Thread.run(Thread.java:1583)

