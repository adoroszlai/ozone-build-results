No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2025-12-05 19:46:42,151 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.2
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.1.0
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/f2406c4b4eb2b1295d06ec379cfe684ed9a16637 ; compiled by 'ppogde' on 2021-04-09T04:10Z
STARTUP_MSG:   java = 11.0.25
************************************************************/
2025-12-05 19:46:42,183 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-05 19:46:42,334 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:46:42,537 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-c628df5d-4cdc-4ccd-922b-26d578ef4b8c;layoutVersion=0
2025-12-05 19:46:42,560 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.2
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2025-12-05 19:46:47,404 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.1.0
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/f2406c4b4eb2b1295d06ec379cfe684ed9a16637 ; compiled by 'ppogde' on 2021-04-09T04:10Z
STARTUP_MSG:   java = 11.0.25
************************************************************/
2025-12-05 19:46:47,432 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-05 19:46:47,935 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:46:49,139 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
2025-12-05 19:46:49,144 [main] INFO server.StorageContainerManager: SCM login successful.
2025-12-05 19:46:49,721 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:46:54,254 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.2,host:scm
2025-12-05 19:46:54,256 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 19:46:54,507 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:46:54,561 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2025-12-05 19:46:54,769 [Listener at 0.0.0.0/9961] INFO net.NodeSchemaLoader: Loading schema from [file:/opt/hadoop/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0.jar!/network-topology-default.xml]
2025-12-05 19:46:54,770 [Listener at 0.0.0.0/9961] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2025-12-05 19:46:54,942 [Listener at 0.0.0.0/9961] INFO node.SCMNodeManager: Entering startup safe mode.
2025-12-05 19:46:55,080 [Listener at 0.0.0.0/9961] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2025-12-05 19:46:55,103 [Listener at 0.0.0.0/9961] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-05 19:46:55,105 [Listener at 0.0.0.0/9961] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
2025-12-05 19:46:55,122 [Listener at 0.0.0.0/9961] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-05 19:46:55,174 [Listener at 0.0.0.0/9961] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:46:55,175 [Listener at 0.0.0.0/9961] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-05 19:46:55,729 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:46:55,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2025-12-05 19:46:55,745 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:46:55,746 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2025-12-05 19:46:55,758 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:46:55,759 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2025-12-05 19:46:55,777 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2025-12-05 19:46:55,839 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-12-05 19:46:55,853 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-12-05 19:46:55,853 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2025-12-05 19:46:56,050 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2025-12-05 19:46:56,053 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:46:56,054 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2025-12-05 19:46:56,106 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2025-12-05 19:46:56,146 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2025-12-05 19:46:56,147 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:46:56,149 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2025-12-05 19:46:56,202 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
2025-12-05 19:46:56,202 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
2025-12-05 19:46:56,207 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2025-12-05 19:46:56,208 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:46:56,269 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2025-12-05 19:46:56,272 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:46:56,273 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2025-12-05 19:46:56,290 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73613ae5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
2025-12-05 19:46:56,317 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2025-12-05 19:46:56,317 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2025-12-05 19:46:56,318 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2025-12-05 19:46:56,532 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @13365ms to org.eclipse.jetty.util.log.Slf4jLog
2025-12-05 19:46:57,011 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:39551
2025-12-05 19:46:57,041 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:35293
2025-12-05 19:46:57,050 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:39641
2025-12-05 19:46:57,059 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:40807
2025-12-05 19:46:57,066 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2025-12-05 19:46:57,077 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:46:57,079 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42669
2025-12-05 19:46:57,083 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:46:57,085 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:46:57,086 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:41997
2025-12-05 19:46:57,082 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-05 19:46:57,077 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:46:57,090 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2025-12-05 19:46:57,098 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-12-05 19:46:57,099 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-12-05 19:46:57,097 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:46:57,100 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:46:57,104 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2025-12-05 19:46:57,142 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm uses base directory /tmp/ozone_http
2025-12-05 19:46:57,143 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
2025-12-05 19:46:57,144 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.25+9-LTS
2025-12-05 19:46:57,224 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
2025-12-05 19:46:57,225 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
2025-12-05 19:46:57,226 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
2025-12-05 19:46:57,260 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 3d08150c-9f05-459a-a01e-407e49775160
2025-12-05 19:46:57,265 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: e889c8aa-a302-414b-a59f-2790ce72fa4a
2025-12-05 19:46:57,275 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 19:46:57,285 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3ece79fe{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2025-12-05 19:46:57,286 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@78da899f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0.jar!/webapps/static,AVAILABLE}
2025-12-05 19:46:57,631 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 2f999d3d-2d8e-47d8-b6e6-c0cc87724d64
2025-12-05 19:46:57,635 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 30cda18c-5b41-4b10-b268-7e63095bb8e5
2025-12-05 19:46:57,758 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5
2025-12-05 19:46:58,904 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 19:46:58,961 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5bf9ea6b{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0_jar-_-any-7688495250091227022/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0.jar!/webapps/scm}
2025-12-05 19:46:59,044 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4db77402{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2025-12-05 19:46:59,051 [Listener at 0.0.0.0/9860] INFO server.Server: Started @15884ms
2025-12-05 19:46:59,079 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
2025-12-05 19:46:59,079 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
2025-12-05 19:46:59,080 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2025-12-05 19:47:00,141 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40257
2025-12-05 19:47:00,194 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:47:02,725 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:45101
2025-12-05 19:47:02,740 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:47:02,765 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: ace6ef40-368e-491f-ba12-59e6c2d7bd14
2025-12-05 19:47:07,153 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:41651
2025-12-05 19:47:07,162 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:47:07,331 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:39757
2025-12-05 19:47:07,334 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:47:07,831 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:41477
2025-12-05 19:47:07,836 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:47:08,381 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:34391
2025-12-05 19:47:08,385 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:08,443 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41675
2025-12-05 19:47:08,449 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:08,501 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:33175
2025-12-05 19:47:08,519 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:08,590 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:40743
2025-12-05 19:47:08,604 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:08,946 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:42651
2025-12-05 19:47:08,955 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:10,348 [IPC Server handler 98 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e889c8aa-a302-414b-a59f-2790ce72fa4a
2025-12-05 19:47:10,349 [IPC Server handler 98 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e889c8aa-a302-414b-a59f-2790ce72fa4a{ip: 172.18.0.20, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 195682190200, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:47:10,366 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 19:47:10,367 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 5 required.
2025-12-05 19:47:10,372 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=98ea6263-a99b-4f16-b52c-4186559ae96e to datanode:e889c8aa-a302-414b-a59f-2790ce72fa4a
2025-12-05 19:47:10,373 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:10,374 [IPC Server handler 96 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/30cda18c-5b41-4b10-b268-7e63095bb8e5
2025-12-05 19:47:10,375 [IPC Server handler 96 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 30cda18c-5b41-4b10-b268-7e63095bb8e5{ip: 172.18.0.4, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 195862311229, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:47:10,375 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 19:47:10,375 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:10,376 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 5 required.
2025-12-05 19:47:10,380 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 98ea6263-a99b-4f16-b52c-4186559ae96e, Nodes: e889c8aa-a302-414b-a59f-2790ce72fa4a{ip: 172.18.0.20, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:47:10.361062Z]
2025-12-05 19:47:10,387 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3b4f72c4-b34e-4480-af4b-8b51abda7382 to datanode:30cda18c-5b41-4b10-b268-7e63095bb8e5
2025-12-05 19:47:10,387 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3b4f72c4-b34e-4480-af4b-8b51abda7382, Nodes: 30cda18c-5b41-4b10-b268-7e63095bb8e5{ip: 172.18.0.4, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:47:10.387309Z]
2025-12-05 19:47:10,399 [IPC Server handler 82 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3d08150c-9f05-459a-a01e-407e49775160
2025-12-05 19:47:10,400 [IPC Server handler 82 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3d08150c-9f05-459a-a01e-407e49775160{ip: 172.18.0.19, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 195670247192, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:47:10,400 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 5 required.
2025-12-05 19:47:10,400 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 19:47:10,401 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:10,401 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f553b031-0ee1-43c6-8a96-308b5dcd9998 to datanode:3d08150c-9f05-459a-a01e-407e49775160
2025-12-05 19:47:10,402 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f553b031-0ee1-43c6-8a96-308b5dcd9998, Nodes: 3d08150c-9f05-459a-a01e-407e49775160{ip: 172.18.0.19, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:47:10.401770Z]
2025-12-05 19:47:10,426 [IPC Server handler 51 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/2f999d3d-2d8e-47d8-b6e6-c0cc87724d64
2025-12-05 19:47:10,426 [IPC Server handler 51 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2f999d3d-2d8e-47d8-b6e6-c0cc87724d64{ip: 172.18.0.18, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 195857287790, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:47:10,427 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 5 required.
2025-12-05 19:47:10,427 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 19:47:10,429 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:10,430 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=5922d299-0fbd-4347-8121-78f7722c4e42 to datanode:2f999d3d-2d8e-47d8-b6e6-c0cc87724d64
2025-12-05 19:47:10,430 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 5922d299-0fbd-4347-8121-78f7722c4e42, Nodes: 2f999d3d-2d8e-47d8-b6e6-c0cc87724d64{ip: 172.18.0.18, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:47:10.430210Z]
2025-12-05 19:47:10,931 [IPC Server handler 14 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5
2025-12-05 19:47:10,932 [IPC Server handler 14 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5{ip: 172.18.0.17, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 195985623894, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:47:10,932 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 19:47:10,933 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 5 DataNodes registered, 5 required.
2025-12-05 19:47:10,933 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:10,933 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2025-12-05 19:47:10,933 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2025-12-05 19:47:10,933 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9f831af0-7050-4a9a-847c-4ad0b28a69fb to datanode:ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5
2025-12-05 19:47:10,934 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 9f831af0-7050-4a9a-847c-4ad0b28a69fb, Nodes: ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5{ip: 172.18.0.17, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:47:10.933649Z]
2025-12-05 19:47:10,937 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=91cea541-c2d4-424d-a3f6-173e6cecf698 to datanode:ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5
2025-12-05 19:47:10,937 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=91cea541-c2d4-424d-a3f6-173e6cecf698 to datanode:e889c8aa-a302-414b-a59f-2790ce72fa4a
2025-12-05 19:47:10,937 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=91cea541-c2d4-424d-a3f6-173e6cecf698 to datanode:30cda18c-5b41-4b10-b268-7e63095bb8e5
2025-12-05 19:47:10,937 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 91cea541-c2d4-424d-a3f6-173e6cecf698, Nodes: ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5{ip: 172.18.0.17, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e889c8aa-a302-414b-a59f-2790ce72fa4a{ip: 172.18.0.20, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}30cda18c-5b41-4b10-b268-7e63095bb8e5{ip: 172.18.0.4, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:47:10.936992Z]
2025-12-05 19:47:13,396 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:13,396 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 98ea6263-a99b-4f16-b52c-4186559ae96e, Nodes: e889c8aa-a302-414b-a59f-2790ce72fa4a{ip: 172.18.0.20, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:e889c8aa-a302-414b-a59f-2790ce72fa4a, CreationTimestamp2025-12-05T19:47:10.361062Z] moved to OPEN state
2025-12-05 19:47:13,433 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:13,445 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:42157
2025-12-05 19:47:13,452 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:47:13,461 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 3b4f72c4-b34e-4480-af4b-8b51abda7382, Nodes: 30cda18c-5b41-4b10-b268-7e63095bb8e5{ip: 172.18.0.4, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:30cda18c-5b41-4b10-b268-7e63095bb8e5, CreationTimestamp2025-12-05T19:47:10.387309Z] moved to OPEN state
2025-12-05 19:47:13,462 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:13,462 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:13,513 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:13,514 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f553b031-0ee1-43c6-8a96-308b5dcd9998, Nodes: 3d08150c-9f05-459a-a01e-407e49775160{ip: 172.18.0.19, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:3d08150c-9f05-459a-a01e-407e49775160, CreationTimestamp2025-12-05T19:47:10.401770Z] moved to OPEN state
2025-12-05 19:47:13,515 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:13,605 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 5922d299-0fbd-4347-8121-78f7722c4e42, Nodes: 2f999d3d-2d8e-47d8-b6e6-c0cc87724d64{ip: 172.18.0.18, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:2f999d3d-2d8e-47d8-b6e6-c0cc87724d64, CreationTimestamp2025-12-05T19:47:10.430210Z] moved to OPEN state
2025-12-05 19:47:13,606 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:13,606 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:13,610 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:13,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:13,661 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:13,661 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:14,039 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:14,039 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 9f831af0-7050-4a9a-847c-4ad0b28a69fb, Nodes: ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5{ip: 172.18.0.17, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5, CreationTimestamp2025-12-05T19:47:10.933649Z] moved to OPEN state
2025-12-05 19:47:14,040 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:14,230 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:14,232 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:18,664 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:18,664 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:18,762 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:18,762 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:18,791 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:18,791 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:18,794 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:18,801 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:19,376 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:19,379 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:48,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:33641
2025-12-05 19:47:48,680 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:48,681 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:48,681 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:48,776 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:36913
2025-12-05 19:47:48,778 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:48,780 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:48,782 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:48,812 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42513
2025-12-05 19:47:48,815 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:48,816 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:43099
2025-12-05 19:47:48,817 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:48,817 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:48,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:48,822 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:48,823 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:47:49,379 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:46329
2025-12-05 19:47:49,383 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:47:49,384 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:47:49,384 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:48:04,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:39941
2025-12-05 19:48:04,909 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:04,910 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:48:04,910 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 91cea541-c2d4-424d-a3f6-173e6cecf698, Nodes: ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5{ip: 172.18.0.17, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e889c8aa-a302-414b-a59f-2790ce72fa4a{ip: 172.18.0.20, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}30cda18c-5b41-4b10-b268-7e63095bb8e5{ip: 172.18.0.4, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:ab6edfee-bd64-4cc8-9a45-49e0ccfce5f5, CreationTimestamp2025-12-05T19:47:10.936992Z] moved to OPEN state
2025-12-05 19:48:04,911 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:48:04,912 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-05 19:48:04,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2025-12-05 19:48:04,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2025-12-05 19:48:04,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2025-12-05 19:48:09,261 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:45117
2025-12-05 19:48:09,264 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:48:10,346 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:42929
2025-12-05 19:48:10,351 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:48:10,436 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:36345
2025-12-05 19:48:10,445 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:48:10,459 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38229
2025-12-05 19:48:10,464 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:48:10,614 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:41019
2025-12-05 19:48:10,621 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:48:10,718 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36577
2025-12-05 19:48:10,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:34549
2025-12-05 19:48:10,746 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:10,756 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:18,785 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:38433
2025-12-05 19:48:18,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:18,807 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:44439
2025-12-05 19:48:18,811 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:30,141 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:46431
2025-12-05 19:48:30,143 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:48:40,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:37477
2025-12-05 19:48:40,598 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:40,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33925
2025-12-05 19:48:40,730 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:40535
2025-12-05 19:48:40,732 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:40,740 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:43,447 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:44585
2025-12-05 19:48:43,449 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:48:43,611 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:38677
2025-12-05 19:48:43,616 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:48:43,649 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:33265
2025-12-05 19:48:43,652 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:48:48,805 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:35511
2025-12-05 19:48:48,820 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:01,316 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:40981
2025-12-05 19:49:01,318 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:49:02,533 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:46215
2025-12-05 19:49:02,535 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:49:10,590 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:34931
2025-12-05 19:49:10,593 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:10,697 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:43783
2025-12-05 19:49:10,703 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:13,628 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:42523
2025-12-05 19:49:13,650 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:17,976 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43711
2025-12-05 19:49:17,990 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:18,816 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:37425
2025-12-05 19:49:18,821 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:40,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:36305
2025-12-05 19:49:40,603 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:40,696 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:39701
2025-12-05 19:49:40,700 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:42,789 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:45555
2025-12-05 19:49:42,790 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:49:42,805 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:42461
2025-12-05 19:49:42,807 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:49:42,809 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:49:43,622 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:33683
2025-12-05 19:49:43,626 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:47,466 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:49:47,971 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43329
2025-12-05 19:49:47,979 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:48,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:46175
2025-12-05 19:49:48,808 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:49:52,127 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:50:05,261 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:36211
2025-12-05 19:50:05,262 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:50:05,262 [IPC Server handler 98 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:50:09,193 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:50:10,578 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:41951
2025-12-05 19:50:10,582 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:10,687 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:46831
2025-12-05 19:50:10,690 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:13,617 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:34557
2025-12-05 19:50:13,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:17,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41349
2025-12-05 19:50:17,959 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:18,805 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:36951
2025-12-05 19:50:18,814 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:20,439 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:39533
2025-12-05 19:50:20,441 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:50:20,453 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:35759
2025-12-05 19:50:20,455 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:50:20,457 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:50:24,858 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:50:29,374 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:50:40,585 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:37167
2025-12-05 19:50:40,596 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:40,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:42229
2025-12-05 19:50:40,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:42,751 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.12:44405
2025-12-05 19:50:42,753 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:50:42,754 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:50:43,613 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:35589
2025-12-05 19:50:43,618 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:46,961 [IPC Server handler 34 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.14
2025-12-05 19:50:47,967 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:32981
2025-12-05 19:50:47,971 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:50:48,800 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:34967
2025-12-05 19:50:48,803 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2025-12-05 19:50:59,945 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.10
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
STARTUP_MSG:   java = 11.0.25
************************************************************/
2025-12-05 19:50:59,998 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-05 19:51:00,337 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:51:00,596 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 19:51:00,597 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 19:51:00,872 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2025-12-05 19:51:03,786 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2025-12-05 19:51:03,786 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2025-12-05 19:51:03,787 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2025-12-05 19:51:06,807 [main] INFO ha.HASecurityUtils: Init response: GETCERT
2025-12-05 19:51:11,798 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.10,host:scm
2025-12-05 19:51:11,801 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 19:51:12,138 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.10,host:scm
2025-12-05 19:51:12,143 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 19:51:12,144 [main] ERROR client.SCMCertificateClient: Invalid domain scm
2025-12-05 19:51:12,152 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm,scmId:c2167109-bc20-4736-b4fe-72a0c594fdab,clusterId:CID-2c2f844b-ca26-497a-a308-dbb0fd470e2c,subject:scm-sub@scm
2025-12-05 19:51:12,383 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
2025-12-05 19:51:12,432 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-2c2f844b-ca26-497a-a308-dbb0fd470e2c; layoutVersion=2; scmId=c2167109-bc20-4736-b4fe-72a0c594fdab
2025-12-05 19:51:12,501 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.10
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2025-12-05 19:51:14,790 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.10
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
STARTUP_MSG:   java = 11.0.25
************************************************************/
2025-12-05 19:51:14,797 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-05 19:51:14,927 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 19:51:14,929 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 19:51:15,058 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:51:15,106 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
2025-12-05 19:51:15,426 [main] INFO reflections.Reflections: Reflections took 184 ms to scan 3 urls, producing 103 keys and 211 values 
2025-12-05 19:51:16,158 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
2025-12-05 19:51:16,337 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
2025-12-05 19:51:16,345 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
2025-12-05 19:51:16,349 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/450510078617.crt.
2025-12-05 19:51:16,492 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2025-12-05 19:51:16,492 [main] INFO server.StorageContainerManager: SCM login successful.
2025-12-05 19:51:16,519 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:51:16,681 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:51:16,848 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/opt/hadoop/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar!/network-topology-default.xml]
2025-12-05 19:51:16,848 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2025-12-05 19:51:16,935 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2025-12-05 19:51:16,940 [main] INFO ha.SequenceIdGenerator: upgrade localId to 115816896921600000
2025-12-05 19:51:16,940 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2025-12-05 19:51:16,941 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2025-12-05 19:51:16,942 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2025-12-05 19:51:17,004 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2025-12-05 19:51:17,018 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2025-12-05 19:51:17,022 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2025-12-05 19:51:17,042 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-05 19:51:17,076 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2025-12-05 19:51:17,076 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2025-12-05 19:51:17,103 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-05 19:51:17,113 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2025-12-05 19:51:17,126 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2025-12-05 19:51:17,127 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
2025-12-05 19:51:17,140 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2025-12-05 19:51:17,145 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:51:17,135 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 4 milliseconds for processing 0 containers.
2025-12-05 19:51:17,146 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-05 19:51:17,193 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2025-12-05 19:51:17,241 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2025-12-05 19:51:17,242 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 450510078617 on primary SCM
2025-12-05 19:51:17,247 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
2025-12-05 19:51:17,273 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:51:17,314 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2025-12-05 19:51:18,035 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:51:18,036 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2025-12-05 19:51:18,046 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:51:18,047 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2025-12-05 19:51:18,057 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:51:18,057 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2025-12-05 19:51:18,087 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2025-12-05 19:51:18,090 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          0.1
Max Datanodes to Involve per Iteration(ratio)      0.2
Max Size to Move per Iteration                     32212254720B

2025-12-05 19:51:18,091 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2025-12-05 19:51:18,091 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-05 19:51:18,097 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2025-12-05 19:51:18,098 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
2025-12-05 19:51:18,098 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
2025-12-05 19:51:18,193 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-12-05 19:51:18,202 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-12-05 19:51:18,202 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2025-12-05 19:51:18,366 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2025-12-05 19:51:18,366 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:51:18,366 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2025-12-05 19:51:18,447 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2025-12-05 19:51:18,448 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2025-12-05 19:51:18,449 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:51:18,449 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2025-12-05 19:51:18,471 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
2025-12-05 19:51:18,471 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
2025-12-05 19:51:18,472 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:51:18,473 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2025-12-05 19:51:18,490 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2025-12-05 19:51:18,491 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:51:18,493 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2025-12-05 19:51:18,493 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2025-12-05 19:51:19,237 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:43179
2025-12-05 19:51:19,296 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:33231
2025-12-05 19:51:19,280 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.16:38649
2025-12-05 19:51:19,307 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:38019
2025-12-05 19:51:19,314 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:43221
2025-12-05 19:51:19,332 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:51:19,332 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:51:19,334 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:51:19,335 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:44193
2025-12-05 19:51:19,341 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:51:19,350 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:51:19,372 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:51:19,374 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:40179
2025-12-05 19:51:19,386 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:51:19,519 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: e428aba8-4c76-4754-955b-12481bdbf056
2025-12-05 19:51:19,523 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 2673759f-f5dc-4630-95df-168d0270f5b4
2025-12-05 19:51:19,855 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 5b68e38e-2063-45f9-8dd5-9368622e4c7c
2025-12-05 19:51:19,932 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@799c8758] INFO util.JvmPauseMonitor: Starting JVM pause monitor
2025-12-05 19:51:19,994 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 1f8b8143-ac06-4c67-9857-8196f1fc2412
2025-12-05 19:51:20,038 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2025-12-05 19:51:20,041 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2025-12-05 19:51:20,043 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2025-12-05 19:51:20,079 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 96194e2b-a974-49a8-93de-72d3ed217183
2025-12-05 19:51:20,266 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @7232ms to org.eclipse.jetty.util.log.Slf4jLog
2025-12-05 19:51:21,023 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2025-12-05 19:51:21,072 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-05 19:51:21,081 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2025-12-05 19:51:21,081 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-12-05 19:51:21,082 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-12-05 19:51:21,098 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2025-12-05 19:51:21,372 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm uses base directory /tmp/ozone_http
2025-12-05 19:51:21,389 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
2025-12-05 19:51:21,390 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.25+9-LTS
2025-12-05 19:51:21,816 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
2025-12-05 19:51:21,817 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
2025-12-05 19:51:21,830 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
2025-12-05 19:51:22,005 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 19:51:22,049 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1322b575{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2025-12-05 19:51:22,050 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1a17dd6f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar!/webapps/static,AVAILABLE}
2025-12-05 19:51:24,811 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 19:51:24,955 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3e28dc96{scm,/,file:///tmp/ozone_http/jetty-0_0_0_0-9876-hdds-server-scm-1_2_1_jar-_-any-1655721181906613020/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar!/webapps/scm}
2025-12-05 19:51:25,112 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34175
2025-12-05 19:51:25,134 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:51:25,144 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: c81d355b-eb1b-4b28-b0d6-de2327deb6a0
2025-12-05 19:51:25,258 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@e795a1d{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2025-12-05 19:51:25,258 [Listener at 0.0.0.0/9860] INFO server.Server: Started @12223ms
2025-12-05 19:51:25,276 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
2025-12-05 19:51:25,277 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
2025-12-05 19:51:25,280 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2025-12-05 19:51:30,322 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:41077
2025-12-05 19:51:30,346 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:51:30,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:43577
2025-12-05 19:51:30,576 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:51:30,869 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:35837
2025-12-05 19:51:30,882 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:51:30,972 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:37563
2025-12-05 19:51:30,981 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:51:31,282 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:45339
2025-12-05 19:51:31,292 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:51:31,298 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37929
2025-12-05 19:51:31,309 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:51:31,721 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:45335
2025-12-05 19:51:31,735 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:51:32,566 [IPC Server handler 81 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1f8b8143-ac06-4c67-9857-8196f1fc2412
2025-12-05 19:51:32,571 [IPC Server handler 81 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1f8b8143-ac06-4c67-9857-8196f1fc2412{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 458222614067, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:51:32,576 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:51:32,582 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 19:51:32,591 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:51:32,583 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 5 required.
2025-12-05 19:51:32,600 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9e75a968-2768-4a40-9ccf-04434fe11a09 to datanode:1f8b8143-ac06-4c67-9857-8196f1fc2412
2025-12-05 19:51:32,615 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 9e75a968-2768-4a40-9ccf-04434fe11a09, Nodes: 1f8b8143-ac06-4c67-9857-8196f1fc2412{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:51:32.596Z[UTC]].
2025-12-05 19:51:32,857 [IPC Server handler 23 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/2673759f-f5dc-4630-95df-168d0270f5b4
2025-12-05 19:51:32,858 [IPC Server handler 23 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2673759f-f5dc-4630-95df-168d0270f5b4{ip: 172.18.0.19, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 458018148424, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:51:32,859 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:51:32,864 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 5 required.
2025-12-05 19:51:32,866 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=96ecccea-71f2-4f28-9d66-9847858cc24e to datanode:2673759f-f5dc-4630-95df-168d0270f5b4
2025-12-05 19:51:32,867 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 96ecccea-71f2-4f28-9d66-9847858cc24e, Nodes: 2673759f-f5dc-4630-95df-168d0270f5b4{ip: 172.18.0.19, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:51:32.866Z[UTC]].
2025-12-05 19:51:32,928 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e428aba8-4c76-4754-955b-12481bdbf056
2025-12-05 19:51:32,928 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e428aba8-4c76-4754-955b-12481bdbf056{ip: 172.18.0.17, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 457892509210, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:51:32,928 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:51:32,932 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 5 required.
2025-12-05 19:51:32,935 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=bac86f52-8cc2-431f-8bd6-9e7faba03f14 to datanode:e428aba8-4c76-4754-955b-12481bdbf056
2025-12-05 19:51:32,936 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: bac86f52-8cc2-431f-8bd6-9e7faba03f14, Nodes: e428aba8-4c76-4754-955b-12481bdbf056{ip: 172.18.0.17, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:51:32.935Z[UTC]].
2025-12-05 19:51:33,289 [IPC Server handler 12 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/96194e2b-a974-49a8-93de-72d3ed217183
2025-12-05 19:51:33,289 [IPC Server handler 12 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 96194e2b-a974-49a8-93de-72d3ed217183{ip: 172.18.0.14, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 458319153161, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:51:33,294 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:51:33,295 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 5 required.
2025-12-05 19:51:33,301 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8f3666f3-be94-4bd0-9cdf-d574cfdb92a5 to datanode:96194e2b-a974-49a8-93de-72d3ed217183
2025-12-05 19:51:33,302 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8f3666f3-be94-4bd0-9cdf-d574cfdb92a5, Nodes: 96194e2b-a974-49a8-93de-72d3ed217183{ip: 172.18.0.14, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:51:33.301Z[UTC]].
2025-12-05 19:51:33,693 [IPC Server handler 10 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5b68e38e-2063-45f9-8dd5-9368622e4c7c
2025-12-05 19:51:33,694 [IPC Server handler 10 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 5b68e38e-2063-45f9-8dd5-9368622e4c7c{ip: 172.18.0.18, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 458139546915, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:51:33,695 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:51:33,695 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 5 DataNodes registered, 5 required.
2025-12-05 19:51:33,696 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2025-12-05 19:51:33,696 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2025-12-05 19:51:33,696 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=708eaa65-f187-464b-ae12-d49267247ae7 to datanode:5b68e38e-2063-45f9-8dd5-9368622e4c7c
2025-12-05 19:51:33,696 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2025-12-05 19:51:33,697 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-05 19:51:33,697 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:51:33,697 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 708eaa65-f187-464b-ae12-d49267247ae7, Nodes: 5b68e38e-2063-45f9-8dd5-9368622e4c7c{ip: 172.18.0.18, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:51:33.696Z[UTC]].
2025-12-05 19:51:33,701 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=5599b3b6-8025-4e58-868d-07c1bffce963 to datanode:96194e2b-a974-49a8-93de-72d3ed217183
2025-12-05 19:51:33,701 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=5599b3b6-8025-4e58-868d-07c1bffce963 to datanode:1f8b8143-ac06-4c67-9857-8196f1fc2412
2025-12-05 19:51:33,701 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=5599b3b6-8025-4e58-868d-07c1bffce963 to datanode:2673759f-f5dc-4630-95df-168d0270f5b4
2025-12-05 19:51:33,702 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 5599b3b6-8025-4e58-868d-07c1bffce963, Nodes: 96194e2b-a974-49a8-93de-72d3ed217183{ip: 172.18.0.14, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1f8b8143-ac06-4c67-9857-8196f1fc2412{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2673759f-f5dc-4630-95df-168d0270f5b4{ip: 172.18.0.19, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:51:33.701Z[UTC]].
2025-12-05 19:51:35,584 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 9e75a968-2768-4a40-9ccf-04434fe11a09, Nodes: 1f8b8143-ac06-4c67-9857-8196f1fc2412{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1f8b8143-ac06-4c67-9857-8196f1fc2412, CreationTimestamp2025-12-05T19:51:32.596Z[UTC]] moved to OPEN state
2025-12-05 19:51:35,588 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:35,600 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.16:42727
2025-12-05 19:51:35,603 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:51:35,686 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:35,899 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 96ecccea-71f2-4f28-9d66-9847858cc24e, Nodes: 2673759f-f5dc-4630-95df-168d0270f5b4{ip: 172.18.0.19, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:2673759f-f5dc-4630-95df-168d0270f5b4, CreationTimestamp2025-12-05T19:51:32.866Z[UTC]] moved to OPEN state
2025-12-05 19:51:35,901 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:36,034 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: bac86f52-8cc2-431f-8bd6-9e7faba03f14, Nodes: e428aba8-4c76-4754-955b-12481bdbf056{ip: 172.18.0.17, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e428aba8-4c76-4754-955b-12481bdbf056, CreationTimestamp2025-12-05T19:51:32.935Z[UTC]] moved to OPEN state
2025-12-05 19:51:36,038 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:36,101 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:36,330 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8f3666f3-be94-4bd0-9cdf-d574cfdb92a5, Nodes: 96194e2b-a974-49a8-93de-72d3ed217183{ip: 172.18.0.14, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:96194e2b-a974-49a8-93de-72d3ed217183, CreationTimestamp2025-12-05T19:51:33.301Z[UTC]] moved to OPEN state
2025-12-05 19:51:36,333 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:36,442 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:36,735 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 708eaa65-f187-464b-ae12-d49267247ae7, Nodes: 5b68e38e-2063-45f9-8dd5-9368622e4c7c{ip: 172.18.0.18, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:5b68e38e-2063-45f9-8dd5-9368622e4c7c, CreationTimestamp2025-12-05T19:51:33.696Z[UTC]] moved to OPEN state
2025-12-05 19:51:36,739 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:40,702 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:41,170 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:41,323 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:41,484 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:51:41,813 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:52:01,269 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:45651
2025-12-05 19:52:01,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:01,290 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 5599b3b6-8025-4e58-868d-07c1bffce963, Nodes: 96194e2b-a974-49a8-93de-72d3ed217183{ip: 172.18.0.14, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1f8b8143-ac06-4c67-9857-8196f1fc2412{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2673759f-f5dc-4630-95df-168d0270f5b4{ip: 172.18.0.19, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:96194e2b-a974-49a8-93de-72d3ed217183, CreationTimestamp2025-12-05T19:51:33.701Z[UTC]] moved to OPEN state
2025-12-05 19:52:01,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-05 19:52:01,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2025-12-05 19:52:01,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2025-12-05 19:52:01,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2025-12-05 19:52:01,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2025-12-05 19:52:01,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-05 19:52:01,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2025-12-05 19:52:01,291 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2025-12-05 19:52:05,432 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:38991
2025-12-05 19:52:05,435 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:52:05,439 [IPC Server handler 22 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2025-12-05 19:52:05,448 [IPC Server handler 22 on default port 9863] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 115816896921600000.
2025-12-05 19:52:05,448 [IPC Server handler 22 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 115816896921600000 to 115816896921601000.
2025-12-05 19:52:06,436 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:43929
2025-12-05 19:52:06,442 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:52:06,473 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:35635
2025-12-05 19:52:06,481 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:52:06,486 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:34567
2025-12-05 19:52:06,490 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:52:06,609 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.16:36009
2025-12-05 19:52:06,611 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:52:06,675 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:38039
2025-12-05 19:52:06,679 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:06,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:46815
2025-12-05 19:52:06,698 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:11,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:41221
2025-12-05 19:52:11,348 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:11,833 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:40657
2025-12-05 19:52:11,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:27,451 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:36823
2025-12-05 19:52:27,453 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:52:33,033 [IPC Server handler 22 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
2025-12-05 19:52:36,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:46583
2025-12-05 19:52:36,605 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:36,653 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:38447
2025-12-05 19:52:36,653 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:41405
2025-12-05 19:52:36,657 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:36,659 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:41,054 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.16:45615
2025-12-05 19:52:41,056 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:52:41,327 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:38753
2025-12-05 19:52:41,329 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:41,828 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:42795
2025-12-05 19:52:41,834 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:45,827 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:34691
2025-12-05 19:52:45,829 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:52:50,628 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:45883
2025-12-05 19:52:50,631 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:52:59,735 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:42337
2025-12-05 19:52:59,739 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:53:01,220 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:46849
2025-12-05 19:53:01,223 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:53:06,641 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:34199
2025-12-05 19:53:06,648 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:11,059 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:41977
2025-12-05 19:53:11,064 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:11,820 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:44019
2025-12-05 19:53:11,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:15,921 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:36421
2025-12-05 19:53:15,928 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:20,621 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:33973
2025-12-05 19:53:20,627 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:33,029 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:39103
2025-12-05 19:53:33,031 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:53:36,647 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:44753
2025-12-05 19:53:36,651 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:41,055 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:45745
2025-12-05 19:53:41,060 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:41,827 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:36687
2025-12-05 19:53:41,838 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:43,125 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:46385
2025-12-05 19:53:43,127 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:53:43,140 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40693
2025-12-05 19:53:43,144 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:53:43,146 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:53:45,952 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:36519
2025-12-05 19:53:45,954 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:47,626 [IPC Server handler 32 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:53:50,633 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:37981
2025-12-05 19:53:50,640 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:53:52,203 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:54:05,647 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34659
2025-12-05 19:54:05,651 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:54:05,651 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:54:06,644 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:38169
2025-12-05 19:54:06,650 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:09,954 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:54:11,050 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:35849
2025-12-05 19:54:11,056 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:11,822 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:41087
2025-12-05 19:54:11,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:15,935 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:42373
2025-12-05 19:54:15,937 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:20,624 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.14:36375
2025-12-05 19:54:20,630 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:21,346 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37867
2025-12-05 19:54:21,349 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:54:21,360 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:42775
2025-12-05 19:54:21,363 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:54:21,363 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:54:25,342 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:54:29,726 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:54:36,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:40253
2025-12-05 19:54:36,658 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:41,059 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:40527
2025-12-05 19:54:41,065 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:41,846 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:34775
2025-12-05 19:54:41,850 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:42,937 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34333
2025-12-05 19:54:42,947 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:54:42,947 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
2025-12-05 19:54:45,933 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:33185
2025-12-05 19:54:45,934 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:54:47,063 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.5
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2025-12-05 19:55:02,134 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.3
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.3.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/d0d18a3bff64b90f5f0755edb6003301049ffb32 ; compiled by 'micahzhao' on 2022-12-10T13:23Z
STARTUP_MSG:   java = 11.0.25
************************************************************/
2025-12-05 19:55:02,186 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-05 19:55:02,509 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:55:02,816 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 19:55:02,913 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 19:55:03,157 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2025-12-05 19:55:06,638 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2025-12-05 19:55:06,650 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2025-12-05 19:55:06,653 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2025-12-05 19:55:11,166 [main] INFO ha.HASecurityUtils: Init response: GETCERT
2025-12-05 19:55:14,605 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.3,host:scm
2025-12-05 19:55:14,628 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 19:55:15,080 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.3,host:scm
2025-12-05 19:55:15,081 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 19:55:15,082 [main] ERROR client.SCMCertificateClient: Invalid domain scm
2025-12-05 19:55:15,082 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm,scmId:d0548f32-4c75-44db-be5d-ada19a10c695,clusterId:CID-45189cc7-675a-44c1-8074-f84febb5a622,subject:scm-sub@scm
2025-12-05 19:55:15,303 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
2025-12-05 19:55:15,675 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2025-12-05 19:55:16,132 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-05 19:55:16,133 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 19:55:16,143 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-05 19:55:16,144 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 19:55:16,144 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2025-12-05 19:55:16,144 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2025-12-05 19:55:16,145 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2025-12-05 19:55:16,156 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 19:55:16,157 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-12-05 19:55:16,158 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 19:55:16,204 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2025-12-05 19:55:16,219 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-12-05 19:55:16,225 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-12-05 19:55:16,730 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2025-12-05 19:55:16,750 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2025-12-05 19:55:16,750 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2025-12-05 19:55:16,751 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-05 19:55:16,751 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 19:55:16,773 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 19:55:16,830 [main] INFO server.RaftServer: d0548f32-4c75-44db-be5d-ada19a10c695: addNew group-F84FEBB5A622:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|priority:0|startupRole:FOLLOWER] returns group-F84FEBB5A622:java.util.concurrent.CompletableFuture@42c2f48c[Not completed]
2025-12-05 19:55:16,888 [pool-2-thread-1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695: new RaftServerImpl for group-F84FEBB5A622:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
2025-12-05 19:55:16,905 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 19:55:16,905 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2025-12-05 19:55:16,905 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2025-12-05 19:55:16,905 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-05 19:55:16,905 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 19:55:16,905 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 19:55:16,920 [pool-2-thread-1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: ConfigurationManager, init=-1: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2025-12-05 19:55:16,923 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 19:55:16,933 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2025-12-05 19:55:16,934 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2025-12-05 19:55:16,987 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2025-12-05 19:55:17,005 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2025-12-05 19:55:17,007 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2025-12-05 19:55:17,092 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2025-12-05 19:55:17,397 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-12-05 19:55:17,398 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2025-12-05 19:55:17,399 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2025-12-05 19:55:17,400 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2025-12-05 19:55:17,400 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2025-12-05 19:55:17,403 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622 does not exist. Creating ...
2025-12-05 19:55:17,417 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622/in_use.lock acquired by nodename 11@scm
2025-12-05 19:55:17,434 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622 has been successfully formatted.
2025-12-05 19:55:17,440 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2025-12-05 19:55:17,466 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2025-12-05 19:55:17,470 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 19:55:17,471 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-12-05 19:55:17,472 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2025-12-05 19:55:17,476 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 19:55:17,490 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2025-12-05 19:55:17,491 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-12-05 19:55:17,496 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622
2025-12-05 19:55:17,497 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-12-05 19:55:17,497 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2025-12-05 19:55:17,499 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 19:55:17,499 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2025-12-05 19:55:17,501 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2025-12-05 19:55:17,502 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2025-12-05 19:55:17,502 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-12-05 19:55:17,503 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-12-05 19:55:17,516 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2025-12-05 19:55:17,517 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2025-12-05 19:55:17,517 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2025-12-05 19:55:17,518 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2025-12-05 19:55:17,533 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-05 19:55:17,533 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-05 19:55:17,540 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: start as a follower, conf=-1: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2025-12-05 19:55:17,543 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-05 19:55:17,550 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: start d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState
2025-12-05 19:55:17,551 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2025-12-05 19:55:17,551 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2025-12-05 19:55:17,555 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F84FEBB5A622,id=d0548f32-4c75-44db-be5d-ada19a10c695
2025-12-05 19:55:17,560 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-12-05 19:55:17,561 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-12-05 19:55:17,562 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2025-12-05 19:55:17,566 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2025-12-05 19:55:17,571 [main] INFO server.RaftServer: d0548f32-4c75-44db-be5d-ada19a10c695: start RPC server
2025-12-05 19:55:17,772 [main] INFO server.GrpcService: d0548f32-4c75-44db-be5d-ada19a10c695: GrpcService started, listening on 9894
2025-12-05 19:55:17,783 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-d0548f32-4c75-44db-be5d-ada19a10c695: Started
2025-12-05 19:55:22,681 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO impl.FollowerState: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5136535838ns, electionTimeout:5129ms
2025-12-05 19:55:22,683 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: shutdown d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState
2025-12-05 19:55:22,683 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-05 19:55:22,685 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
2025-12-05 19:55:22,685 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: start d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1
2025-12-05 19:55:22,692 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO impl.LeaderElection: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2025-12-05 19:55:22,692 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO impl.LeaderElection: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2025-12-05 19:55:22,693 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: shutdown d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1
2025-12-05 19:55:22,693 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-05 19:55:22,693 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: change Leader from null to d0548f32-4c75-44db-be5d-ada19a10c695 at term 1 for becomeLeader, leader elected after 5706ms
2025-12-05 19:55:22,697 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2025-12-05 19:55:22,701 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 19:55:22,701 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-12-05 19:55:22,706 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2025-12-05 19:55:22,706 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2025-12-05 19:55:22,707 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2025-12-05 19:55:22,714 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 19:55:22,718 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-12-05 19:55:22,723 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: start d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderStateImpl
2025-12-05 19:55:22,739 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-05 19:55:22,764 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: set configuration 0: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2025-12-05 19:55:22,821 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622/current/log_inprogress_0
2025-12-05 19:55:23,782 [main] INFO server.RaftServer: d0548f32-4c75-44db-be5d-ada19a10c695: close
2025-12-05 19:55:23,783 [main] INFO server.GrpcService: d0548f32-4c75-44db-be5d-ada19a10c695: shutdown server GrpcServerProtocolService now
2025-12-05 19:55:23,783 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: shutdown
2025-12-05 19:55:23,783 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F84FEBB5A622,id=d0548f32-4c75-44db-be5d-ada19a10c695
2025-12-05 19:55:23,783 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: shutdown d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderStateImpl
2025-12-05 19:55:23,788 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO impl.PendingRequests: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-PendingRequests: sendNotLeaderResponses
2025-12-05 19:55:23,789 [main] INFO server.GrpcService: d0548f32-4c75-44db-be5d-ada19a10c695: shutdown server GrpcServerProtocolService successfully
2025-12-05 19:55:23,790 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO impl.StateMachineUpdater: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater: set stopIndex = 0
2025-12-05 19:55:23,791 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO impl.StateMachineUpdater: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater: Took a snapshot at index 0
2025-12-05 19:55:23,791 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO impl.StateMachineUpdater: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-05 19:55:23,793 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: closes. applyIndex: 0
2025-12-05 19:55:23,794 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2025-12-05 19:55:23,796 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker close()
2025-12-05 19:55:23,797 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-d0548f32-4c75-44db-be5d-ada19a10c695: Stopped
2025-12-05 19:55:23,797 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:55:23,799 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-45189cc7-675a-44c1-8074-f84febb5a622; layoutVersion=4; scmId=d0548f32-4c75-44db-be5d-ada19a10c695
2025-12-05 19:55:23,800 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.3
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2025-12-05 19:55:24,970 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.3.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/d0d18a3bff64b90f5f0755edb6003301049ffb32 ; compiled by 'micahzhao' on 2022-12-10T13:23Z
STARTUP_MSG:   java = 11.0.25
************************************************************/
2025-12-05 19:55:24,980 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-05 19:55:25,003 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:55:25,021 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 19:55:25,026 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 19:55:25,395 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
2025-12-05 19:55:25,456 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
2025-12-05 19:55:25,461 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
2025-12-05 19:55:25,463 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/693397633953.crt.
2025-12-05 19:55:25,551 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2025-12-05 19:55:25,551 [main] INFO server.StorageContainerManager: SCM login successful.
2025-12-05 19:55:25,560 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:55:25,664 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 19:55:25,791 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0.jar!/network-topology-default.xml]
2025-12-05 19:55:25,791 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2025-12-05 19:55:25,831 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2025-12-05 19:55:25,841 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:d0548f32-4c75-44db-be5d-ada19a10c695
2025-12-05 19:55:25,889 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2025-12-05 19:55:25,943 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-05 19:55:25,944 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 19:55:25,944 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-05 19:55:25,945 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 19:55:25,945 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2025-12-05 19:55:25,945 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2025-12-05 19:55:25,945 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2025-12-05 19:55:25,947 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 19:55:25,947 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-12-05 19:55:25,948 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 19:55:25,956 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2025-12-05 19:55:25,959 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-12-05 19:55:25,960 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-12-05 19:55:26,282 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2025-12-05 19:55:26,284 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2025-12-05 19:55:26,284 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2025-12-05 19:55:26,284 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-05 19:55:26,284 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 19:55:26,286 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 19:55:26,288 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer: d0548f32-4c75-44db-be5d-ada19a10c695: found a subdirectory /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622
2025-12-05 19:55:26,292 [main] INFO server.RaftServer: d0548f32-4c75-44db-be5d-ada19a10c695: addNew group-F84FEBB5A622:[] returns group-F84FEBB5A622:java.util.concurrent.CompletableFuture@28501a4b[Not completed]
2025-12-05 19:55:26,307 [pool-16-thread-1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695: new RaftServerImpl for group-F84FEBB5A622:[] with SCMStateMachine:uninitialized
2025-12-05 19:55:26,309 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 19:55:26,309 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2025-12-05 19:55:26,309 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2025-12-05 19:55:26,310 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-05 19:55:26,310 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 19:55:26,310 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 19:55:26,316 [pool-16-thread-1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2025-12-05 19:55:26,316 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 19:55:26,319 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2025-12-05 19:55:26,319 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2025-12-05 19:55:26,329 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2025-12-05 19:55:26,331 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2025-12-05 19:55:26,331 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2025-12-05 19:55:26,414 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-12-05 19:55:26,415 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2025-12-05 19:55:26,415 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2025-12-05 19:55:26,416 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2025-12-05 19:55:26,416 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2025-12-05 19:55:26,417 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2025-12-05 19:55:26,417 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-05 19:55:26,418 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2025-12-05 19:55:26,505 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2025-12-05 19:55:26,605 [main] INFO reflections.Reflections: Reflections took 81 ms to scan 3 urls, producing 112 keys and 252 values 
2025-12-05 19:55:26,652 [main] INFO ha.SequenceIdGenerator: upgrade localId to 115816896921600000
2025-12-05 19:55:26,652 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2025-12-05 19:55:26,654 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2025-12-05 19:55:26,655 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2025-12-05 19:55:26,679 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2025-12-05 19:55:26,687 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2025-12-05 19:55:26,688 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-05 19:55:26,693 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2025-12-05 19:55:26,711 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-05 19:55:26,711 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-05 19:55:26,715 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2025-12-05 19:55:26,715 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2025-12-05 19:55:26,718 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2025-12-05 19:55:26,718 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2025-12-05 19:55:26,722 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-05 19:55:26,723 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2025-12-05 19:55:26,746 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-05 19:55:26,755 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2025-12-05 19:55:26,786 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2025-12-05 19:55:26,794 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2025-12-05 19:55:26,794 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2025-12-05 19:55:26,800 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2025-12-05 19:55:26,802 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:26,803 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-05 19:55:26,817 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2025-12-05 19:55:26,822 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2025-12-05 19:55:26,823 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 693397633953 on primary SCM
2025-12-05 19:55:26,827 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
2025-12-05 19:55:26,848 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:55:26,871 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2025-12-05 19:55:27,259 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 19:55:27,265 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:55:27,267 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2025-12-05 19:55:27,295 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 19:55:27,298 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:55:27,299 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2025-12-05 19:55:27,325 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 19:55:27,331 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 19:55:27,333 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2025-12-05 19:55:27,367 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2025-12-05 19:55:27,368 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2025-12-05 19:55:27,368 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2025-12-05 19:55:27,368 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-05 19:55:27,372 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2025-12-05 19:55:27,375 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2025-12-05 19:55:27,380 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622/in_use.lock acquired by nodename 6@scm
2025-12-05 19:55:27,385 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=d0548f32-4c75-44db-be5d-ada19a10c695} from /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622/current/raft-meta
2025-12-05 19:55:27,402 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: set configuration 0: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2025-12-05 19:55:27,403 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2025-12-05 19:55:27,408 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2025-12-05 19:55:27,408 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 19:55:27,409 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-12-05 19:55:27,410 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2025-12-05 19:55:27,412 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 19:55:27,416 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2025-12-05 19:55:27,416 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-12-05 19:55:27,420 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622
2025-12-05 19:55:27,420 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-12-05 19:55:27,421 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2025-12-05 19:55:27,421 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 19:55:27,422 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2025-12-05 19:55:27,422 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2025-12-05 19:55:27,422 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2025-12-05 19:55:27,423 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-12-05 19:55:27,423 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-12-05 19:55:27,429 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2025-12-05 19:55:27,429 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2025-12-05 19:55:27,430 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2025-12-05 19:55:27,430 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2025-12-05 19:55:27,445 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: set configuration 0: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2025-12-05 19:55:27,446 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622/current/log_inprogress_0
2025-12-05 19:55:27,450 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
2025-12-05 19:55:27,450 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-05 19:55:27,488 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: start as a follower, conf=0: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2025-12-05 19:55:27,488 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: changes role from      null to FOLLOWER at term 1 for startAsFollower
2025-12-05 19:55:27,489 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: start d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState
2025-12-05 19:55:27,491 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2025-12-05 19:55:27,491 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2025-12-05 19:55:27,491 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F84FEBB5A622,id=d0548f32-4c75-44db-be5d-ada19a10c695
2025-12-05 19:55:27,493 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-12-05 19:55:27,493 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-12-05 19:55:27,494 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2025-12-05 19:55:27,494 [d0548f32-4c75-44db-be5d-ada19a10c695-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2025-12-05 19:55:27,497 [Listener at 0.0.0.0/9860] INFO server.RaftServer: d0548f32-4c75-44db-be5d-ada19a10c695: start RPC server
2025-12-05 19:55:27,526 [Listener at 0.0.0.0/9860] INFO server.GrpcService: d0548f32-4c75-44db-be5d-ada19a10c695: GrpcService started, listening on 9894
2025-12-05 19:55:27,527 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-d0548f32-4c75-44db-be5d-ada19a10c695: Started
2025-12-05 19:55:27,533 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
2025-12-05 19:55:27,533 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2025-12-05 19:55:27,534 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
2025-12-05 19:55:27,534 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
2025-12-05 19:55:27,583 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-12-05 19:55:27,592 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-12-05 19:55:27,592 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2025-12-05 19:55:27,799 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2025-12-05 19:55:27,801 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:55:27,801 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2025-12-05 19:55:27,844 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2025-12-05 19:55:27,845 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2025-12-05 19:55:27,845 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:55:27,845 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2025-12-05 19:55:27,890 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2025-12-05 19:55:27,894 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:55:27,894 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2025-12-05 19:55:27,898 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2025-12-05 19:55:27,985 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@ff5d4f1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
2025-12-05 19:55:27,996 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2025-12-05 19:55:27,998 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2025-12-05 19:55:27,999 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2025-12-05 19:55:28,034 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @3794ms to org.eclipse.jetty.util.log.Slf4jLog
2025-12-05 19:55:28,217 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2025-12-05 19:55:28,236 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-05 19:55:28,241 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2025-12-05 19:55:28,241 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-12-05 19:55:28,241 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-12-05 19:55:28,243 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2025-12-05 19:55:28,292 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37461
2025-12-05 19:55:28,297 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:44671
2025-12-05 19:55:28,340 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm uses base directory /tmp/ozone_http
2025-12-05 19:55:28,341 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
2025-12-05 19:55:28,342 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.25+9-LTS
2025-12-05 19:55:28,441 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:55:28,444 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:55:28,506 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:46367
2025-12-05 19:55:28,543 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:55:28,559 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
2025-12-05 19:55:28,559 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
2025-12-05 19:55:28,566 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
2025-12-05 19:55:28,620 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:34637
2025-12-05 19:55:28,624 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 19:55:28,642 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:55:28,662 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b1ea1d9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2025-12-05 19:55:28,663 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4eb1943b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar!/webapps/static,AVAILABLE}
2025-12-05 19:55:28,704 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:37757
2025-12-05 19:55:28,719 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:55:28,731 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45307
2025-12-05 19:55:28,756 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.9:37461
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:28,757 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.17:44671
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:28,761 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:55:28,797 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#5 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.19:46367
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:28,798 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.7:34637
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:28,802 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.20:37757
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:28,964 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:35837
2025-12-05 19:55:28,981 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:55:28,989 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.18:35837
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:29,106 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 19:55:29,115 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@34eaf9c1{scm,/,file:///tmp/ozone_http/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0_jar-_-any-16997415302788469763/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar!/webapps/scm}
2025-12-05 19:55:29,124 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7f030c72{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2025-12-05 19:55:29,124 [Listener at 0.0.0.0/9860] INFO server.Server: Started @4884ms
2025-12-05 19:55:29,128 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
2025-12-05 19:55:29,128 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
2025-12-05 19:55:29,129 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2025-12-05 19:55:30,316 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:35975
2025-12-05 19:55:30,327 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:55:30,783 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.9:37461
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:30,797 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.17:44671
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:30,815 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.19:46367
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:30,831 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.7:34637
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:30,833 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.20:37757
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:31,006 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#8 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.18:35837
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:d0548f32-4c75-44db-be5d-ada19a10c695 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2025-12-05 19:55:32,499 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO impl.FollowerState: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5009601428ns, electionTimeout:5007ms
2025-12-05 19:55:32,500 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: shutdown d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState
2025-12-05 19:55:32,500 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2025-12-05 19:55:32,502 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
2025-12-05 19:55:32,502 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-FollowerState] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: start d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1
2025-12-05 19:55:32,509 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO impl.LeaderElection: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2025-12-05 19:55:32,510 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO impl.LeaderElection: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2025-12-05 19:55:32,510 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: shutdown d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1
2025-12-05 19:55:32,510 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2025-12-05 19:55:32,510 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2025-12-05 19:55:32,510 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2025-12-05 19:55:32,511 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: change Leader from null to d0548f32-4c75-44db-be5d-ada19a10c695 at term 2 for becomeLeader, leader elected after 6181ms
2025-12-05 19:55:32,515 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2025-12-05 19:55:32,537 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 19:55:32,537 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-12-05 19:55:32,540 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2025-12-05 19:55:32,540 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2025-12-05 19:55:32,541 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2025-12-05 19:55:32,544 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 19:55:32,545 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-12-05 19:55:32,546 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO impl.RoleInfo: d0548f32-4c75-44db-be5d-ada19a10c695: start d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderStateImpl
2025-12-05 19:55:32,551 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2025-12-05 19:55:32,554 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-LeaderElection1] INFO server.RaftServer$Division: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622: set configuration 1: peers:[d0548f32-4c75-44db-be5d-ada19a10c695|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2025-12-05 19:55:32,555 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622/current/log_inprogress_0 to /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622/current/log_0-0
2025-12-05 19:55:32,566 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/45189cc7-675a-44c1-8074-f84febb5a622/current/log_inprogress_1
2025-12-05 19:55:32,570 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2025-12-05 19:55:32,570 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2025-12-05 19:55:32,572 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:32,573 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2025-12-05 19:55:32,573 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-05 19:55:32,573 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2025-12-05 19:55:32,574 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 19:55:32,575 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2025-12-05 19:55:32,797 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: b0002301-2198-4db0-abb8-4ca1e14503c4
2025-12-05 19:55:32,807 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 2bdc892a-b240-4262-94f2-b9ccce18f7ca
2025-12-05 19:55:32,961 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:32,966 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 19:55:32,966 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 19:55:32,991 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 4e9965cb-3ab3-4a10-a4d0-8095770d52d0
2025-12-05 19:55:33,036 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:33,046 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 9c19ba53-bf3c-427e-a7b8-1549de610d6e
2025-12-05 19:55:33,060 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:33,079 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 57156d3f-251f-4b6b-aa8a-7952a9948920
2025-12-05 19:55:33,119 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:33,139 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: e756a468-2373-4906-9a1b-f14bfb09c7ea
2025-12-05 19:55:33,188 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:33,263 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:37,957 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41517
2025-12-05 19:55:37,975 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:55:37,978 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: 2f61f1a0-2085-4e25-b770-6fcfc3bb7427
2025-12-05 19:55:38,062 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:45,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:33045
2025-12-05 19:55:45,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:55:45,320 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34805
2025-12-05 19:55:45,321 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:55:45,612 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:40701
2025-12-05 19:55:45,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:55:45,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:36607
2025-12-05 19:55:45,728 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43667
2025-12-05 19:55:45,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:55:45,780 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:55:45,929 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:39381
2025-12-05 19:55:45,938 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:55:47,045 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:41831
2025-12-05 19:55:47,047 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:55:47,188 [IPC Server handler 10 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e756a468-2373-4906-9a1b-f14bfb09c7ea
2025-12-05 19:55:47,190 [IPC Server handler 10 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e756a468-2373-4906-9a1b-f14bfb09c7ea{ip: 172.18.0.18, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711393386131, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:55:47,194 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:55:47,198 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 5 required.
2025-12-05 19:55:47,223 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7737d8a4-b77b-420d-be07-b6b944bead13 to datanode:e756a468-2373-4906-9a1b-f14bfb09c7ea
2025-12-05 19:55:47,262 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7737d8a4-b77b-420d-be07-b6b944bead13, Nodes: e756a468-2373-4906-9a1b-f14bfb09c7ea{ip: 172.18.0.18, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:55:47.205Z[UTC]].
2025-12-05 19:55:47,263 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:47,320 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/b0002301-2198-4db0-abb8-4ca1e14503c4
2025-12-05 19:55:47,325 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : b0002301-2198-4db0-abb8-4ca1e14503c4{ip: 172.18.0.9, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711040582825, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:55:47,326 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 5 required.
2025-12-05 19:55:47,327 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:55:47,333 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=89270959-59b7-4752-bf02-9ebdd15d070f to datanode:b0002301-2198-4db0-abb8-4ca1e14503c4
2025-12-05 19:55:47,339 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 89270959-59b7-4752-bf02-9ebdd15d070f, Nodes: b0002301-2198-4db0-abb8-4ca1e14503c4{ip: 172.18.0.9, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:55:47.333Z[UTC]].
2025-12-05 19:55:47,339 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:47,600 [IPC Server handler 70 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/2bdc892a-b240-4262-94f2-b9ccce18f7ca
2025-12-05 19:55:47,609 [IPC Server handler 70 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2bdc892a-b240-4262-94f2-b9ccce18f7ca{ip: 172.18.0.17, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711169531661, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:55:47,611 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:55:47,617 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9c17fc07-bfe8-4fd2-a64f-a01770c93114 to datanode:2bdc892a-b240-4262-94f2-b9ccce18f7ca
2025-12-05 19:55:47,620 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 5 required.
2025-12-05 19:55:47,627 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 9c17fc07-bfe8-4fd2-a64f-a01770c93114, Nodes: 2bdc892a-b240-4262-94f2-b9ccce18f7ca{ip: 172.18.0.17, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:55:47.617Z[UTC]].
2025-12-05 19:55:47,627 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:47,700 [IPC Server handler 12 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4e9965cb-3ab3-4a10-a4d0-8095770d52d0
2025-12-05 19:55:47,703 [IPC Server handler 12 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4e9965cb-3ab3-4a10-a4d0-8095770d52d0{ip: 172.18.0.19, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711228345566, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:55:47,703 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:55:47,703 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 5 required.
2025-12-05 19:55:47,704 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=993bfb7a-5b66-4389-ad08-7d9219e9ee62 to datanode:4e9965cb-3ab3-4a10-a4d0-8095770d52d0
2025-12-05 19:55:47,708 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 993bfb7a-5b66-4389-ad08-7d9219e9ee62, Nodes: 4e9965cb-3ab3-4a10-a4d0-8095770d52d0{ip: 172.18.0.19, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:55:47.704Z[UTC]].
2025-12-05 19:55:47,708 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:47,884 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/57156d3f-251f-4b6b-aa8a-7952a9948920
2025-12-05 19:55:47,885 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 57156d3f-251f-4b6b-aa8a-7952a9948920{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711330750388, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 19:55:47,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 5 DataNodes registered, 5 required.
2025-12-05 19:55:47,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2025-12-05 19:55:47,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2025-12-05 19:55:47,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2025-12-05 19:55:47,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-05 19:55:47,887 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:55:47,888 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0c67ed59-e775-4df1-9445-20712e094d3b to datanode:57156d3f-251f-4b6b-aa8a-7952a9948920
2025-12-05 19:55:47,889 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 19:55:47,893 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0c67ed59-e775-4df1-9445-20712e094d3b, Nodes: 57156d3f-251f-4b6b-aa8a-7952a9948920{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:55:47.888Z[UTC]].
2025-12-05 19:55:47,893 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:47,899 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a9d04797-1e50-4189-953a-142edc296d68 to datanode:b0002301-2198-4db0-abb8-4ca1e14503c4
2025-12-05 19:55:47,900 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a9d04797-1e50-4189-953a-142edc296d68 to datanode:2bdc892a-b240-4262-94f2-b9ccce18f7ca
2025-12-05 19:55:47,900 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a9d04797-1e50-4189-953a-142edc296d68 to datanode:e756a468-2373-4906-9a1b-f14bfb09c7ea
2025-12-05 19:55:47,908 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a9d04797-1e50-4189-953a-142edc296d68, Nodes: b0002301-2198-4db0-abb8-4ca1e14503c4{ip: 172.18.0.9, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2bdc892a-b240-4262-94f2-b9ccce18f7ca{ip: 172.18.0.17, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e756a468-2373-4906-9a1b-f14bfb09c7ea{ip: 172.18.0.18, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:55:47.899Z[UTC]].
2025-12-05 19:55:47,909 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:50,251 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7737d8a4-b77b-420d-be07-b6b944bead13, Nodes: e756a468-2373-4906-9a1b-f14bfb09c7ea{ip: 172.18.0.18, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e756a468-2373-4906-9a1b-f14bfb09c7ea, CreationTimestamp2025-12-05T19:55:47.205Z[UTC]] moved to OPEN state
2025-12-05 19:55:50,262 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:50,264 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:50,322 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:50,438 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 89270959-59b7-4752-bf02-9ebdd15d070f, Nodes: b0002301-2198-4db0-abb8-4ca1e14503c4{ip: 172.18.0.9, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:b0002301-2198-4db0-abb8-4ca1e14503c4, CreationTimestamp2025-12-05T19:55:47.333Z[UTC]] moved to OPEN state
2025-12-05 19:55:50,442 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:50,442 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:50,512 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:50,789 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 9c17fc07-bfe8-4fd2-a64f-a01770c93114, Nodes: 2bdc892a-b240-4262-94f2-b9ccce18f7ca{ip: 172.18.0.17, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:2bdc892a-b240-4262-94f2-b9ccce18f7ca, CreationTimestamp2025-12-05T19:55:47.617Z[UTC]] moved to OPEN state
2025-12-05 19:55:50,793 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:50,794 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:50,923 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 993bfb7a-5b66-4389-ad08-7d9219e9ee62, Nodes: 4e9965cb-3ab3-4a10-a4d0-8095770d52d0{ip: 172.18.0.19, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4e9965cb-3ab3-4a10-a4d0-8095770d52d0, CreationTimestamp2025-12-05T19:55:47.704Z[UTC]] moved to OPEN state
2025-12-05 19:55:50,933 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:50,935 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:51,065 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:51,099 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0c67ed59-e775-4df1-9445-20712e094d3b, Nodes: 57156d3f-251f-4b6b-aa8a-7952a9948920{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:57156d3f-251f-4b6b-aa8a-7952a9948920, CreationTimestamp2025-12-05T19:55:47.888Z[UTC]] moved to OPEN state
2025-12-05 19:55:51,104 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 19:55:51,105 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:55,447 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:55,513 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:56,040 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:56,129 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:55:56,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:56:25,455 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:41797
2025-12-05 19:56:25,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:25,518 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:42135
2025-12-05 19:56:25,520 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:26,047 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:42915
2025-12-05 19:56:26,053 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:26,139 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:43505
2025-12-05 19:56:26,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:26,284 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:44985
2025-12-05 19:56:26,287 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:36,104 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:44419
2025-12-05 19:56:36,107 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:36,108 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a9d04797-1e50-4189-953a-142edc296d68, Nodes: b0002301-2198-4db0-abb8-4ca1e14503c4{ip: 172.18.0.9, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2bdc892a-b240-4262-94f2-b9ccce18f7ca{ip: 172.18.0.17, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e756a468-2373-4906-9a1b-f14bfb09c7ea{ip: 172.18.0.18, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:b0002301-2198-4db0-abb8-4ca1e14503c4, CreationTimestamp2025-12-05T19:55:47.899Z[UTC]] moved to OPEN state
2025-12-05 19:56:36,109 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 19:56:36,112 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2025-12-05 19:56:36,116 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-05 19:56:36,117 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2025-12-05 19:56:36,117 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2025-12-05 19:56:36,117 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2025-12-05 19:56:36,117 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2025-12-05 19:56:36,118 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-05 19:56:36,118 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2025-12-05 19:56:36,118 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2025-12-05 19:56:36,118 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2025-12-05 19:56:36,120 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2025-12-05 19:56:41,384 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42583
2025-12-05 19:56:41,386 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:56:41,396 [IPC Server handler 1 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2025-12-05 19:56:41,408 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 115816896921600000.
2025-12-05 19:56:41,410 [IPC Server handler 1 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 115816896921600000 to 115816896921601000.
2025-12-05 19:56:42,548 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:42259
2025-12-05 19:56:42,551 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:56:42,591 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:37183
2025-12-05 19:56:42,601 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:36451
2025-12-05 19:56:42,605 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:56:42,607 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:56:42,629 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:43407
2025-12-05 19:56:42,632 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:56:42,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:36683
2025-12-05 19:56:42,681 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:35381
2025-12-05 19:56:42,685 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:42,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:53,012 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37941
2025-12-05 19:56:53,014 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:56:56,143 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:41559
2025-12-05 19:56:56,147 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:56:56,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:40041
2025-12-05 19:56:56,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:03,852 [d0548f32-4c75-44db-be5d-ada19a10c695@group-F84FEBB5A622-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f6fa150d-8c17-4f3a-bb9e-4fdb711f7a48, Nodes: b0002301-2198-4db0-abb8-4ca1e14503c4{ip: 172.18.0.9, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711040582825, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}2bdc892a-b240-4262-94f2-b9ccce18f7ca{ip: 172.18.0.17, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711169531661, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}57156d3f-251f-4b6b-aa8a-7952a9948920{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711330750388, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}4e9965cb-3ab3-4a10-a4d0-8095770d52d0{ip: 172.18.0.19, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711228345566, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}e756a468-2373-4906-9a1b-f14bfb09c7ea{ip: 172.18.0.18, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711393386131, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:57:03.849Z[UTC]].
2025-12-05 19:57:03,854 [IPC Server handler 15 on default port 9863] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f6fa150d-8c17-4f3a-bb9e-4fdb711f7a48, Nodes: b0002301-2198-4db0-abb8-4ca1e14503c4{ip: 172.18.0.9, host: xcompat-datanode-3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711040582825, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}2bdc892a-b240-4262-94f2-b9ccce18f7ca{ip: 172.18.0.17, host: xcompat-datanode-1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711169531661, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}57156d3f-251f-4b6b-aa8a-7952a9948920{ip: 172.18.0.20, host: xcompat-datanode-5.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711330750388, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}4e9965cb-3ab3-4a10-a4d0-8095770d52d0{ip: 172.18.0.19, host: xcompat-datanode-2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711228345566, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}e756a468-2373-4906-9a1b-f14bfb09c7ea{ip: 172.18.0.18, host: xcompat-datanode-4.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 711393386131, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: EC/ECReplicationConfig{data=3, parity=2, ecChunkSize=1048576, codec=rs}, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T19:57:03.849Z[UTC]] moved to OPEN state
2025-12-05 19:57:05,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:44819
2025-12-05 19:57:05,081 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:44439
2025-12-05 19:57:05,082 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:05,101 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:42237
2025-12-05 19:57:05,108 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:05,119 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:35969
2025-12-05 19:57:05,122 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:57:05,124 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:57:05,295 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:44411
2025-12-05 19:57:05,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:05,397 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:36059
2025-12-05 19:57:05,399 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 19:57:16,155 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45181
2025-12-05 19:57:16,157 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:57:35,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:36473
2025-12-05 19:57:35,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:41443
2025-12-05 19:57:35,072 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:35,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:35,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:43811
2025-12-05 19:57:35,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:35,292 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:33353
2025-12-05 19:57:35,296 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:35,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:34571
2025-12-05 19:57:35,456 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:57:47,585 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41315
2025-12-05 19:57:47,586 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:57:48,268 [IPC Server handler 15 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
2025-12-05 19:58:05,044 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:46133
2025-12-05 19:58:05,051 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:05,055 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:34215
2025-12-05 19:58:05,067 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:05,214 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:35353
2025-12-05 19:58:05,230 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:05,319 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:33821
2025-12-05 19:58:05,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:05,471 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:42265
2025-12-05 19:58:05,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:15,740 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36705
2025-12-05 19:58:15,743 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:58:17,155 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40687
2025-12-05 19:58:17,159 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:58:35,054 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34711
2025-12-05 19:58:35,076 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:41711
2025-12-05 19:58:35,079 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:35,085 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:35,206 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:38967
2025-12-05 19:58:35,210 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:35,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:36155
2025-12-05 19:58:35,313 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:35,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:39081
2025-12-05 19:58:35,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:58:43,035 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44271
2025-12-05 19:58:43,045 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:58:44,577 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33023
2025-12-05 19:58:44,578 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:58:56,892 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33243
2025-12-05 19:58:56,894 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:59:05,071 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:45567
2025-12-05 19:59:05,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40743
2025-12-05 19:59:05,083 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:05,084 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:05,187 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:35693
2025-12-05 19:59:05,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:05,296 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:44295
2025-12-05 19:59:05,297 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:05,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:33005
2025-12-05 19:59:05,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:35,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:46455
2025-12-05 19:59:35,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34543
2025-12-05 19:59:35,068 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:35,077 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:35,191 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:43945
2025-12-05 19:59:35,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:35,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:40213
2025-12-05 19:59:35,311 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:35,460 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:35785
2025-12-05 19:59:35,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 19:59:58,972 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40333
2025-12-05 19:59:58,977 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 19:59:58,988 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43203
2025-12-05 19:59:58,991 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 19:59:58,993 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:00:03,622 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:00:05,046 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:45803
2025-12-05 20:00:05,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:34113
2025-12-05 20:00:05,059 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:05,064 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:05,195 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:34177
2025-12-05 20:00:05,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:05,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:45621
2025-12-05 20:00:05,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:05,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:44843
2025-12-05 20:00:05,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:08,525 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:00:13,321 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:00:17,839 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:00:26,795 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2025-12-05 20:00:35,037 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34715
2025-12-05 20:00:35,040 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:35,058 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:32987
2025-12-05 20:00:35,065 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:35,190 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:37399
2025-12-05 20:00:35,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:35,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:33479
2025-12-05 20:00:35,314 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:35,463 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:32903
2025-12-05 20:00:35,471 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:00:44,412 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36731
2025-12-05 20:00:44,414 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:00:44,429 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37911
2025-12-05 20:00:44,432 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:00:44,432 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:00:47,444 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:41449
2025-12-05 20:00:47,451 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:00:48,727 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:00:53,364 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:00:58,045 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:01:02,838 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:01:05,045 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:39095
2025-12-05 20:01:05,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:45099
2025-12-05 20:01:05,060 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:05,067 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:05,192 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:33631
2025-12-05 20:01:05,196 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:05,290 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:44421
2025-12-05 20:01:05,295 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:05,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:36903
2025-12-05 20:01:05,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:20,912 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34795
2025-12-05 20:01:20,916 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:01:20,926 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44687
2025-12-05 20:01:20,927 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:01:20,928 [IPC Server handler 78 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:01:25,382 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:01:30,005 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:01:34,954 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:01:35,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:43199
2025-12-05 20:01:35,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:44655
2025-12-05 20:01:35,075 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:35,079 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:35,192 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:37193
2025-12-05 20:01:35,202 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:35,315 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:46777
2025-12-05 20:01:35,325 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:35,452 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:35783
2025-12-05 20:01:35,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:01:39,668 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:01:56,796 [Under Replicated Processor] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
2025-12-05 20:01:56,796 [Over Replicated Processor] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
2025-12-05 20:02:04,411 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45567
2025-12-05 20:02:04,412 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:02:04,419 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35105
2025-12-05 20:02:04,420 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:02:04,420 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:02:05,039 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34351
2025-12-05 20:02:05,058 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:02:05,078 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:32931
2025-12-05 20:02:05,084 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:02:05,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:38015
2025-12-05 20:02:05,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:02:05,294 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:43951
2025-12-05 20:02:05,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:02:05,459 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:43445
2025-12-05 20:02:05,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:02:08,888 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:02:13,577 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:02:17,993 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:02:22,490 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2025-12-05 20:02:45,603 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.14
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.4.1
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.6.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.1.1.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.78.1.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.78.1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.26.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.2.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.37.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.5.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.8.1.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/commons-text-1.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.78.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.1.jar
STARTUP_MSG:   build = git@github.com:apache/ozone.git/a9d5d1c630d903b28984d1c46daa78a1812674ac ; compiled by 'ozone' on 2024-11-14T09:02Z
STARTUP_MSG:   java = 11.0.25
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/dn.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/dn@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.volume.min.free.space.percent=0.001f, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/scm.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=5, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.basedir=/tmp/ozone_http, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/om.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.administrators=testuser2, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=*, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/s3g.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=1, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=1, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=scm:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2025-12-05 20:02:45,670 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-05 20:02:45,877 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:02:47,033 [main] INFO reflections.Reflections: Reflections took 1030 ms to scan 3 urls, producing 133 keys and 290 values 
2025-12-05 20:02:47,553 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 20:02:47,620 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 20:02:47,803 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2025-12-05 20:02:53,453 [main] INFO client.SCMCertificateClient: Certificate serial ID set to null
2025-12-05 20:02:53,453 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2025-12-05 20:02:53,454 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2025-12-05 20:02:53,461 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2025-12-05 20:02:56,562 [main] INFO client.SCMCertificateClient: Init response: GETCERT
2025-12-05 20:02:58,359 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.14,host:scm
2025-12-05 20:02:58,360 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 20:02:58,366 [main] ERROR utils.SelfSignedCertificate: Invalid domain scm
2025-12-05 20:02:59,141 [main] INFO utils.SelfSignedCertificate: Certificate 1 is issued by CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1 to CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1, valid from Fri Dec 05 20:02:58 UTC 2025 to Mon Jan 13 20:02:58 UTC 2031
2025-12-05 20:02:59,200 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/ca/certs/certificate.crt
2025-12-05 20:02:59,202 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDsTCCApmgAwIBAgIBATANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNjFhOTAwMzYtMWY3Yy00MmJlLTgzNTctZjUyMGJlOWEz
MzFlMTEwLwYDVQQKDChDSUQtNDg2OTA1YWUtY2U3YS00NDI5LTkzNDktOTQyYzA3
YjlmN2MxMQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMDI1OFoXDTMxMDExMzIwMDI1
OFowgYAxEDAOBgNVBAMMB3NjbUBzY20xLTArBgNVBAsMJDYxYTkwMDM2LTFmN2Mt
NDJiZS04MzU3LWY1MjBiZTlhMzMxZTExMC8GA1UECgwoQ0lELTQ4NjkwNWFlLWNl
N2EtNDQyOS05MzQ5LTk0MmMwN2I5ZjdjMTEKMAgGA1UEBRMBMTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAIyX+sx6VsgxQaiud3q6oNoJZf/1wPSaffZB
CsAJpd4P8ldle5vD/5yFrzqJ0R2Nwl4+JpawjqEjQfyW7VUWoY9sNds4KLNjVfl7
f4r9lbW8ZmcycG1gUGcBEv7/7juFN2XFtb/lo3VY9P0DUAp4QB1UZ5VMgL+Us5ad
cAVA/k8GzUgm8G0FLNrMkpic5yEn3boy237lOjARm/nQiTXKx3xLH7oImSDegiFh
8XgPHY9UA085WqaxP1L8z41PoJKxHZlBu3ZYkVo9LW4sJK3aDiqM9Ha9HDW3Wsmk
hDCxaT85h75JMtI9IkypFMoixNLDUbJfD64HqwZGwZCGyKAsiDkCAwEAAaM0MDIw
DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0RBAgwBocErBIA
DjANBgkqhkiG9w0BAQsFAAOCAQEAZQjKiNavND9ZgZZPxumfy7Ks249Bs6To8VyB
3Tm46xZOdY/fsObj8DXU3L744J/NV6SsHvijQIkVw4ItcK/muk2nOoT6A/rMMxsT
wWF3ziTPg1ZE+RhFgk+fLtWH9+5Odt2TiKDcYMsBgRrxh/Qq7kIQiH8ce+WViOoq
XipFbH2P5Uwtn/3Su5OFitzlDNOPDnol+RkT/EywMUOtrCxpTwwug93xPfumKWb3
ahyT9qzDiAKjuitU1bwt6bfrcv8GvkNBjVkbByKocX0rY1jW32j7cGMYn0Aoi9Wk
NaP1BXrxwAGW0OyDbLnXW25cqQwgwPdiGZQYdfIUMaoZ/G8KKw==
-----END CERTIFICATE-----

2025-12-05 20:02:59,422 [main] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm,scmId:61a90036-1f7c-42be-8357-f520be9a331e,clusterId:CID-486905ae-ce7a-4429-9349-942c07b9f7c1,subject:scm-sub@scm
2025-12-05 20:02:59,442 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.14,host:scm
2025-12-05 20:02:59,443 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 20:02:59,447 [main] ERROR utils.CertificateSignRequest: Invalid domain scm
2025-12-05 20:02:59,882 [main] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.19, 2.5.29.15, 2.5.29.17
2025-12-05 20:02:59,883 [main] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:03:00,011 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/CA-1.crt
2025-12-05 20:03:00,011 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDsTCCApmgAwIBAgIBATANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNjFhOTAwMzYtMWY3Yy00MmJlLTgzNTctZjUyMGJlOWEz
MzFlMTEwLwYDVQQKDChDSUQtNDg2OTA1YWUtY2U3YS00NDI5LTkzNDktOTQyYzA3
YjlmN2MxMQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMDI1OFoXDTMxMDExMzIwMDI1
OFowgYAxEDAOBgNVBAMMB3NjbUBzY20xLTArBgNVBAsMJDYxYTkwMDM2LTFmN2Mt
NDJiZS04MzU3LWY1MjBiZTlhMzMxZTExMC8GA1UECgwoQ0lELTQ4NjkwNWFlLWNl
N2EtNDQyOS05MzQ5LTk0MmMwN2I5ZjdjMTEKMAgGA1UEBRMBMTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAIyX+sx6VsgxQaiud3q6oNoJZf/1wPSaffZB
CsAJpd4P8ldle5vD/5yFrzqJ0R2Nwl4+JpawjqEjQfyW7VUWoY9sNds4KLNjVfl7
f4r9lbW8ZmcycG1gUGcBEv7/7juFN2XFtb/lo3VY9P0DUAp4QB1UZ5VMgL+Us5ad
cAVA/k8GzUgm8G0FLNrMkpic5yEn3boy237lOjARm/nQiTXKx3xLH7oImSDegiFh
8XgPHY9UA085WqaxP1L8z41PoJKxHZlBu3ZYkVo9LW4sJK3aDiqM9Ha9HDW3Wsmk
hDCxaT85h75JMtI9IkypFMoixNLDUbJfD64HqwZGwZCGyKAsiDkCAwEAAaM0MDIw
DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0RBAgwBocErBIA
DjANBgkqhkiG9w0BAQsFAAOCAQEAZQjKiNavND9ZgZZPxumfy7Ks249Bs6To8VyB
3Tm46xZOdY/fsObj8DXU3L744J/NV6SsHvijQIkVw4ItcK/muk2nOoT6A/rMMxsT
wWF3ziTPg1ZE+RhFgk+fLtWH9+5Odt2TiKDcYMsBgRrxh/Qq7kIQiH8ce+WViOoq
XipFbH2P5Uwtn/3Su5OFitzlDNOPDnol+RkT/EywMUOtrCxpTwwug93xPfumKWb3
ahyT9qzDiAKjuitU1bwt6bfrcv8GvkNBjVkbByKocX0rY1jW32j7cGMYn0Aoi9Wk
NaP1BXrxwAGW0OyDbLnXW25cqQwgwPdiGZQYdfIUMaoZ/G8KKw==
-----END CERTIFICATE-----

2025-12-05 20:03:00,043 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/2.crt
2025-12-05 20:03:00,048 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDtTCCAp2gAwIBAgIBAjANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNjFhOTAwMzYtMWY3Yy00MmJlLTgzNTctZjUyMGJlOWEz
MzFlMTEwLwYDVQQKDChDSUQtNDg2OTA1YWUtY2U3YS00NDI5LTkzNDktOTQyYzA3
YjlmN2MxMQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMDI1OVoXDTMxMDExMzIwMDI1
OVowgYQxFDASBgNVBAMMC3NjbS1zdWJAc2NtMS0wKwYDVQQLDCQ2MWE5MDAzNi0x
ZjdjLTQyYmUtODM1Ny1mNTIwYmU5YTMzMWUxMTAvBgNVBAoMKENJRC00ODY5MDVh
ZS1jZTdhLTQ0MjktOTM0OS05NDJjMDdiOWY3YzExCjAIBgNVBAUTATIwggEiMA0G
CSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDRsfq0ncsxiYT4GFiSlVRlRaEIIJAq
lvTW9SvzN9IQXtbo4M0EORTuoYeQpgtif0scOGBEyWPLkf1lBQ27r88I4sNoxdzG
8m9QOktHIVwBNDs1o4MkFOuf4N2Aa7G1XdCzu0xXc+qNzdnCjFaRTZhatp5abs9+
0VjXlR0HOAgV4fJzqOEOqeNvO9hVJ8tMAdE6UpnwumAZ0iIuTbVMj0YoH3aNVMoG
OFqxknKLJKSsaURngAl6qir+yyiOi2j2rXR9phZzF72lJaUuRe57tLFU9K8t0Xmq
3nUmyHZdYm/0URgbIckmnzf8GZLLjnA+k2LVlfscSfDknZ7vo+XE/K5HAgMBAAGj
NDAyMA4GA1UdDwEB/wQEAwIBvjAPBgNVHREECDAGhwSsEgAOMA8GA1UdEwEB/wQF
MAMBAf8wDQYJKoZIhvcNAQELBQADggEBAAaDSFdr685moxPXgXI1eZnQ/QS1Bvd9
yvTXRRyV+PIH9tLZLAhht3eEMdde6B3yaNsearZkOTQVaEnMkqypNWD5im225CRx
1Jt/o9fZO872uo8nwf9+87XknOrmkPbyC6UXLYBlgbSgxYSNXhpdAXa1Q/DOgK78
U0omtC27aBWtMa8knRuFrUx7to13/Waea2JdTaZWDEZEN1QVCsFfL116PE91FrhI
czQxt/xHGiIZHDiBcHUoDtG+39Z4R1gsM7yLSq078+IjVqs1faDSaxyAnHoX7HUY
hCGvafUAppb+6HWbiYH5gk+XZhnApr1sDvhe6LCow493rgzn3kGpGMU=
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDsTCCApmgAwIBAgIBATANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNjFhOTAwMzYtMWY3Yy00MmJlLTgzNTctZjUyMGJlOWEz
MzFlMTEwLwYDVQQKDChDSUQtNDg2OTA1YWUtY2U3YS00NDI5LTkzNDktOTQyYzA3
YjlmN2MxMQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMDI1OFoXDTMxMDExMzIwMDI1
OFowgYAxEDAOBgNVBAMMB3NjbUBzY20xLTArBgNVBAsMJDYxYTkwMDM2LTFmN2Mt
NDJiZS04MzU3LWY1MjBiZTlhMzMxZTExMC8GA1UECgwoQ0lELTQ4NjkwNWFlLWNl
N2EtNDQyOS05MzQ5LTk0MmMwN2I5ZjdjMTEKMAgGA1UEBRMBMTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAIyX+sx6VsgxQaiud3q6oNoJZf/1wPSaffZB
CsAJpd4P8ldle5vD/5yFrzqJ0R2Nwl4+JpawjqEjQfyW7VUWoY9sNds4KLNjVfl7
f4r9lbW8ZmcycG1gUGcBEv7/7juFN2XFtb/lo3VY9P0DUAp4QB1UZ5VMgL+Us5ad
cAVA/k8GzUgm8G0FLNrMkpic5yEn3boy237lOjARm/nQiTXKx3xLH7oImSDegiFh
8XgPHY9UA085WqaxP1L8z41PoJKxHZlBu3ZYkVo9LW4sJK3aDiqM9Ha9HDW3Wsmk
hDCxaT85h75JMtI9IkypFMoixNLDUbJfD64HqwZGwZCGyKAsiDkCAwEAAaM0MDIw
DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0RBAgwBocErBIA
DjANBgkqhkiG9w0BAQsFAAOCAQEAZQjKiNavND9ZgZZPxumfy7Ks249Bs6To8VyB
3Tm46xZOdY/fsObj8DXU3L744J/NV6SsHvijQIkVw4ItcK/muk2nOoT6A/rMMxsT
wWF3ziTPg1ZE+RhFgk+fLtWH9+5Odt2TiKDcYMsBgRrxh/Qq7kIQiH8ce+WViOoq
XipFbH2P5Uwtn/3Su5OFitzlDNOPDnol+RkT/EywMUOtrCxpTwwug93xPfumKWb3
ahyT9qzDiAKjuitU1bwt6bfrcv8GvkNBjVkbByKocX0rY1jW32j7cGMYn0Aoi9Wk
NaP1BXrxwAGW0OyDbLnXW25cqQwgwPdiGZQYdfIUMaoZ/G8KKw==
-----END CERTIFICATE-----

2025-12-05 20:03:00,049 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/certificate.crt
2025-12-05 20:03:00,049 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDtTCCAp2gAwIBAgIBAjANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNjFhOTAwMzYtMWY3Yy00MmJlLTgzNTctZjUyMGJlOWEz
MzFlMTEwLwYDVQQKDChDSUQtNDg2OTA1YWUtY2U3YS00NDI5LTkzNDktOTQyYzA3
YjlmN2MxMQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMDI1OVoXDTMxMDExMzIwMDI1
OVowgYQxFDASBgNVBAMMC3NjbS1zdWJAc2NtMS0wKwYDVQQLDCQ2MWE5MDAzNi0x
ZjdjLTQyYmUtODM1Ny1mNTIwYmU5YTMzMWUxMTAvBgNVBAoMKENJRC00ODY5MDVh
ZS1jZTdhLTQ0MjktOTM0OS05NDJjMDdiOWY3YzExCjAIBgNVBAUTATIwggEiMA0G
CSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDRsfq0ncsxiYT4GFiSlVRlRaEIIJAq
lvTW9SvzN9IQXtbo4M0EORTuoYeQpgtif0scOGBEyWPLkf1lBQ27r88I4sNoxdzG
8m9QOktHIVwBNDs1o4MkFOuf4N2Aa7G1XdCzu0xXc+qNzdnCjFaRTZhatp5abs9+
0VjXlR0HOAgV4fJzqOEOqeNvO9hVJ8tMAdE6UpnwumAZ0iIuTbVMj0YoH3aNVMoG
OFqxknKLJKSsaURngAl6qir+yyiOi2j2rXR9phZzF72lJaUuRe57tLFU9K8t0Xmq
3nUmyHZdYm/0URgbIckmnzf8GZLLjnA+k2LVlfscSfDknZ7vo+XE/K5HAgMBAAGj
NDAyMA4GA1UdDwEB/wQEAwIBvjAPBgNVHREECDAGhwSsEgAOMA8GA1UdEwEB/wQF
MAMBAf8wDQYJKoZIhvcNAQELBQADggEBAAaDSFdr685moxPXgXI1eZnQ/QS1Bvd9
yvTXRRyV+PIH9tLZLAhht3eEMdde6B3yaNsearZkOTQVaEnMkqypNWD5im225CRx
1Jt/o9fZO872uo8nwf9+87XknOrmkPbyC6UXLYBlgbSgxYSNXhpdAXa1Q/DOgK78
U0omtC27aBWtMa8knRuFrUx7to13/Waea2JdTaZWDEZEN1QVCsFfL116PE91FrhI
czQxt/xHGiIZHDiBcHUoDtG+39Z4R1gsM7yLSq078+IjVqs1faDSaxyAnHoX7HUY
hCGvafUAppb+6HWbiYH5gk+XZhnApr1sDvhe6LCow493rgzn3kGpGMU=
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDsTCCApmgAwIBAgIBATANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNjFhOTAwMzYtMWY3Yy00MmJlLTgzNTctZjUyMGJlOWEz
MzFlMTEwLwYDVQQKDChDSUQtNDg2OTA1YWUtY2U3YS00NDI5LTkzNDktOTQyYzA3
YjlmN2MxMQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMDI1OFoXDTMxMDExMzIwMDI1
OFowgYAxEDAOBgNVBAMMB3NjbUBzY20xLTArBgNVBAsMJDYxYTkwMDM2LTFmN2Mt
NDJiZS04MzU3LWY1MjBiZTlhMzMxZTExMC8GA1UECgwoQ0lELTQ4NjkwNWFlLWNl
N2EtNDQyOS05MzQ5LTk0MmMwN2I5ZjdjMTEKMAgGA1UEBRMBMTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAIyX+sx6VsgxQaiud3q6oNoJZf/1wPSaffZB
CsAJpd4P8ldle5vD/5yFrzqJ0R2Nwl4+JpawjqEjQfyW7VUWoY9sNds4KLNjVfl7
f4r9lbW8ZmcycG1gUGcBEv7/7juFN2XFtb/lo3VY9P0DUAp4QB1UZ5VMgL+Us5ad
cAVA/k8GzUgm8G0FLNrMkpic5yEn3boy237lOjARm/nQiTXKx3xLH7oImSDegiFh
8XgPHY9UA085WqaxP1L8z41PoJKxHZlBu3ZYkVo9LW4sJK3aDiqM9Ha9HDW3Wsmk
hDCxaT85h75JMtI9IkypFMoixNLDUbJfD64HqwZGwZCGyKAsiDkCAwEAAaM0MDIw
DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0RBAgwBocErBIA
DjANBgkqhkiG9w0BAQsFAAOCAQEAZQjKiNavND9ZgZZPxumfy7Ks249Bs6To8VyB
3Tm46xZOdY/fsObj8DXU3L744J/NV6SsHvijQIkVw4ItcK/muk2nOoT6A/rMMxsT
wWF3ziTPg1ZE+RhFgk+fLtWH9+5Odt2TiKDcYMsBgRrxh/Qq7kIQiH8ce+WViOoq
XipFbH2P5Uwtn/3Su5OFitzlDNOPDnol+RkT/EywMUOtrCxpTwwug93xPfumKWb3
ahyT9qzDiAKjuitU1bwt6bfrcv8GvkNBjVkbByKocX0rY1jW32j7cGMYn0Aoi9Wk
NaP1BXrxwAGW0OyDbLnXW25cqQwgwPdiGZQYdfIUMaoZ/G8KKw==
-----END CERTIFICATE-----

2025-12-05 20:03:00,049 [main] INFO client.SCMCertificateClient: Successfully stored SCM signed certificate.
2025-12-05 20:03:00,567 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:00,691 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2025-12-05 20:03:01,028 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-05 20:03:01,042 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 20:03:01,042 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-05 20:03:01,044 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 20:03:01,050 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2025-12-05 20:03:01,050 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2025-12-05 20:03:01,051 [main] INFO server.GrpcService: raft.grpc.message.size.max = 34603008 (custom)
2025-12-05 20:03:01,051 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-12-05 20:03:01,052 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 20:03:01,087 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2025-12-05 20:03:01,099 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:01,109 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-12-05 20:03:01,109 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-12-05 20:03:02,186 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2025-12-05 20:03:02,195 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 20:03:02,196 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2025-12-05 20:03:02,196 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 20:03:02,212 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 20:03:02,213 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2025-12-05 20:03:02,214 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2025-12-05 20:03:02,264 [main] INFO server.RaftServer: 61a90036-1f7c-42be-8357-f520be9a331e: addNew group-942C07B9F7C1:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894] returns group-942C07B9F7C1:java.util.concurrent.CompletableFuture@4d9754a8[Not completed]
2025-12-05 20:03:02,393 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e: new RaftServerImpl for group-942C07B9F7C1:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894] with SCMStateMachine:uninitialized
2025-12-05 20:03:02,414 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 20:03:02,419 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2025-12-05 20:03:02,419 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2025-12-05 20:03:02,419 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-05 20:03:02,419 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 20:03:02,423 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2025-12-05 20:03:02,424 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 20:03:02,464 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: ConfigurationManager, init=conf: {index: -1, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-05 20:03:02,491 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2025-12-05 20:03:02,517 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2025-12-05 20:03:02,538 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2025-12-05 20:03:02,539 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-12-05 20:03:02,571 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2025-12-05 20:03:02,593 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-12-05 20:03:02,643 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2025-12-05 20:03:03,105 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 20:03:03,110 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-12-05 20:03:03,111 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2025-12-05 20:03:03,111 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2025-12-05 20:03:03,111 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2025-12-05 20:03:03,112 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2025-12-05 20:03:03,123 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2025-12-05 20:03:03,123 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2025-12-05 20:03:03,126 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 20:03:03,156 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1 does not exist. Creating ...
2025-12-05 20:03:03,182 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1/in_use.lock acquired by nodename 12@scm
2025-12-05 20:03:03,203 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1 has been successfully formatted.
2025-12-05 20:03:03,216 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2025-12-05 20:03:03,236 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2025-12-05 20:03:03,236 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:03,239 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-12-05 20:03:03,242 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2025-12-05 20:03:03,248 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 20:03:03,264 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2025-12-05 20:03:03,264 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-12-05 20:03:03,265 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:03,272 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO util.AwaitToRun: Thread[61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-cacheEviction-AwaitToRun,5,main] started
2025-12-05 20:03:03,279 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1
2025-12-05 20:03:03,280 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-12-05 20:03:03,280 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2025-12-05 20:03:03,282 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 20:03:03,285 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2025-12-05 20:03:03,286 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2025-12-05 20:03:03,287 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2025-12-05 20:03:03,287 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-12-05 20:03:03,287 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-12-05 20:03:03,293 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2025-12-05 20:03:03,299 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:03,300 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2025-12-05 20:03:03,300 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2025-12-05 20:03:03,301 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2025-12-05 20:03:03,311 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-05 20:03:03,311 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-05 20:03:03,318 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: start as a follower, conf=conf: {index: -1, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:03,324 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-05 20:03:03,325 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: start 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState
2025-12-05 20:03:03,332 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2025-12-05 20:03:03,334 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2025-12-05 20:03:03,336 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-942C07B9F7C1,id=61a90036-1f7c-42be-8357-f520be9a331e
2025-12-05 20:03:03,336 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO util.JmxRegister: register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-942C07B9F7C1,id=61a90036-1f7c-42be-8357-f520be9a331e
2025-12-05 20:03:03,338 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-12-05 20:03:03,341 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-12-05 20:03:03,341 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-12-05 20:03:03,342 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-12-05 20:03:03,343 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2025-12-05 20:03:03,347 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2025-12-05 20:03:03,352 [main] INFO server.RaftServer: 61a90036-1f7c-42be-8357-f520be9a331e: start RPC server
2025-12-05 20:03:03,412 [main] INFO server.GrpcService: 61a90036-1f7c-42be-8357-f520be9a331e: GrpcService started, listening on 9894
2025-12-05 20:03:03,419 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-61a90036-1f7c-42be-8357-f520be9a331e: Started
2025-12-05 20:03:08,394 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO impl.FollowerState: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5069301178ns, electionTimeout:5059ms
2025-12-05 20:03:08,394 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: shutdown 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState
2025-12-05 20:03:08,395 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-05 20:03:08,397 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2025-12-05 20:03:08,397 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: start 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1
2025-12-05 20:03:08,400 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.LeaderElection: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:08,401 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.LeaderElection: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2025-12-05 20:03:08,403 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.LeaderElection: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:08,403 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.LeaderElection: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2025-12-05 20:03:08,403 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: shutdown 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1
2025-12-05 20:03:08,403 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-05 20:03:08,407 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2025-12-05 20:03:08,409 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 20:03:08,410 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-12-05 20:03:08,412 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2025-12-05 20:03:08,412 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2025-12-05 20:03:08,412 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2025-12-05 20:03:08,419 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2025-12-05 20:03:08,420 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-12-05 20:03:08,421 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 20:03:08,421 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.log-metadata.enabled = true (default)
2025-12-05 20:03:08,421 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 20:03:08,421 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-12-05 20:03:08,423 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: start 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderStateImpl
2025-12-05 20:03:08,423 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: set firstElectionSinceStartup to false for becomeLeader
2025-12-05 20:03:08,423 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: change Leader from null to 61a90036-1f7c-42be-8357-f520be9a331e at term 1 for becomeLeader, leader elected after 5932ms
2025-12-05 20:03:08,441 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-05 20:03:08,454 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2025-12-05 20:03:08,456 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: set configuration conf: {index: 0, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:08,461 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1/current/log_inprogress_0
2025-12-05 20:03:08,470 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO server.RaftServer$Division: Leader 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-05 20:03:09,420 [main] INFO server.RaftServer: 61a90036-1f7c-42be-8357-f520be9a331e: close
2025-12-05 20:03:09,420 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: shutdown
2025-12-05 20:03:09,420 [main] INFO server.GrpcService: 61a90036-1f7c-42be-8357-f520be9a331e: shutdown server GrpcServerProtocolService now
2025-12-05 20:03:09,421 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-942C07B9F7C1,id=61a90036-1f7c-42be-8357-f520be9a331e
2025-12-05 20:03:09,421 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: shutdown 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderStateImpl
2025-12-05 20:03:09,424 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO impl.PendingRequests: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-PendingRequests: sendNotLeaderResponses
2025-12-05 20:03:09,426 [main] INFO server.GrpcService: 61a90036-1f7c-42be-8357-f520be9a331e: shutdown server GrpcServerProtocolService successfully
2025-12-05 20:03:09,428 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO impl.StateMachineUpdater: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater: set stopIndex = 0
2025-12-05 20:03:09,429 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO impl.StateMachineUpdater: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater: Took a snapshot at index 0
2025-12-05 20:03:09,429 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO impl.StateMachineUpdater: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-05 20:03:09,432 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO impl.StateMachineUpdater: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:1, i:0)
2025-12-05 20:03:09,433 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-cacheEviction-AwaitToRun] INFO util.AwaitToRun: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-05 20:03:09,467 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker close()
2025-12-05 20:03:09,472 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-61a90036-1f7c-42be-8357-f520be9a331e: Stopped
2025-12-05 20:03:09,472 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:03:09,474 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-486905ae-ce7a-4429-9349-942c07b9f7c1; layoutVersion=7; scmId=61a90036-1f7c-42be-8357-f520be9a331e
2025-12-05 20:03:09,485 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.14
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2025-12-05 20:03:10,835 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.14
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.1
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.6.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.1.1.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.78.1.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.78.1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.1.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.26.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.2.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.37.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.5.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.54.v20240208.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.8.1.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/commons-text-1.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.78.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.1.jar
STARTUP_MSG:   build = git@github.com:apache/ozone.git/a9d5d1c630d903b28984d1c46daa78a1812674ac ; compiled by 'ozone' on 2024-11-14T09:02Z
STARTUP_MSG:   java = 11.0.25
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/dn.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/dn@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.volume.min.free.space.percent=0.001f, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/scm.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=5, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.basedir=/tmp/ozone_http, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/om.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.administrators=testuser2, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=*, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/s3g.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=1, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=1, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=scm:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2025-12-05 20:03:10,843 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-05 20:03:10,872 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:03:11,014 [main] INFO reflections.Reflections: Reflections took 111 ms to scan 3 urls, producing 133 keys and 290 values 
2025-12-05 20:03:11,067 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 20:03:11,072 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 20:03:11,204 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2025-12-05 20:03:11,204 [main] INFO server.StorageContainerManager: SCM login successful.
2025-12-05 20:03:11,610 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 2
2025-12-05 20:03:11,755 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 2
             IssuerDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:02:59 UTC 2025
           Final Date: Mon Jan 13 20:02:59 UTC 2031
            SubjectDN: CN=scm-sub@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=2
           Public Key: RSA Public Key [02:ed:40:0c:a8:85:1e:13:fd:ec:85:b4:d3:ba:aa:d3:22:c3:13:ab],[56:66:d1:a4]
        modulus: d1b1fab49dcb318984f818589295546545a10820902a96f4d6f52bf337d2105ed6e8e0cd043914eea18790a60b627f4b1c386044c963cb91fd65050dbbafcf08e2c368c5dcc6f26f503a4b47215c01343b35a3832414eb9fe0dd806bb1b55dd0b3bb4c5773ea8dcdd9c28c56914d985ab69e5a6ecf7ed158d7951d07380815e1f273a8e10ea9e36f3bd85527cb4c01d13a5299f0ba6019d2222e4db54c8f46281f768d54ca06385ab192728b24a4ac69446780097aaa2afecb288e8b68f6ad747da6167317bda525a52e45ee7bb4b154f4af2dd179aade7526c8765d626ff451181b21c9269f37fc1992cb8e703e9362d595fb1c49f0e49d9eefa3e5c4fcae47
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 068348576bebce66a313d78172357999d0fd04b5
                       06f77dcaf4d7451c95f8f207f6d2d92c0861b777
                       8431d75ee81df268db1e6ab6643934156849cc92
                       aca93560f98a6db6e42471d49b7fa3d7d93bcef6
                       ba8f27c1ff7ef3b5e49ceae690f6f20ba5172d80
                       6581b4a0c5848d5e1a5d0176b543f0ce80aefc53
                       4a26b42dbb6815ad31af249d1b85ad4c7bb68d77
                       fd669e6b625d4da6560c46443754150ac15f2f5d
                       7a3c4f7516b848733431b7fc471a22191c388170
                       75280ed1bedfd67847582c33bc8b4aad3bf3e223
                       56ab357da0d26b1c809c7a17ec75188421af69f5
                       00a696fee8759b8981f9824f976619c0a6bd6c0e
                       f85ee8b0a8c38f77ae0ce7de41a918c5
       Extensions: 
                       critical(true) KeyUsage: 0xbe
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 

                       critical(true) BasicConstraints: isCa(true)
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2025-12-05 20:03:11,784 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:02:58 UTC 2025
           Final Date: Mon Jan 13 20:02:58 UTC 2031
            SubjectDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Public Key: RSA Public Key [d2:68:ab:3e:f1:a9:57:e8:a3:ed:fa:2d:90:45:7b:73:3c:2c:3e:bf],[56:66:d1:a4]
        modulus: 8c97facc7a56c83141a8ae777abaa0da0965fff5c0f49a7df6410ac009a5de0ff257657b9bc3ff9c85af3a89d11d8dc25e3e2696b08ea12341fc96ed5516a18f6c35db3828b36355f97b7f8afd95b5bc666732706d6050670112feffee3b853765c5b5bfe5a37558f4fd03500a78401d5467954c80bf94b3969d700540fe4f06cd4826f06d052cdacc92989ce72127ddba32db7ee53a30119bf9d08935cac77c4b1fba089920de822161f1780f1d8f54034f395aa6b13f52fccf8d4fa092b11d9941bb7658915a3d2d6e2c24adda0e2a8cf476bd1c35b75ac9a48430b1693f3987be4932d23d224ca914ca22c4d2c351b25f0fae07ab0646c19086c8a02c8839
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 6508ca88d6af343f5981964fc6e99fcbb2acdb8f
                       41b3a4e8f15c81dd39b8eb164e758fdfb0e6e3f0
                       35d4dcbef8e09fcd57a4ac1ef8a3408915c3822d
                       70afe6ba4da73a84fa03facc331b13c16177ce24
                       cf835644f91845824f9f2ed587f7ee4e76dd9388
                       a0dc60cb01811af187f42aee4210887f1c7be595
                       88ea2a5e2a456c7d8fe54c2d9ffdd2bb93858adc
                       e50cd38f0e7a25f91913fc4cb03143adac2c694f
                       0c2e83ddf13dfba62966f76a1c93f6acc38802a3
                       ba2b54d5bc2de9b7eb72ff06be43418d591b0722
                       a8717d2b6358d6df68fb7063189f40288bd5a435
                       a3f5057af1c00196d0ec836cb9d75b6e5ca90c20
                       c0f76219941875f21431aa19fc6f0a2b
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2025-12-05 20:03:11,789 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 2
             IssuerDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:02:59 UTC 2025
           Final Date: Mon Jan 13 20:02:59 UTC 2031
            SubjectDN: CN=scm-sub@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=2
           Public Key: RSA Public Key [02:ed:40:0c:a8:85:1e:13:fd:ec:85:b4:d3:ba:aa:d3:22:c3:13:ab],[56:66:d1:a4]
        modulus: d1b1fab49dcb318984f818589295546545a10820902a96f4d6f52bf337d2105ed6e8e0cd043914eea18790a60b627f4b1c386044c963cb91fd65050dbbafcf08e2c368c5dcc6f26f503a4b47215c01343b35a3832414eb9fe0dd806bb1b55dd0b3bb4c5773ea8dcdd9c28c56914d985ab69e5a6ecf7ed158d7951d07380815e1f273a8e10ea9e36f3bd85527cb4c01d13a5299f0ba6019d2222e4db54c8f46281f768d54ca06385ab192728b24a4ac69446780097aaa2afecb288e8b68f6ad747da6167317bda525a52e45ee7bb4b154f4af2dd179aade7526c8765d626ff451181b21c9269f37fc1992cb8e703e9362d595fb1c49f0e49d9eefa3e5c4fcae47
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 068348576bebce66a313d78172357999d0fd04b5
                       06f77dcaf4d7451c95f8f207f6d2d92c0861b777
                       8431d75ee81df268db1e6ab6643934156849cc92
                       aca93560f98a6db6e42471d49b7fa3d7d93bcef6
                       ba8f27c1ff7ef3b5e49ceae690f6f20ba5172d80
                       6581b4a0c5848d5e1a5d0176b543f0ce80aefc53
                       4a26b42dbb6815ad31af249d1b85ad4c7bb68d77
                       fd669e6b625d4da6560c46443754150ac15f2f5d
                       7a3c4f7516b848733431b7fc471a22191c388170
                       75280ed1bedfd67847582c33bc8b4aad3bf3e223
                       56ab357da0d26b1c809c7a17ec75188421af69f5
                       00a696fee8759b8981f9824f976619c0a6bd6c0e
                       f85ee8b0a8c38f77ae0ce7de41a918c5
       Extensions: 
                       critical(true) KeyUsage: 0xbe
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 

                       critical(true) BasicConstraints: isCa(true)
 from file: /data/metadata/scm/sub-ca/certs/2.crt.
2025-12-05 20:03:11,789 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2025-12-05 20:03:11,813 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:03:11,909 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:03:11,914 [main] INFO utils.LeakDetector: Starting leak detector thread ManagedRocksObject0.
2025-12-05 20:03:12,045 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.1.jar!/network-topology-default.xml]
2025-12-05 20:03:12,046 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2025-12-05 20:03:12,081 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2025-12-05 20:03:12,179 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:61a90036-1f7c-42be-8357-f520be9a331e
2025-12-05 20:03:12,196 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2025-12-05 20:03:12,198 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 2
             IssuerDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:02:59 UTC 2025
           Final Date: Mon Jan 13 20:02:59 UTC 2031
            SubjectDN: CN=scm-sub@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=2
           Public Key: RSA Public Key [02:ed:40:0c:a8:85:1e:13:fd:ec:85:b4:d3:ba:aa:d3:22:c3:13:ab],[56:66:d1:a4]
        modulus: d1b1fab49dcb318984f818589295546545a10820902a96f4d6f52bf337d2105ed6e8e0cd043914eea18790a60b627f4b1c386044c963cb91fd65050dbbafcf08e2c368c5dcc6f26f503a4b47215c01343b35a3832414eb9fe0dd806bb1b55dd0b3bb4c5773ea8dcdd9c28c56914d985ab69e5a6ecf7ed158d7951d07380815e1f273a8e10ea9e36f3bd85527cb4c01d13a5299f0ba6019d2222e4db54c8f46281f768d54ca06385ab192728b24a4ac69446780097aaa2afecb288e8b68f6ad747da6167317bda525a52e45ee7bb4b154f4af2dd179aade7526c8765d626ff451181b21c9269f37fc1992cb8e703e9362d595fb1c49f0e49d9eefa3e5c4fcae47
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 068348576bebce66a313d78172357999d0fd04b5
                       06f77dcaf4d7451c95f8f207f6d2d92c0861b777
                       8431d75ee81df268db1e6ab6643934156849cc92
                       aca93560f98a6db6e42471d49b7fa3d7d93bcef6
                       ba8f27c1ff7ef3b5e49ceae690f6f20ba5172d80
                       6581b4a0c5848d5e1a5d0176b543f0ce80aefc53
                       4a26b42dbb6815ad31af249d1b85ad4c7bb68d77
                       fd669e6b625d4da6560c46443754150ac15f2f5d
                       7a3c4f7516b848733431b7fc471a22191c388170
                       75280ed1bedfd67847582c33bc8b4aad3bf3e223
                       56ab357da0d26b1c809c7a17ec75188421af69f5
                       00a696fee8759b8981f9824f976619c0a6bd6c0e
                       f85ee8b0a8c38f77ae0ce7de41a918c5
       Extensions: 
                       critical(true) KeyUsage: 0xbe
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 

                       critical(true) BasicConstraints: isCa(true)

2025-12-05 20:03:12,199 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:02:58 UTC 2025
           Final Date: Mon Jan 13 20:02:58 UTC 2031
            SubjectDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Public Key: RSA Public Key [d2:68:ab:3e:f1:a9:57:e8:a3:ed:fa:2d:90:45:7b:73:3c:2c:3e:bf],[56:66:d1:a4]
        modulus: 8c97facc7a56c83141a8ae777abaa0da0965fff5c0f49a7df6410ac009a5de0ff257657b9bc3ff9c85af3a89d11d8dc25e3e2696b08ea12341fc96ed5516a18f6c35db3828b36355f97b7f8afd95b5bc666732706d6050670112feffee3b853765c5b5bfe5a37558f4fd03500a78401d5467954c80bf94b3969d700540fe4f06cd4826f06d052cdacc92989ce72127ddba32db7ee53a30119bf9d08935cac77c4b1fba089920de822161f1780f1d8f54034f395aa6b13f52fccf8d4fa092b11d9941bb7658915a3d2d6e2c24adda0e2a8cf476bd1c35b75ac9a48430b1693f3987be4932d23d224ca914ca22c4d2c351b25f0fae07ab0646c19086c8a02c8839
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 6508ca88d6af343f5981964fc6e99fcbb2acdb8f
                       41b3a4e8f15c81dd39b8eb164e758fdfb0e6e3f0
                       35d4dcbef8e09fcd57a4ac1ef8a3408915c3822d
                       70afe6ba4da73a84fa03facc331b13c16177ce24
                       cf835644f91845824f9f2ed587f7ee4e76dd9388
                       a0dc60cb01811af187f42aee4210887f1c7be595
                       88ea2a5e2a456c7d8fe54c2d9ffdd2bb93858adc
                       e50cd38f0e7a25f91913fc4cb03143adac2c694f
                       0c2e83ddf13dfba62966f76a1c93f6acc38802a3
                       ba2b54d5bc2de9b7eb72ff06be43418d591b0722
                       a8717d2b6358d6df68fb7063189f40288bd5a435
                       a3f5057af1c00196d0ec836cb9d75b6e5ca90c20
                       c0f76219941875f21431aa19fc6f0a2b
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 


2025-12-05 20:03:12,202 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:12,202 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:12,202 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2025-12-05 20:03:12,204 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:02:58 UTC 2025
           Final Date: Mon Jan 13 20:02:58 UTC 2031
            SubjectDN: CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1
           Public Key: RSA Public Key [d2:68:ab:3e:f1:a9:57:e8:a3:ed:fa:2d:90:45:7b:73:3c:2c:3e:bf],[56:66:d1:a4]
        modulus: 8c97facc7a56c83141a8ae777abaa0da0965fff5c0f49a7df6410ac009a5de0ff257657b9bc3ff9c85af3a89d11d8dc25e3e2696b08ea12341fc96ed5516a18f6c35db3828b36355f97b7f8afd95b5bc666732706d6050670112feffee3b853765c5b5bfe5a37558f4fd03500a78401d5467954c80bf94b3969d700540fe4f06cd4826f06d052cdacc92989ce72127ddba32db7ee53a30119bf9d08935cac77c4b1fba089920de822161f1780f1d8f54034f395aa6b13f52fccf8d4fa092b11d9941bb7658915a3d2d6e2c24adda0e2a8cf476bd1c35b75ac9a48430b1693f3987be4932d23d224ca914ca22c4d2c351b25f0fae07ab0646c19086c8a02c8839
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 6508ca88d6af343f5981964fc6e99fcbb2acdb8f
                       41b3a4e8f15c81dd39b8eb164e758fdfb0e6e3f0
                       35d4dcbef8e09fcd57a4ac1ef8a3408915c3822d
                       70afe6ba4da73a84fa03facc331b13c16177ce24
                       cf835644f91845824f9f2ed587f7ee4e76dd9388
                       a0dc60cb01811af187f42aee4210887f1c7be595
                       88ea2a5e2a456c7d8fe54c2d9ffdd2bb93858adc
                       e50cd38f0e7a25f91913fc4cb03143adac2c694f
                       0c2e83ddf13dfba62966f76a1c93f6acc38802a3
                       ba2b54d5bc2de9b7eb72ff06be43418d591b0722
                       a8717d2b6358d6df68fb7063189f40288bd5a435
                       a3f5057af1c00196d0ec836cb9d75b6e5ca90c20
                       c0f76219941875f21431aa19fc6f0a2b
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 


2025-12-05 20:03:12,214 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:12,217 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:12,228 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:12,254 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2025-12-05 20:03:12,260 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-05 20:03:12,261 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 20:03:12,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-05 20:03:12,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 20:03:12,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2025-12-05 20:03:12,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2025-12-05 20:03:12,263 [main] INFO server.GrpcService: raft.grpc.message.size.max = 34603008 (custom)
2025-12-05 20:03:12,263 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-12-05 20:03:12,264 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 20:03:12,271 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2025-12-05 20:03:12,271 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:12,273 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-12-05 20:03:12,273 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-12-05 20:03:12,369 [main] INFO server.GrpcService: Setting TLS for 0.0.0.0/0.0.0.0:9894
2025-12-05 20:03:12,538 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2025-12-05 20:03:12,540 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 20:03:12,540 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2025-12-05 20:03:12,540 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 20:03:12,544 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 20:03:12,545 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2025-12-05 20:03:12,546 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2025-12-05 20:03:12,549 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServer: 61a90036-1f7c-42be-8357-f520be9a331e: found a subdirectory /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1
2025-12-05 20:03:12,554 [main] INFO server.RaftServer: 61a90036-1f7c-42be-8357-f520be9a331e: addNew group-942C07B9F7C1:[] returns group-942C07B9F7C1:java.util.concurrent.CompletableFuture@2ba42204[Not completed]
2025-12-05 20:03:12,570 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e: new RaftServerImpl for group-942C07B9F7C1:[] with SCMStateMachine:uninitialized
2025-12-05 20:03:12,572 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 20:03:12,572 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2025-12-05 20:03:12,572 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2025-12-05 20:03:12,572 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-05 20:03:12,573 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 20:03:12,573 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2025-12-05 20:03:12,573 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 20:03:12,579 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-05 20:03:12,584 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2025-12-05 20:03:12,589 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2025-12-05 20:03:12,592 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2025-12-05 20:03:12,592 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-12-05 20:03:12,596 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2025-12-05 20:03:12,597 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-12-05 20:03:12,692 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 20:03:12,694 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-12-05 20:03:12,694 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2025-12-05 20:03:12,694 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2025-12-05 20:03:12,695 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2025-12-05 20:03:12,695 [61a90036-1f7c-42be-8357-f520be9a331e-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2025-12-05 20:03:12,697 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2025-12-05 20:03:12,697 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-05 20:03:12,698 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2025-12-05 20:03:12,718 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2025-12-05 20:03:12,747 [main] INFO ha.SequenceIdGenerator: upgrade localId to 115816896921600000
2025-12-05 20:03:12,748 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2025-12-05 20:03:12,754 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2025-12-05 20:03:12,757 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2025-12-05 20:03:12,759 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2025-12-05 20:03:12,849 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2025-12-05 20:03:12,864 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-12-05 20:03:12,866 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-05 20:03:12,871 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2025-12-05 20:03:12,880 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-05 20:03:12,880 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-05 20:03:12,885 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2025-12-05 20:03:12,885 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2025-12-05 20:03:12,887 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2025-12-05 20:03:12,889 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2025-12-05 20:03:12,893 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-05 20:03:12,894 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2025-12-05 20:03:12,909 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-05 20:03:12,909 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-05 20:03:12,931 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2025-12-05 20:03:12,972 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2025-12-05 20:03:12,973 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2025-12-05 20:03:12,973 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.hadoop.hdds.utils.MetricsUtil (file:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.1.jar) to method java.lang.Class.annotationData()
WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.hdds.utils.MetricsUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2025-12-05 20:03:12,985 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2025-12-05 20:03:12,987 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:12,988 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-05 20:03:13,121 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT10M
2025-12-05 20:03:13,121 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2025-12-05 20:03:13,132 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2025-12-05 20:03:13,135 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2025-12-05 20:03:13,136 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 2 on primary SCM
2025-12-05 20:03:13,155 [main] INFO server.SCMCertStore: Scm certificate 2 for CN=scm-sub@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=2 is stored
2025-12-05 20:03:13,155 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
2025-12-05 20:03:13,157 [main] INFO server.SCMCertStore: Scm certificate 1 for CN=scm@scm,OU=61a90036-1f7c-42be-8357-f520be9a331e,O=CID-486905ae-ce7a-4429-9349-942c07b9f7c1,SERIALNUMBER=1 is stored
2025-12-05 20:03:13,161 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2025-12-05 20:03:13,173 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 20:03:13,195 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2025-12-05 20:03:13,196 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2025-12-05 20:03:13,215 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2025-12-05 20:03:13,595 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 20:03:13,599 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 20:03:13,599 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2025-12-05 20:03:13,599 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2025-12-05 20:03:13,619 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 20:03:13,623 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 20:03:13,623 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2025-12-05 20:03:13,624 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2025-12-05 20:03:13,646 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 20:03:13,652 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-05 20:03:13,652 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2025-12-05 20:03:13,652 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2025-12-05 20:03:13,687 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2025-12-05 20:03:13,688 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2025-12-05 20:03:13,688 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-05 20:03:13,690 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2025-12-05 20:03:13,692 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2025-12-05 20:03:13,695 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2025-12-05 20:03:13,695 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2025-12-05 20:03:13,695 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 20:03:13,708 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1/in_use.lock acquired by nodename 7@scm
2025-12-05 20:03:13,713 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=61a90036-1f7c-42be-8357-f520be9a331e} from /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1/current/raft-meta
2025-12-05 20:03:13,735 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: set configuration conf: {index: 0, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:13,786 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2025-12-05 20:03:13,800 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2025-12-05 20:03:13,802 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:13,805 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-12-05 20:03:13,805 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2025-12-05 20:03:13,811 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 20:03:13,816 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2025-12-05 20:03:13,817 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-12-05 20:03:13,817 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:13,819 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO util.AwaitToRun: Thread[61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-cacheEviction-AwaitToRun,5,main] started
2025-12-05 20:03:13,824 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1
2025-12-05 20:03:13,824 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-12-05 20:03:13,824 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2025-12-05 20:03:13,826 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 20:03:13,826 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2025-12-05 20:03:13,827 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2025-12-05 20:03:13,827 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2025-12-05 20:03:13,828 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-12-05 20:03:13,828 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-12-05 20:03:13,830 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2025-12-05 20:03:13,836 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:03:13,837 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2025-12-05 20:03:13,837 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2025-12-05 20:03:13,838 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2025-12-05 20:03:13,859 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: set configuration conf: {index: 0, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:13,860 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1/current/log_inprogress_0
2025-12-05 20:03:13,863 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-05 20:03:13,876 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO segmented.BufferedWriteChannel: open log_inprogress_0 (append) at position 69
2025-12-05 20:03:13,877 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: start as a follower, conf=conf: {index: 0, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:13,878 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: changes role from      null to FOLLOWER at term 1 for startAsFollower
2025-12-05 20:03:13,879 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: start 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState
2025-12-05 20:03:13,879 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2025-12-05 20:03:13,880 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2025-12-05 20:03:13,881 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-942C07B9F7C1,id=61a90036-1f7c-42be-8357-f520be9a331e
2025-12-05 20:03:13,881 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO util.JmxRegister: register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-942C07B9F7C1,id=61a90036-1f7c-42be-8357-f520be9a331e
2025-12-05 20:03:13,883 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-12-05 20:03:13,883 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-12-05 20:03:13,884 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-12-05 20:03:13,884 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-12-05 20:03:13,884 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2025-12-05 20:03:13,885 [61a90036-1f7c-42be-8357-f520be9a331e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2025-12-05 20:03:13,890 [main] INFO server.RaftServer: 61a90036-1f7c-42be-8357-f520be9a331e: start RPC server
2025-12-05 20:03:13,920 [main] INFO server.GrpcService: 61a90036-1f7c-42be-8357-f520be9a331e: GrpcService started, listening on 9894
2025-12-05 20:03:13,921 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-61a90036-1f7c-42be-8357-f520be9a331e: Started
2025-12-05 20:03:13,928 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]
2025-12-05 20:03:13,928 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2025-12-05 20:03:13,930 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2025-12-05 20:03:13,930 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2025-12-05 20:03:13,930 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2025-12-05 20:03:14,026 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-12-05 20:03:14,037 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-12-05 20:03:14,037 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2025-12-05 20:03:14,120 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2025-12-05 20:03:14,120 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 20:03:14,121 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2025-12-05 20:03:14,141 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2025-12-05 20:03:14,142 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2025-12-05 20:03:14,143 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 20:03:14,143 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2025-12-05 20:03:14,158 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2025-12-05 20:03:14,160 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 20:03:14,161 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2025-12-05 20:03:14,183 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2025-12-05 20:03:14,237 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2025-12-05 20:03:14,237 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2025-12-05 20:03:14,241 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2025-12-05 20:03:14,290 [main] INFO util.log: Logging initialized @4313ms to org.eclipse.jetty.util.log.Slf4jLog
2025-12-05 20:03:14,531 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2025-12-05 20:03:14,537 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-05 20:03:14,538 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2025-12-05 20:03:14,539 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-12-05 20:03:14,539 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-12-05 20:03:14,541 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2025-12-05 20:03:14,596 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /tmp/ozone_http
2025-12-05 20:03:14,605 [main] INFO http.HttpServer2: Jetty bound to port 9876
2025-12-05 20:03:14,616 [main] INFO server.Server: jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS
2025-12-05 20:03:14,616 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:40055 / 172.18.0.8:40055
2025-12-05 20:03:14,625 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:42379 / 172.18.0.17:42379
2025-12-05 20:03:14,641 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:38409 / 172.18.0.18:38409
2025-12-05 20:03:14,682 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:03:14,688 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:03:14,690 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:03:14,707 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2025-12-05 20:03:14,707 [main] INFO server.session: No SessionScavenger set, using defaults
2025-12-05 20:03:14,709 [main] INFO server.session: node0 Scavenging every 660000ms
2025-12-05 20:03:14,724 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 20:03:14,728 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3c9ef37b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2025-12-05 20:03:14,729 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@51f4439e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.1.jar!/webapps/static,AVAILABLE}
2025-12-05 20:03:14,793 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-3.xcompat_default:42379 / 172.18.0.17:42379
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:14,793 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-5.xcompat_default:40055 / 172.18.0.8:40055
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:14,799 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-1.xcompat_default:38409 / 172.18.0.18:38409
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:15,114 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from xcompat-recon-1.xcompat_default:46685 / 172.18.0.11:46685
2025-12-05 20:03:15,162 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 20:03:15,167 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:03:15,180 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-recon-1.xcompat_default:46685 / 172.18.0.11:46685
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:15,197 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:43783 / 172.18.0.20:43783
2025-12-05 20:03:15,226 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:03:15,237 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-2.xcompat_default:43783 / 172.18.0.20:43783
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:15,259 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@55b74e6b{scm,/,file:///tmp/ozone_http/jetty-0_0_0_0-9876-hdds-server-scm-1_4_1_jar-_-any-4585702788638184978/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.1.jar!/webapps/scm}
2025-12-05 20:03:15,307 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:36975 / 172.18.0.19:36975
2025-12-05 20:03:15,316 [main] INFO server.AbstractConnector: Started ServerConnector@3580134d{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2025-12-05 20:03:15,316 [main] INFO server.Server: Started @5340ms
2025-12-05 20:03:15,334 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2025-12-05 20:03:15,334 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2025-12-05 20:03:15,339 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2025-12-05 20:03:15,362 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:03:15,364 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-4.xcompat_default:36975 / 172.18.0.19:36975
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:15,435 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:36015 / 172.18.0.2:36015
2025-12-05 20:03:15,473 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:03:15,583 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm:38949 / 172.18.0.14:38949
2025-12-05 20:03:15,599 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:03:15,600 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#0 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from scm:38949 / 172.18.0.14:38949
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:16,818 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-3.xcompat_default:42379 / 172.18.0.17:42379
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:16,821 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#8 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-1.xcompat_default:38409 / 172.18.0.18:38409
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:16,822 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#8 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-5.xcompat_default:40055 / 172.18.0.8:40055
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:17,216 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-recon-1.xcompat_default:46685 / 172.18.0.11:46685
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:17,271 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-2.xcompat_default:43783 / 172.18.0.20:43783
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:17,399 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#8 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-4.xcompat_default:36975 / 172.18.0.19:36975
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:17,631 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#1 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from scm:38949 / 172.18.0.14:38949
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:17,635 [61a90036-1f7c-42be-8357-f520be9a331e-scm/sub-ca-refreshCACertificates] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
, while invoking $Proxy14.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.14:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-12-05 20:03:17,683 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from scm:37585 / 172.18.0.14:37585
2025-12-05 20:03:17,698 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:03:18,824 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#8 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-3.xcompat_default:42379 / 172.18.0.17:42379
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:18,825 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-1.xcompat_default:38409 / 172.18.0.18:38409
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:18,832 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from xcompat-datanode-5.xcompat_default:40055 / 172.18.0.8:40055
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:61a90036-1f7c-42be-8357-f520be9a331e is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:248)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2025-12-05 20:03:19,060 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO impl.FollowerState: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5181743779ns, electionTimeout:5180ms
2025-12-05 20:03:19,061 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: shutdown 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState
2025-12-05 20:03:19,061 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2025-12-05 20:03:19,063 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2025-12-05 20:03:19,063 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-FollowerState] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: start 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1
2025-12-05 20:03:19,065 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.LeaderElection: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 1 for conf: {index: 0, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:19,065 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.LeaderElection: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1 PRE_VOTE round 0: result PASSED (term=1)
2025-12-05 20:03:19,070 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.LeaderElection: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for conf: {index: 0, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:19,070 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.LeaderElection: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2025-12-05 20:03:19,070 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: shutdown 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1
2025-12-05 20:03:19,070 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2025-12-05 20:03:19,075 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2025-12-05 20:03:19,078 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 20:03:19,078 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-12-05 20:03:19,080 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2025-12-05 20:03:19,080 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2025-12-05 20:03:19,081 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2025-12-05 20:03:19,085 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2025-12-05 20:03:19,086 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-12-05 20:03:19,087 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 20:03:19,087 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.log-metadata.enabled = true (default)
2025-12-05 20:03:19,087 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 20:03:19,087 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-12-05 20:03:19,088 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO impl.RoleInfo: 61a90036-1f7c-42be-8357-f520be9a331e: start 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderStateImpl
2025-12-05 20:03:19,089 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: set firstElectionSinceStartup to false for becomeLeader
2025-12-05 20:03:19,089 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2025-12-05 20:03:19,089 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2025-12-05 20:03:19,092 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: change Leader from null to 61a90036-1f7c-42be-8357-f520be9a331e at term 2 for becomeLeader, leader elected after 6505ms
2025-12-05 20:03:19,096 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2025-12-05 20:03:19,099 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1/current/log_inprogress_0 to /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1/current/log_0-0
2025-12-05 20:03:19,100 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderElection1] INFO server.RaftServer$Division: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1: set configuration conf: {index: 1, cur=peers:[61a90036-1f7c-42be-8357-f520be9a331e|scm:9894]|listeners:[], old=null}
2025-12-05 20:03:19,102 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_1 at position 0
2025-12-05 20:03:19,108 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/486905ae-ce7a-4429-9349-942c07b9f7c1/current/log_inprogress_1
2025-12-05 20:03:19,117 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO server.RaftServer$Division: Leader 61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-LeaderStateImpl is ready since appliedIndex == startIndex == 1
2025-12-05 20:03:19,118 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2025-12-05 20:03:19,118 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2025-12-05 20:03:19,119 [SecretKeyManagerService] INFO symmetric.SecretKeyManager: Initializing SecretKeys.
2025-12-05 20:03:19,120 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:19,120 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2025-12-05 20:03:19,121 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-05 20:03:19,121 [SecretKeyManagerService] INFO symmetric.SecretKeyManager: No valid key has been loaded. A new key is generated: SecretKey(id = 570f078b-dfbe-4660-8023-56d031fc2873, creation at: 2025-12-05T20:03:19.119883Z, expire at: 2025-12-12T20:03:19.119883Z)
2025-12-05 20:03:19,121 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2025-12-05 20:03:19,122 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 20:03:19,123 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2025-12-05 20:03:19,168 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 570f078b-dfbe-4660-8023-56d031fc2873, creation at: 2025-12-05T20:03:19.119Z, expire at: 2025-12-12T20:03:19.119Z)]
2025-12-05 20:03:19,168 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 570f078b-dfbe-4660-8023-56d031fc2873, creation at: 2025-12-05T20:03:19.119Z, expire at: 2025-12-12T20:03:19.119Z)
2025-12-05 20:03:19,197 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 570f078b-dfbe-4660-8023-56d031fc2873, creation at: 2025-12-05T20:03:19.119Z, expire at: 2025-12-12T20:03:19.119Z)] to file /data/metadata/scm/keys/secret_keys.json
2025-12-05 20:03:19,198 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:19,198 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 20:03:19,198 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 20:03:19,233 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: a7f8a519-8534-4235-8464-384d7af0cbb3
2025-12-05 20:03:19,242 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for CertificateId, expected lastId is 0, actual lastId is 2.
2025-12-05 20:03:19,245 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:19,248 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:19,248 [IPC Server handler 0 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 2 to 3.
2025-12-05 20:03:19,275 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 07585ec7-5037-4470-93d6-ef4ce0e7a51a
2025-12-05 20:03:19,314 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:03:19,314 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:03:19,329 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:19,649 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:19,683 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:19,684 [IPC Server handler 1 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 3 to 4.
2025-12-05 20:03:19,710 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:03:19,715 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:03:19,725 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:19,831 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:19,872 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 5a1a0d81-4db8-4117-b493-ff156c8fd7b6
2025-12-05 20:03:19,891 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:19,893 [IPC Server handler 0 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 4 to 5.
2025-12-05 20:03:19,937 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:03:19,941 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:03:19,970 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:20,112 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:20,138 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:20,138 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:20,140 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:20,142 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:20,142 [61a90036-1f7c-42be-8357-f520be9a331e-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:20,154 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:20,154 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:20,154 [61a90036-1f7c-42be-8357-f520be9a331e-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:20,176 [61a90036-1f7c-42be-8357-f520be9a331e-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2025-12-05 20:03:20,242 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:20,244 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:20,628 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:43031 / 172.18.0.20:43031
2025-12-05 20:03:20,645 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:03:20,805 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:34137 / 172.18.0.19:34137
2025-12-05 20:03:20,818 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:03:20,830 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 569b9fb2-82b6-4559-8b5c-6169228d8873
2025-12-05 20:03:20,830 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 9ffe1c75-be62-4e0f-b30d-5afdf9132cca
2025-12-05 20:03:20,839 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:20,841 [IPC Server handler 0 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 5 to 6.
2025-12-05 20:03:20,887 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:03:20,888 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:03:20,898 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:21,022 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:21,095 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:21,106 [IPC Server handler 1 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 6 to 7.
2025-12-05 20:03:21,190 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:44509 / 172.18.0.2:44509
2025-12-05 20:03:21,201 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:03:21,202 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:03:21,211 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:03:21,229 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:21,371 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:21,438 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 6c247cb8-b413-43ae-ade9-1f068b8c2b36
2025-12-05 20:03:21,454 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:21,458 [IPC Server handler 0 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 7 to 8.
2025-12-05 20:03:21,517 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:03:21,517 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:03:21,532 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:21,652 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:21,684 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: a504f90a-fb6b-4f49-bf5e-679ec2a3c352
2025-12-05 20:03:21,688 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:21,689 [IPC Server handler 0 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 8 to 9.
2025-12-05 20:03:21,720 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:03:21,720 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:03:21,731 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:03:21,878 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:21,919 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:21,919 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:21,920 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:21,921 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:21,924 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:21,924 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:22,124 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:03:22,125 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:03:22,688 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:35765 / 172.18.0.17:35765
2025-12-05 20:03:22,730 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:03:22,782 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:45529 / 172.18.0.18:45529
2025-12-05 20:03:22,804 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:36181 / 172.18.0.8:36181
2025-12-05 20:03:22,807 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:03:22,837 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:03:33,479 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:45067 / 172.18.0.19:45067
2025-12-05 20:03:33,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:03:33,629 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:45113 / 172.18.0.20:45113
2025-12-05 20:03:33,637 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:03:34,441 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:39371 / 172.18.0.2:39371
2025-12-05 20:03:34,458 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:03:34,866 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:40999 / 172.18.0.17:40999
2025-12-05 20:03:34,878 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:03:34,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:37047 / 172.18.0.18:37047
2025-12-05 20:03:34,909 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:03:35,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:40619 / 172.18.0.8:40619
2025-12-05 20:03:35,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:03:35,477 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5a1a0d81-4db8-4117-b493-ff156c8fd7b6
2025-12-05 20:03:35,482 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 5a1a0d81-4db8-4117-b493-ff156c8fd7b6{ip: 172.18.0.19, host: xcompat-datanode-4.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 5, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:03:35,497 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:03:35,497 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 5 required.
2025-12-05 20:03:35,528 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8f73b285-ba00-49d1-8501-7c8e02a06b72 to datanode:5a1a0d81-4db8-4117-b493-ff156c8fd7b6
2025-12-05 20:03:35,556 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:35,559 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 8f73b285-ba00-49d1-8501-7c8e02a06b72, Nodes: 5a1a0d81-4db8-4117-b493-ff156c8fd7b6(xcompat-datanode-4.xcompat_default/172.18.0.19) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:03:35.527402Z[UTC]]
2025-12-05 20:03:35,624 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/07585ec7-5037-4470-93d6-ef4ce0e7a51a
2025-12-05 20:03:35,625 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 07585ec7-5037-4470-93d6-ef4ce0e7a51a{ip: 172.18.0.20, host: xcompat-datanode-2.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 4, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:03:35,627 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 5 required.
2025-12-05 20:03:35,627 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:03:35,630 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=56e50d7e-5cf4-4841-ae86-f4549b8b6b99 to datanode:07585ec7-5037-4470-93d6-ef4ce0e7a51a
2025-12-05 20:03:35,635 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:35,636 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 56e50d7e-5cf4-4841-ae86-f4549b8b6b99, Nodes: 07585ec7-5037-4470-93d6-ef4ce0e7a51a(xcompat-datanode-2.xcompat_default/172.18.0.20) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:03:35.630347Z[UTC]]
2025-12-05 20:03:36,386 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from xcompat-recon-1.xcompat_default:43545 / 172.18.0.11:43545
2025-12-05 20:03:36,389 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:03:36,863 [IPC Server handler 18 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9ffe1c75-be62-4e0f-b30d-5afdf9132cca
2025-12-05 20:03:36,864 [IPC Server handler 18 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 9ffe1c75-be62-4e0f-b30d-5afdf9132cca{ip: 172.18.0.17, host: xcompat-datanode-3.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 7, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:03:36,865 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:03:36,866 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 5 required.
2025-12-05 20:03:36,870 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=83df3b78-d527-414a-b437-756d3e85b7b2 to datanode:9ffe1c75-be62-4e0f-b30d-5afdf9132cca
2025-12-05 20:03:36,877 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:36,880 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 83df3b78-d527-414a-b437-756d3e85b7b2, Nodes: 9ffe1c75-be62-4e0f-b30d-5afdf9132cca(xcompat-datanode-3.xcompat_default/172.18.0.17) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:03:36.870082Z[UTC]]
2025-12-05 20:03:36,908 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/569b9fb2-82b6-4559-8b5c-6169228d8873
2025-12-05 20:03:36,908 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 569b9fb2-82b6-4559-8b5c-6169228d8873{ip: 172.18.0.18, host: xcompat-datanode-1.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 6, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:03:36,909 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:03:36,910 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 5 required.
2025-12-05 20:03:36,911 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3aeca3ee-6de9-48db-9902-aa2b57437d66 to datanode:569b9fb2-82b6-4559-8b5c-6169228d8873
2025-12-05 20:03:36,915 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:36,918 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 3aeca3ee-6de9-48db-9902-aa2b57437d66, Nodes: 569b9fb2-82b6-4559-8b5c-6169228d8873(xcompat-datanode-1.xcompat_default/172.18.0.18) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:03:36.911105Z[UTC]]
2025-12-05 20:03:37,095 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6c247cb8-b413-43ae-ade9-1f068b8c2b36
2025-12-05 20:03:37,096 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 6c247cb8-b413-43ae-ade9-1f068b8c2b36{ip: 172.18.0.8, host: xcompat-datanode-5.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:03:37,097 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:03:37,098 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 5 DataNodes registered, 5 required.
2025-12-05 20:03:37,098 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2025-12-05 20:03:37,098 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2025-12-05 20:03:37,099 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-05 20:03:37,100 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:03:37,100 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=1c242159-3d1d-4af2-8d7d-1f8292b8bb24 to datanode:6c247cb8-b413-43ae-ade9-1f068b8c2b36
2025-12-05 20:03:37,103 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:37,104 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 1c242159-3d1d-4af2-8d7d-1f8292b8bb24, Nodes: 6c247cb8-b413-43ae-ade9-1f068b8c2b36(xcompat-datanode-5.xcompat_default/172.18.0.8) ReplicaIndex: 0, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:03:37.099837Z[UTC]]
2025-12-05 20:03:37,108 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=850bd7e0-21b3-4b2e-a9bb-9c6e34c7a29d to datanode:6c247cb8-b413-43ae-ade9-1f068b8c2b36
2025-12-05 20:03:37,108 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=850bd7e0-21b3-4b2e-a9bb-9c6e34c7a29d to datanode:9ffe1c75-be62-4e0f-b30d-5afdf9132cca
2025-12-05 20:03:37,108 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=850bd7e0-21b3-4b2e-a9bb-9c6e34c7a29d to datanode:5a1a0d81-4db8-4117-b493-ff156c8fd7b6
2025-12-05 20:03:37,114 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:37,114 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 850bd7e0-21b3-4b2e-a9bb-9c6e34c7a29d, Nodes: 6c247cb8-b413-43ae-ade9-1f068b8c2b36(xcompat-datanode-5.xcompat_default/172.18.0.8) ReplicaIndex: 09ffe1c75-be62-4e0f-b30d-5afdf9132cca(xcompat-datanode-3.xcompat_default/172.18.0.17) ReplicaIndex: 05a1a0d81-4db8-4117-b493-ff156c8fd7b6(xcompat-datanode-4.xcompat_default/172.18.0.19) ReplicaIndex: 0, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:03:37.108706Z[UTC]]
2025-12-05 20:03:38,326 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:35625 / 172.18.0.2:35625
2025-12-05 20:03:38,328 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2025-12-05 20:03:38,638 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:38,642 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=8f73b285-ba00-49d1-8501-7c8e02a06b72
2025-12-05 20:03:38,643 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:38,805 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:38,840 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:38,841 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=56e50d7e-5cf4-4841-ae86-f4549b8b6b99
2025-12-05 20:03:38,842 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:40,072 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:40,072 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=83df3b78-d527-414a-b437-756d3e85b7b2
2025-12-05 20:03:40,072 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:40,136 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:40,140 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=3aeca3ee-6de9-48db-9902-aa2b57437d66
2025-12-05 20:03:40,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:40,162 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:03:40,164 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=1c242159-3d1d-4af2-8d7d-1f8292b8bb24
2025-12-05 20:03:40,165 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:40,293 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:43,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:44,129 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:45,057 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:03:45,061 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2025-12-05 20:03:45,061 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=850bd7e0-21b3-4b2e-a9bb-9c6e34c7a29d
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO block.SCMBlockDeletingService: notifyStatusChanged:RUNNING
2025-12-05 20:03:45,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2025-12-05 20:03:45,065 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2025-12-05 20:03:45,065 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2025-12-05 20:03:50,390 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:40181 / 172.18.0.2:40181
2025-12-05 20:03:50,392 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:03:50,398 [IPC Server handler 4 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2025-12-05 20:03:50,406 [61a90036-1f7c-42be-8357-f520be9a331e@group-942C07B9F7C1-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 115816896921600000.
2025-12-05 20:03:50,408 [IPC Server handler 4 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 115816896921600000 to 115816896921601000.
2025-12-05 20:03:51,423 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:44043 / 172.18.0.8:44043
2025-12-05 20:03:51,425 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:03:51,567 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from xcompat-recon-1.xcompat_default:33663 / 172.18.0.11:33663
2025-12-05 20:03:51,571 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:04:04,432 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:40041 / 172.18.0.2:40041
2025-12-05 20:04:04,434 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:04:06,718 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from xcompat-recon-1.xcompat_default:36015 / 172.18.0.11:36015
2025-12-05 20:04:06,724 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:04:14,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:43465 / 172.18.0.20:43465
2025-12-05 20:04:14,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:15,395 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:43923 / 172.18.0.18:43923
2025-12-05 20:04:15,398 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:18,099 [IPC Server handler 58 on default port 9863] INFO algorithms.SCMContainerPlacementRackScatter: Chosen nodes: [07585ec7-5037-4470-93d6-ef4ce0e7a51a(xcompat-datanode-2.xcompat_default/172.18.0.20), 569b9fb2-82b6-4559-8b5c-6169228d8873(xcompat-datanode-1.xcompat_default/172.18.0.18), 9ffe1c75-be62-4e0f-b30d-5afdf9132cca(xcompat-datanode-3.xcompat_default/172.18.0.17), 5a1a0d81-4db8-4117-b493-ff156c8fd7b6(xcompat-datanode-4.xcompat_default/172.18.0.19), 6c247cb8-b413-43ae-ade9-1f068b8c2b36(xcompat-datanode-5.xcompat_default/172.18.0.8)]. isPolicySatisfied: true.
2025-12-05 20:04:18,107 [IPC Server handler 58 on default port 9863] INFO pipeline.WritableECContainerProvider: Created and opened new pipeline Pipeline[ Id: c55c9ab1-a48a-46cb-a640-0aa2104e5018, Nodes: 07585ec7-5037-4470-93d6-ef4ce0e7a51a(xcompat-datanode-2.xcompat_default/172.18.0.20) ReplicaIndex: 1569b9fb2-82b6-4559-8b5c-6169228d8873(xcompat-datanode-1.xcompat_default/172.18.0.18) ReplicaIndex: 29ffe1c75-be62-4e0f-b30d-5afdf9132cca(xcompat-datanode-3.xcompat_default/172.18.0.17) ReplicaIndex: 35a1a0d81-4db8-4117-b493-ff156c8fd7b6(xcompat-datanode-4.xcompat_default/172.18.0.19) ReplicaIndex: 46c247cb8-b413-43ae-ade9-1f068b8c2b36(xcompat-datanode-5.xcompat_default/172.18.0.8) ReplicaIndex: 5, ReplicationConfig: EC{rs-3-2-1024k}, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:04:18.099358Z[UTC]]
2025-12-05 20:04:19,250 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:35735 / 172.18.0.8:35735
2025-12-05 20:04:19,257 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:37869 / 172.18.0.19:37869
2025-12-05 20:04:19,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:19,265 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:04:19,282 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from xcompat-recon-1.xcompat_default:33989 / 172.18.0.11:33989
2025-12-05 20:04:19,289 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:04:19,325 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:33411 / 172.18.0.19:33411
2025-12-05 20:04:19,342 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:40169 / 172.18.0.20:40169
2025-12-05 20:04:19,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:19,347 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:04:19,528 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:37677 / 172.18.0.17:37677
2025-12-05 20:04:19,531 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:04:19,579 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:45123 / 172.18.0.17:45123
2025-12-05 20:04:19,589 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:19,687 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:44225 / 172.18.0.18:44225
2025-12-05 20:04:19,689 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:04:33,011 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:33033 / 172.18.0.2:33033
2025-12-05 20:04:33,013 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:04:36,619 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from xcompat-recon-1.xcompat_default:35703 / 172.18.0.11:35703
2025-12-05 20:04:36,625 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:04:38,369 [IPC Server handler 1 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
2025-12-05 20:04:49,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:39303 / 172.18.0.8:39303
2025-12-05 20:04:49,245 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:49,314 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:34097 / 172.18.0.19:34097
2025-12-05 20:04:49,317 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:49,411 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:38955 / 172.18.0.20:38955
2025-12-05 20:04:49,421 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:49,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:35431 / 172.18.0.17:35431
2025-12-05 20:04:49,577 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:49,763 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:43571 / 172.18.0.18:43571
2025-12-05 20:04:49,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:04:55,908 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:38265 / 172.18.0.2:38265
2025-12-05 20:04:55,911 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:05:10,275 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:42645 / 172.18.0.2:42645
2025-12-05 20:05:10,279 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:05:19,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:41349 / 172.18.0.8:41349
2025-12-05 20:05:19,233 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:19,324 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:34467 / 172.18.0.19:34467
2025-12-05 20:05:19,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:19,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:33571 / 172.18.0.20:33571
2025-12-05 20:05:19,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:19,570 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:45767 / 172.18.0.17:45767
2025-12-05 20:05:19,575 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:19,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:41505 / 172.18.0.18:41505
2025-12-05 20:05:19,750 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:42,097 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:41679 / 172.18.0.2:41679
2025-12-05 20:05:42,099 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:05:49,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:41263 / 172.18.0.8:41263
2025-12-05 20:05:49,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:49,320 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:38161 / 172.18.0.19:38161
2025-12-05 20:05:49,335 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:49,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:44607 / 172.18.0.20:44607
2025-12-05 20:05:49,416 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:49,573 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:41091 / 172.18.0.17:41091
2025-12-05 20:05:49,580 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:05:49,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:39905 / 172.18.0.18:39905
2025-12-05 20:05:49,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:09,911 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:38521 / 172.18.0.2:38521
2025-12-05 20:06:09,915 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:06:11,545 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:34827 / 172.18.0.2:34827
2025-12-05 20:06:11,550 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:06:19,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:35439 / 172.18.0.8:35439
2025-12-05 20:06:19,240 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:19,314 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:33749 / 172.18.0.19:33749
2025-12-05 20:06:19,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:19,417 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:45911 / 172.18.0.20:45911
2025-12-05 20:06:19,427 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:19,579 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:41133 / 172.18.0.17:41133
2025-12-05 20:06:19,586 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:19,748 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:46427 / 172.18.0.18:46427
2025-12-05 20:06:19,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:27,614 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:35979 / 172.18.0.2:35979
2025-12-05 20:06:27,617 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:06:27,631 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:36851 / 172.18.0.2:36851
2025-12-05 20:06:27,633 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:06:27,635 [IPC Server handler 47 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:06:31,647 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:06:35,536 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:06:39,863 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:06:43,954 [IPC Server handler 81 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:06:49,234 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:35417 / 172.18.0.8:35417
2025-12-05 20:06:49,239 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:49,310 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:37663 / 172.18.0.19:37663
2025-12-05 20:06:49,320 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:49,399 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:45431 / 172.18.0.20:45431
2025-12-05 20:06:49,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:49,575 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:35563 / 172.18.0.17:35563
2025-12-05 20:06:49,581 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:06:49,753 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:43803 / 172.18.0.18:43803
2025-12-05 20:06:49,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:06,419 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:34943 / 172.18.0.2:34943
2025-12-05 20:07:06,422 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:07:06,422 [IPC Server handler 82 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:07:09,965 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:41563 / 172.18.0.2:41563
2025-12-05 20:07:09,967 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:07:10,007 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:07:13,497 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:07:16,998 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:07:19,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:38715 / 172.18.0.8:38715
2025-12-05 20:07:19,229 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:19,328 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:38603 / 172.18.0.19:38603
2025-12-05 20:07:19,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:19,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:34795 / 172.18.0.20:34795
2025-12-05 20:07:19,423 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:19,566 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:34555 / 172.18.0.17:34555
2025-12-05 20:07:19,579 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:19,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:42173 / 172.18.0.18:42173
2025-12-05 20:07:19,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:20,715 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:07:24,731 [IPC Server handler 81 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.13
2025-12-05 20:07:44,488 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:38477 / 172.18.0.2:38477
2025-12-05 20:07:44,492 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:07:44,492 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:07:48,961 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:07:49,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:36423 / 172.18.0.8:36423
2025-12-05 20:07:49,239 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:49,305 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:35313 / 172.18.0.19:35313
2025-12-05 20:07:49,315 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:49,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:45467 / 172.18.0.20:45467
2025-12-05 20:07:49,413 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:49,572 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:36671 / 172.18.0.17:36671
2025-12-05 20:07:49,576 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:49,741 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:41837 / 172.18.0.18:41837
2025-12-05 20:07:49,750 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:07:53,502 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:34435 / 172.18.0.2:34435
2025-12-05 20:07:53,505 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:07:53,644 [IPC Server handler 47 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:07:58,430 [IPC Server handler 82 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:08:02,805 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:08:10,283 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:38589 / 172.18.0.2:38589
2025-12-05 20:08:10,285 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:08:12,974 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2025-12-05 20:08:19,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:45275 / 172.18.0.8:45275
2025-12-05 20:08:19,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:19,320 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:35169 / 172.18.0.19:35169
2025-12-05 20:08:19,323 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:19,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:38977 / 172.18.0.20:38977
2025-12-05 20:08:19,428 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:19,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:41785 / 172.18.0.17:41785
2025-12-05 20:08:19,575 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:19,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:37857 / 172.18.0.18:37857
2025-12-05 20:08:19,747 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:29,489 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:34093 / 172.18.0.2:34093
2025-12-05 20:08:29,493 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:08:29,494 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:08:33,885 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:40431 / 172.18.0.2:40431
2025-12-05 20:08:33,888 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:08:34,049 [IPC Server handler 78 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:08:38,793 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:08:43,718 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:08:48,447 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:08:49,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:44251 / 172.18.0.8:44251
2025-12-05 20:08:49,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:49,313 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:43173 / 172.18.0.19:43173
2025-12-05 20:08:49,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:49,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:34035 / 172.18.0.20:34035
2025-12-05 20:08:49,430 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:49,565 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:39639 / 172.18.0.17:39639
2025-12-05 20:08:49,572 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:49,761 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:45915 / 172.18.0.18:45915
2025-12-05 20:08:49,764 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:08:53,260 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:09:06,817 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from xcompat-recon-1.xcompat_default:44115 / 172.18.0.11:44115
2025-12-05 20:09:06,821 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:09:14,110 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:37737 / 172.18.0.2:37737
2025-12-05 20:09:14,114 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:09:14,115 [IPC Server handler 51 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:09:18,980 [IPC Server handler 78 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:09:19,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:44635 / 172.18.0.8:44635
2025-12-05 20:09:19,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:19,319 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:34349 / 172.18.0.19:34349
2025-12-05 20:09:19,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:19,417 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:34897 / 172.18.0.20:34897
2025-12-05 20:09:19,420 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:19,567 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:34541 / 172.18.0.17:34541
2025-12-05 20:09:19,575 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:19,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:39771 / 172.18.0.18:39771
2025-12-05 20:09:19,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:23,903 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:42031 / 172.18.0.2:42031
2025-12-05 20:09:23,905 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:09:24,048 [IPC Server handler 51 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:09:28,962 [IPC Server handler 78 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:09:33,718 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:09:41,232 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:38099 / 172.18.0.2:38099
2025-12-05 20:09:41,235 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:09:49,229 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:46045 / 172.18.0.8:46045
2025-12-05 20:09:49,234 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:49,317 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:43825 / 172.18.0.19:43825
2025-12-05 20:09:49,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:49,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:33767 / 172.18.0.20:33767
2025-12-05 20:09:49,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:49,562 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:35167 / 172.18.0.17:35167
2025-12-05 20:09:49,573 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:09:49,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:46617 / 172.18.0.18:46617
2025-12-05 20:09:49,754 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:10:00,514 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:42641 / 172.18.0.2:42641
2025-12-05 20:10:00,517 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:10:00,517 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:10:05,136 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from xcompat-om-1.xcompat_default:43199 / 172.18.0.2:43199
2025-12-05 20:10:05,138 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:10:05,279 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:10:10,102 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:10:14,847 [IPC Server handler 78 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:10:19,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-5.xcompat_default:46391 / 172.18.0.8:46391
2025-12-05 20:10:19,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:10:19,320 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-4.xcompat_default:41787 / 172.18.0.19:41787
2025-12-05 20:10:19,325 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:10:19,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-2.xcompat_default:44091 / 172.18.0.20:44091
2025-12-05 20:10:19,418 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:10:19,569 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-3.xcompat_default:37087 / 172.18.0.17:37087
2025-12-05 20:10:19,578 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:10:19,752 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from xcompat-datanode-1.xcompat_default:43551 / 172.18.0.18:43551
2025-12-05 20:10:19,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:10:19,833 [IPC Server handler 78 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
2025-12-05 20:10:24,765 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.18.0.7
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2025-12-05 20:10:49,867 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.9
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 2.0.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.2.jar:/opt/hadoop/share/ozone/lib/guava-32.1.3-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.37.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.29.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-io-2.18.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.6.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.27.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.17.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.17.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-2.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.25.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.25.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.25.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-2.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.1.2.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.25.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.10.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.30.2-GA.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/hdds-config-2.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-2.0.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.7-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.24.2.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-2.0.0.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.40.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.4.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.7.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.4.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-2.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_25-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-2.0.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.26.jar:/opt/hadoop/share/ozone/lib/jnr-constants-0.10.4.jar:/opt/hadoop/share/ozone/lib/jnr-posix-3.1.20.jar:/opt/hadoop/share/ozone/lib/jnr-ffi-2.2.17.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13-native.jar:/opt/hadoop/share/ozone/lib/asm-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-commons-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-analysis-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-tree-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-util-9.7.1.jar:/opt/hadoop/share/ozone/lib/jnr-a64asm-1.0.0.jar:/opt/hadoop/share/ozone/lib/jnr-x86asm-1.0.2.jar:/opt/hadoop/share/ozone/lib/gson-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.11.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.24.2.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-2.0.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.12.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-2.0.0.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.1.2.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.46.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.46.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.46.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.46.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.17.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.3.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.5.4.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-classes-epoll-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-2.0.0.jar:/opt/hadoop/share/ozone/web
STARTUP_MSG:   build = https://github.com/apache/ozone.git/ea8762e509ba1c95c437481190c5530e37208e0b
STARTUP_MSG:   java = 21.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachine.write.wait.interval=10m, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.delete.container.timeout=60s, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/dn.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/dn@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.kerberos.keytab.file=/etc/security/keytabs/dn.keytab, hdds.datanode.kerberos.principal=dn/dn@EXAMPLE.COM, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.read.threadpool=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.auto-compaction-small-sst-file.interval.minutes=120, hdds.datanode.rocksdb.auto-compaction-small-sst-file.threads=1, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.volume.min.free.space.percent=0.001f, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/scm.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.event.timeout=12m, hdds.scm.replication.event.timeout.datanode.offset=6m, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=5, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.hbase.enhancements.allowed=false, ozone.http.basedir=/tmp/ozone_http, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/om.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.rocksdb.metrics.enabled=false, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.volume.listall.allowed=true, ozone.recon.address=recon:9891, ozone.recon.administrators=testuser2, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=*, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=5s, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/s3g.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=1, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=1, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=scm:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2025-12-05 20:10:50,113 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [SIGHUP, SIGINT, SIGTERM]
2025-12-05 20:10:50,324 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:10:51,993 [main] INFO reflections.Reflections: Reflections took 1494 ms to scan 3 urls, producing 128 keys and 286 values
2025-12-05 20:10:52,778 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 20:10:52,778 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 20:10:56,152 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2025-12-05 20:10:57,033 [main] INFO proxy.SCMSecurityProtocolFailoverProxyProvider: Created fail-over proxy for protocol SCMSecurityProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.9:9961]
2025-12-05 20:10:57,298 [main] INFO client.SCMCertificateClient: Certificate serial ID set to null
2025-12-05 20:10:57,306 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2025-12-05 20:10:57,307 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2025-12-05 20:10:57,308 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2025-12-05 20:10:59,050 [main] INFO keys.KeyStorage: Storing public key to /data/metadata/scm/sub-ca/keys/public.pem.
2025-12-05 20:10:59,091 [main] INFO keys.KeyStorage: Storing private key to /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:10:59,101 [main] INFO client.SCMCertificateClient: Init response: GETCERT
2025-12-05 20:10:59,315 [main] INFO keys.KeyStorage: Reading public key from /data/metadata/scm/ca/keys/public.pem.
2025-12-05 20:10:59,329 [main] ERROR keys.KeyStorage: Failed to read the public key.
java.nio.file.NoSuchFileException: /data/metadata/scm/ca/keys/public.pem
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:261)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:379)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:431)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3268)
	at org.apache.hadoop.hdds.security.x509.keys.KeyStorage.readPublicKey(KeyStorage.java:176)
	at org.apache.hadoop.hdds.security.x509.keys.KeyStorage.readKeyPair(KeyStorage.java:184)
	at org.apache.hadoop.hdds.security.x509.certificate.authority.DefaultCAServer.checkIfKeysExist(DefaultCAServer.java:354)
	at org.apache.hadoop.hdds.security.x509.certificate.authority.DefaultCAServer.verifySelfSignedCA(DefaultCAServer.java:323)
	at org.apache.hadoop.hdds.security.x509.certificate.authority.DefaultCAServer.init(DefaultCAServer.java:162)
	at org.apache.hadoop.hdds.security.x509.certificate.client.SCMCertificateClient.initializeRootCertificateServer(SCMCertificateClient.java:397)
	at org.apache.hadoop.hdds.security.x509.certificate.client.SCMCertificateClient.getPrimarySCMSelfSignedCert(SCMCertificateClient.java:347)
	at org.apache.hadoop.hdds.security.x509.certificate.client.SCMCertificateClient.recoverStateIfNeeded(SCMCertificateClient.java:287)
	at org.apache.hadoop.hdds.security.x509.certificate.client.DefaultCertificateClient.initWithRecovery(DefaultCertificateClient.java:698)
	at org.apache.hadoop.hdds.scm.ha.HASecurityUtils.initializeSecurity(HASecurityUtils.java:97)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.scmInit(StorageContainerManager.java:1254)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter$SCMStarterHelper.init(StorageContainerManagerStarter.java:182)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.initScm(StorageContainerManagerStarter.java:112)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at picocli.CommandLine.executeUserObject(CommandLine.java:2066)
	at picocli.CommandLine.access$1500(CommandLine.java:148)
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2461)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2453)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2415)
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2273)
	at picocli.CommandLine$RunLast.execute(CommandLine.java:2417)
	at picocli.CommandLine.execute(CommandLine.java:2170)
	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:88)
	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:79)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.main(StorageContainerManagerStarter.java:59)
2025-12-05 20:11:02,328 [main] INFO keys.KeyStorage: Storing public key to /data/metadata/scm/ca/keys/public.pem.
2025-12-05 20:11:02,336 [main] INFO keys.KeyStorage: Storing private key to /data/metadata/scm/ca/keys/private.pem.
2025-12-05 20:11:02,387 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.9,host:scm
2025-12-05 20:11:02,389 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 20:11:02,410 [main] ERROR utils.SelfSignedCertificate: Invalid domain scm
2025-12-05 20:11:02,875 [main] INFO utils.SelfSignedCertificate: Certificate 1 is issued by SERIALNUMBER=1, O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5, OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0, CN=scm@scm to SERIALNUMBER=1, O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5, OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0, CN=scm@scm, valid from Fri Dec 05 20:11:02 UTC 2025 to Mon Jan 13 20:11:02 UTC 2031
2025-12-05 20:11:02,890 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/ca/certs/certificate.crt
2025-12-05 20:11:02,893 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDsTCCApmgAwIBAgIBATANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNTM1ZDFkOTctYTlhMS00ZTI5LTg2YmMtMTYwNjhlZTEw
ZmUwMTEwLwYDVQQKDChDSUQtMWZlMDlmYTktY2U0Mi00ZGM0LTkyYzItZDMzZjUy
ZWU1MGQ1MQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMTEwMloXDTMxMDExMzIwMTEw
MlowgYAxEDAOBgNVBAMMB3NjbUBzY20xLTArBgNVBAsMJDUzNWQxZDk3LWE5YTEt
NGUyOS04NmJjLTE2MDY4ZWUxMGZlMDExMC8GA1UECgwoQ0lELTFmZTA5ZmE5LWNl
NDItNGRjNC05MmMyLWQzM2Y1MmVlNTBkNTEKMAgGA1UEBRMBMTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAMkr6s6lLTZDayg6N1I+utF7/IdIffkI1B4j
Owp2lSSg+0RgApEm6k44X2U3xBEqRWB+Y2ow+OwwwFS5QT2E+yGCsfLbQqdHe/LE
JuoEWcv6u5ac5A8ro0Rl5DI+5dCAvSUTNDOCu8kUPNohoXv1Mvq+G3BxIAXZhYBh
jZaqWobRhXgj+AIe4wwJ3Yr4Qyr2L8H1rcZZ5WPs5UGI8re4lpZXrWBk5OHe6Qul
5PFD2aBlKdW95kps6wvuXPU821lNcTY4Agr7emwdovZJn4u8n7PmEBQE/Gf2HUMX
RekrAK6PdznJb5CDtXk+5Y9QG+pbE39MiefyzGaLBXgYvgC3OTkCAwEAAaM0MDIw
DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0RBAgwBocErBIA
CTANBgkqhkiG9w0BAQsFAAOCAQEAb5H+Zl5MATkzDkCOupYUBhg0pjWUggOo7Q0m
j17u82nRN/2jLFOtAmUYuN+QA6DGNRooNqPzIorzIL8W88QTEr6IIYuZ33K5i4Wf
pUICzqExvFkRBRmXZtwbPqcZ2GkwI7m/NkR4SKjlqS66gLpGrTb6yfbZR6I6/tSE
MPWsO64exsNeA/czZH7h9fSjpgHW44fG4Z+K4urB43weLvCh7kGvQ/ZkSfvLQN8x
NelX6PsWDog31tXKDhiZPu5jqpWmBZQTBz3K0ayTeEY+SWcbCMcgcsYVaP8njQ83
AzypqMs6kc9mzXM72xXQE8Y1TrYqblfUlfU3WA6lhD+Jg6qeZw==
-----END CERTIFICATE-----

2025-12-05 20:11:02,893 [main] INFO keys.KeyStorage: Reading public key from /data/metadata/scm/ca/keys/public.pem.
2025-12-05 20:11:02,898 [main] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/ca/keys/private.pem.
2025-12-05 20:11:02,953 [main] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm,scmId:535d1d97-a9a1-4e29-86bc-16068ee10fe0,clusterId:CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,subject:scm-sub@scm
2025-12-05 20:11:02,955 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.9,host:scm
2025-12-05 20:11:02,955 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2025-12-05 20:11:02,955 [main] ERROR utils.CertificateSignRequest: Invalid domain scm
2025-12-05 20:11:03,005 [main] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/ca/keys/private.pem.
2025-12-05 20:11:03,072 [main] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.19, 2.5.29.15, 2.5.29.17
2025-12-05 20:11:03,076 [main] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:11:03,122 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/CA-1.crt
2025-12-05 20:11:03,126 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDsTCCApmgAwIBAgIBATANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNTM1ZDFkOTctYTlhMS00ZTI5LTg2YmMtMTYwNjhlZTEw
ZmUwMTEwLwYDVQQKDChDSUQtMWZlMDlmYTktY2U0Mi00ZGM0LTkyYzItZDMzZjUy
ZWU1MGQ1MQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMTEwMloXDTMxMDExMzIwMTEw
MlowgYAxEDAOBgNVBAMMB3NjbUBzY20xLTArBgNVBAsMJDUzNWQxZDk3LWE5YTEt
NGUyOS04NmJjLTE2MDY4ZWUxMGZlMDExMC8GA1UECgwoQ0lELTFmZTA5ZmE5LWNl
NDItNGRjNC05MmMyLWQzM2Y1MmVlNTBkNTEKMAgGA1UEBRMBMTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAMkr6s6lLTZDayg6N1I+utF7/IdIffkI1B4j
Owp2lSSg+0RgApEm6k44X2U3xBEqRWB+Y2ow+OwwwFS5QT2E+yGCsfLbQqdHe/LE
JuoEWcv6u5ac5A8ro0Rl5DI+5dCAvSUTNDOCu8kUPNohoXv1Mvq+G3BxIAXZhYBh
jZaqWobRhXgj+AIe4wwJ3Yr4Qyr2L8H1rcZZ5WPs5UGI8re4lpZXrWBk5OHe6Qul
5PFD2aBlKdW95kps6wvuXPU821lNcTY4Agr7emwdovZJn4u8n7PmEBQE/Gf2HUMX
RekrAK6PdznJb5CDtXk+5Y9QG+pbE39MiefyzGaLBXgYvgC3OTkCAwEAAaM0MDIw
DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0RBAgwBocErBIA
CTANBgkqhkiG9w0BAQsFAAOCAQEAb5H+Zl5MATkzDkCOupYUBhg0pjWUggOo7Q0m
j17u82nRN/2jLFOtAmUYuN+QA6DGNRooNqPzIorzIL8W88QTEr6IIYuZ33K5i4Wf
pUICzqExvFkRBRmXZtwbPqcZ2GkwI7m/NkR4SKjlqS66gLpGrTb6yfbZR6I6/tSE
MPWsO64exsNeA/czZH7h9fSjpgHW44fG4Z+K4urB43weLvCh7kGvQ/ZkSfvLQN8x
NelX6PsWDog31tXKDhiZPu5jqpWmBZQTBz3K0ayTeEY+SWcbCMcgcsYVaP8njQ83
AzypqMs6kc9mzXM72xXQE8Y1TrYqblfUlfU3WA6lhD+Jg6qeZw==
-----END CERTIFICATE-----

2025-12-05 20:11:03,133 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/2.crt
2025-12-05 20:11:03,136 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDtTCCAp2gAwIBAgIBAjANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNTM1ZDFkOTctYTlhMS00ZTI5LTg2YmMtMTYwNjhlZTEw
ZmUwMTEwLwYDVQQKDChDSUQtMWZlMDlmYTktY2U0Mi00ZGM0LTkyYzItZDMzZjUy
ZWU1MGQ1MQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMTEwMloXDTMxMDExMzIwMTEw
MlowgYQxFDASBgNVBAMMC3NjbS1zdWJAc2NtMS0wKwYDVQQLDCQ1MzVkMWQ5Ny1h
OWExLTRlMjktODZiYy0xNjA2OGVlMTBmZTAxMTAvBgNVBAoMKENJRC0xZmUwOWZh
OS1jZTQyLTRkYzQtOTJjMi1kMzNmNTJlZTUwZDUxCjAIBgNVBAUTATIwggEiMA0G
CSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCtvXKFtcmX2BPOovqf/akvetw7VVx2
BKZdD2yAYCD5yjDPYk25Yod4M+9LECd7yJK1KIYtYDZUX4rB2G7oDu8Zn1UpQgjy
M5aJXuv4Q+t0ZCRlrJX1Lz1YTQ2mkbpD5/wVDhpYdyZ12WlF7ROKHfJz3lIU1rAT
NwMe86wkDx05cV+SjSmN+0VTyPji2HIpq4Hi5cEh2M8JDpFP4qMgZOGSSd3S/YXX
jS7mZVPRiE3W1y8Yihva8icd1D3Ztu57U3gGhZUvTwAjKFJ3NfmwmRkUtTVboN+y
/UHxgvYuQ0sUuXBYM6uvJHIPGDrRQM4F/J/2bs01/pwRmgNn50gHQSyDAgMBAAGj
NDAyMA4GA1UdDwEB/wQEAwIBvjAPBgNVHREECDAGhwSsEgAJMA8GA1UdEwEB/wQF
MAMBAf8wDQYJKoZIhvcNAQELBQADggEBACJsuYFEehaCfHU5pAhlWZQOJvZb5izh
ZyX0cwfEEVVU9tSLrGCazILdM6WtpUwD6s2arXiniRTokLZsmUrnMQzngUsLog3s
8znSnKzM6HVRJIWECjY89Gh/RnIIbMJFP4AaXCOV33QKczyYF9z6W9JZEXZ81QEj
6uxCYGoYz9cxv20Qaviw87vZSRfVmMJeTyid0J+8TG4OKmnHtV+xMAYQgLXxMy58
AG6nBGhKY78LUQFp9z7VmLDE4gXZ819/ULOMWpv7qSEmDjlniHKMimThAbQi01Xn
fxX1QABxLEgX7qVQiPBr1chfv0ATVijvKc/Y6J64oCxOfGhAm6quX/c=
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDsTCCApmgAwIBAgIBATANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNTM1ZDFkOTctYTlhMS00ZTI5LTg2YmMtMTYwNjhlZTEw
ZmUwMTEwLwYDVQQKDChDSUQtMWZlMDlmYTktY2U0Mi00ZGM0LTkyYzItZDMzZjUy
ZWU1MGQ1MQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMTEwMloXDTMxMDExMzIwMTEw
MlowgYAxEDAOBgNVBAMMB3NjbUBzY20xLTArBgNVBAsMJDUzNWQxZDk3LWE5YTEt
NGUyOS04NmJjLTE2MDY4ZWUxMGZlMDExMC8GA1UECgwoQ0lELTFmZTA5ZmE5LWNl
NDItNGRjNC05MmMyLWQzM2Y1MmVlNTBkNTEKMAgGA1UEBRMBMTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAMkr6s6lLTZDayg6N1I+utF7/IdIffkI1B4j
Owp2lSSg+0RgApEm6k44X2U3xBEqRWB+Y2ow+OwwwFS5QT2E+yGCsfLbQqdHe/LE
JuoEWcv6u5ac5A8ro0Rl5DI+5dCAvSUTNDOCu8kUPNohoXv1Mvq+G3BxIAXZhYBh
jZaqWobRhXgj+AIe4wwJ3Yr4Qyr2L8H1rcZZ5WPs5UGI8re4lpZXrWBk5OHe6Qul
5PFD2aBlKdW95kps6wvuXPU821lNcTY4Agr7emwdovZJn4u8n7PmEBQE/Gf2HUMX
RekrAK6PdznJb5CDtXk+5Y9QG+pbE39MiefyzGaLBXgYvgC3OTkCAwEAAaM0MDIw
DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0RBAgwBocErBIA
CTANBgkqhkiG9w0BAQsFAAOCAQEAb5H+Zl5MATkzDkCOupYUBhg0pjWUggOo7Q0m
j17u82nRN/2jLFOtAmUYuN+QA6DGNRooNqPzIorzIL8W88QTEr6IIYuZ33K5i4Wf
pUICzqExvFkRBRmXZtwbPqcZ2GkwI7m/NkR4SKjlqS66gLpGrTb6yfbZR6I6/tSE
MPWsO64exsNeA/czZH7h9fSjpgHW44fG4Z+K4urB43weLvCh7kGvQ/ZkSfvLQN8x
NelX6PsWDog31tXKDhiZPu5jqpWmBZQTBz3K0ayTeEY+SWcbCMcgcsYVaP8njQ83
AzypqMs6kc9mzXM72xXQE8Y1TrYqblfUlfU3WA6lhD+Jg6qeZw==
-----END CERTIFICATE-----

2025-12-05 20:11:03,137 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/certificate.crt
2025-12-05 20:11:03,137 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDtTCCAp2gAwIBAgIBAjANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNTM1ZDFkOTctYTlhMS00ZTI5LTg2YmMtMTYwNjhlZTEw
ZmUwMTEwLwYDVQQKDChDSUQtMWZlMDlmYTktY2U0Mi00ZGM0LTkyYzItZDMzZjUy
ZWU1MGQ1MQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMTEwMloXDTMxMDExMzIwMTEw
MlowgYQxFDASBgNVBAMMC3NjbS1zdWJAc2NtMS0wKwYDVQQLDCQ1MzVkMWQ5Ny1h
OWExLTRlMjktODZiYy0xNjA2OGVlMTBmZTAxMTAvBgNVBAoMKENJRC0xZmUwOWZh
OS1jZTQyLTRkYzQtOTJjMi1kMzNmNTJlZTUwZDUxCjAIBgNVBAUTATIwggEiMA0G
CSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCtvXKFtcmX2BPOovqf/akvetw7VVx2
BKZdD2yAYCD5yjDPYk25Yod4M+9LECd7yJK1KIYtYDZUX4rB2G7oDu8Zn1UpQgjy
M5aJXuv4Q+t0ZCRlrJX1Lz1YTQ2mkbpD5/wVDhpYdyZ12WlF7ROKHfJz3lIU1rAT
NwMe86wkDx05cV+SjSmN+0VTyPji2HIpq4Hi5cEh2M8JDpFP4qMgZOGSSd3S/YXX
jS7mZVPRiE3W1y8Yihva8icd1D3Ztu57U3gGhZUvTwAjKFJ3NfmwmRkUtTVboN+y
/UHxgvYuQ0sUuXBYM6uvJHIPGDrRQM4F/J/2bs01/pwRmgNn50gHQSyDAgMBAAGj
NDAyMA4GA1UdDwEB/wQEAwIBvjAPBgNVHREECDAGhwSsEgAJMA8GA1UdEwEB/wQF
MAMBAf8wDQYJKoZIhvcNAQELBQADggEBACJsuYFEehaCfHU5pAhlWZQOJvZb5izh
ZyX0cwfEEVVU9tSLrGCazILdM6WtpUwD6s2arXiniRTokLZsmUrnMQzngUsLog3s
8znSnKzM6HVRJIWECjY89Gh/RnIIbMJFP4AaXCOV33QKczyYF9z6W9JZEXZ81QEj
6uxCYGoYz9cxv20Qaviw87vZSRfVmMJeTyid0J+8TG4OKmnHtV+xMAYQgLXxMy58
AG6nBGhKY78LUQFp9z7VmLDE4gXZ819/ULOMWpv7qSEmDjlniHKMimThAbQi01Xn
fxX1QABxLEgX7qVQiPBr1chfv0ATVijvKc/Y6J64oCxOfGhAm6quX/c=
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDsTCCApmgAwIBAgIBATANBgkqhkiG9w0BAQsFADCBgDEQMA4GA1UEAwwHc2Nt
QHNjbTEtMCsGA1UECwwkNTM1ZDFkOTctYTlhMS00ZTI5LTg2YmMtMTYwNjhlZTEw
ZmUwMTEwLwYDVQQKDChDSUQtMWZlMDlmYTktY2U0Mi00ZGM0LTkyYzItZDMzZjUy
ZWU1MGQ1MQowCAYDVQQFEwExMB4XDTI1MTIwNTIwMTEwMloXDTMxMDExMzIwMTEw
MlowgYAxEDAOBgNVBAMMB3NjbUBzY20xLTArBgNVBAsMJDUzNWQxZDk3LWE5YTEt
NGUyOS04NmJjLTE2MDY4ZWUxMGZlMDExMC8GA1UECgwoQ0lELTFmZTA5ZmE5LWNl
NDItNGRjNC05MmMyLWQzM2Y1MmVlNTBkNTEKMAgGA1UEBRMBMTCCASIwDQYJKoZI
hvcNAQEBBQADggEPADCCAQoCggEBAMkr6s6lLTZDayg6N1I+utF7/IdIffkI1B4j
Owp2lSSg+0RgApEm6k44X2U3xBEqRWB+Y2ow+OwwwFS5QT2E+yGCsfLbQqdHe/LE
JuoEWcv6u5ac5A8ro0Rl5DI+5dCAvSUTNDOCu8kUPNohoXv1Mvq+G3BxIAXZhYBh
jZaqWobRhXgj+AIe4wwJ3Yr4Qyr2L8H1rcZZ5WPs5UGI8re4lpZXrWBk5OHe6Qul
5PFD2aBlKdW95kps6wvuXPU821lNcTY4Agr7emwdovZJn4u8n7PmEBQE/Gf2HUMX
RekrAK6PdznJb5CDtXk+5Y9QG+pbE39MiefyzGaLBXgYvgC3OTkCAwEAAaM0MDIw
DwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0RBAgwBocErBIA
CTANBgkqhkiG9w0BAQsFAAOCAQEAb5H+Zl5MATkzDkCOupYUBhg0pjWUggOo7Q0m
j17u82nRN/2jLFOtAmUYuN+QA6DGNRooNqPzIorzIL8W88QTEr6IIYuZ33K5i4Wf
pUICzqExvFkRBRmXZtwbPqcZ2GkwI7m/NkR4SKjlqS66gLpGrTb6yfbZR6I6/tSE
MPWsO64exsNeA/czZH7h9fSjpgHW44fG4Z+K4urB43weLvCh7kGvQ/ZkSfvLQN8x
NelX6PsWDog31tXKDhiZPu5jqpWmBZQTBz3K0ayTeEY+SWcbCMcgcsYVaP8njQ83
AzypqMs6kc9mzXM72xXQE8Y1TrYqblfUlfU3WA6lhD+Jg6qeZw==
-----END CERTIFICATE-----

2025-12-05 20:11:03,138 [main] INFO client.SCMCertificateClient: Successfully stored SCM signed certificate.
2025-12-05 20:11:03,173 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:11:03,176 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 20:11:03,176 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 20:11:03,342 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:03,446 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2025-12-05 20:11:03,620 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-05 20:11:03,622 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 20:11:03,623 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-05 20:11:03,623 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 20:11:03,623 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2025-12-05 20:11:03,623 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2025-12-05 20:11:03,624 [main] INFO server.GrpcService: raft.grpc.message.size.max = 34603008 (custom)
2025-12-05 20:11:03,626 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-12-05 20:11:03,628 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 20:11:03,637 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2025-12-05 20:11:03,638 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:03,640 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-12-05 20:11:03,642 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-12-05 20:11:03,877 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2025-12-05 20:11:03,880 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 20:11:03,880 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2025-12-05 20:11:03,880 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 20:11:03,887 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 20:11:03,888 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2025-12-05 20:11:03,889 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2025-12-05 20:11:03,895 [main] INFO server.RaftServer: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: addNew group-D33F52EE50D5:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894] returns group-D33F52EE50D5:java.util.concurrent.CompletableFuture@3330f3ad[Not completed]
2025-12-05 20:11:03,907 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: new RaftServerImpl for group-D33F52EE50D5:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894] with SCMStateMachine:uninitialized
2025-12-05 20:11:03,909 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 20:11:03,909 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2025-12-05 20:11:03,909 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2025-12-05 20:11:03,909 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-05 20:11:03,910 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 20:11:03,910 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2025-12-05 20:11:03,910 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 20:11:03,916 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: ConfigurationManager, init=conf: {index: -1, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-05 20:11:03,925 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2025-12-05 20:11:03,931 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2025-12-05 20:11:03,938 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2025-12-05 20:11:03,941 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-12-05 20:11:03,945 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2025-12-05 20:11:03,945 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-12-05 20:11:04,166 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 20:11:04,169 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-12-05 20:11:04,169 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2025-12-05 20:11:04,169 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2025-12-05 20:11:04,170 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2025-12-05 20:11:04,170 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2025-12-05 20:11:04,175 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2025-12-05 20:11:04,176 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2025-12-05 20:11:04,178 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 20:11:04,187 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5 does not exist. Creating ...
2025-12-05 20:11:04,192 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5/in_use.lock acquired by nodename 12@scm
2025-12-05 20:11:04,198 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5 has been successfully formatted.
2025-12-05 20:11:04,200 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO ha.SCMStateMachine: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: initialize group-D33F52EE50D5
2025-12-05 20:11:04,203 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2025-12-05 20:11:04,209 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2025-12-05 20:11:04,210 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:04,211 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-12-05 20:11:04,211 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2025-12-05 20:11:04,214 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 20:11:04,218 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2025-12-05 20:11:04,218 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-12-05 20:11:04,218 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:04,223 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO util.AwaitToRun: Thread[#34,535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-cacheEviction-AwaitToRun,5,main] started
2025-12-05 20:11:04,230 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5
2025-12-05 20:11:04,231 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-12-05 20:11:04,232 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2025-12-05 20:11:04,235 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 20:11:04,236 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2025-12-05 20:11:04,236 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2025-12-05 20:11:04,237 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2025-12-05 20:11:04,238 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-12-05 20:11:04,240 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-12-05 20:11:04,242 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2025-12-05 20:11:04,247 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:04,247 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2025-12-05 20:11:04,247 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2025-12-05 20:11:04,248 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2025-12-05 20:11:04,254 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-12-05 20:11:04,254 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-05 20:11:04,256 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: start as a follower, conf=conf: {index: -1, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:04,257 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-12-05 20:11:04,258 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: start 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState
2025-12-05 20:11:04,259 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2025-12-05 20:11:04,259 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2025-12-05 20:11:04,261 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D33F52EE50D5,id=535d1d97-a9a1-4e29-86bc-16068ee10fe0
2025-12-05 20:11:04,262 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO util.JmxRegister: register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-D33F52EE50D5,id=535d1d97-a9a1-4e29-86bc-16068ee10fe0
2025-12-05 20:11:04,265 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-12-05 20:11:04,265 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-12-05 20:11:04,265 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-12-05 20:11:04,266 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-12-05 20:11:04,269 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2025-12-05 20:11:04,270 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2025-12-05 20:11:04,274 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: Successfully started.
2025-12-05 20:11:04,275 [main] INFO server.RaftServer: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: start RPC server
2025-12-05 20:11:04,322 [main] INFO server.GrpcService: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: GrpcService started, listening on 9894
2025-12-05 20:11:04,325 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-535d1d97-a9a1-4e29-86bc-16068ee10fe0: Started
2025-12-05 20:11:09,337 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO impl.FollowerState: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5079136799ns, electionTimeout:5076ms
2025-12-05 20:11:09,337 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: shutdown 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState
2025-12-05 20:11:09,337 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-12-05 20:11:09,339 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2025-12-05 20:11:09,339 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: start 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1
2025-12-05 20:11:09,341 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.LeaderElection: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:09,342 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.LeaderElection: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2025-12-05 20:11:09,344 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.LeaderElection: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:09,344 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.LeaderElection: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2025-12-05 20:11:09,345 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: shutdown 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1
2025-12-05 20:11:09,345 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-12-05 20:11:09,348 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2025-12-05 20:11:09,350 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 20:11:09,351 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-12-05 20:11:09,353 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2025-12-05 20:11:09,353 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2025-12-05 20:11:09,354 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2025-12-05 20:11:09,358 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2025-12-05 20:11:09,359 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-12-05 20:11:09,360 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 20:11:09,360 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.log-metadata.enabled = true (default)
2025-12-05 20:11:09,360 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 20:11:09,360 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-12-05 20:11:09,361 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: start 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderStateImpl
2025-12-05 20:11:09,362 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: set firstElectionSinceStartup to false for becomeLeader
2025-12-05 20:11:09,362 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: change Leader from null to 535d1d97-a9a1-4e29-86bc-16068ee10fe0 at term 1 for becomeLeader, leader elected after 5437ms
2025-12-05 20:11:09,376 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker: Starting segment from index:0
2025-12-05 20:11:09,391 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: set configuration conf: {index: 0, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:09,400 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2025-12-05 20:11:09,407 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5/current/log_inprogress_0
2025-12-05 20:11:09,415 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO server.RaftServer$Division: Leader 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-12-05 20:11:10,326 [main] INFO server.RaftServer: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: close
2025-12-05 20:11:10,326 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: shutdown
2025-12-05 20:11:10,326 [main] INFO server.GrpcService: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: shutdown server GrpcServerProtocolService now
2025-12-05 20:11:10,327 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D33F52EE50D5,id=535d1d97-a9a1-4e29-86bc-16068ee10fe0
2025-12-05 20:11:10,327 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: shutdown 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderStateImpl
2025-12-05 20:11:10,330 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO impl.PendingRequests: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-PendingRequests: sendNotLeaderResponses
2025-12-05 20:11:10,334 [main] INFO server.GrpcService: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: shutdown server GrpcServerProtocolService successfully
2025-12-05 20:11:10,335 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO impl.StateMachineUpdater: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater: set stopIndex = 0
2025-12-05 20:11:10,335 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO impl.StateMachineUpdater: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater: Took a snapshot at index 0
2025-12-05 20:11:10,335 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO impl.StateMachineUpdater: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-12-05 20:11:10,337 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO impl.StateMachineUpdater: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:1, i:0)
2025-12-05 20:11:10,338 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-cacheEviction-AwaitToRun] INFO util.AwaitToRun: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-12-05 20:11:10,412 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker close()
2025-12-05 20:11:10,417 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-535d1d97-a9a1-4e29-86bc-16068ee10fe0: Stopped
2025-12-05 20:11:10,420 [main] INFO server.StorageContainerManager: Enabled Ratis!
2025-12-05 20:11:10,421 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5; layoutVersion=8; scmId=535d1d97-a9a1-4e29-86bc-16068ee10fe0
2025-12-05 20:11:10,422 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.9
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2025-12-05 20:11:11,608 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm/172.18.0.9
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.0.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.2.jar:/opt/hadoop/share/ozone/lib/guava-32.1.3-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.37.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.29.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-io-2.18.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.6.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.27.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.17.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.17.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-2.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.25.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.25.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.25.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-2.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.1.2.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.25.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.10.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.30.2-GA.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/hdds-config-2.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-2.0.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.7-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.24.2.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-2.0.0.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.40.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.4.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.7.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.4.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-2.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_25-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-2.0.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.26.jar:/opt/hadoop/share/ozone/lib/jnr-constants-0.10.4.jar:/opt/hadoop/share/ozone/lib/jnr-posix-3.1.20.jar:/opt/hadoop/share/ozone/lib/jnr-ffi-2.2.17.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13-native.jar:/opt/hadoop/share/ozone/lib/asm-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-commons-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-analysis-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-tree-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-util-9.7.1.jar:/opt/hadoop/share/ozone/lib/jnr-a64asm-1.0.0.jar:/opt/hadoop/share/ozone/lib/jnr-x86asm-1.0.2.jar:/opt/hadoop/share/ozone/lib/gson-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.11.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.24.2.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-2.0.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.12.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-2.0.0.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.1.2.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.46.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.46.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.46.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.46.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.17.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.3.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.5.4.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-classes-epoll-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-2.0.0.jar:/opt/hadoop/share/ozone/web
STARTUP_MSG:   build = https://github.com/apache/ozone.git/ea8762e509ba1c95c437481190c5530e37208e0b
STARTUP_MSG:   java = 21.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachine.write.wait.interval=10m, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.delete.container.timeout=60s, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/dn.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/dn@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.kerberos.keytab.file=/etc/security/keytabs/dn.keytab, hdds.datanode.kerberos.principal=dn/dn@EXAMPLE.COM, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.read.threadpool=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.auto-compaction-small-sst-file.interval.minutes=120, hdds.datanode.rocksdb.auto-compaction-small-sst-file.threads=1, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.volume.min.free.space.percent=0.001f, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/scm.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.event.timeout=12m, hdds.scm.replication.event.timeout.datanode.offset=6m, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=5, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.hbase.enhancements.allowed=false, ozone.http.basedir=/tmp/ozone_http, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/om.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.rocksdb.metrics.enabled=false, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.volume.listall.allowed=true, ozone.recon.address=recon:9891, ozone.recon.administrators=testuser2, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=*, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=5s, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/s3g.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=1, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=1, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=scm:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2025-12-05 20:11:11,625 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [SIGHUP, SIGINT, SIGTERM]
2025-12-05 20:11:11,645 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:11:11,796 [main] INFO reflections.Reflections: Reflections took 138 ms to scan 3 urls, producing 128 keys and 286 values
2025-12-05 20:11:11,926 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-12-05 20:11:11,927 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-12-05 20:11:12,367 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2025-12-05 20:11:12,367 [main] INFO server.StorageContainerManager: SCM login successful.
2025-12-05 20:11:12,386 [main] INFO proxy.SCMSecurityProtocolFailoverProxyProvider: Created fail-over proxy for protocol SCMSecurityProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.9:9961]
2025-12-05 20:11:12,410 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 2
2025-12-05 20:11:12,455 [main] INFO client.SCMCertificateClient: Added certificate 2 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2025-12-05 20:11:12,457 [main] INFO client.SCMCertificateClient: Added certificate 1 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2025-12-05 20:11:12,459 [main] INFO client.SCMCertificateClient: Added certificate 2 from file: /data/metadata/scm/sub-ca/certs/2.crt.
2025-12-05 20:11:12,460 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2025-12-05 20:11:12,490 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:11:12,582 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-12-05 20:11:12,681 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-2.0.0.jar!/network-topology-default.xml]
2025-12-05 20:11:12,682 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2025-12-05 20:11:12,818 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:535d1d97-a9a1-4e29-86bc-16068ee10fe0
2025-12-05 20:11:12,824 [main] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:12,906 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2025-12-05 20:11:12,959 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 2
             IssuerDN: CN=scm@scm,OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0,O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:11:02 UTC 2025
           Final Date: Mon Jan 13 20:11:02 UTC 2031
            SubjectDN: CN=scm-sub@scm,OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0,O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,SERIALNUMBER=2
           Public Key: RSA Public Key [0b:0d:15:37:fe:cf:09:42:3e:36:41:9d:da:56:e3:b9:86:2e:a5:40],[56:66:d1:a4]
        modulus: adbd7285b5c997d813cea2fa9ffda92f7adc3b555c7604a65d0f6c806020f9ca30cf624db962877833ef4b10277bc892b528862d6036545f8ac1d86ee80eef199f55294208f23396895eebf843eb74642465ac95f52f3d584d0da691ba43e7fc150e1a58772675d96945ed138a1df273de5214d6b01337031ef3ac240f1d39715f928d298dfb4553c8f8e2d87229ab81e2e5c121d8cf090e914fe2a32064e19249ddd2fd85d78d2ee66553d1884dd6d72f188a1bdaf2271dd43dd9b6ee7b53780685952f4f002328527735f9b0991914b5355ba0dfb2fd41f182f62e434b14b9705833abaf24720f183ad140ce05fc9ff66ecd35fe9c119a0367e74807412c83
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 226cb981447a16827c7539a4086559940e26f65b
                       e62ce16725f47307c4115554f6d48bac609acc82
                       dd33a5ada54c03eacd9aad78a78914e890b66c99
                       4ae7310ce7814b0ba20decf339d29caccce87551
                       2485840a363cf4687f4672086cc2453f801a5c23
                       95df740a733c9817dcfa5bd25911767cd50123ea
                       ec42606a18cfd731bf6d106af8b0f3bbd94917d5
                       98c25e4f289dd09fbc4c6e0e2a69c7b55fb13006
                       1080b5f1332e7c006ea704684a63bf0b510169f7
                       3ed598b0c4e205d9f35f7f50b38c5a9bfba92126
                       0e396788728c8a64e101b422d355e77f15f54000
                       712c4817eea55088f06bd5c85fbf40135628ef29
                       cfd8e89eb8a02c4e7c68409baaae5ff7
       Extensions: 
                       critical(true) KeyUsage: 0xbe
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 

                       critical(true) BasicConstraints: isCa(true)

2025-12-05 20:11:12,986 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm,OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0,O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:11:02 UTC 2025
           Final Date: Mon Jan 13 20:11:02 UTC 2031
            SubjectDN: CN=scm@scm,OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0,O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,SERIALNUMBER=1
           Public Key: RSA Public Key [c3:cd:83:af:8a:1e:e2:92:59:b0:fe:74:28:b5:ee:31:0c:bd:d8:82],[56:66:d1:a4]
        modulus: c92beacea52d36436b283a37523ebad17bfc87487df908d41e233b0a769524a0fb4460029126ea4e385f6537c4112a45607e636a30f8ec30c054b9413d84fb2182b1f2db42a7477bf2c426ea0459cbfabb969ce40f2ba34465e4323ee5d080bd2513343382bbc9143cda21a17bf532fabe1b70712005d98580618d96aa5a86d1857823f8021ee30c09dd8af8432af62fc1f5adc659e563ece54188f2b7b8969657ad6064e4e1dee90ba5e4f143d9a06529d5bde64a6ceb0bee5cf53cdb594d713638020afb7a6c1da2f6499f8bbc9fb3e6101404fc67f61d431745e92b00ae8f7739c96f9083b5793ee58f501bea5b137f4c89e7f2cc668b057818be00b73939
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 6f91fe665e4c0139330e408eba9614061834a635
                       948203a8ed0d268f5eeef369d137fda32c53ad02
                       6518b8df9003a0c6351a2836a3f3228af320bf16
                       f3c41312be88218b99df72b98b859fa54202cea1
                       31bc591105199766dc1b3ea719d8693023b9bf36
                       447848a8e5a92eba80ba46ad36fac9f6d947a23a
                       fed48430f5ac3bae1ec6c35e03f733647ee1f5f4
                       a3a601d6e387c6e19f8ae2eac1e37c1e2ef0a1ee
                       41af43f66449fbcb40df3135e957e8fb160e8837
                       d6d5ca0e18993eee63aa95a6059413073dcad1ac
                       9378463e49671b08c72072c61568ff278d0f3703
                       3ca9a8cb3a91cf66cd733bdb15d013c6354eb62a
                       6e57d495f537580ea5843f8983aa9e67
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 


2025-12-05 20:11:13,010 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2025-12-05 20:11:13,012 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm,OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0,O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,SERIALNUMBER=1
           Start Date: Fri Dec 05 20:11:02 UTC 2025
           Final Date: Mon Jan 13 20:11:02 UTC 2031
            SubjectDN: CN=scm@scm,OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0,O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,SERIALNUMBER=1
           Public Key: RSA Public Key [c3:cd:83:af:8a:1e:e2:92:59:b0:fe:74:28:b5:ee:31:0c:bd:d8:82],[56:66:d1:a4]
        modulus: c92beacea52d36436b283a37523ebad17bfc87487df908d41e233b0a769524a0fb4460029126ea4e385f6537c4112a45607e636a30f8ec30c054b9413d84fb2182b1f2db42a7477bf2c426ea0459cbfabb969ce40f2ba34465e4323ee5d080bd2513343382bbc9143cda21a17bf532fabe1b70712005d98580618d96aa5a86d1857823f8021ee30c09dd8af8432af62fc1f5adc659e563ece54188f2b7b8969657ad6064e4e1dee90ba5e4f143d9a06529d5bde64a6ceb0bee5cf53cdb594d713638020afb7a6c1da2f6499f8bbc9fb3e6101404fc67f61d431745e92b00ae8f7739c96f9083b5793ee58f501bea5b137f4c89e7f2cc668b057818be00b73939
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 6f91fe665e4c0139330e408eba9614061834a635
                       948203a8ed0d268f5eeef369d137fda32c53ad02
                       6518b8df9003a0c6351a2836a3f3228af320bf16
                       f3c41312be88218b99df72b98b859fa54202cea1
                       31bc591105199766dc1b3ea719d8693023b9bf36
                       447848a8e5a92eba80ba46ad36fac9f6d947a23a
                       fed48430f5ac3bae1ec6c35e03f733647ee1f5f4
                       a3a601d6e387c6e19f8ae2eac1e37c1e2ef0a1ee
                       41af43f66449fbcb40df3135e957e8fb160e8837
                       d6d5ca0e18993eee63aa95a6059413073dcad1ac
                       9378463e49671b08c72072c61568ff278d0f3703
                       3ca9a8cb3a91cf66cd733bdb15d013c6354eb62a
                       6e57d495f537580ea5843f8983aa9e67
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [CONTEXT 7] IMPLICIT 
        DER Octet String[4] 


2025-12-05 20:11:13,021 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:13,023 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:13,040 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:13,077 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2025-12-05 20:11:13,084 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-12-05 20:11:13,085 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 20:11:13,085 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-12-05 20:11:13,085 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2025-12-05 20:11:13,085 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2025-12-05 20:11:13,086 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2025-12-05 20:11:13,086 [main] INFO server.GrpcService: raft.grpc.message.size.max = 34603008 (custom)
2025-12-05 20:11:13,086 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-12-05 20:11:13,087 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 20:11:13,095 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2025-12-05 20:11:13,095 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:13,098 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-12-05 20:11:13,099 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-12-05 20:11:13,182 [main] INFO server.GrpcService: Setting TLS for 0.0.0.0/0.0.0.0:9894
2025-12-05 20:11:13,386 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2025-12-05 20:11:13,388 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 20:11:13,388 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2025-12-05 20:11:13,388 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 20:11:13,392 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 20:11:13,392 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2025-12-05 20:11:13,393 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2025-12-05 20:11:13,396 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: found a subdirectory /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5
2025-12-05 20:11:13,400 [main] INFO server.RaftServer: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: addNew group-D33F52EE50D5:[] returns group-D33F52EE50D5:java.util.concurrent.CompletableFuture@64e7d698[Not completed]
2025-12-05 20:11:13,412 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: new RaftServerImpl for group-D33F52EE50D5:[] with SCMStateMachine:uninitialized
2025-12-05 20:11:13,413 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 20:11:13,413 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2025-12-05 20:11:13,413 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2025-12-05 20:11:13,413 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-12-05 20:11:13,413 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-12-05 20:11:13,413 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2025-12-05 20:11:13,414 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-12-05 20:11:13,419 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: ConfigurationManager, init=conf: {index: -1, cur=peers:[]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-12-05 20:11:13,423 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2025-12-05 20:11:13,425 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2025-12-05 20:11:13,428 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2025-12-05 20:11:13,428 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-12-05 20:11:13,431 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2025-12-05 20:11:13,431 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-12-05 20:11:13,563 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-12-05 20:11:13,564 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-12-05 20:11:13,564 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2025-12-05 20:11:13,565 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2025-12-05 20:11:13,565 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2025-12-05 20:11:13,565 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2025-12-05 20:11:13,566 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2025-12-05 20:11:13,566 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2025-12-05 20:11:13,566 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2025-12-05 20:11:13,580 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HBASE_SUPPORT (version = 8), software layout = HBASE_SUPPORT (version = 8)
2025-12-05 20:11:13,593 [main] INFO ha.SequenceIdGenerator: upgrade localId to 115816896921600000
2025-12-05 20:11:13,594 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2025-12-05 20:11:13,597 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2025-12-05 20:11:13,598 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2025-12-05 20:11:13,598 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2025-12-05 20:11:13,632 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2025-12-05 20:11:13,638 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2025-12-05 20:11:13,641 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-05 20:11:13,650 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2025-12-05 20:11:13,659 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2025-12-05 20:11:13,660 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2025-12-05 20:11:13,664 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2025-12-05 20:11:13,665 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2025-12-05 20:11:13,672 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2025-12-05 20:11:13,675 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2025-12-05 20:11:13,679 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2025-12-05 20:11:13,680 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2025-12-05 20:11:13,697 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-05 20:11:13,697 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2025-12-05 20:11:13,715 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2025-12-05 20:11:13,749 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2025-12-05 20:11:13,750 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2025-12-05 20:11:13,757 [main] INFO safemode.ContainerSafeModeRule: Refreshed Containers with one replica threshold count 0, with ec n replica threshold count 0.
2025-12-05 20:11:13,760 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:13,761 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-05 20:11:13,873 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT10M
2025-12-05 20:11:13,873 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2025-12-05 20:11:13,939 [main] INFO keys.KeyStorage: Reading public key from /data/metadata/scm/sub-ca/keys/public.pem.
2025-12-05 20:11:13,940 [main] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:13,941 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2025-12-05 20:11:13,941 [main] INFO keys.KeyStorage: Reading public key from /data/metadata/scm/ca/keys/public.pem.
2025-12-05 20:11:13,941 [main] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/ca/keys/private.pem.
2025-12-05 20:11:13,942 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2025-12-05 20:11:13,943 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 2 on primary SCM
2025-12-05 20:11:13,962 [main] INFO server.SCMCertStore: Scm certificate 2 for CN=scm-sub@scm,OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0,O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,SERIALNUMBER=2 is stored
2025-12-05 20:11:13,962 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
2025-12-05 20:11:13,964 [main] INFO server.SCMCertStore: Scm certificate 1 for CN=scm@scm,OU=535d1d97-a9a1-4e29-86bc-16068ee10fe0,O=CID-1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5,SERIALNUMBER=1 is stored
2025-12-05 20:11:13,967 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2025-12-05 20:11:13,978 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-12-05 20:11:13,996 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2025-12-05 20:11:13,997 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2025-12-05 20:11:14,015 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2025-12-05 20:11:14,301 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 20:11:14,305 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-12-05 20:11:14,305 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2025-12-05 20:11:14,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2025-12-05 20:11:14,310 [Socket Reader #2 for port 9861] INFO ipc.Server: Starting Socket Reader #2 for port 9861
2025-12-05 20:11:14,313 [Socket Reader #3 for port 9861] INFO ipc.Server: Starting Socket Reader #3 for port 9861
2025-12-05 20:11:14,316 [Socket Reader #4 for port 9861] INFO ipc.Server: Starting Socket Reader #4 for port 9861
2025-12-05 20:11:14,318 [Socket Reader #5 for port 9861] INFO ipc.Server: Starting Socket Reader #5 for port 9861
2025-12-05 20:11:14,319 [Socket Reader #6 for port 9861] INFO ipc.Server: Starting Socket Reader #6 for port 9861
2025-12-05 20:11:14,320 [Socket Reader #7 for port 9861] INFO ipc.Server: Starting Socket Reader #7 for port 9861
2025-12-05 20:11:14,320 [Socket Reader #8 for port 9861] INFO ipc.Server: Starting Socket Reader #8 for port 9861
2025-12-05 20:11:14,321 [Socket Reader #10 for port 9861] INFO ipc.Server: Starting Socket Reader #10 for port 9861
2025-12-05 20:11:14,321 [Socket Reader #9 for port 9861] INFO ipc.Server: Starting Socket Reader #9 for port 9861
2025-12-05 20:11:14,351 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 20:11:14,354 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-12-05 20:11:14,355 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2025-12-05 20:11:14,355 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2025-12-05 20:11:14,356 [Socket Reader #2 for port 9863] INFO ipc.Server: Starting Socket Reader #2 for port 9863
2025-12-05 20:11:14,356 [Socket Reader #3 for port 9863] INFO ipc.Server: Starting Socket Reader #3 for port 9863
2025-12-05 20:11:14,356 [Socket Reader #4 for port 9863] INFO ipc.Server: Starting Socket Reader #4 for port 9863
2025-12-05 20:11:14,357 [Socket Reader #5 for port 9863] INFO ipc.Server: Starting Socket Reader #5 for port 9863
2025-12-05 20:11:14,357 [Socket Reader #6 for port 9863] INFO ipc.Server: Starting Socket Reader #6 for port 9863
2025-12-05 20:11:14,357 [Socket Reader #7 for port 9863] INFO ipc.Server: Starting Socket Reader #7 for port 9863
2025-12-05 20:11:14,358 [Socket Reader #8 for port 9863] INFO ipc.Server: Starting Socket Reader #8 for port 9863
2025-12-05 20:11:14,358 [Socket Reader #9 for port 9863] INFO ipc.Server: Starting Socket Reader #9 for port 9863
2025-12-05 20:11:14,364 [Socket Reader #10 for port 9863] INFO ipc.Server: Starting Socket Reader #10 for port 9863
2025-12-05 20:11:14,396 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2025-12-05 20:11:14,403 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false, ipcFailOver: false.
2025-12-05 20:11:14,403 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2025-12-05 20:11:14,403 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2025-12-05 20:11:14,404 [Socket Reader #2 for port 9860] INFO ipc.Server: Starting Socket Reader #2 for port 9860
2025-12-05 20:11:14,404 [Socket Reader #3 for port 9860] INFO ipc.Server: Starting Socket Reader #3 for port 9860
2025-12-05 20:11:14,404 [Socket Reader #4 for port 9860] INFO ipc.Server: Starting Socket Reader #4 for port 9860
2025-12-05 20:11:14,404 [Socket Reader #5 for port 9860] INFO ipc.Server: Starting Socket Reader #5 for port 9860
2025-12-05 20:11:14,404 [Socket Reader #6 for port 9860] INFO ipc.Server: Starting Socket Reader #6 for port 9860
2025-12-05 20:11:14,405 [Socket Reader #7 for port 9860] INFO ipc.Server: Starting Socket Reader #7 for port 9860
2025-12-05 20:11:14,405 [Socket Reader #8 for port 9860] INFO ipc.Server: Starting Socket Reader #8 for port 9860
2025-12-05 20:11:14,405 [Socket Reader #9 for port 9860] INFO ipc.Server: Starting Socket Reader #9 for port 9860
2025-12-05 20:11:14,405 [Socket Reader #10 for port 9860] INFO ipc.Server: Starting Socket Reader #10 for port 9860
2025-12-05 20:11:14,449 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2025-12-05 20:11:14,449 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2025-12-05 20:11:14,457 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2025-12-05 20:11:14,461 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2025-12-05 20:11:14,464 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2025-12-05 20:11:14,465 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2025-12-05 20:11:14,467 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-12-05 20:11:14,484 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5/in_use.lock acquired by nodename 7@scm
2025-12-05 20:11:14,493 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=535d1d97-a9a1-4e29-86bc-16068ee10fe0} from /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5/current/raft-meta
2025-12-05 20:11:14,542 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: set configuration conf: {index: 0, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:14,544 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO ha.SCMStateMachine: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: initialize group-D33F52EE50D5
2025-12-05 20:11:14,545 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2025-12-05 20:11:14,555 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2025-12-05 20:11:14,555 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:14,556 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-12-05 20:11:14,557 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2025-12-05 20:11:14,561 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 20:11:14,566 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2025-12-05 20:11:14,567 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-12-05 20:11:14,567 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:14,569 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO util.AwaitToRun: Thread[#103,535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-cacheEviction-AwaitToRun,5,main] started
2025-12-05 20:11:14,573 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5
2025-12-05 20:11:14,573 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-12-05 20:11:14,574 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2025-12-05 20:11:14,576 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-12-05 20:11:14,576 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2025-12-05 20:11:14,576 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2025-12-05 20:11:14,577 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2025-12-05 20:11:14,577 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-12-05 20:11:14,577 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-12-05 20:11:14,578 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2025-12-05 20:11:14,584 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-12-05 20:11:14,585 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2025-12-05 20:11:14,585 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2025-12-05 20:11:14,585 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2025-12-05 20:11:14,607 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: set configuration conf: {index: 0, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:14,608 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5/current/log_inprogress_0
2025-12-05 20:11:14,611 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-12-05 20:11:14,632 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO segmented.BufferedWriteChannel: open log_inprogress_0 (append) at position 69
2025-12-05 20:11:14,634 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: start as a follower, conf=conf: {index: 0, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:14,635 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: changes role from      null to FOLLOWER at term 1 for startAsFollower
2025-12-05 20:11:14,636 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: start 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState
2025-12-05 20:11:14,636 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2025-12-05 20:11:14,637 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2025-12-05 20:11:14,638 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D33F52EE50D5,id=535d1d97-a9a1-4e29-86bc-16068ee10fe0
2025-12-05 20:11:14,638 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO util.JmxRegister: register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-D33F52EE50D5,id=535d1d97-a9a1-4e29-86bc-16068ee10fe0
2025-12-05 20:11:14,639 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-12-05 20:11:14,640 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-12-05 20:11:14,640 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-12-05 20:11:14,640 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-12-05 20:11:14,640 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2025-12-05 20:11:14,641 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2025-12-05 20:11:14,644 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-impl-thread1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: Successfully started.
2025-12-05 20:11:14,645 [main] INFO server.RaftServer: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: start RPC server
2025-12-05 20:11:14,684 [main] INFO server.GrpcService: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: GrpcService started, listening on 9894
2025-12-05 20:11:14,686 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-535d1d97-a9a1-4e29-86bc-16068ee10fe0: Started
2025-12-05 20:11:14,692 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]
2025-12-05 20:11:14,692 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2025-12-05 20:11:14,693 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2025-12-05 20:11:14,694 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2025-12-05 20:11:14,694 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2025-12-05 20:11:14,772 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-12-05 20:11:14,781 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-12-05 20:11:14,781 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2025-12-05 20:11:14,836 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2025-12-05 20:11:14,837 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 20:11:14,837 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2025-12-05 20:11:14,851 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2025-12-05 20:11:14,852 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2025-12-05 20:11:14,852 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 20:11:14,852 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2025-12-05 20:11:14,865 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2025-12-05 20:11:14,866 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 20:11:14,866 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2025-12-05 20:11:14,878 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2025-12-05 20:11:14,878 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2025-12-05 20:11:14,878 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2025-12-05 20:11:14,895 [main] INFO util.log: Logging initialized @4003ms to org.eclipse.jetty.util.log.Slf4jLog
2025-12-05 20:11:14,987 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2025-12-05 20:11:14,996 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2025-12-05 20:11:14,998 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2025-12-05 20:11:14,999 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2025-12-05 20:11:14,999 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2025-12-05 20:11:15,002 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2025-12-05 20:11:15,016 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44997
2025-12-05 20:11:15,038 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /tmp/ozone_http
2025-12-05 20:11:15,039 [main] INFO http.HttpServer2: Jetty bound to port 9876
2025-12-05 20:11:15,041 [main] INFO server.Server: jetty-9.4.57.v20241219; built: 2025-01-08T21:24:30.412Z; git: df524e6b29271c2e09ba9aea83c18dc9db464a31; jvm 21.0.2+13-58
2025-12-05 20:11:15,049 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:11:15,085 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2025-12-05 20:11:15,085 [main] INFO server.session: No SessionScavenger set, using defaults
2025-12-05 20:11:15,087 [main] INFO server.session: node0 Scavenging every 660000ms
2025-12-05 20:11:15,099 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 20:11:15,101 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2792c28{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2025-12-05 20:11:15,102 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44106e25{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-2.0.0.jar!/webapps/static,AVAILABLE}
2025-12-05 20:11:15,240 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.8:44997
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:15,324 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:46599
2025-12-05 20:11:15,351 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:11:15,352 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.19:46599
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:15,538 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
2025-12-05 20:11:15,552 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@44d84313{scm,/,file:///tmp/ozone_http/jetty-0_0_0_0-9876-hdds-server-scm-2_0_0_jar-_-any-13795724369347993028/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-2.0.0.jar!/webapps/scm}
2025-12-05 20:11:15,561 [main] INFO server.AbstractConnector: Started ServerConnector@3835d3fd{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2025-12-05 20:11:15,562 [main] INFO server.Server: Started @4670ms
2025-12-05 20:11:15,565 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2025-12-05 20:11:15,565 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2025-12-05 20:11:15,567 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2025-12-05 20:11:15,737 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:41881
2025-12-05 20:11:15,751 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:40407
2025-12-05 20:11:15,751 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:37823
2025-12-05 20:11:15,775 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:11:15,782 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:11:15,787 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.18:41881
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:15,792 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.17:37823
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:15,796 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:11:15,804 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#6 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.20:40407
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:15,846 [Socket Reader #2 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:38661
2025-12-05 20:11:15,859 [Socket Reader #2 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:11:15,876 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:39259
2025-12-05 20:11:15,892 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:11:15,893 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#0 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.9:39259
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:16,035 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:45757
2025-12-05 20:11:16,054 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:11:16,056 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.7:45757
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:17,182 [Socket Reader #3 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:33503
2025-12-05 20:11:17,194 [Socket Reader #3 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:11:17,262 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.8:44997
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:17,362 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.19:46599
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:17,800 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.18:41881
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:17,815 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.17:37823
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:17,818 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.20:40407
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:17,908 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#1 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.9:39259
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:17,909 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-scm/sub-ca-refreshCACertificates] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
, while invoking $Proxy25.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.9:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 1.
2025-12-05 20:11:18,067 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#8 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.7:45757
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:19,270 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#8 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.8:44997
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:19,365 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#8 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.19:46599
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: SCM Server:535d1d97-a9a1-4e29-86bc-16068ee10fe0(scm) is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:106)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:247)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:83)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18942)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1246)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1169)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:714)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:525)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3198)
2025-12-05 20:11:19,710 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO impl.FollowerState: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5074343329ns, electionTimeout:5072ms
2025-12-05 20:11:19,710 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: shutdown 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState
2025-12-05 20:11:19,710 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2025-12-05 20:11:19,712 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2025-12-05 20:11:19,712 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-FollowerState] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: start 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1
2025-12-05 20:11:19,713 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.LeaderElection: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 1 for conf: {index: 0, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:19,714 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.LeaderElection: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1 PRE_VOTE round 0: result PASSED (term=1)
2025-12-05 20:11:19,717 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.LeaderElection: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for conf: {index: 0, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:19,717 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.LeaderElection: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2025-12-05 20:11:19,717 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: shutdown 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1
2025-12-05 20:11:19,717 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2025-12-05 20:11:19,721 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2025-12-05 20:11:19,723 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 20:11:19,723 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-12-05 20:11:19,726 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2025-12-05 20:11:19,726 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2025-12-05 20:11:19,727 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2025-12-05 20:11:19,730 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2025-12-05 20:11:19,731 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-12-05 20:11:19,731 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-12-05 20:11:19,731 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.log-metadata.enabled = true (default)
2025-12-05 20:11:19,731 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-12-05 20:11:19,732 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-12-05 20:11:19,733 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO impl.RoleInfo: 535d1d97-a9a1-4e29-86bc-16068ee10fe0: start 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderStateImpl
2025-12-05 20:11:19,733 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: set firstElectionSinceStartup to false for becomeLeader
2025-12-05 20:11:19,733 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2025-12-05 20:11:19,733 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2025-12-05 20:11:19,734 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: change Leader from null to 535d1d97-a9a1-4e29-86bc-16068ee10fe0 at term 2 for becomeLeader, leader elected after 6309ms
2025-12-05 20:11:19,738 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2025-12-05 20:11:19,740 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5/current/log_inprogress_0 to /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5/current/log_0-0
2025-12-05 20:11:19,741 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderElection1] INFO server.RaftServer$Division: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5: set configuration conf: {index: 1, cur=peers:[535d1d97-a9a1-4e29-86bc-16068ee10fe0|scm:9894]|listeners:[], old=null}
2025-12-05 20:11:19,742 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_1 at position 0
2025-12-05 20:11:19,748 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/1fe09fa9-ce42-4dc4-92c2-d33f52ee50d5/current/log_inprogress_1
2025-12-05 20:11:19,755 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO server.RaftServer$Division: Leader 535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-LeaderStateImpl is ready since appliedIndex == startIndex == 1
2025-12-05 20:11:19,755 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2025-12-05 20:11:19,755 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2025-12-05 20:11:19,756 [SecretKeyManagerService] INFO symmetric.SecretKeyManager: Initializing SecretKeys.
2025-12-05 20:11:19,756 [SecretKeyManagerService] INFO symmetric.SecretKeyManager: No valid key has been loaded. A new key is generated: SecretKey(id = 57a6a553-2f0d-4ed6-b755-a0f13e62471d, creation at: 2025-12-05T20:11:19.756325925Z, expire at: 2025-12-12T20:11:19.756325925Z)
2025-12-05 20:11:19,756 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:19,756 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed Containers with one replica threshold count 0, with ec n replica threshold count 0.
2025-12-05 20:11:19,757 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2025-12-05 20:11:19,757 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2025-12-05 20:11:19,757 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2025-12-05 20:11:19,758 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2025-12-05 20:11:19,794 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 57a6a553-2f0d-4ed6-b755-a0f13e62471d, creation at: 2025-12-05T20:11:19.756Z, expire at: 2025-12-12T20:11:19.756Z)]
2025-12-05 20:11:19,794 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 57a6a553-2f0d-4ed6-b755-a0f13e62471d, creation at: 2025-12-05T20:11:19.756Z, expire at: 2025-12-12T20:11:19.756Z)
2025-12-05 20:11:19,821 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 45bdca34-c32e-4a8c-8dba-7decdebd7d3b
2025-12-05 20:11:19,821 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: ca7811e8-36b5-4883-a8da-00997f505d61
2025-12-05 20:11:19,833 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 57a6a553-2f0d-4ed6-b755-a0f13e62471d, creation at: 2025-12-05T20:11:19.756Z, expire at: 2025-12-12T20:11:19.756Z)] to file /data/metadata/scm/keys/secret_keys.json
2025-12-05 20:11:19,834 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:19,834 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2025-12-05 20:11:19,834 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2025-12-05 20:11:19,841 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for CertificateId, expected lastId is 0, actual lastId is 2.
2025-12-05 20:11:19,843 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:19,846 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:19,846 [IPC Server handler 1 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 2 to 3.
2025-12-05 20:11:19,879 [IPC Server handler 1 on default port 9961] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:19,900 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:11:19,900 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:11:19,916 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:20,312 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,364 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,364 [IPC Server handler 0 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 3 to 4.
2025-12-05 20:11:20,382 [IPC Server handler 0 on default port 9961] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:20,387 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:11:20,388 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:11:20,402 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:20,478 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,493 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: a670af30-7480-44fd-bb54-3d60af02aa37
2025-12-05 20:11:20,501 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,503 [IPC Server handler 1 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 4 to 5.
2025-12-05 20:11:20,524 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:42307
2025-12-05 20:11:20,526 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2025-12-05 20:11:20,531 [IPC Server handler 1 on default port 9961] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:20,542 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:11:20,542 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:11:20,552 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:20,584 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,600 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc
2025-12-05 20:11:20,600 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:20,601 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:20,604 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:20,604 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:20,605 [535d1d97-a9a1-4e29-86bc-16068ee10fe0-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2025-12-05 20:11:20,606 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: 5c08dd91-2628-47a8-bcf2-c85565c022a6
2025-12-05 20:11:20,607 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,608 [IPC Server handler 1 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 5 to 6.
2025-12-05 20:11:20,622 [IPC Server handler 1 on default port 9961] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:20,627 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:11:20,627 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:11:20,636 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:20,681 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,690 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,691 [IPC Server handler 0 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 6 to 7.
2025-12-05 20:11:20,699 [IPC Server handler 0 on default port 9961] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:20,702 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:11:20,702 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:11:20,708 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:20,732 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:20,739 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:20,739 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:20,742 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:20,742 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:20,744 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:20,744 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:20,796 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:20,805 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:20,828 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:20,828 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:21,034 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:33435
2025-12-05 20:11:21,040 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:11:21,077 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35215
2025-12-05 20:11:21,081 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:11:21,158 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:37887
2025-12-05 20:11:21,162 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:38881
2025-12-05 20:11:21,164 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:11:21,169 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:11:21,274 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 86dc8798-4243-4927-879b-8d01683f1175
2025-12-05 20:11:21,282 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:21,290 [IPC Server handler 1 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 7 to 8.
2025-12-05 20:11:21,350 [IPC Server handler 1 on default port 9961] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:21,367 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:11:21,367 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:11:21,371 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn dn, UUID: 73211515-f5b6-4553-a3c5-f561f12cdaf9
2025-12-05 20:11:21,402 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:21,595 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:21,656 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:21,658 [IPC Server handler 0 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 8 to 9.
2025-12-05 20:11:21,761 [IPC Server handler 0 on default port 9961] INFO keys.KeyStorage: Reading private key from /data/metadata/scm/sub-ca/keys/private.pem.
2025-12-05 20:11:21,779 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2025-12-05 20:11:21,788 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.15, 2.5.29.17, 2.5.29.35, 2.5.29.37, 2.5.29.19, 1.3.6.1.5.5.7.1.12
2025-12-05 20:11:21,824 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2025-12-05 20:11:22,029 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:22,252 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:22,252 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:22,384 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2025-12-05 20:11:22,384 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2025-12-05 20:11:22,925 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:37685
2025-12-05 20:11:22,960 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:11:33,377 [Socket Reader #3 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:35533
2025-12-05 20:11:33,405 [Socket Reader #3 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:11:33,537 [Socket Reader #2 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:37323
2025-12-05 20:11:33,542 [Socket Reader #2 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:11:33,613 [Socket Reader #3 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:37819
2025-12-05 20:11:33,631 [Socket Reader #3 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:11:33,678 [Socket Reader #4 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:38333
2025-12-05 20:11:33,684 [Socket Reader #4 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:11:34,292 [Socket Reader #5 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:46731
2025-12-05 20:11:34,297 [Socket Reader #5 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:11:34,595 [Socket Reader #6 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:33913
2025-12-05 20:11:34,598 [Socket Reader #6 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:11:35,541 [IPC Server handler 14 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ca7811e8-36b5-4883-a8da-00997f505d61
2025-12-05 20:11:35,547 [IPC Server handler 14 on default port 9861] INFO node.SCMNodeManager: Registered datanode: ca7811e8-36b5-4883-a8da-00997f505d61{ip: 172.18.0.17, host: xcompat-datanode-4.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 4, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:11:35,550 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:11:35,551 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 5 required.
2025-12-05 20:11:35,559 [IPC Server handler 16 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/45bdca34-c32e-4a8c-8dba-7decdebd7d3b
2025-12-05 20:11:35,559 [IPC Server handler 16 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 45bdca34-c32e-4a8c-8dba-7decdebd7d3b{ip: 172.18.0.18, host: xcompat-datanode-2.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 3, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:11:35,559 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:11:35,560 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 5 required.
2025-12-05 20:11:35,570 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=21d71045-c130-4c31-9573-c78886c85ae1 to datanode:ca7811e8-36b5-4883-a8da-00997f505d61
2025-12-05 20:11:35,628 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/997ebb83-0b3d-4c5b-b284-b2468e1b1fcc
2025-12-05 20:11:35,630 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc{ip: 172.18.0.7, host: xcompat-datanode-5.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 6, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:11:35,632 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 5 required.
2025-12-05 20:11:35,634 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:35,636 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline{ Id: 21d71045-c130-4c31-9573-c78886c85ae1, Nodes: [ {ca7811e8-36b5-4883-a8da-00997f505d61(xcompat-datanode-4.xcompat_default/172.18.0.17), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:11:35.567663959Z[UTC]}
2025-12-05 20:11:35,637 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ed6502df-5dff-4dd1-a8ae-f9bec65bdb55 to datanode:45bdca34-c32e-4a8c-8dba-7decdebd7d3b
2025-12-05 20:11:35,637 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:11:35,641 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:35,643 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline{ Id: ed6502df-5dff-4dd1-a8ae-f9bec65bdb55, Nodes: [ {45bdca34-c32e-4a8c-8dba-7decdebd7d3b(xcompat-datanode-2.xcompat_default/172.18.0.18), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:11:35.636985943Z[UTC]}
2025-12-05 20:11:35,644 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=be198bdd-07ec-486e-8dca-79acd4397311 to datanode:997ebb83-0b3d-4c5b-b284-b2468e1b1fcc
2025-12-05 20:11:35,653 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:35,653 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline{ Id: be198bdd-07ec-486e-8dca-79acd4397311, Nodes: [ {997ebb83-0b3d-4c5b-b284-b2468e1b1fcc(xcompat-datanode-5.xcompat_default/172.18.0.7), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:11:35.644182615Z[UTC]}
2025-12-05 20:11:35,831 [Socket Reader #4 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42423
2025-12-05 20:11:35,833 [Socket Reader #4 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:11:36,270 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/a670af30-7480-44fd-bb54-3d60af02aa37
2025-12-05 20:11:36,271 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered datanode: a670af30-7480-44fd-bb54-3d60af02aa37{ip: 172.18.0.20, host: xcompat-datanode-1.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 5, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:11:36,272 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 5 required.
2025-12-05 20:11:36,272 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:11:36,274 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cdf06b4f-65e0-4e57-a766-27316717df8a to datanode:a670af30-7480-44fd-bb54-3d60af02aa37
2025-12-05 20:11:36,280 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:36,281 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline{ Id: cdf06b4f-65e0-4e57-a766-27316717df8a, Nodes: [ {a670af30-7480-44fd-bb54-3d60af02aa37(xcompat-datanode-1.xcompat_default/172.18.0.20), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:11:36.274639784Z[UTC]}
2025-12-05 20:11:36,531 [IPC Server handler 14 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/73211515-f5b6-4553-a3c5-f561f12cdaf9
2025-12-05 20:11:36,532 [IPC Server handler 14 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 73211515-f5b6-4553-a3c5-f561f12cdaf9{ip: 172.18.0.19, host: xcompat-datanode-3.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 9, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2025-12-05 20:11:36,532 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:11:36,532 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 5 DataNodes registered, 5 required.
2025-12-05 20:11:36,534 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2025-12-05 20:11:36,534 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2025-12-05 20:11:36,534 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2025-12-05 20:11:36,534 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2025-12-05 20:11:36,535 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e7ab36ec-7ac3-4cbe-bab6-e5c3468cd38d to datanode:73211515-f5b6-4553-a3c5-f561f12cdaf9
2025-12-05 20:11:36,542 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:36,543 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline{ Id: e7ab36ec-7ac3-4cbe-bab6-e5c3468cd38d, Nodes: [ {73211515-f5b6-4553-a3c5-f561f12cdaf9(xcompat-datanode-3.xcompat_default/172.18.0.19), ReplicaIndex: 0},], ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:11:36.535365837Z[UTC]}
2025-12-05 20:11:36,554 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 to datanode:ca7811e8-36b5-4883-a8da-00997f505d61
2025-12-05 20:11:36,556 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 to datanode:997ebb83-0b3d-4c5b-b284-b2468e1b1fcc
2025-12-05 20:11:36,556 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 to datanode:45bdca34-c32e-4a8c-8dba-7decdebd7d3b
2025-12-05 20:11:36,561 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:36,562 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline{ Id: 3ca950fc-a2f6-4c67-9af9-0c44d2f79133, Nodes: [ {ca7811e8-36b5-4883-a8da-00997f505d61(xcompat-datanode-4.xcompat_default/172.18.0.17), ReplicaIndex: 0}, {997ebb83-0b3d-4c5b-b284-b2468e1b1fcc(xcompat-datanode-5.xcompat_default/172.18.0.7), ReplicaIndex: 0}, {45bdca34-c32e-4a8c-8dba-7decdebd7d3b(xcompat-datanode-2.xcompat_default/172.18.0.18), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:11:36.554399127Z[UTC]}
2025-12-05 20:11:37,753 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:43181
2025-12-05 20:11:37,755 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2025-12-05 20:11:37,863 [Socket Reader #4 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:38937
2025-12-05 20:11:37,864 [Socket Reader #4 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:11:38,827 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:38,835 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=be198bdd-07ec-486e-8dca-79acd4397311
2025-12-05 20:11:38,843 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:38,851 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:38,852 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=ed6502df-5dff-4dd1-a8ae-f9bec65bdb55
2025-12-05 20:11:38,853 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:38,861 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:38,862 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=21d71045-c130-4c31-9573-c78886c85ae1
2025-12-05 20:11:38,864 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:38,950 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:38,966 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:38,972 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:39,505 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:39,507 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=cdf06b4f-65e0-4e57-a766-27316717df8a
2025-12-05 20:11:39,509 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:39,891 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2025-12-05 20:11:39,892 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=e7ab36ec-7ac3-4cbe-bab6-e5c3468cd38d
2025-12-05 20:11:39,892 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:43,939 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:44,011 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:44,092 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:44,259 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2025-12-05 20:11:44,264 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2025-12-05 20:11:44,265 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133
2025-12-05 20:11:44,265 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2025-12-05 20:11:44,265 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2025-12-05 20:11:44,265 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2025-12-05 20:11:44,265 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2025-12-05 20:11:44,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2025-12-05 20:11:44,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2025-12-05 20:11:44,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2025-12-05 20:11:44,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO block.SCMBlockDeletingService: notifyStatusChanged:RUNNING
2025-12-05 20:11:44,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2025-12-05 20:11:44,267 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2025-12-05 20:11:44,267 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2025-12-05 20:11:49,247 [Socket Reader #5 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:44441
2025-12-05 20:11:49,248 [Socket Reader #5 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:11:49,255 [IPC Server handler 6 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2025-12-05 20:11:49,265 [535d1d97-a9a1-4e29-86bc-16068ee10fe0@group-D33F52EE50D5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 115816896921600000.
2025-12-05 20:11:49,266 [IPC Server handler 6 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 115816896921600000 to 115816896921601000.
2025-12-05 20:11:50,273 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:35775
2025-12-05 20:11:50,274 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:12:00,696 [Socket Reader #6 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:41525
2025-12-05 20:12:00,698 [Socket Reader #6 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:12:06,212 [Socket Reader #5 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36187
2025-12-05 20:12:06,218 [Socket Reader #5 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:12:11,624 [IPC Server handler 22 on default port 9863] INFO algorithms.SCMContainerPlacementRackScatter: Chosen nodes: [73211515-f5b6-4553-a3c5-f561f12cdaf9(xcompat-datanode-3.xcompat_default/172.18.0.19), a670af30-7480-44fd-bb54-3d60af02aa37(xcompat-datanode-1.xcompat_default/172.18.0.20), 45bdca34-c32e-4a8c-8dba-7decdebd7d3b(xcompat-datanode-2.xcompat_default/172.18.0.18), ca7811e8-36b5-4883-a8da-00997f505d61(xcompat-datanode-4.xcompat_default/172.18.0.17), 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc(xcompat-datanode-5.xcompat_default/172.18.0.7)]. isPolicySatisfied: true.
2025-12-05 20:12:11,635 [IPC Server handler 22 on default port 9863] INFO pipeline.WritableECContainerProvider: Created and opened new pipeline Pipeline{ Id: 94a98573-2ce1-4544-b4e8-c9b2e2396df8, Nodes: [ {73211515-f5b6-4553-a3c5-f561f12cdaf9(xcompat-datanode-3.xcompat_default/172.18.0.19), ReplicaIndex: 1}, {a670af30-7480-44fd-bb54-3d60af02aa37(xcompat-datanode-1.xcompat_default/172.18.0.20), ReplicaIndex: 2}, {45bdca34-c32e-4a8c-8dba-7decdebd7d3b(xcompat-datanode-2.xcompat_default/172.18.0.18), ReplicaIndex: 3}, {ca7811e8-36b5-4883-a8da-00997f505d61(xcompat-datanode-4.xcompat_default/172.18.0.17), ReplicaIndex: 4}, {997ebb83-0b3d-4c5b-b284-b2468e1b1fcc(xcompat-datanode-5.xcompat_default/172.18.0.7), ReplicaIndex: 5},], ReplicationConfig: EC{rs-3-2-1024k}, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:12:11.624876797Z[UTC]}
2025-12-05 20:12:12,651 [Socket Reader #7 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:33181
2025-12-05 20:12:12,654 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:36329
2025-12-05 20:12:12,657 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:12:12,666 [Socket Reader #7 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:12,745 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:40483
2025-12-05 20:12:12,749 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:12:12,750 [Socket Reader #8 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:41969
2025-12-05 20:12:12,762 [Socket Reader #8 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:12,858 [Socket Reader #9 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:34381
2025-12-05 20:12:12,861 [Socket Reader #9 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:12,944 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:33165
2025-12-05 20:12:12,946 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:12:12,995 [Socket Reader #10 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:45997
2025-12-05 20:12:12,999 [Socket Reader #10 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:13,100 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:43581
2025-12-05 20:12:13,101 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2025-12-05 20:12:13,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:35289
2025-12-05 20:12:13,178 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:24,445 [Socket Reader #6 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:42239
2025-12-05 20:12:24,446 [Socket Reader #6 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:12:36,045 [Socket Reader #7 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41697
2025-12-05 20:12:36,047 [Socket Reader #7 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:12:37,933 [IPC Server handler 6 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
2025-12-05 20:12:42,627 [Socket Reader #2 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:44109
2025-12-05 20:12:42,632 [Socket Reader #2 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:42,640 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1, current state: OPEN
2025-12-05 20:12:42,656 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2, current state: OPEN
2025-12-05 20:12:42,720 [Socket Reader #3 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:32801
2025-12-05 20:12:42,726 [Socket Reader #3 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:42,728 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1, current state: CLOSING
2025-12-05 20:12:42,729 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2, current state: CLOSING
2025-12-05 20:12:42,827 [Socket Reader #4 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:40269
2025-12-05 20:12:42,829 [Socket Reader #4 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:42,986 [Socket Reader #5 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:37527
2025-12-05 20:12:42,988 [Socket Reader #5 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:42,990 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1, current state: CLOSING
2025-12-05 20:12:42,991 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2, current state: CLOSING
2025-12-05 20:12:43,161 [Socket Reader #6 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:40899
2025-12-05 20:12:43,163 [Socket Reader #6 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:12:45,895 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:12:45,899 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineManagerImpl: Container #3 closed for pipeline=PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133
2025-12-05 20:12:45,899 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3, current state: CLOSING
2025-12-05 20:12:45,904 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineManagerImpl: Pipeline PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 moved to CLOSED state
2025-12-05 20:12:45,925 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:12:45,956 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:12:55,461 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:13:06,570 [RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 10485760 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2025-12-05 20:13:12,825 [Socket Reader #7 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:39263
2025-12-05 20:13:12,828 [Socket Reader #7 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:13,161 [Socket Reader #8 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:43055
2025-12-05 20:13:13,162 [Socket Reader #8 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:15,891 [Socket Reader #9 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:34783
2025-12-05 20:13:15,893 [Socket Reader #9 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:15,894 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:13:15,963 [Socket Reader #10 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:34401
2025-12-05 20:13:15,967 [Socket Reader #10 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:15,967 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:13:25,469 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:40853
2025-12-05 20:13:25,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:25,471 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:13:36,571 [RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 10485760 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2025-12-05 20:13:37,924 [Socket Reader #7 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:39871
2025-12-05 20:13:37,925 [Socket Reader #7 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:13:42,825 [Socket Reader #2 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:39215
2025-12-05 20:13:42,827 [Socket Reader #2 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:43,160 [Socket Reader #3 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:37287
2025-12-05 20:13:43,162 [Socket Reader #3 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:45,889 [Socket Reader #4 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:45661
2025-12-05 20:13:45,890 [Socket Reader #4 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:45,892 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:13:45,960 [Socket Reader #5 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35217
2025-12-05 20:13:45,961 [Socket Reader #5 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:45,962 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:13:55,467 [Socket Reader #6 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:45335
2025-12-05 20:13:55,469 [Socket Reader #6 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:13:55,471 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:14:06,571 [RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 10485760 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2025-12-05 20:14:12,824 [Socket Reader #7 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:36057
2025-12-05 20:14:12,826 [Socket Reader #7 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:13,157 [Socket Reader #8 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:46881
2025-12-05 20:14:13,159 [Socket Reader #8 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:15,888 [Socket Reader #9 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:38641
2025-12-05 20:14:15,889 [Socket Reader #9 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:15,890 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:14:15,961 [Socket Reader #10 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:32975
2025-12-05 20:14:15,964 [Socket Reader #10 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:15,964 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:14:25,469 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:40031
2025-12-05 20:14:25,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:25,471 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:14:36,572 [RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 10485760 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2025-12-05 20:14:42,827 [Socket Reader #2 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:36689
2025-12-05 20:14:42,828 [Socket Reader #2 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:43,165 [Socket Reader #3 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:40615
2025-12-05 20:14:43,169 [Socket Reader #3 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:45,892 [Socket Reader #4 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:33131
2025-12-05 20:14:45,894 [Socket Reader #4 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:45,896 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:14:45,964 [Socket Reader #5 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:33277
2025-12-05 20:14:45,969 [Socket Reader #5 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:45,970 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:14:55,469 [Socket Reader #6 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:32945
2025-12-05 20:14:55,471 [Socket Reader #6 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:14:55,472 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:15:06,573 [RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 10485760 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2025-12-05 20:15:12,826 [Socket Reader #7 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:42787
2025-12-05 20:15:12,828 [Socket Reader #7 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:13,158 [Socket Reader #8 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:38689
2025-12-05 20:15:13,159 [Socket Reader #8 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:13,837 [FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #2 from CLOSING to CLOSED state, datanode 73211515-f5b6-4553-a3c5-f561f12cdaf9(xcompat-datanode-3.xcompat_default/172.18.0.19) reported CLOSED replica with index 1.
2025-12-05 20:15:15,888 [Socket Reader #9 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:45561
2025-12-05 20:15:15,890 [Socket Reader #9 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:15,892 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:15:15,959 [Socket Reader #10 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:39367
2025-12-05 20:15:15,960 [Socket Reader #10 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:15,961 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:15:16,894 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:15:16,903 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:15:16,975 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:15:16,980 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:15:16,985 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:15:25,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:36613
2025-12-05 20:15:25,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:25,469 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:15:26,472 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:15:26,478 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:15:36,574 [RatisPipelineUtilsThread-0] WARN scm.SCMCommonPlacementPolicy: Unable to find enough nodes that meet the space requirement of 10485760 bytes for metadata and 1073741824 bytes for data in healthy node set. Required 3. Found 2.
2025-12-05 20:15:43,842 [Socket Reader #2 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:39615
2025-12-05 20:15:43,844 [Socket Reader #2 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:44,178 [Socket Reader #3 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:45947
2025-12-05 20:15:44,179 [Socket Reader #3 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:46,909 [Socket Reader #4 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:45337
2025-12-05 20:15:46,915 [Socket Reader #4 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:46,917 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:15:46,992 [Socket Reader #5 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:38161
2025-12-05 20:15:46,995 [Socket Reader #5 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:46,996 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:15:56,486 [Socket Reader #6 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:42819
2025-12-05 20:15:56,488 [Socket Reader #6 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:15:56,489 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:16:06,575 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=20ab9a6a-bbda-4fee-9ac6-ad55ebf923c2 to datanode:45bdca34-c32e-4a8c-8dba-7decdebd7d3b
2025-12-05 20:16:06,575 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=20ab9a6a-bbda-4fee-9ac6-ad55ebf923c2 to datanode:73211515-f5b6-4553-a3c5-f561f12cdaf9
2025-12-05 20:16:06,575 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=20ab9a6a-bbda-4fee-9ac6-ad55ebf923c2 to datanode:ca7811e8-36b5-4883-a8da-00997f505d61
2025-12-05 20:16:06,577 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline{ Id: 20ab9a6a-bbda-4fee-9ac6-ad55ebf923c2, Nodes: [ {45bdca34-c32e-4a8c-8dba-7decdebd7d3b(xcompat-datanode-2.xcompat_default/172.18.0.18), ReplicaIndex: 0}, {73211515-f5b6-4553-a3c5-f561f12cdaf9(xcompat-datanode-3.xcompat_default/172.18.0.19), ReplicaIndex: 0}, {ca7811e8-36b5-4883-a8da-00997f505d61(xcompat-datanode-4.xcompat_default/172.18.0.17), ReplicaIndex: 0},], ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2025-12-05T20:16:06.575210435Z[UTC]}
2025-12-05 20:16:13,750 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2025-12-05 20:16:13,844 [Socket Reader #7 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:36325
2025-12-05 20:16:13,845 [Socket Reader #7 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:14,178 [Socket Reader #8 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:41487
2025-12-05 20:16:14,180 [Socket Reader #8 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:14,857 [Socket Reader #8 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37961
2025-12-05 20:16:14,858 [Socket Reader #8 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:16:15,031 [Socket Reader #9 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:34335
2025-12-05 20:16:15,032 [Socket Reader #9 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:15,033 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:16:15,130 [Socket Reader #10 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:37137
2025-12-05 20:16:15,137 [Socket Reader #10 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:15,139 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:16:16,992 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:45415
2025-12-05 20:16:16,996 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:16,997 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:16:20,055 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=20ab9a6a-bbda-4fee-9ac6-ad55ebf923c2
2025-12-05 20:16:44,181 [Socket Reader #2 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:44085
2025-12-05 20:16:44,183 [Socket Reader #2 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:45,023 [Socket Reader #3 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:46375
2025-12-05 20:16:45,024 [Socket Reader #3 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:45,025 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:16:45,125 [Socket Reader #4 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:33277
2025-12-05 20:16:45,126 [Socket Reader #4 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:45,127 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:16:46,991 [Socket Reader #5 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:44137
2025-12-05 20:16:46,992 [Socket Reader #5 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:16:46,993 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:16:50,052 [Socket Reader #6 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:35711
2025-12-05 20:16:50,054 [Socket Reader #6 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:06,256 [Socket Reader #9 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37265
2025-12-05 20:17:06,257 [Socket Reader #9 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:17:14,177 [Socket Reader #7 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:40061
2025-12-05 20:17:14,179 [Socket Reader #7 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:15,025 [Socket Reader #8 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:34277
2025-12-05 20:17:15,026 [Socket Reader #8 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:15,029 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:17:15,125 [Socket Reader #9 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:43545
2025-12-05 20:17:15,127 [Socket Reader #9 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:15,129 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:17:16,992 [Socket Reader #10 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:36555
2025-12-05 20:17:16,995 [Socket Reader #10 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:16,995 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:17:20,052 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:37721
2025-12-05 20:17:20,053 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:40,674 [Socket Reader #8 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:36425
2025-12-05 20:17:40,675 [Socket Reader #8 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2025-12-05 20:17:41,639 [Socket Reader #2 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.19:37099
2025-12-05 20:17:41,647 [Socket Reader #4 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.17:42831
2025-12-05 20:17:41,648 [Socket Reader #3 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.18:38289
2025-12-05 20:17:41,654 [Socket Reader #4 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:41,654 [Socket Reader #2 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:41,659 [Socket Reader #3 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:41,662 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 45bdca34-c32e-4a8c-8dba-7decdebd7d3b. Reason : ContainerID 3 creation failed
2025-12-05 20:17:41,662 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode ca7811e8-36b5-4883-a8da-00997f505d61. Reason : ContainerID 3 creation failed
2025-12-05 20:17:41,682 [Socket Reader #10 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:34009
2025-12-05 20:17:41,685 [Socket Reader #10 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2025-12-05 20:17:44,189 [Socket Reader #5 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.20:42113
2025-12-05 20:17:44,191 [Socket Reader #5 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:46,996 [Socket Reader #6 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35177
2025-12-05 20:17:46,997 [Socket Reader #6 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2025-12-05 20:17:46,997 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=3ca950fc-a2f6-4c67-9af9-0c44d2f79133 from datanode 997ebb83-0b3d-4c5b-b284-b2468e1b1fcc. Reason : ContainerID 3 creation failed
2025-12-05 20:17:51,059 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.13:35931
2025-12-05 20:17:51,060 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
