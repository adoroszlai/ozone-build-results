Using Docker Compose v2
Executing test compatibility/test.sh
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
WARNING: HADOOP_OPTS has been deprecated by OZONE_OPTS.
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Dn :: Test datanode compatibility                                             
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Dn :: Test datanode compatibility                                     | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-001.xml
==============================================================================
Om :: Test om compatibility                                                   
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Rejects Atomic Key Rewrite                                            | PASS |
------------------------------------------------------------------------------
Om :: Test om compatibility                                           | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-002.xml
==============================================================================
Recon :: Test recon compatibility                                             
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Recon :: Test recon compatibility                                     | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-003.xml
==============================================================================
Scm :: Test scm compatibility                                                 
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Scm :: Test scm compatibility                                         | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-004.xml
==============================================================================
Dn-One-Rocksdb :: Test merge rocksdb in datanode compatibility                
==============================================================================
Create a container and check container schema version                 | PASS |
------------------------------------------------------------------------------
Dn-One-Rocksdb :: Test merge rocksdb in datanode compatibility        | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-005.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/compatibility.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-Tk7Xxy/compatibility.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility.xml'
removed 'compatibility/result/robot-001.xml'
removed 'compatibility/result/robot-002.xml'
removed 'compatibility/result/robot-003.xml'
removed 'compatibility/result/robot-004.xml'
removed 'compatibility/result/robot-005.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility'
renamed 'compatibility/result/dn-audit-e80b505610ed.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/dn-audit-e80b505610ed.log'
renamed 'compatibility/result/docker-compatibility-datanode-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-datanode-1.log'
renamed 'compatibility/result/docker-compatibility-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-om-1.log'
renamed 'compatibility/result/docker-compatibility-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-recon-1.log'
renamed 'compatibility/result/docker-compatibility-s3g-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-s3g-1.log'
renamed 'compatibility/result/docker-compatibility-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-scm-1.log'
renamed 'compatibility/result/om-audit-543c39d16c0e.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/om-audit-543c39d16c0e.log'
renamed 'compatibility/result/om-sys-audit-543c39d16c0e.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/om-sys-audit-543c39d16c0e.log'
renamed 'compatibility/result/s3g-audit-76bf165b558a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/s3g-audit-76bf165b558a.log'
renamed 'compatibility/result/scm-audit-5c944d8f841e.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/compatibility/scm-audit-5c944d8f841e.log'
Executing test ozone-csi/test.sh
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Csi :: Smoketest Ozone CSI service                                            
==============================================================================
Check if CSI server is started                                        | PASS |
------------------------------------------------------------------------------
Test CSI identity service                                             | PASS |
------------------------------------------------------------------------------
Csi :: Smoketest Ozone CSI service                                    | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-csi/result/robot-001.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/ozone-csi.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-fvBk1x/ozone-csi.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi.xml'
removed 'ozone-csi/result/robot-001.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi'
renamed 'ozone-csi/result/dn-audit-17612b5099ed.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-17612b5099ed.log'
renamed 'ozone-csi/result/dn-audit-4e9d8d9761ef.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-4e9d8d9761ef.log'
renamed 'ozone-csi/result/dn-audit-ea1d81defdda.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-ea1d81defdda.log'
renamed 'ozone-csi/result/docker-ozone-csi-csi-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-csi-1.log'
renamed 'ozone-csi/result/docker-ozone-csi-datanode-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-datanode-1.log'
renamed 'ozone-csi/result/docker-ozone-csi-datanode-2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-datanode-2.log'
renamed 'ozone-csi/result/docker-ozone-csi-datanode-3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-datanode-3.log'
renamed 'ozone-csi/result/docker-ozone-csi-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-om-1.log'
renamed 'ozone-csi/result/docker-ozone-csi-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-scm-1.log'
renamed 'ozone-csi/result/om-audit-03fc3098b6f7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/om-audit-03fc3098b6f7.log'
renamed 'ozone-csi/result/om-sys-audit-03fc3098b6f7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/om-sys-audit-03fc3098b6f7.log'
renamed 'ozone-csi/result/scm-audit-3768730bb720.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-csi/scm-audit-3768730bb720.log'
Executing test ozone-om-prepare/test.sh
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is out of safe mode.
Could not determine or connect to OM Leader.
Waiting for OM leader for service omservice
SECONDS: 11
Found OM leader for service omservice: om3 : LEADER (om3)
Replaced OM order with om3,om2,om1 in ozone-om-prepare-dn1-1
Replaced OM order with om3,om2,om1 in ozone-om-prepare-dn2-1
Replaced OM order with om3,om2,om1 in ozone-om-prepare-dn3-1
Replaced OM order with om3,om2,om1 in ozone-om-prepare-om1-1
Replaced OM order with om3,om2,om1 in ozone-om-prepare-om2-1
Replaced OM order with om3,om2,om1 in ozone-om-prepare-om3-1
Replaced OM order with om3,om2,om1 in ozone-om-prepare-scm-1
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | PASS |
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-001.xml
==============================================================================
Om-Cancel-Prepare :: Smoke test for ozone manager cancel prepare              
==============================================================================
Cancel Ozone Manager Prepare                                          | PASS |
------------------------------------------------------------------------------
Test write operations                                                 | PASS |
------------------------------------------------------------------------------
Om-Cancel-Prepare :: Smoke test for ozone manager cancel prepare      | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-002.xml
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | PASS |
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-003.xml
==============================================================================
Om-Prepared :: Smoke test to test that OMs are prepared in an OM HA cluster.  
==============================================================================
Test create volume fails                                              | PASS |
------------------------------------------------------------------------------
Test list volumes succeeds                                            | PASS |
------------------------------------------------------------------------------
Om-Prepared :: Smoke test to test that OMs are prepared in an OM H... | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-004.xml
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is out of safe mode.
Found OM leader for service omservice: om1 : LEADER (om1)
Replaced OM order with om1,om3,om2 in ozone-om-prepare-dn1-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-dn2-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-dn3-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-om1-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-om2-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-om3-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-scm-1
==============================================================================
Om-Prepared :: Smoke test to test that OMs are prepared in an OM HA cluster.  
==============================================================================
Test create volume fails                                              | PASS |
------------------------------------------------------------------------------
Test list volumes succeeds                                            | PASS |
------------------------------------------------------------------------------
Om-Prepared :: Smoke test to test that OMs are prepared in an OM H... | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-005.xml
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is out of safe mode.
Found OM leader for service omservice: om1 : LEADER (om1)
Replaced OM order with om1,om3,om2 in ozone-om-prepare-dn1-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-dn2-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-dn3-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-om1-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-om2-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-om3-1
Replaced OM order with om1,om3,om2 in ozone-om-prepare-scm-1
==============================================================================
Loaddata :: Smoketest ozone cluster startup                                   
==============================================================================
Create a volume, bucket and key                                       | PASS |
------------------------------------------------------------------------------
Loaddata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-006.xml
==============================================================================
Readdata :: Smoketest ozone cluster startup                                   
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
Readdata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-007.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/ozone-om-prepare.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-ouvNfj/ozone-om-prepare.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare.xml'
removed 'ozone-om-prepare/result/robot-001.xml'
removed 'ozone-om-prepare/result/robot-002.xml'
removed 'ozone-om-prepare/result/robot-003.xml'
removed 'ozone-om-prepare/result/robot-004.xml'
removed 'ozone-om-prepare/result/robot-005.xml'
removed 'ozone-om-prepare/result/robot-006.xml'
removed 'ozone-om-prepare/result/robot-007.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare'
renamed 'ozone-om-prepare/result/dn-audit-dn1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-dn1.log'
renamed 'ozone-om-prepare/result/dn-audit-dn2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-dn2.log'
renamed 'ozone-om-prepare/result/dn-audit-dn3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-dn3.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-dn1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-dn1-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-dn2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-dn2-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-dn3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-dn3-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-om1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-om1-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-om2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-om2-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-om3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-om3-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-scm-1.log'
renamed 'ozone-om-prepare/result/om-audit-0cfd6d532e13.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-0cfd6d532e13.log'
renamed 'ozone-om-prepare/result/om-audit-16565d5f02c5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-16565d5f02c5.log'
renamed 'ozone-om-prepare/result/om-audit-33e83bc6c8a5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-33e83bc6c8a5.log'
renamed 'ozone-om-prepare/result/om-audit-3efa882464fa.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-3efa882464fa.log'
renamed 'ozone-om-prepare/result/om-audit-6f6034b6370a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-6f6034b6370a.log'
renamed 'ozone-om-prepare/result/om-audit-a0a9681d8c10.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-a0a9681d8c10.log'
renamed 'ozone-om-prepare/result/om-audit-a7a7b9c65ab9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-a7a7b9c65ab9.log'
renamed 'ozone-om-prepare/result/om-audit-b3029d063e6f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-b3029d063e6f.log'
renamed 'ozone-om-prepare/result/om-audit-cc6a09886e7d.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-cc6a09886e7d.log'
renamed 'ozone-om-prepare/result/om-sys-audit-0cfd6d532e13.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-0cfd6d532e13.log'
renamed 'ozone-om-prepare/result/om-sys-audit-16565d5f02c5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-16565d5f02c5.log'
renamed 'ozone-om-prepare/result/om-sys-audit-33e83bc6c8a5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-33e83bc6c8a5.log'
renamed 'ozone-om-prepare/result/om-sys-audit-3efa882464fa.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-3efa882464fa.log'
renamed 'ozone-om-prepare/result/om-sys-audit-6f6034b6370a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-6f6034b6370a.log'
renamed 'ozone-om-prepare/result/om-sys-audit-a0a9681d8c10.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-a0a9681d8c10.log'
renamed 'ozone-om-prepare/result/om-sys-audit-a7a7b9c65ab9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-a7a7b9c65ab9.log'
renamed 'ozone-om-prepare/result/om-sys-audit-b3029d063e6f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-b3029d063e6f.log'
renamed 'ozone-om-prepare/result/om-sys-audit-cc6a09886e7d.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-cc6a09886e7d.log'
renamed 'ozone-om-prepare/result/scm-audit-442cadace8a0.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-442cadace8a0.log'
renamed 'ozone-om-prepare/result/scm-audit-a71c79444c14.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-a71c79444c14.log'
renamed 'ozone-om-prepare/result/scm-audit-b0bb0d2e3bbb.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-b0bb0d2e3bbb.log'
Executing test ozone-topology/test.sh
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 227
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 226
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Basic :: Smoketest ozone cluster startup                                      
==============================================================================
Check webui static resources                                          | PASS |
------------------------------------------------------------------------------
Basic Freon smoketest                                                 | PASS |
------------------------------------------------------------------------------
Basic :: Smoketest ozone cluster startup                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-001.xml
==============================================================================
Cli :: Smoketest ozone cluster startup                                        
==============================================================================
Run printTopology                                                     | PASS |
------------------------------------------------------------------------------
Run printTopology -o                                                  | PASS |
------------------------------------------------------------------------------
Run printTopology --operational-state IN_SERVICE                      | PASS |
------------------------------------------------------------------------------
Run printTopology --node-state HEALTHY                                | PASS |
------------------------------------------------------------------------------
Cli :: Smoketest ozone cluster startup                                | PASS |
4 tests, 4 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-002.xml
==============================================================================
Recon                                                                         
==============================================================================
Recon.Recon-Api :: Smoke test to start cluster with docker-compose environm...
==============================================================================
Check if Recon picks up OM data                                       | PASS |
------------------------------------------------------------------------------
Check if Recon picks up DN heartbeats                                 | PASS |
------------------------------------------------------------------------------
Check if Recon Web UI is up                                           | PASS |
------------------------------------------------------------------------------
Check web UI access                                                   | PASS |
------------------------------------------------------------------------------
Check admin only api access                                           | PASS |
------------------------------------------------------------------------------
Check unhealthy, (admin) api access                                   | PASS |
------------------------------------------------------------------------------
Check normal api access                                               | PASS |
------------------------------------------------------------------------------
Recon.Recon-Api :: Smoke test to start cluster with docker-compose... | PASS |
7 tests, 7 passed, 0 failed
==============================================================================
Recon.Recon-Nssummary :: Smoke test for Recon Namespace Summary Endpoint fo...
==============================================================================
Check volume creation                                                 | PASS |
------------------------------------------------------------------------------
Check bucket creation                                                 | PASS |
------------------------------------------------------------------------------
Check keys creation                                                   | PASS |
------------------------------------------------------------------------------
Check Summary api access                                              | PASS |
------------------------------------------------------------------------------
Check Disk Usage api access                                           | PASS |
------------------------------------------------------------------------------
Check Quota Usage api access                                          | PASS |
------------------------------------------------------------------------------
Check File Size Distribution api access                               | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Root                                    | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Volume                                  | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Bucket                                  | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Key                                     | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Directory                               | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Disk Usage                                      | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Volume Quota Usage                              | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Bucket Quota Usage                              | PASS |
------------------------------------------------------------------------------
Check Recon Namespace File Size Distribution Root                     | PASS |
------------------------------------------------------------------------------
Recon.Recon-Nssummary :: Smoke test for Recon Namespace Summary En... | PASS |
16 tests, 16 passed, 0 failed
==============================================================================
Recon.Recon-Taskstatus :: Test to validate the recon task status API works ...
==============================================================================
Prepopulate Data and Trigger OM DB Sync :: Use Freon to prepopulat... | PASS |
------------------------------------------------------------------------------
Validate Task Status After Sync :: Validate that task status is up... | PASS |
------------------------------------------------------------------------------
Validate Stats for Specific Task :: Validate response for a specif... | PASS |
------------------------------------------------------------------------------
Validate All Tasks Updated After Sync :: Ensure all tasks have bee... | PASS |
------------------------------------------------------------------------------
Validate Sequence number is updated after sync                        | PASS |
------------------------------------------------------------------------------
Recon.Recon-Taskstatus :: Test to validate the recon task status A... | PASS |
5 tests, 5 passed, 0 failed
==============================================================================
Recon                                                                 | PASS |
28 tests, 28 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-003.xml
==============================================================================
Loaddata :: Smoketest ozone cluster startup                                   
==============================================================================
Create a volume, bucket and key                                       | PASS |
------------------------------------------------------------------------------
Loaddata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-004.xml
==============================================================================
readdata-first-half :: Smoketest ozone cluster startup                        
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
readdata-first-half :: Smoketest ozone cluster startup                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-005.xml
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is available on datanode_1
Port 9858 is not available on datanode_2 yet
Port 9858 is available on datanode_2
Port 9858 is available on datanode_3
==============================================================================
readdata-second-half :: Smoketest ozone cluster startup                       
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
readdata-second-half :: Smoketest ozone cluster startup               | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-006.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/ozone-topology.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-aHnfIY/ozone-topology.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology.xml'
removed 'ozone-topology/result/robot-001.xml'
removed 'ozone-topology/result/robot-002.xml'
removed 'ozone-topology/result/robot-003.xml'
removed 'ozone-topology/result/robot-004.xml'
removed 'ozone-topology/result/robot-005.xml'
removed 'ozone-topology/result/robot-006.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology'
renamed 'ozone-topology/result/dn-audit-1ae39c071f2d.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-1ae39c071f2d.log'
renamed 'ozone-topology/result/dn-audit-a7817bb4d3ee.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-a7817bb4d3ee.log'
renamed 'ozone-topology/result/dn-audit-c742082d9091.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-c742082d9091.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_1-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_2-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_3-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_4-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_4-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_5-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_5-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_6-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_6-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-om-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-recon-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-scm-1.log'
renamed 'ozone-topology/result/om-audit-f5d96460edc9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/om-audit-f5d96460edc9.log'
renamed 'ozone-topology/result/om-sys-audit-f5d96460edc9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/om-sys-audit-f5d96460edc9.log'
renamed 'ozone-topology/result/scm-audit-a6f94b03484b.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozone-topology/scm-audit-a6f94b03484b.log'
Executing test ozonescripts/test.sh
Using Docker Compose v2
Port 22 is available on scm
Port 22 is available on om
Port 22 is available on datanode
No OM HA service, no need to wait
Using Docker Compose v2
+ docker-compose ps
+ docker compose --progress quiet ps
+ grep datanode
+ awk '{print $1}'
+ xargs -n1 docker inspect --format '{{ .Config.Hostname }}'
+ docker-compose ps
+ docker compose --progress quiet ps
+ grep ozonescripts
+ awk '{print $1}'
+ xargs -I CONTAINER -n1 docker exec CONTAINER cp /opt/hadoop/etc/hadoop/workers /etc/hadoop/workers
+ docker-compose exec -T scm /opt/hadoop/bin/ozone scm --init
+ docker compose --progress quiet exec -T scm /opt/hadoop/bin/ozone scm --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2025-10-20 07:58:34,097 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:        host = 027808e30467/172.18.0.3
STARTUP_MSG:     version = 2.1.0-SNAPSHOT
STARTUP_MSG:       build = https://github.com/apache/ozone/819e9cf088ce698ce347be3ffd19249e0399e806
STARTUP_MSG:        java = 21.0.2
STARTUP_MSG:        args = [--init]
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.2.jar:/opt/hadoop/share/ozone/lib/guava-33.5.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.3.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jspecify-1.0.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.29.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-3.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.18.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.7.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/commons-collections4-4.4.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.27.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.18.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.18.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.4.2.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-10.4.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_25-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.4.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.8.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.11.1.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.5.4.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.12.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.13.1.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.13.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.55.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-classes-epoll-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.81.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-3.6.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.10.0.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.11.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentelemetry-api-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-context-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-common-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-otlp-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-metrics-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-logs-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-otlp-common-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-common-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-sender-okhttp-1.54.1.jar:/opt/hadoop/share/ozone/lib/okhttp-jvm-5.1.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.15.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.25.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-extension-autoconfigure-spi-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-common-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-trace-1.54.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.2.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.2.0.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/hdds-config-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.4.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.25.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.7-5.jar:/opt/hadoop/share/ozone/lib/apache-log4j-extras-1.2.17.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.26.jar:/opt/hadoop/share/ozone/lib/jnr-constants-0.10.4.jar:/opt/hadoop/share/ozone/lib/jnr-posix-3.1.20.jar:/opt/hadoop/share/ozone/lib/jnr-ffi-2.2.17.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13-native.jar:/opt/hadoop/share/ozone/lib/asm-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-commons-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-analysis-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-tree-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-util-9.7.1.jar:/opt/hadoop/share/ozone/lib/jnr-a64asm-1.0.0.jar:/opt/hadoop/share/ozone/lib/jnr-x86asm-1.0.2.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.6.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.71.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.47.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.47.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.47.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.47.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.10.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.30.2-GA.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.25.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.8.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.9.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.81.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.81.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.17.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web
STARTUP_MSG:        conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachine.write.wait.interval=10m, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=20000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.checksum.lock.stripes=127, hdds.datanode.container.client.cache.size=100, hdds.datanode.container.client.cache.stale.threshold=10000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.delete.container.timeout=60s, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.read.threadpool=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.auto-compaction-small-sst-file.interval.minutes=120, hdds.datanode.rocksdb.auto-compaction-small-sst-file.threads=1, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.choosing.policy=org.apache.hadoop.ozone.container.common.volume.CapacityVolumeChoosingPolicy, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.volume.min.free.space.percent=0.02, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.initial-interval=2s, hdds.heartbeat.interval=30s, hdds.heartbeat.recon.initial-interval=60s, hdds.heartbeat.recon.interval=60s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=500000, hdds.scm.block.deletion.txn.dn.commit.map.limit=5000000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.event.timeout=12m, hdds.scm.replication.event.timeout.datanode.offset=6m, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=9d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.hbase.enhancements.allowed=false, ozone.http.basedir=/tmp/ozone_http, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=50000, ozone.key.preallocation.max.blocks=64, ozone.ksm.address=ksm, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.compaction.service.columnfamilies=keyTable,fileTable,directoryTable,deletedTable,deletedDirectoryTable,multipartInfoTable, ozone.om.compaction.service.enabled=false, ozone.om.compaction.service.run.interval=6h, ozone.om.compaction.service.timeout=10m, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.edekcacheloader.initial.delay.ms=3000, ozone.om.edekcacheloader.interval.ms=1000, ozone.om.edekcacheloader.max-retries=10, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=10000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.hierarchical.resource.locks.hard.limit=10000, ozone.om.hierarchical.resource.locks.soft.limit=1024, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=64MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.pending.write.byte-limit=64MB, ozone.om.ratis.server.pending.write.element-limit=4096, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.s3.grpc.server_enabled=true, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compact.non.snapshot.diff.tables=false, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=10m, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.prune.compaction.backup.batch.size=2000, ozone.om.snapshot.rocksdb.metrics.enabled=false, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.volume.listall.allowed=true, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.event.buffer.capacity=20000, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=5s, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.https-address=0.0.0.0:9879, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.list.max.keys.limit=1000, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.s3g.webadmin.https-address=0.0.0.0:19879, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.per.dn.distribution.factor=8, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=60s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=64MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=1, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.defrag.limit.per.task=1, ozone.snapshot.defrag.service.interval=-1, ozone.snapshot.defrag.service.timeout=300s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2025-10-20 07:58:34,130 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [SIGHUP, SIGINT, SIGTERM]
2025-10-20 07:58:34,163 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-10-20 07:58:34,313 [main] INFO reflections.Reflections: Reflections took 134 ms to scan 3 urls, producing 131 keys and 298 values
2025-10-20 07:58:34,384 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-10-20 07:58:34,384 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-10-20 07:58:34,752 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-10-20 07:58:34,755 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-10-20 07:58:34,755 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-10-20 07:58:34,793 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-10-20 07:58:34,818 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2025-10-20 07:58:34,870 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-10-20 07:58:34,871 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2025-10-20 07:58:34,871 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-10-20 07:58:34,871 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2025-10-20 07:58:34,871 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2025-10-20 07:58:34,872 [main] INFO server.GrpcServicesImpl: raft.grpc.message.size.max = 34603008 (custom)
2025-10-20 07:58:34,872 [main] INFO server.GrpcServicesImpl: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-10-20 07:58:34,873 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-10-20 07:58:34,876 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2025-10-20 07:58:34,877 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-10-20 07:58:34,879 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-10-20 07:58:34,880 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-10-20 07:58:35,002 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2025-10-20 07:58:35,004 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-10-20 07:58:35,004 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2025-10-20 07:58:35,004 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-10-20 07:58:35,008 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-10-20 07:58:35,009 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2025-10-20 07:58:35,009 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2025-10-20 07:58:35,015 [main] INFO server.RaftServer: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: addNew group-06B4BFDE0B9A:[76ce0ce1-2835-44a7-ba94-f68a8b83539c|027808e30467:9894] returns group-06B4BFDE0B9A:java.util.concurrent.CompletableFuture@31c2affc[Not completed]
2025-10-20 07:58:35,038 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: new RaftServerImpl for group-06B4BFDE0B9A:[76ce0ce1-2835-44a7-ba94-f68a8b83539c|027808e30467:9894] with SCMStateMachine:uninitialized
2025-10-20 07:58:35,040 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-10-20 07:58:35,040 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2025-10-20 07:58:35,040 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2025-10-20 07:58:35,040 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-10-20 07:58:35,041 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2025-10-20 07:58:35,046 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: ConfigurationManager, init=conf: {index: -1, cur=peers:[76ce0ce1-2835-44a7-ba94-f68a8b83539c|027808e30467:9894]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-10-20 07:58:35,050 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2025-10-20 07:58:35,053 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2025-10-20 07:58:35,055 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2025-10-20 07:58:35,056 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-10-20 07:58:35,066 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2025-10-20 07:58:35,067 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-10-20 07:58:35,193 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-10-20 07:58:35,194 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2025-10-20 07:58:35,194 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2025-10-20 07:58:35,194 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2025-10-20 07:58:35,195 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2025-10-20 07:58:35,198 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2025-10-20 07:58:35,199 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2025-10-20 07:58:35,205 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/fb0a19ef-014d-49ed-a10a-06b4bfde0b9a does not exist. Creating ...
2025-10-20 07:58:35,209 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/fb0a19ef-014d-49ed-a10a-06b4bfde0b9a/in_use.lock acquired by nodename 38@027808e30467
2025-10-20 07:58:35,212 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/fb0a19ef-014d-49ed-a10a-06b4bfde0b9a has been successfully formatted.
2025-10-20 07:58:35,213 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO ha.SCMStateMachine: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: initialize group-06B4BFDE0B9A
2025-10-20 07:58:35,214 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2025-10-20 07:58:35,220 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2025-10-20 07:58:35,220 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-10-20 07:58:35,221 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-10-20 07:58:35,221 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2025-10-20 07:58:35,223 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 67108864 (custom)
2025-10-20 07:58:35,226 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2025-10-20 07:58:35,226 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-10-20 07:58:35,226 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-10-20 07:58:35,228 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO util.AwaitToRun: Thread[#34,76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-cacheEviction-AwaitToRun,5,main] started
2025-10-20 07:58:35,231 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/fb0a19ef-014d-49ed-a10a-06b4bfde0b9a
2025-10-20 07:58:35,232 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-10-20 07:58:35,232 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2025-10-20 07:58:35,233 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 67108864 (custom)
2025-10-20 07:58:35,234 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2025-10-20 07:58:35,234 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2025-10-20 07:58:35,234 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2025-10-20 07:58:35,235 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-10-20 07:58:35,235 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-10-20 07:58:35,237 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2025-10-20 07:58:35,244 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-10-20 07:58:35,244 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2025-10-20 07:58:35,245 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2025-10-20 07:58:35,245 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2025-10-20 07:58:35,250 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-10-20 07:58:35,250 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-10-20 07:58:35,252 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: start as a follower, conf=conf: {index: -1, cur=peers:[76ce0ce1-2835-44a7-ba94-f68a8b83539c|027808e30467:9894]|listeners:[], old=null}
2025-10-20 07:58:35,252 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-10-20 07:58:35,253 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO impl.RoleInfo: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: start 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState
2025-10-20 07:58:35,254 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2025-10-20 07:58:35,255 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2025-10-20 07:58:35,256 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-06B4BFDE0B9A,id=76ce0ce1-2835-44a7-ba94-f68a8b83539c
2025-10-20 07:58:35,256 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO util.JmxRegister: register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-06B4BFDE0B9A,id=76ce0ce1-2835-44a7-ba94-f68a8b83539c
2025-10-20 07:58:35,258 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-10-20 07:58:35,258 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-10-20 07:58:35,258 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-10-20 07:58:35,258 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-10-20 07:58:35,259 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2025-10-20 07:58:35,260 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2025-10-20 07:58:35,262 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: Successfully started.
2025-10-20 07:58:35,262 [main] INFO server.RaftServer: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: start RPC server
2025-10-20 07:58:35,293 [main] INFO server.GrpcServicesImpl: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: GrpcServicesImpl started, listening on 9894
2025-10-20 07:58:35,298 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-76ce0ce1-2835-44a7-ba94-f68a8b83539c: Started
2025-10-20 07:58:40,400 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState] INFO impl.FollowerState: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5147049464ns, electionTimeout:5144ms
2025-10-20 07:58:40,401 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState] INFO impl.RoleInfo: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: shutdown 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState
2025-10-20 07:58:40,401 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-10-20 07:58:40,403 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2025-10-20 07:58:40,403 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-FollowerState] INFO impl.RoleInfo: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: start 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1
2025-10-20 07:58:40,408 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO impl.LeaderElection: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[76ce0ce1-2835-44a7-ba94-f68a8b83539c|027808e30467:9894]|listeners:[], old=null}
2025-10-20 07:58:40,408 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO impl.LeaderElection: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2025-10-20 07:58:40,412 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO impl.LeaderElection: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[76ce0ce1-2835-44a7-ba94-f68a8b83539c|027808e30467:9894]|listeners:[], old=null}
2025-10-20 07:58:40,412 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO impl.LeaderElection: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2025-10-20 07:58:40,412 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO impl.RoleInfo: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: shutdown 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1
2025-10-20 07:58:40,413 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-10-20 07:58:40,416 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2025-10-20 07:58:40,417 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.timeout = 15600ms (fallback to raft.server.rpc.timeout.max)
2025-10-20 07:58:40,419 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-10-20 07:58:40,420 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-10-20 07:58:40,422 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2025-10-20 07:58:40,422 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2025-10-20 07:58:40,423 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2025-10-20 07:58:40,430 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2025-10-20 07:58:40,432 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-10-20 07:58:40,432 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.log-metadata.enabled = false (custom)
2025-10-20 07:58:40,432 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-10-20 07:58:40,434 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO impl.RoleInfo: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: start 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderStateImpl
2025-10-20 07:58:40,434 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: set firstElectionSinceStartup to false for becomeLeader
2025-10-20 07:58:40,435 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: change Leader from null to 76ce0ce1-2835-44a7-ba94-f68a8b83539c at term 1 for becomeLeader, leader elected after 5384ms
2025-10-20 07:58:40,453 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-SegmentedRaftLogWorker: Starting segment from index:0
2025-10-20 07:58:40,470 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderElection1] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: set configuration conf: {index: 0, cur=peers:[76ce0ce1-2835-44a7-ba94-f68a8b83539c|027808e30467:9894]|listeners:[], old=null}
2025-10-20 07:58:40,476 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2025-10-20 07:58:40,482 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/fb0a19ef-014d-49ed-a10a-06b4bfde0b9a/current/log_inprogress_0
2025-10-20 07:58:40,493 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-StateMachineUpdater] INFO server.RaftServer$Division: Leader 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-10-20 07:58:41,299 [main] INFO server.RaftServer: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: close
2025-10-20 07:58:41,300 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO server.RaftServer$Division: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A: shutdown
2025-10-20 07:58:41,300 [main] INFO server.GrpcServicesImpl: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: shutdown server GrpcServerProtocolService now
2025-10-20 07:58:41,300 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-06B4BFDE0B9A,id=76ce0ce1-2835-44a7-ba94-f68a8b83539c
2025-10-20 07:58:41,300 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO impl.RoleInfo: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: shutdown 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-LeaderStateImpl
2025-10-20 07:58:41,303 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO impl.PendingRequests: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-PendingRequests: sendNotLeaderResponses
2025-10-20 07:58:41,305 [main] INFO server.GrpcServicesImpl: 76ce0ce1-2835-44a7-ba94-f68a8b83539c: shutdown server GrpcServerProtocolService successfully
2025-10-20 07:58:41,306 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO impl.StateMachineUpdater: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-StateMachineUpdater: set stopIndex = 0
2025-10-20 07:58:41,307 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-StateMachineUpdater] INFO impl.StateMachineUpdater: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-StateMachineUpdater: Took a snapshot at index 0
2025-10-20 07:58:41,307 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-StateMachineUpdater] INFO impl.StateMachineUpdater: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-10-20 07:58:41,308 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-StateMachineUpdater] INFO impl.StateMachineUpdater: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:1, i:0)
2025-10-20 07:58:41,309 [76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-cacheEviction-AwaitToRun] INFO util.AwaitToRun: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-10-20 07:58:41,488 [76ce0ce1-2835-44a7-ba94-f68a8b83539c-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 76ce0ce1-2835-44a7-ba94-f68a8b83539c@group-06B4BFDE0B9A-SegmentedRaftLogWorker close()
2025-10-20 07:58:41,493 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-76ce0ce1-2835-44a7-ba94-f68a8b83539c: Stopped
2025-10-20 07:58:41,496 [main] INFO server.StorageContainerManager: Enabled Ratis!
2025-10-20 07:58:41,496 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-fb0a19ef-014d-49ed-a10a-06b4bfde0b9a; layoutVersion=9; scmId=76ce0ce1-2835-44a7-ba94-f68a8b83539c
2025-10-20 07:58:41,498 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at 027808e30467/172.18.0.3
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
+ docker compose --progress quiet exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
9b2f2192cec7: Warning: Permanently added '9b2f2192cec7' (ED25519) to the list of known hosts.
9b2f2192cec7: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om' (ED25519) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm' (ED25519) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
+ sleep 10
+ docker-compose exec -T om /opt/hadoop/bin/ozone om --init
+ docker compose --progress quiet exec -T om /opt/hadoop/bin/ozone om --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2025-10-20 07:59:03,050 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting OzoneManager
STARTUP_MSG:        host = 3164b0582609/172.18.0.2
STARTUP_MSG:     version = 2.1.0-SNAPSHOT
STARTUP_MSG:       build = https://github.com/apache/ozone/819e9cf088ce698ce347be3ffd19249e0399e806
STARTUP_MSG:        java = 21.0.2
STARTUP_MSG:        args = [--init]
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.2.jar:/opt/hadoop/share/ozone/lib/guava-33.5.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.3.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jspecify-1.0.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.29.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-3.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.18.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.18.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.7.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.71.0.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.71.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.24.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.71.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.71.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.27.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/grpc-util-1.71.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.71.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.27.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.18.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.12.1.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.4.2.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-10.4.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_25-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.4.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.8.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.11.1.jar:/opt/hadoop/share/ozone/lib/commons-collections4-4.4.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.5.4.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.12.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.13.1.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.13.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.55.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-classes-epoll-4.1.119.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.81.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-3.6.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.4.2.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.10.0.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.11.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-2.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentelemetry-api-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-context-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-common-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-otlp-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-metrics-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-logs-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-otlp-common-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-common-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-exporter-sender-okhttp-1.54.1.jar:/opt/hadoop/share/ozone/lib/okhttp-jvm-5.1.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.15.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.25.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-extension-autoconfigure-spi-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-common-1.54.1.jar:/opt/hadoop/share/ozone/lib/opentelemetry-sdk-trace-1.54.1.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.81.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.81.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.2.0.jar:/opt/hadoop/share/ozone/lib/jcl-over-slf4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/hdds-config-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.26.jar:/opt/hadoop/share/ozone/lib/jnr-constants-0.10.4.jar:/opt/hadoop/share/ozone/lib/jnr-posix-3.1.20.jar:/opt/hadoop/share/ozone/lib/jnr-ffi-2.2.17.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13-native.jar:/opt/hadoop/share/ozone/lib/asm-commons-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-analysis-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-tree-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-util-9.7.1.jar:/opt/hadoop/share/ozone/lib/jnr-a64asm-1.0.0.jar:/opt/hadoop/share/ozone/lib/jnr-x86asm-1.0.2.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.6.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.47.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.47.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.47.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.47.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/apache-log4j-extras-1.2.17.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.25.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.8.jar:/opt/hadoop/share/ozone/lib/ozone-common-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.71.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.51.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.71.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.9.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.24.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/reflections-0.10.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.30.2-GA.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.17.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.5.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.70.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.70.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.70.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.70.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.70.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.70.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.70.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/asm-9.8.jar:/opt/hadoop/share/ozone/lib/ozone-manager-2.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-base-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-json-provider-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/gethostname4j-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.6.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-logs-1.12.765.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-core-1.12.788.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-cbor-2.16.2.jar:/opt/hadoop/share/ozone/lib/jmespath-java-1.12.765.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aircompressor-0.27.jar:/opt/hadoop/share/ozone/lib/joda-time-2.12.7.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.16.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/orc-shims-1.5.8.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.58.v20250814.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.6.0.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/ozone-multitenancy-ranger-2.1.0-SNAPSHOT.jar
STARTUP_MSG:        conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachine.write.wait.interval=10m, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.token.enabled=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.refresh.period=1h, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.threadpool=10, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.choosing.policy=org.apache.hadoop.ozone.container.common.volume.CapacityVolumeChoosingPolicy, hdds.datanode.volume.min.free.space=100MB, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.initial-interval=2s, hdds.heartbeat.interval=30s, hdds.heartbeat.recon.initial-interval=60s, hdds.heartbeat.recon.interval=60s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=500000, hdds.scm.block.deletion.txn.dn.commit.map.limit=5000000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=9d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.hbase.enhancements.allowed=false, ozone.http.basedir=/tmp/ozone_http, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=50000, ozone.key.preallocation.max.blocks=64, ozone.ksm.address=ksm, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.compaction.service.columnfamilies=keyTable,fileTable,directoryTable,deletedTable,deletedDirectoryTable,multipartInfoTable, ozone.om.compaction.service.enabled=false, ozone.om.compaction.service.run.interval=6h, ozone.om.compaction.service.timeout=10m, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.edekcacheloader.initial.delay.ms=3000, ozone.om.edekcacheloader.interval.ms=1000, ozone.om.edekcacheloader.max-retries=10, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=10000, ozone.om.group.rights=READ, LIST, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=100, ozone.om.hierarchical.resource.locks.hard.limit=10000, ozone.om.hierarchical.resource.locks.soft.limit=1024, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=64MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.pending.write.byte-limit=64MB, ozone.om.ratis.server.pending.write.element-limit=4096, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.s3.grpc.server_enabled=true, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.server.list.max.size=1000, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compact.non.snapshot.diff.tables=false, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=10m, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.prune.compaction.backup.batch.size=2000, ozone.om.snapshot.rocksdb.metrics.enabled=false, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.event.buffer.capacity=20000, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=5s, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.https-address=0.0.0.0:9879, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.list.max.keys.limit=1000, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.s3g.webadmin.https-address=0.0.0.0:19879, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.per.dn.distribution.factor=8, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=60s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=64MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=1, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.defrag.limit.per.task=1, ozone.snapshot.defrag.service.interval=-1, ozone.snapshot.defrag.service.timeout=300s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2025-10-20 07:59:03,086 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [SIGHUP, SIGINT, SIGTERM]
2025-10-20 07:59:03,574 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
2025-10-20 07:59:03,586 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMSystemAudit to [].
2025-10-20 07:59:03,679 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2025-10-20 07:59:03,716 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.2:9862
2025-10-20 07:59:03,716 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2025-10-20 07:59:03,716 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
2025-10-20 07:59:04,059 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-10-20 07:59:04,209 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9863]
OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-fb0a19ef-014d-49ed-a10a-06b4bfde0b9a;layoutVersion=8
2025-10-20 07:59:04,374 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down OzoneManager at 3164b0582609/172.18.0.2
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
+ docker compose --progress quiet exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
9b2f2192cec7: Warning: Permanently added '9b2f2192cec7' (ED25519) to the list of known hosts.
9b2f2192cec7: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
9b2f2192cec7: datanode is running as process 91.  Stop it first.
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om' (ED25519) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm' (ED25519) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
scm: scm is running as process 722.  Stop it first.
Using Docker Compose v2
xargs: warning: options --max-args and --replace/-I/-i are mutually exclusive, ignoring previous --max-args value
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      6 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     11 ?        S      0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups
     91 ?        Sl     0:10 /usr/local/jdk-21.0.2/bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dlog4j.configurationFile=/etc/hadoop/dn-audit-log4j2.properties,/etc/hadoop/dn-container-log4j2.properties -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dorg.apache.ratis.thirdparty.io.netty.tryReflectionSetAccessible=true --add-opens java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED -XX:ParallelGCThreads=8 -Dhadoop.log.dir=/var/log/hadoop -Dhadoop.log.file=ozone-hadoop-datanode-9b2f2192cec7.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.HddsDatanodeService
    368 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      7 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     12 ?        S      0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups
    323 ?        Sl     0:09 /usr/local/jdk-21.0.2/bin/java -Dproc_om -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dorg.apache.ratis.thirdparty.io.netty.tryReflectionSetAccessible=true -Dlog4j.configurationFile=/etc/hadoop/om-audit-log4j2.properties --add-opens java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED -XX:ParallelGCThreads=8 -Dhadoop.log.dir=/var/log/hadoop -Dhadoop.log.file=ozone-hadoop-om-3164b0582609.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.om.OzoneManagerStarter
    416 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      7 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     12 ?        S      0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups
    722 ?        Sl     0:11 /usr/local/jdk-21.0.2/bin/java -Dproc_scm -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dorg.apache.ratis.thirdparty.io.netty.tryReflectionSetAccessible=true -Dlog4j.configurationFile=/etc/hadoop/scm-audit-log4j2.properties --add-opens java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED -XX:ParallelGCThreads=8 -Dhadoop.log.dir=/var/log/hadoop -Dhadoop.log.file=ozone-hadoop-scm-027808e30467.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter
   1746 ?        Rs     0:00 ps xa
==============================================================================
Single Node :: Smoketest for one datanode                                     
==============================================================================
Basic Freon smoketest for one datanode                                | PASS |
------------------------------------------------------------------------------
Single Node :: Smoketest for one datanode                             | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-001.xml
==============================================================================
Pipeline :: Test ozone admin pipeline command                                 
==============================================================================
List pipelines                                                        | PASS |
------------------------------------------------------------------------------
List pipeline with json option                                        | PASS |
------------------------------------------------------------------------------
List pipelines with explicit host                                     | PASS |
------------------------------------------------------------------------------
List pipelines with explicit host and json option                     | PASS |
------------------------------------------------------------------------------
Deactivate pipeline                                                   | PASS |
------------------------------------------------------------------------------
Activate pipeline                                                     | PASS |
------------------------------------------------------------------------------
Close pipeline                                                        | PASS |
------------------------------------------------------------------------------
Incomplete command                                                    | PASS |
------------------------------------------------------------------------------
Create pipeline                                                       | PASS |
------------------------------------------------------------------------------
Pipeline :: Test ozone admin pipeline command                         | PASS |
9 tests, 9 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-002.xml
Using Docker Compose v2
Stopping datanodes
9b2f2192cec7: Warning: Permanently added '9b2f2192cec7' (ED25519) to the list of known hosts.
9b2f2192cec7: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Stopping Ozone Manager nodes [om]
om: Warning: Permanently added 'om' (ED25519) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Stopping storage container manager nodes [scm]
scm: Warning: Permanently added 'scm' (ED25519) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/ozonescripts.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-HCdpcb/ozonescripts.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts.xml'
removed 'ozonescripts/result/robot-001.xml'
removed 'ozonescripts/result/robot-002.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts'
renamed 'ozonescripts/result/dn-audit-9b2f2192cec7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/dn-audit-9b2f2192cec7.log'
renamed 'ozonescripts/result/docker-ozonescripts-datanode-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts-datanode-1.log'
renamed 'ozonescripts/result/docker-ozonescripts-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts-om-1.log'
renamed 'ozonescripts/result/docker-ozonescripts-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts-scm-1.log'
renamed 'ozonescripts/result/om-audit-3164b0582609.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/om-audit-3164b0582609.log'
renamed 'ozonescripts/result/om-sys-audit-3164b0582609.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/om-sys-audit-3164b0582609.log'
renamed 'ozonescripts/result/ozone-hadoop-datanode-9b2f2192cec7.out' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/ozone-hadoop-datanode-9b2f2192cec7.out'
renamed 'ozonescripts/result/ozone-hadoop-om-3164b0582609.out' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/ozone-hadoop-om-3164b0582609.out'
renamed 'ozonescripts/result/ozone-hadoop-om-3164b0582609.out.1' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/ozone-hadoop-om-3164b0582609.out.1'
renamed 'ozonescripts/result/ozone-hadoop-scm-027808e30467.out' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/ozone-hadoop-scm-027808e30467.out'
renamed 'ozonescripts/result/scm-audit-027808e30467.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonescripts/scm-audit-027808e30467.log'
Executing test ozonesecure-ha/test-ranger.sh
Using Docker Compose v2
Downloading /tmp/apache-ranger-2.6.0.tar.gz from https://www.apache.org/dyn/closer.lua?action=download&filename=ranger/2.6.0/apache-ranger-2.6.0.tar.gz
Downloading /tmp/ranger-2.6.0-ozone-plugin.tar.gz from https://www.apache.org/dyn/closer.lua?action=download&filename=ranger/2.6.0/plugins/ozone/ranger-2.6.0-ozone-plugin.tar.gz
Error response from daemon: Head "https://registry-1.docker.io/v2/library/postgres/manifests/12": received unexpected HTTP status: 503 Service Unavailable
ERROR: Test execution of ozonesecure-ha/test-ranger.sh is FAILED!!!!
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/ranger'
mv: cannot stat 'ozonesecure-ha/result/*': No such file or directory
Executing test ozonesecure-ha/test-s3g-virtual-host.sh
Using Docker Compose v2
Port 88 is not available on kdc yet
Port 88 is available on kdc
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is available on scm1.org
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 227
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 226
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 225
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 224
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 223
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 222
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 221
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 220
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 219
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 218
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 217
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 216
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 215
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 214
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 213
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 212
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 211
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 210
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 209
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 208
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 207
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 206
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 205
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 204
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 203
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 202
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 201
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 199
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 198
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 197
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 196
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 195
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 194
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 193
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 192
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 191
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 190
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 189
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 188
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 187
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 186
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 185
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 184
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 183
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 182
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 181
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 180
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 179
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 178
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 177
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 176
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 175
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 174
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 173
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 172
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 171
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 170
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 169
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 168
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 167
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 166
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 165
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 164
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 163
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 162
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 161
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 160
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 159
SCM is out of safe mode.
Found OM leader for service omservice: om2 : LEADER (om2)
Replaced OM order with om2,om3,om1 in ozonesecure-ha-datanode1-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-datanode2-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-datanode3-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-httpfs-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-om1-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-om2-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-om3-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-recon-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-s3g-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-scm1.org-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-scm2.org-1
Replaced OM order with om2,om3,om1 in ozonesecure-ha-scm3.org-1
==============================================================================
s3-virtual-host :: S3 gateway test with aws cli using virtual host style ad...
==============================================================================
File upload and directory list with virtual style addressing          | PASS |
------------------------------------------------------------------------------
s3-virtual-host :: S3 gateway test with aws cli using virtual host... | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-ha/result/robot-001.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/ozonesecure-ha-s3g-virtual-host.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-0EZpwf/ozonesecure-ha-s3g-virtual-host.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha-s3g-virtual-host.xml'
removed 'ozonesecure-ha/result/robot-001.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host'
renamed 'ozonesecure-ha/result/dn-audit-02decb00c023.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/dn-audit-02decb00c023.log'
renamed 'ozonesecure-ha/result/dn-audit-270f18f996b5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/dn-audit-270f18f996b5.log'
renamed 'ozonesecure-ha/result/dn-audit-c21049221477.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/dn-audit-c21049221477.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-datanode1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-datanode1-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-datanode2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-datanode2-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-datanode3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-datanode3-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-httpfs-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-httpfs-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-kdc-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-kdc-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-kms-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-kms-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-om1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-om1-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-om2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-om2-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-om3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-om3-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-om4-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-om4-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-recon-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-s3g-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-s3g-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-scm1.org-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-scm1.org-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-scm2.org-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-scm2.org-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-scm3.org-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-scm3.org-1.log'
renamed 'ozonesecure-ha/result/kms-audit.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/kms-audit.log'
renamed 'ozonesecure-ha/result/om-audit-om1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-audit-om1.log'
renamed 'ozonesecure-ha/result/om-audit-om2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-audit-om2.log'
renamed 'ozonesecure-ha/result/om-audit-om3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-audit-om3.log'
renamed 'ozonesecure-ha/result/om-sys-audit-om1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-sys-audit-om1.log'
renamed 'ozonesecure-ha/result/om-sys-audit-om2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-sys-audit-om2.log'
renamed 'ozonesecure-ha/result/om-sys-audit-om3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-sys-audit-om3.log'
renamed 'ozonesecure-ha/result/s3g-audit-s3g.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/s3g-audit-s3g.log'
renamed 'ozonesecure-ha/result/scm-audit-scm1.org.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/scm-audit-scm1.org.log'
renamed 'ozonesecure-ha/result/scm-audit-scm2.org.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/scm-audit-scm2.org.log'
renamed 'ozonesecure-ha/result/scm-audit-scm3.org.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/scm-audit-scm3.org.log'
Executing test ozonesecure/test-vault.sh
Using Docker Compose v2
Error response from daemon: Head "https://registry-1.docker.io/v2/hashicorp/vault/manifests/1.13.2": received unexpected HTTP status: 503 Service Unavailable
ERROR: Test execution of ozonesecure/test-vault.sh is FAILED!!!!
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/ozonesecure/vault'
mv: cannot stat 'ozonesecure/result/*': No such file or directory
Executing test restart/test.sh
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-001.xml
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-002.xml
==============================================================================
Generate-Chunk :: Test freon chunk generation commands                        
==============================================================================
DN Chunk Generator                                                    | PASS |
------------------------------------------------------------------------------
Generate-Chunk :: Test freon chunk generation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-003.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-004.xml
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 238
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 237
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-005.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-006.xml
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-007.xml
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-008.xml
==============================================================================
Generate-Chunk :: Test freon chunk generation commands                        
==============================================================================
DN Chunk Generator                                                    | PASS |
------------------------------------------------------------------------------
Generate-Chunk :: Test freon chunk generation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-009.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-010.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/restart.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-0VqANL/restart.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart.xml'
removed 'restart/result/robot-001.xml'
removed 'restart/result/robot-002.xml'
removed 'restart/result/robot-003.xml'
removed 'restart/result/robot-004.xml'
removed 'restart/result/robot-005.xml'
removed 'restart/result/robot-006.xml'
removed 'restart/result/robot-007.xml'
removed 'restart/result/robot-008.xml'
removed 'restart/result/robot-009.xml'
removed 'restart/result/robot-010.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart'
renamed 'restart/result/dn-audit-19ac92ebd716.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/dn-audit-19ac92ebd716.log'
renamed 'restart/result/dn-audit-42017ce7a76b.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/dn-audit-42017ce7a76b.log'
renamed 'restart/result/dn-audit-6c7d60ffa5ce.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/dn-audit-6c7d60ffa5ce.log'
renamed 'restart/result/dn-audit-bd2c07d8a38a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/dn-audit-bd2c07d8a38a.log'
renamed 'restart/result/dn-audit-c304cad07bed.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/dn-audit-c304cad07bed.log'
renamed 'restart/result/dn-audit-e803985a28dc.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/dn-audit-e803985a28dc.log'
renamed 'restart/result/docker-restart-dn1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/docker-restart-dn1-1.log'
renamed 'restart/result/docker-restart-dn2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/docker-restart-dn2-1.log'
renamed 'restart/result/docker-restart-dn3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/docker-restart-dn3-1.log'
renamed 'restart/result/docker-restart-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/docker-restart-om-1.log'
renamed 'restart/result/docker-restart-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/docker-restart-recon-1.log'
renamed 'restart/result/docker-restart-s3g-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/docker-restart-s3g-1.log'
renamed 'restart/result/docker-restart-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/docker-restart-scm-1.log'
renamed 'restart/result/om-audit-a25265cff4d4.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/om-audit-a25265cff4d4.log'
renamed 'restart/result/om-audit-a9a80728f2a3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/om-audit-a9a80728f2a3.log'
renamed 'restart/result/om-sys-audit-a25265cff4d4.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/om-sys-audit-a25265cff4d4.log'
renamed 'restart/result/om-sys-audit-a9a80728f2a3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/om-sys-audit-a9a80728f2a3.log'
renamed 'restart/result/s3g-audit-0405edfa0c4d.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/s3g-audit-0405edfa0c4d.log'
renamed 'restart/result/s3g-audit-4a7f90994135.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/s3g-audit-4a7f90994135.log'
renamed 'restart/result/scm-audit-2f67f82c045e.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/scm-audit-2f67f82c045e.log'
renamed 'restart/result/scm-audit-b5aa0a6d548a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/restart/scm-audit-b5aa0a6d548a.log'
Executing test upgrade/testlib.sh
Using Docker Compose v2
find: upgrade/result: No such file or directory
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/upgrade'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/upgrade/testlib'
mv: cannot stat 'upgrade/result/*': No such file or directory
To use Ozone please mount ozone folder to /opt/hadoop
Log:     /rebot-output/log.html
Report:  /rebot-output/report.html
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-dWJIHv/log.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/log.html'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/rebot-dWJIHv/report.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.1.0-SNAPSHOT/compose/result/report.html'
removed directory '/tmp/robot-data-6SOl1O'
