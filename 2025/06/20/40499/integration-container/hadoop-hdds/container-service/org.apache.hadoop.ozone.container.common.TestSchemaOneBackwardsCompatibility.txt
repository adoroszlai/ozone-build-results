-------------------------------------------------------------------------------
Test set: org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility
-------------------------------------------------------------------------------
Tests run: 20, Failures: 0, Errors: 12, Skipped: 0, Time elapsed: 3.721 s <<< FAILURE! -- in org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility
org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks(String)[1] -- Time elapsed: 0.893 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks(TestSchemaOneBackwardsCompatibility.java:539)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 50 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks(String)[2] -- Time elapsed: 0.082 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks(TestSchemaOneBackwardsCompatibility.java:539)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 50 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testBlockIteration(String)[1] -- Time elapsed: 0.062 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.countDeletedBlocks(TestSchemaOneBackwardsCompatibility.java:635)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testBlockIteration(TestSchemaOneBackwardsCompatibility.java:180)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 51 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testBlockIteration(String)[2] -- Time elapsed: 0.050 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.countDeletedBlocks(TestSchemaOneBackwardsCompatibility.java:635)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testBlockIteration(TestSchemaOneBackwardsCompatibility.java:180)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 51 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata(String)[1] -- Time elapsed: 0.055 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.getUsedBytesAndBlockCount(KeyValueContainerUtil.java:403)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.populateContainerMetadata(KeyValueContainerUtil.java:347)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.parseKVContainerData(KeyValueContainerUtil.java:274)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.parseKVContainerData(KeyValueContainerUtil.java:206)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.newKvData(TestSchemaOneBackwardsCompatibility.java:613)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata(TestSchemaOneBackwardsCompatibility.java:261)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=13) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 50 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:24002)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 55 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata(String)[2] -- Time elapsed: 0.067 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.getUsedBytesAndBlockCount(KeyValueContainerUtil.java:403)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.populateContainerMetadata(KeyValueContainerUtil.java:347)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.parseKVContainerData(KeyValueContainerUtil.java:274)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.parseKVContainerData(KeyValueContainerUtil.java:206)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.newKvData(TestSchemaOneBackwardsCompatibility.java:613)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata(TestSchemaOneBackwardsCompatibility.java:261)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=13) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 50 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:24002)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 55 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadBlockData(String)[1] -- Time elapsed: 0.051 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadBlockData(TestSchemaOneBackwardsCompatibility.java:438)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=8) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 45 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:133)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:630)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:23953)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 50 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadBlockData(String)[2] -- Time elapsed: 0.056 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadBlockData(TestSchemaOneBackwardsCompatibility.java:438)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=8) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 45 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:133)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:630)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:23953)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 50 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo(String)[1] -- Time elapsed: 0.138 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo(TestSchemaOneBackwardsCompatibility.java:362)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 50 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo(String)[2] -- Time elapsed: 0.055 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo(TestSchemaOneBackwardsCompatibility.java:362)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 50 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData(String)[1] -- Time elapsed: 0.069 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData(TestSchemaOneBackwardsCompatibility.java:493)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=8) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 45 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:133)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:630)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:23953)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 50 more

org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData(String)[2] -- Time elapsed: 0.059 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData(TestSchemaOneBackwardsCompatibility.java:493)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=8) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 45 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:133)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:630)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:23953)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 50 more

