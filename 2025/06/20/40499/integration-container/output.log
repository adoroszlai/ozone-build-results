Apache Maven 3.9.10 (5f519b97e944483d878815739f519b2eade0a91d)
Maven home: /usr/share/apache-maven-3.9.10
Java version: 21.0.7, vendor: Eclipse Adoptium, runtime: /usr/lib/jvm/temurin-21-jdk-amd64
Default locale: en, platform encoding: UTF-8
OS name: "linux", version: "6.11.0-1015-azure", arch: "amd64", family: "unix"
[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Detecting the operating system and CPU architecture
[INFO] ------------------------------------------------------------------------
[INFO] os.detected.name: linux
[INFO] os.detected.arch: x86_64
[INFO] os.detected.bitness: 64
[INFO] os.detected.version: 6.11
[INFO] os.detected.version.major: 6
[INFO] os.detected.version.minor: 11
[INFO] os.detected.release: ubuntu
[INFO] os.detected.release.version: 24.04
[INFO] os.detected.release.like.ubuntu: true
[INFO] os.detected.release.like.debian: true
[INFO] os.detected.classifier: linux-x86_64
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Apache Ozone Main                                                  [pom]
[INFO] Apache Ozone Dev Support                                           [jar]
[INFO] Apache Ozone HDDS                                                  [pom]
[INFO] Apache Ozone Annotation Processing                                 [jar]
[INFO] Apache Ozone HDDS Config                                           [jar]
[INFO] Apache Ozone HDDS Client Interface                                 [jar]
[INFO] Apache Ozone HDDS Admin Interface                                  [jar]
[INFO] Apache Ozone HDDS Test Utils                                       [jar]
[INFO] Apache Ozone HDDS Hadoop Client dependencies                       [pom]
[INFO] Apache Ozone HDDS Common                                           [jar]
[INFO] Apache Ozone HDDS Erasurecode                                      [jar]
[INFO] Apache Ozone HDDS Client                                           [jar]
[INFO] Apache Ozone HDDS Server Interface                                 [jar]
[INFO] Apache Ozone HDDS Managed RocksDB                                  [jar]
[INFO] Apache Ozone HDDS RocksDB Tools                                    [jar]
[INFO] Apache Ozone Checkpoint Differ for RocksDB                         [jar]
[INFO] Apache Ozone HDDS Server Framework                                 [jar]
[INFO] Apache Ozone Documentation                                         [jar]
[INFO] Apache Ozone HDDS Container Service                                [jar]
[INFO] Apache Ozone HDDS Crypto                                           [jar]
[INFO] Apache Ozone HDDS Crypto - Default                                 [jar]
[INFO] Apache Ozone HDDS SCM Server                                       [jar]
[INFO] Apache Ozone                                                       [pom]
[INFO] Apache Ozone Client Interface                                      [jar]
[INFO] Apache Ozone Common                                                [jar]
[INFO] Apache Ozone Client                                                [jar]
[INFO] Apache Ozone FileSystem Common                                     [jar]
[INFO] Apache Ozone FileSystem                                            [jar]
[INFO] Apache Ozone CLI Shell                                             [jar]
[INFO] Apache Ozone CLI Admin                                             [jar]
[INFO] Apache Ozone CSI service                                           [jar]
[INFO] Apache Ozone Datanode                                              [jar]
[INFO] Apache Ozone Storage Interface                                     [jar]
[INFO] Apache Ozone Manager Server                                        [jar]
[INFO] Apache Ozone Freon                                                 [jar]
[INFO] Apache Ozone HttpFS                                                [jar]
[INFO] Apache Ozone Insight Tool                                          [jar]
[INFO] Apache Ozone Recon CodeGen                                         [jar]
[INFO] Apache Ozone Recon                                                 [jar]
[INFO] Apache Ozone S3 Secret Store                                       [jar]
[INFO] Apache Ozone S3 Gateway                                            [jar]
[INFO] Apache Ozone Tools                                                 [jar]
[INFO] Apache Ozone Distribution                                          [jar]
[INFO] Apache Ozone Mini Cluster                                          [jar]
[INFO] Apache Ozone Integration Tests                                     [jar]
[INFO] Apache Ozone Fault Injection Tests                                 [pom]
[INFO] Apache Ozone Mini Ozone Chaos Tests                                [jar]
[INFO] Apache Ozone Network Tests                                         [jar]
[INFO] Apache Ozone Recon Integration Tests                               [jar]
[INFO] Apache Ozone S3 Integration Tests                                  [jar]
[INFO] 
[INFO] --------------------< org.apache.ozone:ozone-main >---------------------
[INFO] Building Apache Ozone Main 2.1.0-SNAPSHOT                         [1/50]
[INFO]   from pom.xml
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-main ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (enforce-property) @ ozone-main ---
[INFO] Rule 0: org.apache.maven.enforcer.rules.property.RequireProperty passed
[INFO] Rule 1: org.apache.maven.enforcer.rules.version.RequireMavenVersion passed
[INFO] Rule 2: org.apache.maven.enforcer.rules.version.RequireJavaVersion passed
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-main ---
[INFO] Verifying file /home/runner/work/ozone/ozone/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-main ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-main ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-main ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-main ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-main ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-main ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-main ---
[INFO] Skipping pom project
[INFO] 
[INFO] -----------------< org.apache.ozone:ozone-dev-support >-----------------
[INFO] Building Apache Ozone Dev Support 2.1.0-SNAPSHOT                  [2/50]
[INFO]   from dev-support/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- resources:3.3.0:copy-resources (copy-resources) @ ozone-dev-support ---
[INFO] Copying 2 resources
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-dev-support ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/dev-support/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-dev-support ---
[INFO] Verifying file /home/runner/work/ozone/ozone/dev-support/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-dev-support ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/dev-support/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-dev-support ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-dev-support ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-dev-support ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-dev-support ---
[INFO] Copying 2 resources to META-INF
[INFO] 
[INFO] --- remote-resources:3.3.0:bundle (default) @ ozone-dev-support ---
[INFO] Writing META-INF/maven/remote-resources.xml descriptor with 2 entries
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-dev-support ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-dev-support ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/dev-support/src/test/resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-dev-support ---
[INFO] No sources to compile
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-dev-support ---
[INFO] No tests to run.
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] No tests to run.
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-dev-support ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-dev-support ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-dev-support ---
[INFO] Building jar: /home/runner/work/ozone/ozone/dev-support/target/ozone-dev-support-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-dev-support ---
[INFO] No dependency problems found
[INFO] 
[INFO] -----------------------< org.apache.ozone:hdds >------------------------
[INFO] Building Apache Ozone HDDS 2.1.0-SNAPSHOT                         [3/50]
[INFO]   from hadoop-hdds/pom.xml
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/target/hdds-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds ---
[INFO] Skipping pom project
[INFO] 
[INFO] ------------< org.apache.ozone:hdds-annotation-processing >-------------
[INFO] Building Apache Ozone Annotation Processing 2.1.0-SNAPSHOT        [4/50]
[INFO]   from hadoop-hdds/annotations/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-annotation-processing ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/annotations/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-annotation-processing ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/annotations/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-annotation-processing ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/annotations/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-annotation-processing ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-annotation-processing ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-annotation-processing ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-annotation-processing ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-annotation-processing ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/annotations/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-annotation-processing ---
[INFO] Compiling 4 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-annotation-processing ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-annotation-processing ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-annotation-processing ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-annotation-processing ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-annotation-processing ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-annotation-processing ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/annotations/target/hdds-annotation-processing-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-annotation-processing ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-annotation-processing ---
[INFO] No dependency problems found
[INFO] 
[INFO] --------------------< org.apache.ozone:hdds-config >--------------------
[INFO] Building Apache Ozone HDDS Config 2.1.0-SNAPSHOT                  [5/50]
[INFO]   from hadoop-hdds/config/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-config ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/config/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-config ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/config/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-config ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/config/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-config ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-config ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-config ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-config ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-config ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/config/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-config ---
[INFO] Compiling 18 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-config ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-config ---
[INFO] Compiling 9 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-config ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-config ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-config ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-config ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/config/target/hdds-config-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-config ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/config/target/hdds-config-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-config ---
[INFO] No dependency problems found
[INFO] 
[INFO] ---------------< org.apache.ozone:hdds-interface-client >---------------
[INFO] Building Apache Ozone HDDS Client Interface 2.1.0-SNAPSHOT        [6/50]
[INFO]   from hadoop-hdds/interface-client/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-interface-client ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-interface-client ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-interface-client ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc-grpc) @ hdds-interface-client ---
[INFO] Compiling 1 proto file(s) to /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/generated-sources/java
[INFO] 
[INFO] --- protobuf:0.6.1:compile-custom (compile-protoc-grpc) @ hdds-interface-client ---
[INFO] Compiling 1 proto file(s) to /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/generated-sources/java
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc-2) @ hdds-interface-client ---
[INFO] Compiling 2 proto file(s) to /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/generated-sources/java
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc-3) @ hdds-interface-client ---
[INFO] Compiling 2 proto file(s) to /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/generated-sources/java/proto3
[INFO] 
[INFO] --- antrun:3.1.0:run (default) @ hdds-interface-client ---
[INFO] Executing tasks
[INFO]      [move] Moving 2 files to /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/generated-sources
[INFO] Executed tasks
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-interface-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.enforcer.rules.version.RequireMavenVersion passed
[INFO] Rule 2: org.apache.maven.enforcer.rules.version.RequireJavaVersion passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-interface-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-interface-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-interface-client ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-interface-client ---
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-interface-client ---
[INFO] Compiling 7 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc-grpc) @ hdds-interface-client ---
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile-custom (compile-protoc-grpc) @ hdds-interface-client ---
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc-2) @ hdds-interface-client ---
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc-3) @ hdds-interface-client ---
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-interface-client ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-interface-client ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-interface-client ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-interface-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-interface-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-interface-client ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/hdds-interface-client-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-interface-client ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-interface-client ---
[INFO] No dependency problems found
[INFO] 
[INFO] --- proto-backwards-compatibility:1.0.7:backwards-compatibility-check (default) @ hdds-interface-client ---
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/protolock-bin/protolock status --lockdir=/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/classes
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/protolock-bin/protolock commit --lockdir=/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/classes
[INFO] Backwards compatibility check passed.
[INFO] 
[INFO] ---------------< org.apache.ozone:hdds-interface-admin >----------------
[INFO] Building Apache Ozone HDDS Admin Interface 2.1.0-SNAPSHOT         [7/50]
[INFO]   from hadoop-hdds/interface-admin/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-interface-admin ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-interface-admin ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-interface-admin ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc-2) @ hdds-interface-admin ---
[INFO] Compiling 1 proto file(s) to /home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/generated-sources/java
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-interface-admin ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-interface-admin ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-interface-admin ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-interface-admin ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-interface-admin ---
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-interface-admin ---
[INFO] Compiling 1 source file with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc-2) @ hdds-interface-admin ---
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-interface-admin ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-interface-admin ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-interface-admin ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-interface-admin ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-interface-admin ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-interface-admin ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/hdds-interface-admin-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-interface-admin ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-interface-admin ---
[INFO] No dependency problems found
[INFO] 
[INFO] --- proto-backwards-compatibility:1.0.7:backwards-compatibility-check (default) @ hdds-interface-admin ---
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/protolock-bin/protolock status --lockdir=/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/classes
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/protolock-bin/protolock commit --lockdir=/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/classes
[INFO] Backwards compatibility check passed.
[INFO] 
[INFO] ------------------< org.apache.ozone:hdds-test-utils >------------------
[INFO] Building Apache Ozone HDDS Test Utils 2.1.0-SNAPSHOT              [8/50]
[INFO]   from hadoop-hdds/test-utils/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-test-utils ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-test-utils ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/test-utils/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-test-utils ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-test-utils ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-test-utils ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-test-utils ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-test-utils ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-test-utils ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/test-utils/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-test-utils ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-test-utils ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-test-utils ---
[INFO] Compiling 18 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/test-utils/src/test/java/org/apache/ozone/test/GenericTestUtils.java: /home/runner/work/ozone/ozone/hadoop-hdds/test-utils/src/test/java/org/apache/ozone/test/GenericTestUtils.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/test-utils/src/test/java/org/apache/ozone/test/GenericTestUtils.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-test-utils ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-test-utils ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-test-utils ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-test-utils ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/hdds-test-utils-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-test-utils ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/hdds-test-utils-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-test-utils ---
[INFO] No dependency problems found
[INFO] 
[INFO] -----------< org.apache.ozone:hdds-hadoop-dependency-client >-----------
[INFO] Building Apache Ozone HDDS Hadoop Client dependencies 2.1.0-SNAPSHOT [9/50]
[INFO]   from hadoop-hdds/hadoop-dependency-client/pom.xml
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-hadoop-dependency-client ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-client/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-hadoop-dependency-client ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-client/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-hadoop-dependency-client ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-client/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-hadoop-dependency-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-hadoop-dependency-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-hadoop-dependency-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-hadoop-dependency-client ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-hadoop-dependency-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-hadoop-dependency-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-hadoop-dependency-client ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-client/target/hdds-hadoop-dependency-client-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-hadoop-dependency-client ---
[INFO] Skipping pom project
[INFO] 
[INFO] --------------------< org.apache.ozone:hdds-common >--------------------
[INFO] Building Apache Ozone HDDS Common 2.1.0-SNAPSHOT                 [10/50]
[INFO]   from hadoop-hdds/common/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-common ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/common/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-common ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/common/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-common ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/common/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-common ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- hadoops:3.4.1:version-info (version-info) @ hdds-common ---
[INFO] SCM: GIT
[INFO] Computed MD5: f8f0104b3e2c383a75118cccf6b526a2
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-common ---
[INFO] Copying 4 resources
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] The encoding used to copy filtered properties files have not been set. This means that the same encoding will be used to copy filtered properties files as when copying other filtered resources. This might not be what you want! Run your build with --debug to see which files might be affected. Read more at https://maven.apache.org/plugins/maven-resources-plugin/examples/filtering-properties-files.html
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-common ---
[INFO] Compiling 277 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/HddsUtils.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/HddsUtils.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/ratis/retrypolicy/RequestTypeDependentRetryPolicyCreator.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/ratis/retrypolicy/RequestTypeDependentRetryPolicyCreator.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-common ---
[INFO] Copying 20 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-common ---
[INFO] Compiling 70 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/client/TestReplicationConfig.java: /home/runner/work/ozone/ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/client/TestReplicationConfig.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/client/TestReplicationConfig.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/client/TestECReplicationConfig.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/client/TestECReplicationConfig.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-common ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerReplicaInfo
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.290 s -- in org.apache.hadoop.hdds.scm.container.TestContainerReplicaInfo
[INFO] Running org.apache.hadoop.hdds.scm.container.common.helpers.TestExcludeList
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.241 s -- in org.apache.hadoop.hdds.scm.container.common.helpers.TestExcludeList
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerInfo
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.238 s -- in org.apache.hadoop.hdds.scm.container.TestContainerInfo
[INFO] Running org.apache.hadoop.hdds.scm.container.TestReplicationManagerReport
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.441 s -- in org.apache.hadoop.hdds.scm.container.TestReplicationManagerReport
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-common ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-common ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-common ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-common ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/common/target/hdds-common-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-common ---
[INFO] No dependency problems found
[INFO] 
[INFO] -----------------< org.apache.ozone:hdds-erasurecode >------------------
[INFO] Building Apache Ozone HDDS Erasurecode 2.1.0-SNAPSHOT            [11/50]
[INFO]   from hadoop-hdds/erasurecode/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-erasurecode ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-erasurecode ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-erasurecode ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-erasurecode ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-erasurecode ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-erasurecode ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-erasurecode ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-erasurecode ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-erasurecode ---
[INFO] Compiling 39 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-erasurecode ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-erasurecode ---
[INFO] Compiling 17 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-erasurecode ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-erasurecode ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-erasurecode ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-erasurecode ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/hdds-erasurecode-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-erasurecode ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/hdds-erasurecode-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-erasurecode ---
[INFO] No dependency problems found
[INFO] 
[INFO] --------------------< org.apache.ozone:hdds-client >--------------------
[INFO] Building Apache Ozone HDDS Client 2.1.0-SNAPSHOT                 [12/50]
[INFO]   from hadoop-hdds/client/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-client ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/client/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-client ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/client/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-client ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/client/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-client ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-client ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/client/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-client ---
[INFO] Compiling 48 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/client/HddsClientUtils.java: /home/runner/work/ozone/ozone/hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/client/HddsClientUtils.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/client/HddsClientUtils.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-client ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-client ---
[INFO] Compiling 17 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/client/src/test/java/org/apache/hadoop/hdds/scm/storage/TestBlockInputStream.java: /home/runner/work/ozone/ozone/hadoop-hdds/client/src/test/java/org/apache/hadoop/hdds/scm/storage/TestBlockInputStream.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/client/src/test/java/org/apache/hadoop/hdds/scm/storage/TestBlockInputStream.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-client ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-client ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/client/target/hdds-client-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-client ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/client/target/hdds-client-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-client ---
[INFO] No dependency problems found
[INFO] 
[INFO] ---------------< org.apache.ozone:hdds-interface-server >---------------
[INFO] Building Apache Ozone HDDS Server Interface 2.1.0-SNAPSHOT       [13/50]
[INFO]   from hadoop-hdds/interface-server/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-interface-server ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-interface-server ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-interface-server ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc-3) @ hdds-interface-server ---
[INFO] Compiling 2 proto file(s) to /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/generated-sources/java
[INFO] 
[INFO] --- protobuf:0.6.1:compile-custom (compile-protoc-3) @ hdds-interface-server ---
[INFO] Compiling 2 proto file(s) to /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/generated-sources/java
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc-2) @ hdds-interface-server ---
[INFO] Compiling 5 proto file(s) to /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/generated-sources/java
[INFO] 
[INFO] --- antrun:3.1.0:run (default) @ hdds-interface-server ---
[INFO] Executing tasks
[INFO] Executed tasks
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-interface-server ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-interface-server ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-interface-server ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-interface-server ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-interface-server ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] Copying 5 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-interface-server ---
[INFO] Compiling 9 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc-3) @ hdds-interface-server ---
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile-custom (compile-protoc-3) @ hdds-interface-server ---
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc-2) @ hdds-interface-server ---
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-interface-server ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-interface-server ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-interface-server ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-interface-server ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-interface-server ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-interface-server ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/hdds-interface-server-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-interface-server ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-interface-server ---
[INFO] No dependency problems found
[INFO] 
[INFO] --- proto-backwards-compatibility:1.0.7:backwards-compatibility-check (default) @ hdds-interface-server ---
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/protolock-bin/protolock status --lockdir=/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/classes
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/protolock-bin/protolock commit --lockdir=/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/classes
[INFO] Backwards compatibility check passed.
[INFO] 
[INFO] ---------------< org.apache.ozone:hdds-managed-rocksdb >----------------
[INFO] Building Apache Ozone HDDS Managed RocksDB 2.1.0-SNAPSHOT        [14/50]
[INFO]   from hadoop-hdds/managed-rocksdb/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-managed-rocksdb ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-managed-rocksdb ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-managed-rocksdb ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-managed-rocksdb ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-managed-rocksdb ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-managed-rocksdb ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-managed-rocksdb ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-managed-rocksdb ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-managed-rocksdb ---
[INFO] Compiling 30 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-managed-rocksdb ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-managed-rocksdb ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-managed-rocksdb ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-managed-rocksdb ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-managed-rocksdb ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-managed-rocksdb ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/target/hdds-managed-rocksdb-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-managed-rocksdb ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-managed-rocksdb ---
[INFO] No dependency problems found
[INFO] 
[INFO] -----------------< org.apache.ozone:hdds-rocks-native >-----------------
[INFO] Building Apache Ozone HDDS RocksDB Tools 2.1.0-SNAPSHOT          [15/50]
[INFO]   from hadoop-hdds/rocks-native/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-rocks-native ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-rocks-native ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/pom.xml
[INFO] 
[INFO] --- dependency:3.8.1:unpack (unpack-dependency) @ hdds-rocks-native ---
[INFO] Configured Artifact: org.rocksdb:rocksdbjni:?:jar
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-rocks-native ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- exec:3.5.1:java (set-property) @ hdds-rocks-native ---
[INFO] 
[INFO] --- properties:1.2.1:read-project-properties (read-property-from-file) @ hdds-rocks-native ---
[WARNING] Unknown properties resource extension: 'txt' assume as: 'properties'
[INFO] Loading 1 properties from File: /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/propertyFile.txt
[INFO] 
[INFO] --- build-helper:3.6.1:cpu-count (get-cpu-count) @ hdds-rocks-native ---
[INFO] CPU count: 4
[INFO] 
[INFO] --- download:1.9.0:wget (rocksdb source download) @ hdds-rocks-native ---
[INFO] 
[INFO] --- antrun:3.1.0:run (unzip-artifact) @ hdds-rocks-native ---
[INFO] Executing tasks
[INFO]     [untar] Expanding: /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/rocksdb/rocksdb-v7.7.3.tar.gz into /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/rocksdb
[INFO] Executed tasks
[INFO] 
[INFO] --- patch:1.1.1:apply (patch) @ hdds-rocks-native ---
[INFO] Applying patch: rocks-native.patch
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-rocks-native ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-rocks-native ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-rocks-native ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-rocks-native ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- antrun:3.1.0:run (build-rocksjava) @ hdds-rocks-native ---
[INFO] Executing tasks
[INFO]      [exec] $DEBUG_LEVEL is 0
[INFO]      [exec] $DEBUG_LEVEL is 0
[INFO]      [exec]   CC       tools/raw_sst_file_reader.o
[INFO]      [exec]   CC       tools/raw_sst_file_iterator.o
[INFO]      [exec]   AR       librocksdb_tools.a
[INFO]      [exec] /usr/bin/ar: creating librocksdb_tools.a
[INFO] Executed tasks
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-rocks-native ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-rocks-native ---
[INFO] Compiling 7 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- antrun:3.1.0:run (build-rocks-tools) @ hdds-rocks-native ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/native/rocksdb
[INFO]      [copy] Copying 1 file to /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/native/rocksdb
[INFO]      [exec] -- The C compiler identification is GNU 13.3.0
[INFO]      [exec] -- The CXX compiler identification is GNU 13.3.0
[INFO]      [exec] -- Detecting C compiler ABI info
[INFO]      [exec] -- Detecting C compiler ABI info - done
[INFO]      [exec] -- Check for working C compiler: /usr/bin/cc - skipped
[INFO]      [exec] -- Detecting C compile features
[INFO]      [exec] -- Detecting C compile features - done
[INFO]      [exec] -- Detecting CXX compiler ABI info
[INFO]      [exec] -- Detecting CXX compiler ABI info - done
[INFO]      [exec] -- Check for working CXX compiler: /usr/bin/c++ - skipped
[INFO]      [exec] -- Detecting CXX compile features
[INFO]      [exec] -- Detecting CXX compile features - done
[INFO]      [exec] -- Found JNI: /opt/hostedtoolcache/Java_Temurin-Hotspot_jdk/21.0.7-6/x64/include  found components: AWT JVM
[INFO]      [exec] -- Configuring done (0.9s)
[INFO]      [exec] -- Generating done (0.0s)
[INFO]      [exec] -- Build files have been written to: /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/native/rocksdb
[INFO]      [exec] [ 33%] Building CXX object CMakeFiles/ozone_rocksdb_tools.dir/main/native/ManagedRawSSTFileReader.cpp.o
[INFO]      [exec] [ 66%] Building CXX object CMakeFiles/ozone_rocksdb_tools.dir/main/native/ManagedRawSSTFileIterator.cpp.o
[INFO]      [exec] [100%] Linking CXX shared library libozone_rocksdb_tools.so
[INFO]      [exec] [100%] Built target ozone_rocksdb_tools
[INFO]    [delete] Deleting directory /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/rocksdb/rocksdb-7.7.3
[INFO] Executed tasks
[INFO] 
[INFO] --- antrun:3.1.0:run (copy-lib-file) @ hdds-rocks-native ---
[INFO] Executing tasks
[INFO]      [copy] Copying 2 files to /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/classes
[INFO] Executed tasks
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-rocks-native ---
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-rocks-native ---
[INFO] Compiling 3 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-rocks-native ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-rocks-native ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-rocks-native ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-rocks-native ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/hdds-rocks-native-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-rocks-native ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/hdds-rocks-native-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-rocks-native ---
[INFO] No dependency problems found
[INFO] 
[INFO] -------------< org.apache.ozone:rocksdb-checkpoint-differ >-------------
[INFO] Building Apache Ozone Checkpoint Differ for RocksDB 2.1.0-SNAPSHOT [16/50]
[INFO]   from hadoop-hdds/rocksdb-checkpoint-differ/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ rocksdb-checkpoint-differ ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ rocksdb-checkpoint-differ ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ rocksdb-checkpoint-differ ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ rocksdb-checkpoint-differ ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ rocksdb-checkpoint-differ ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ rocksdb-checkpoint-differ ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ rocksdb-checkpoint-differ ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ rocksdb-checkpoint-differ ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ rocksdb-checkpoint-differ ---
[INFO] Compiling 12 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ rocksdb-checkpoint-differ ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ rocksdb-checkpoint-differ ---
[INFO] Compiling 5 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/src/test/java/org/apache/ozone/rocksdiff/TestRocksDBCheckpointDiffer.java: /home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/src/test/java/org/apache/ozone/rocksdiff/TestRocksDBCheckpointDiffer.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/src/test/java/org/apache/ozone/rocksdiff/TestRocksDBCheckpointDiffer.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ rocksdb-checkpoint-differ ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ rocksdb-checkpoint-differ ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ rocksdb-checkpoint-differ ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ rocksdb-checkpoint-differ ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/rocksdb-checkpoint-differ-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ rocksdb-checkpoint-differ ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/rocksdb-checkpoint-differ-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ rocksdb-checkpoint-differ ---
[INFO] No dependency problems found
[INFO] 
[INFO] ---------------< org.apache.ozone:hdds-server-framework >---------------
[INFO] Building Apache Ozone HDDS Server Framework 2.1.0-SNAPSHOT       [17/50]
[INFO]   from hadoop-hdds/framework/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-server-framework ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/framework/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-server-framework ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/framework/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-server-framework ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-server-framework ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-server-framework ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-server-framework ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-server-framework ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-server-framework ---
[INFO] Copying 35 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-server-framework ---
[INFO] Compiling 266 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/protocolPB/ReconfigureProtocolClientSideTranslatorPB.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/protocolPB/ReconfigureProtocolClientSideTranslatorPB.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/security/symmetric/ManagedSecretKey.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/security/symmetric/ManagedSecretKey.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-server-framework ---
[INFO] Copying 6 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-server-framework ---
[INFO] Compiling 101 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[WARNING] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/upgrade/TestHDDSLayoutVersionManager.java:[54,32] non-varargs call of varargs method with inexact argument type for last parameter;
  cast to java.lang.Object for a varargs call
  cast to java.lang.Object[] for a non-varargs call and to suppress this warning
[WARNING] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/upgrade/TestHDDSLayoutVersionManager.java:[67,32] non-varargs call of varargs method with inexact argument type for last parameter;
  cast to java.lang.Object for a varargs call
  cast to java.lang.Object[] for a non-varargs call and to suppress this warning
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/ozone/upgrade/TestAbstractLayoutVersionManager.java: /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/ozone/upgrade/TestAbstractLayoutVersionManager.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/ozone/upgrade/TestAbstractLayoutVersionManager.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/symmetric/TestSecretKeyManager.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/symmetric/TestSecretKeyManager.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-server-framework ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-server-framework ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-server-framework ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-server-framework ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/framework/target/hdds-server-framework-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-server-framework ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/framework/target/hdds-server-framework-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-server-framework ---
[INFO] No dependency problems found
[INFO] 
[INFO] ---------------------< org.apache.ozone:hdds-docs >---------------------
[INFO] Building Apache Ozone Documentation 2.1.0-SNAPSHOT               [18/50]
[INFO]   from hadoop-hdds/docs/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-docs ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/docs/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-docs ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/docs/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-docs ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/docs/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-docs ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-docs ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-docs ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-docs ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-docs ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/docs/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-docs ---
[INFO] No sources to compile
[INFO] 
[INFO] --- exec:3.5.1:exec (default) @ hdds-docs ---
mkdir: created directory '/home/runner/work/ozone/ozone/.dev-tools'
mkdir: created directory '/home/runner/work/ozone/ozone/.dev-tools/hugo'
~/work/ozone/ozone/.dev-tools/hugo ~/work/ozone/ozone
Installed hugo in /home/runner/work/ozone/ozone/.dev-tools/hugo
~/work/ozone/ozone
Start building sites  
hugo v0.141.0-e7bd51698e5c3778a86003018702b1a7dcb9559a linux/amd64 BuildDate=2025-01-16T13:11:18Z VendorInfo=gohugoio


                   | EN  | ZH  
-------------------+-----+-----
  Pages            | 122 | 63  
  Paginator pages  |   0 |  0  
  Non-page files   |  35 | 35  
  Static files     |  32 | 32  
  Processed images |   0 |  0  
  Aliases          |   1 |  0  
  Cleaned          |   0 |  0  

Total in 353 ms
/home/runner/work/ozone/ozone
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-docs ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-docs ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-docs ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-docs ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-docs ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-docs ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/docs/target/hdds-docs-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-docs ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-docs ---
[INFO] No dependency problems found
[INFO] 
[INFO] --------------< org.apache.ozone:hdds-container-service >---------------
[INFO] Building Apache Ozone HDDS Container Service 2.1.0-SNAPSHOT      [19/50]
[INFO]   from hadoop-hdds/container-service/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-container-service ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-container-service ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/container-service/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-container-service ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-container-service ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-container-service ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-container-service ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-container-service ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-container-service ---
[INFO] Copying 7 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-container-service ---
[INFO] Compiling 276 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/HddsDatanodeClientProtocolServer.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/HddsDatanodeClientProtocolServer.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/states/datanode/RunningDatanodeState.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/states/datanode/RunningDatanodeState.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-container-service ---
[INFO] Copying 16 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-container-service ---
[INFO] Compiling 116 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/ContainerTestUtils.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/ContainerTestUtils.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/SCMTestUtils.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/SCMTestUtils.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-container-service ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.ozone.container.stream.TestStreamingServer
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.916 s -- in org.apache.hadoop.ozone.container.stream.TestStreamingServer
[INFO] Running org.apache.hadoop.ozone.container.stream.TestDirstreamClientHandler
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.205 s -- in org.apache.hadoop.ozone.container.stream.TestDirstreamClientHandler
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMetadataInspector
[INFO] Tests run: 72, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.218 s -- in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMetadataInspector
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerCheck
[INFO] Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.389 s -- in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerCheck
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueHandler
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.758 s -- in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueHandler
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.helpers.TestChunkUtils
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.444 s -- in org.apache.hadoop.ozone.container.keyvalue.helpers.TestChunkUtils
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer
[WARNING] Tests run: 185, Failures: 0, Errors: 0, Skipped: 6, Time elapsed: 56.87 s -- in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainer
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueHandlerWithUnhealthyContainer
[INFO] Tests run: 68, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.182 s -- in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueHandlerWithUnhealthyContainer
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueBlockIterator
[INFO] Tests run: 96, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.655 s -- in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueBlockIterator
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMarkUnhealthy
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.719 s -- in org.apache.hadoop.ozone.container.keyvalue.TestKeyValueContainerMarkUnhealthy
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.TestTarContainerPacker
[INFO] Tests run: 200, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.765 s -- in org.apache.hadoop.ozone.container.keyvalue.TestTarContainerPacker
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.impl.TestKeyValueStreamDataChannel
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.578 s -- in org.apache.hadoop.ozone.container.keyvalue.impl.TestKeyValueStreamDataChannel
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.impl.TestChunkManagerDummyImpl
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.986 s -- in org.apache.hadoop.ozone.container.keyvalue.impl.TestChunkManagerDummyImpl
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.impl.TestBlockManagerImpl
[WARNING] Tests run: 48, Failures: 0, Errors: 0, Skipped: 12, Time elapsed: 5.921 s -- in org.apache.hadoop.ozone.container.keyvalue.impl.TestBlockManagerImpl
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.impl.TestFilePerBlockStrategy
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.811 s -- in org.apache.hadoop.ozone.container.keyvalue.impl.TestFilePerBlockStrategy
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.impl.TestFilePerChunkStrategy
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.365 s -- in org.apache.hadoop.ozone.container.keyvalue.impl.TestFilePerChunkStrategy
[INFO] Running org.apache.hadoop.ozone.container.keyvalue.impl.TestMappedBufferManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.131 s -- in org.apache.hadoop.ozone.container.keyvalue.impl.TestMappedBufferManager
[INFO] Running org.apache.hadoop.ozone.container.upgrade.TestDataNodeStartupSlvLessThanMlv
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.716 s -- in org.apache.hadoop.ozone.container.upgrade.TestDataNodeStartupSlvLessThanMlv
[INFO] Running org.apache.hadoop.ozone.container.upgrade.TestDatanodeUpgradeToSchemaV3
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 76.91 s -- in org.apache.hadoop.ozone.container.upgrade.TestDatanodeUpgradeToSchemaV3
[INFO] Running org.apache.hadoop.ozone.container.upgrade.TestDatanodeUpgradeToHBaseSupport
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.405 s -- in org.apache.hadoop.ozone.container.upgrade.TestDatanodeUpgradeToHBaseSupport
[INFO] Running org.apache.hadoop.ozone.container.common.TestDatanodeStoreCache
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.698 s -- in org.apache.hadoop.ozone.container.common.TestDatanodeStoreCache
[INFO] Running org.apache.hadoop.ozone.container.common.report.TestReportManager
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.348 s -- in org.apache.hadoop.ozone.container.common.report.TestReportManager
[INFO] Running org.apache.hadoop.ozone.container.common.report.TestReportPublisher
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.157 s -- in org.apache.hadoop.ozone.container.common.report.TestReportPublisher
[INFO] Running org.apache.hadoop.ozone.container.common.report.TestReportPublisherFactory
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.247 s -- in org.apache.hadoop.ozone.container.common.report.TestReportPublisherFactory
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestVolumeSet
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.182 s -- in org.apache.hadoop.ozone.container.common.volume.TestVolumeSet
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestDbVolume
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.826 s -- in org.apache.hadoop.ozone.container.common.volume.TestDbVolume
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestPeriodicVolumeChecker
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.286 s -- in org.apache.hadoop.ozone.container.common.volume.TestPeriodicVolumeChecker
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestStorageVolumeHealthChecks
[INFO] Tests run: 29, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.780 s -- in org.apache.hadoop.ozone.container.common.volume.TestStorageVolumeHealthChecks
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestVolumeIOStatsWithPrometheusSink
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.507 s -- in org.apache.hadoop.ozone.container.common.volume.TestVolumeIOStatsWithPrometheusSink
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestVolumeSetDiskChecks
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.478 s -- in org.apache.hadoop.ozone.container.common.volume.TestVolumeSetDiskChecks
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestRoundRobinVolumeChoosingPolicy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.433 s -- in org.apache.hadoop.ozone.container.common.volume.TestRoundRobinVolumeChoosingPolicy
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestCapacityVolumeChoosingPolicy
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.523 s -- in org.apache.hadoop.ozone.container.common.volume.TestCapacityVolumeChoosingPolicy
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestStorageVolumeChecker
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.586 s -- in org.apache.hadoop.ozone.container.common.volume.TestStorageVolumeChecker
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestReservedVolumeSpace
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.605 s -- in org.apache.hadoop.ozone.container.common.volume.TestReservedVolumeSpace
[INFO] Running org.apache.hadoop.ozone.container.common.volume.TestHddsVolume
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.149 s -- in org.apache.hadoop.ozone.container.common.volume.TestHddsVolume
[INFO] Running org.apache.hadoop.ozone.container.common.TestDatanodeStateMachine
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.383 s -- in org.apache.hadoop.ozone.container.common.TestDatanodeStateMachine
[INFO] Running org.apache.hadoop.ozone.container.common.TestSchemaTwoBackwardsCompatibility
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.539 s -- in org.apache.hadoop.ozone.container.common.TestSchemaTwoBackwardsCompatibility
[INFO] Running org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility
[ERROR] Tests run: 20, Failures: 0, Errors: 12, Skipped: 0, Time elapsed: 3.721 s <<< FAILURE! -- in org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility
[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks(String)[1] -- Time elapsed: 0.893 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks(TestSchemaOneBackwardsCompatibility.java:539)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 50 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks(String)[2] -- Time elapsed: 0.082 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks(TestSchemaOneBackwardsCompatibility.java:539)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 50 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testBlockIteration(String)[1] -- Time elapsed: 0.062 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.countDeletedBlocks(TestSchemaOneBackwardsCompatibility.java:635)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testBlockIteration(TestSchemaOneBackwardsCompatibility.java:180)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 51 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testBlockIteration(String)[2] -- Time elapsed: 0.050 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.countDeletedBlocks(TestSchemaOneBackwardsCompatibility.java:635)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testBlockIteration(TestSchemaOneBackwardsCompatibility.java:180)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 51 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata(String)[1] -- Time elapsed: 0.055 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.getUsedBytesAndBlockCount(KeyValueContainerUtil.java:403)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.populateContainerMetadata(KeyValueContainerUtil.java:347)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.parseKVContainerData(KeyValueContainerUtil.java:274)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.parseKVContainerData(KeyValueContainerUtil.java:206)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.newKvData(TestSchemaOneBackwardsCompatibility.java:613)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata(TestSchemaOneBackwardsCompatibility.java:261)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=13) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 50 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:24002)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 55 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata(String)[2] -- Time elapsed: 0.067 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.getUsedBytesAndBlockCount(KeyValueContainerUtil.java:403)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.populateContainerMetadata(KeyValueContainerUtil.java:347)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.parseKVContainerData(KeyValueContainerUtil.java:274)
	at org.apache.hadoop.ozone.container.keyvalue.helpers.KeyValueContainerUtil.parseKVContainerData(KeyValueContainerUtil.java:206)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.newKvData(TestSchemaOneBackwardsCompatibility.java:613)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata(TestSchemaOneBackwardsCompatibility.java:261)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=13) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 50 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:24002)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 55 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadBlockData(String)[1] -- Time elapsed: 0.051 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadBlockData(TestSchemaOneBackwardsCompatibility.java:438)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=8) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 45 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:133)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:630)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:23953)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 50 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadBlockData(String)[2] -- Time elapsed: 0.056 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadBlockData(TestSchemaOneBackwardsCompatibility.java:438)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=8) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 45 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:133)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:630)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:23953)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 50 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo(String)[1] -- Time elapsed: 0.138 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo(TestSchemaOneBackwardsCompatibility.java:362)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 50 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo(String)[2] -- Time elapsed: 0.055 s <<< ERROR!
org.apache.hadoop.hdds.utils.db.CodecException: Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:75)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:46)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.convert(TypedTable.java:481)
	at org.apache.hadoop.hdds.utils.db.TypedTable.getRangeKVs(TypedTable.java:458)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.DatanodeTable.getRangeKVs(DatanodeTable.java:117)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:109)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneDeletedBlocksTable.getRangeKVs(SchemaOneDeletedBlocksTable.java:46)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo(TestSchemaOneBackwardsCompatibility.java:362)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: While parsing a protocol message, the input ended unexpectedly in the middle of a field.  This could mean either that the input has been truncated or that an embedded message misreported its own length.
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.truncatedMessage(InvalidProtocolBufferException.java:115)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readRawLittleEndian64(CodedInputStream.java:1154)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readFixed64(CodedInputStream.java:774)
	at org.apache.ratis.thirdparty.com.google.protobuf.UnknownFieldSet$Builder.mergeFieldFrom(UnknownFieldSet.java:510)
	at org.apache.ratis.thirdparty.com.google.protobuf.GeneratedMessageV3$Builder.parseUnknownField(GeneratedMessageV3.java:887)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$Builder.mergeFrom(ContainerProtos.java:35718)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36008)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList$1.parsePartialFrom(ContainerProtos.java:36000)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$ChunkInfoList.parseFrom(ContainerProtos.java:35457)
	at org.apache.hadoop.ozone.container.metadata.SchemaOneChunkInfoListCodec.fromPersistedFormat(SchemaOneChunkInfoListCodec.java:73)
	... 50 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData(String)[1] -- Time elapsed: 0.069 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData(TestSchemaOneBackwardsCompatibility.java:493)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=8) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 45 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:133)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:630)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:23953)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 50 more

[ERROR] org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData(String)[2] -- Time elapsed: 0.059 s <<< ERROR!
java.lang.IllegalStateException: Failed next()
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:640)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.next(TypedTable.java:567)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:590)
	at org.apache.hadoop.ozone.container.metadata.AbstractDatanodeStore$KeyValueBlockIterator.hasNext(AbstractDatanodeStore.java:264)
	at org.apache.hadoop.ozone.container.common.TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData(TestSchemaOneBackwardsCompatibility.java:493)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:1024)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1708)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.apache.hadoop.hdds.utils.db.CodecException: Failed to deserialize rawData (length=8) for class org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:122)
	at org.apache.hadoop.hdds.utils.db.DelegatedCodec.fromPersistedFormat(DelegatedCodec.java:93)
	at org.apache.hadoop.hdds.utils.db.TypedTable.decodeValue(TypedTable.java:130)
	at org.apache.hadoop.hdds.utils.db.TypedTable.access$500(TypedTable.java:55)
	at org.apache.hadoop.hdds.utils.db.TypedTable$TypedTableIterator.convert(TypedTable.java:581)
	at org.apache.hadoop.hdds.utils.db.TypedTable$RawIterator.next(TypedTable.java:638)
	... 45 more
Caused by: org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException: Protocol message contained an invalid tag (zero).
	at org.apache.ratis.thirdparty.com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:133)
	at org.apache.ratis.thirdparty.com.google.protobuf.CodedInputStream$ArrayDecoder.readTag(CodedInputStream.java:630)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$Builder.mergeFrom(ContainerProtos.java:23953)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24746)
	at org.apache.hadoop.hdds.protocol.datanode.proto.ContainerProtos$BlockData$1.parsePartialFrom(ContainerProtos.java:24738)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parsePartialFrom(AbstractParser.java:158)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:191)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:203)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:208)
	at org.apache.ratis.thirdparty.com.google.protobuf.AbstractParser.parseFrom(AbstractParser.java:48)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:100)
	at org.apache.hadoop.hdds.utils.db.Proto3Codec.fromPersistedFormatImpl(Proto3Codec.java:34)
	at org.apache.hadoop.hdds.utils.db.Codec.fromPersistedFormat(Codec.java:119)
	... 50 more

[INFO] Running org.apache.hadoop.ozone.container.common.TestStaleRecoveringContainerScrubbingService
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.162 s -- in org.apache.hadoop.ozone.container.common.TestStaleRecoveringContainerScrubbingService
[INFO] Running org.apache.hadoop.ozone.container.common.TestContainerLayoutVersion
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.060 s -- in org.apache.hadoop.ozone.container.common.TestContainerLayoutVersion
[INFO] Running org.apache.hadoop.ozone.container.common.helpers.TestContainerUtils
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.140 s -- in org.apache.hadoop.ozone.container.common.helpers.TestContainerUtils
[INFO] Running org.apache.hadoop.ozone.container.common.helpers.TestDatanodeVersionFile
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.241 s -- in org.apache.hadoop.ozone.container.common.helpers.TestDatanodeVersionFile
[INFO] Running org.apache.hadoop.ozone.container.common.helpers.TestDatanodeIdYaml
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.896 s -- in org.apache.hadoop.ozone.container.common.helpers.TestDatanodeIdYaml
[INFO] Running org.apache.hadoop.ozone.container.common.helpers.TestBlockData
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.318 s -- in org.apache.hadoop.ozone.container.common.helpers.TestBlockData
[INFO] Running org.apache.hadoop.ozone.container.common.states.datanode.TestRunningDatanodeState
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.530 s -- in org.apache.hadoop.ozone.container.common.states.datanode.TestRunningDatanodeState
[INFO] Running org.apache.hadoop.ozone.container.common.states.endpoint.TestHeartbeatEndpointTask
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.298 s -- in org.apache.hadoop.ozone.container.common.states.endpoint.TestHeartbeatEndpointTask
[INFO] Running org.apache.hadoop.ozone.container.common.TestKeyValueContainerData
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.617 s -- in org.apache.hadoop.ozone.container.common.TestKeyValueContainerData
[INFO] Running org.apache.hadoop.ozone.container.common.interfaces.TestHandler
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.295 s -- in org.apache.hadoop.ozone.container.common.interfaces.TestHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerCommandHandler
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.946 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerCommandHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestClosePipelineCommandHandler
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.106 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestClosePipelineCommandHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestReconstructECContainersCommandHandler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.688 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestReconstructECContainersCommandHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestDeleteBlocksCommandHandler
[INFO] Tests run: 41, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.709 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestDeleteBlocksCommandHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestReplicateContainerCommandHandler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.606 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestReplicateContainerCommandHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCreatePipelineCommandHandler
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.895 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCreatePipelineCommandHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestDeleteContainerCommandHandler
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.426 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestDeleteContainerCommandHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.TestDatanodeConfiguration
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.416 s -- in org.apache.hadoop.ozone.container.common.statemachine.TestDatanodeConfiguration
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.TestStateContext
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.189 s -- in org.apache.hadoop.ozone.container.common.statemachine.TestStateContext
[INFO] Running org.apache.hadoop.ozone.container.common.transport.server.ratis.TestContainerStateMachineFollower
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.549 s -- in org.apache.hadoop.ozone.container.common.transport.server.ratis.TestContainerStateMachineFollower
[INFO] Running org.apache.hadoop.ozone.container.common.transport.server.ratis.TestContainerStateMachineLeader
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.453 s -- in org.apache.hadoop.ozone.container.common.transport.server.ratis.TestContainerStateMachineLeader
[INFO] Running org.apache.hadoop.ozone.container.common.utils.TestDiskCheckUtil
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.155 s -- in org.apache.hadoop.ozone.container.common.utils.TestDiskCheckUtil
[INFO] Running org.apache.hadoop.ozone.container.common.utils.TestStorageVolumeUtil
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.876 s -- in org.apache.hadoop.ozone.container.common.utils.TestStorageVolumeUtil
[INFO] Running org.apache.hadoop.ozone.container.common.utils.TestHddsVolumeUtil
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.346 s -- in org.apache.hadoop.ozone.container.common.utils.TestHddsVolumeUtil
[INFO] Running org.apache.hadoop.ozone.container.common.TestBlockDeletingService
[WARNING] Tests run: 56, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 18.94 s -- in org.apache.hadoop.ozone.container.common.TestBlockDeletingService
[INFO] Running org.apache.hadoop.ozone.container.common.TestContainerCache
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.027 s -- in org.apache.hadoop.ozone.container.common.TestContainerCache
[INFO] Running org.apache.hadoop.ozone.container.common.TestDatanodeLayOutVersion
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.044 s -- in org.apache.hadoop.ozone.container.common.TestDatanodeLayOutVersion
[INFO] Running org.apache.hadoop.ozone.container.common.impl.TestHddsDispatcher
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.705 s -- in org.apache.hadoop.ozone.container.common.impl.TestHddsDispatcher
[INFO] Running org.apache.hadoop.ozone.container.common.impl.TestContainerDataYaml
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.804 s -- in org.apache.hadoop.ozone.container.common.impl.TestContainerDataYaml
[INFO] Running org.apache.hadoop.ozone.container.common.impl.TestContainerSet
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.896 s -- in org.apache.hadoop.ozone.container.common.impl.TestContainerSet
[INFO] Running org.apache.hadoop.ozone.container.common.impl.TestContainerPersistence
[WARNING] Tests run: 176, Failures: 0, Errors: 0, Skipped: 8, Time elapsed: 16.19 s -- in org.apache.hadoop.ozone.container.common.impl.TestContainerPersistence
[INFO] Running org.apache.hadoop.ozone.container.common.impl.TestContainerDeletionChoosingPolicy
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.713 s -- in org.apache.hadoop.ozone.container.common.impl.TestContainerDeletionChoosingPolicy
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestBackgroundContainerMetadataScanner
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.300 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestBackgroundContainerMetadataScanner
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestContainerReader
[INFO] Tests run: 40, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.17 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestContainerReader
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestContainerScannerConfiguration
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.350 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestContainerScannerConfiguration
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestOnDemandContainerDataScanner
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.314 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestOnDemandContainerDataScanner
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.178 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestBackgroundContainerDataScanner
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.285 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestBackgroundContainerDataScanner
[INFO] Running org.apache.hadoop.ozone.container.replication.TestContainerImporter
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.941 s -- in org.apache.hadoop.ozone.container.replication.TestContainerImporter
[INFO] Running org.apache.hadoop.ozone.container.replication.TestReplicationSupervisor
[INFO] Tests run: 30, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.07 s -- in org.apache.hadoop.ozone.container.replication.TestReplicationSupervisor
[INFO] Running org.apache.hadoop.ozone.container.replication.TestSendContainerRequestHandler
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.714 s -- in org.apache.hadoop.ozone.container.replication.TestSendContainerRequestHandler
[INFO] Running org.apache.hadoop.ozone.container.replication.TestMeasuredReplicator
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.955 s -- in org.apache.hadoop.ozone.container.replication.TestMeasuredReplicator
[INFO] Running org.apache.hadoop.ozone.container.replication.TestReplicationConfig
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.375 s -- in org.apache.hadoop.ozone.container.replication.TestReplicationConfig
[INFO] Running org.apache.hadoop.ozone.container.replication.TestPushReplicator
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.506 s -- in org.apache.hadoop.ozone.container.replication.TestPushReplicator
[INFO] Running org.apache.hadoop.ozone.container.replication.TestGrpcContainerUploader
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.541 s -- in org.apache.hadoop.ozone.container.replication.TestGrpcContainerUploader
[INFO] Running org.apache.hadoop.ozone.container.replication.TestCopyContainerResponseStream
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.109 s -- in org.apache.hadoop.ozone.container.replication.TestCopyContainerResponseStream
[INFO] Running org.apache.hadoop.ozone.container.replication.TestCopyContainerCompression
[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.499 s -- in org.apache.hadoop.ozone.container.replication.TestCopyContainerCompression
[INFO] Running org.apache.hadoop.ozone.container.replication.ReplicationSupervisorSchedulingBenchmark
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.47 s -- in org.apache.hadoop.ozone.container.replication.ReplicationSupervisorSchedulingBenchmark
[INFO] Running org.apache.hadoop.ozone.container.replication.TestSendContainerOutputStream
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.253 s -- in org.apache.hadoop.ozone.container.replication.TestSendContainerOutputStream
[INFO] Running org.apache.hadoop.ozone.container.replication.TestGrpcReplicationService
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.394 s -- in org.apache.hadoop.ozone.container.replication.TestGrpcReplicationService
[INFO] Running org.apache.hadoop.ozone.container.replication.TestDownloadAndImportReplicator
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.635 s -- in org.apache.hadoop.ozone.container.replication.TestDownloadAndImportReplicator
[INFO] Running org.apache.hadoop.ozone.container.replication.TestSimpleContainerDownloader
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.628 s -- in org.apache.hadoop.ozone.container.replication.TestSimpleContainerDownloader
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   TestSchemaOneBackwardsCompatibility.testBlockIteration:180->countDeletedBlocks:635  Codec Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
[ERROR]   TestSchemaOneBackwardsCompatibility.testBlockIteration:180->countDeletedBlocks:635  Codec Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadBlockData:438  IllegalState Failed next()
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadBlockData:438  IllegalState Failed next()
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo:362  Codec Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadDeletedBlockChunkInfo:362  Codec Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks:539  Codec Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadDeletedBlocks:539  Codec Invalid chunk information. This data may have been written using datanode schema version one, which did not save chunk information.
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData:493  IllegalState Failed next()
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadDeletingBlockData:493  IllegalState Failed next()
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata:261->newKvData:613  IllegalState Failed next()
[ERROR]   TestSchemaOneBackwardsCompatibility.testReadWithoutMetadata:261->newKvData:613  IllegalState Failed next()
[INFO] 
[ERROR] Tests run: 1560, Failures: 0, Errors: 12, Skipped: 30
[INFO] 
[INFO] 
[INFO] ------------------< org.apache.ozone:hdds-crypto-api >------------------
[INFO] Building Apache Ozone HDDS Crypto 2.1.0-SNAPSHOT                 [20/50]
[INFO]   from hadoop-hdds/crypto-api/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-crypto-api ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/crypto-api/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-crypto-api ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/crypto-api/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-crypto-api ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/crypto-api/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-crypto-api ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-crypto-api ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-crypto-api ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-crypto-api ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-crypto-api ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/crypto-api/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-crypto-api ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-crypto-api ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-crypto-api ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-crypto-api ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-crypto-api ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-crypto-api ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-crypto-api ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/crypto-api/target/hdds-crypto-api-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-crypto-api ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-crypto-api ---
[INFO] No dependency problems found
[INFO] 
[INFO] ----------------< org.apache.ozone:hdds-crypto-default >----------------
[INFO] Building Apache Ozone HDDS Crypto - Default 2.1.0-SNAPSHOT       [21/50]
[INFO]   from hadoop-hdds/crypto-default/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-crypto-default ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/crypto-default/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-crypto-default ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/crypto-default/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-crypto-default ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/crypto-default/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-crypto-default ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-crypto-default ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-crypto-default ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-crypto-default ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-crypto-default ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/crypto-default/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-crypto-default ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-crypto-default ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-crypto-default ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-crypto-default ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-crypto-default ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-crypto-default ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ hdds-crypto-default ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-hdds/crypto-default/target/hdds-crypto-default-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ hdds-crypto-default ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ hdds-crypto-default ---
[INFO] No dependency problems found
[INFO] 
[INFO] ------------------< org.apache.ozone:hdds-server-scm >------------------
[INFO] Building Apache Ozone HDDS SCM Server 2.1.0-SNAPSHOT             [22/50]
[INFO]   from hadoop-hdds/server-scm/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ hdds-server-scm ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ hdds-server-scm ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ hdds-server-scm ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ hdds-server-scm ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ hdds-server-scm ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ hdds-server-scm ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ hdds-server-scm ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ hdds-server-scm ---
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ hdds-server-scm ---
[INFO] Compiling 313 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[WARNING] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMHANodeDetails.java:[325,50] non-varargs call of varargs method with inexact argument type for last parameter;
  cast to java.lang.Object for a varargs call
  cast to java.lang.Object[] for a non-varargs call and to suppress this warning
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/server/SCMDatanodeProtocolServer.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/server/SCMDatanodeProtocolServer.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/server/SCMDatanodeHeartbeatDispatcher.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/server/SCMDatanodeHeartbeatDispatcher.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ hdds-server-scm ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/../../hdds/common/src/main/resources
[INFO] Copying 7 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ hdds-server-scm ---
[INFO] Compiling 162 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/HddsTestUtils.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/HddsTestUtils.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/block/TestDeletedBlockLog.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/block/TestDeletedBlockLog.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ hdds-server-scm ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdds.scm.container.report.TestContainerReportValidator
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.335 s -- in org.apache.hadoop.hdds.scm.container.report.TestContainerReportValidator
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerStateManager
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.503 s -- in org.apache.hadoop.hdds.scm.container.TestContainerStateManager
[INFO] Running org.apache.hadoop.hdds.scm.container.TestUnknownContainerReport
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.611 s -- in org.apache.hadoop.hdds.scm.container.TestUnknownContainerReport
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.572 s -- in org.apache.hadoop.hdds.scm.container.TestContainerManagerImpl
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerReportHandler
[INFO] Tests run: 87, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.09 s -- in org.apache.hadoop.hdds.scm.container.TestContainerReportHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.states.TestContainerAttribute
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.263 s -- in org.apache.hadoop.hdds.scm.container.states.TestContainerAttribute
[INFO] Running org.apache.hadoop.hdds.scm.container.balancer.TestMoveManager
[INFO] Tests run: 19, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.668 s -- in org.apache.hadoop.hdds.scm.container.balancer.TestMoveManager
[INFO] Running org.apache.hadoop.hdds.scm.container.balancer.TestContainerBalancerTask
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.043 s -- in org.apache.hadoop.hdds.scm.container.balancer.TestContainerBalancerTask
[INFO] Running org.apache.hadoop.hdds.scm.container.balancer.TestFindTargetStrategy
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.723 s -- in org.apache.hadoop.hdds.scm.container.balancer.TestFindTargetStrategy
[INFO] Running org.apache.hadoop.hdds.scm.container.balancer.TestContainerBalancer
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.308 s -- in org.apache.hadoop.hdds.scm.container.balancer.TestContainerBalancer
[INFO] Running org.apache.hadoop.hdds.scm.container.balancer.TestContainerBalancerStatusInfo
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.438 s -- in org.apache.hadoop.hdds.scm.container.balancer.TestContainerBalancerStatusInfo
[INFO] Running org.apache.hadoop.hdds.scm.container.balancer.TestContainerBalancerDatanodeNodeLimit
[INFO] Tests run: 288, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.78 s -- in org.apache.hadoop.hdds.scm.container.balancer.TestContainerBalancerDatanodeNodeLimit
[INFO] Running org.apache.hadoop.hdds.scm.container.TestCloseContainerEventHandler
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.728 s -- in org.apache.hadoop.hdds.scm.container.TestCloseContainerEventHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.TestIncrementalContainerReportHandler
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.15 s -- in org.apache.hadoop.hdds.scm.container.TestIncrementalContainerReportHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestECContainerReplicaCount
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.381 s -- in org.apache.hadoop.hdds.scm.container.replication.TestECContainerReplicaCount
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestQuasiClosedStuckOverReplicationHandler
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.688 s -- in org.apache.hadoop.hdds.scm.container.replication.TestQuasiClosedStuckOverReplicationHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestRatisContainerReplicaCount
[INFO] Tests run: 49, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.443 s -- in org.apache.hadoop.hdds.scm.container.replication.TestRatisContainerReplicaCount
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestECMisReplicationCheckHandler
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.228 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestECMisReplicationCheckHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestOpenContainerHandler
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.373 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestOpenContainerHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestClosingContainerHandler
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.845 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestClosingContainerHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestClosedWithUnhealthyReplicasHandler
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.356 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestClosedWithUnhealthyReplicasHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestRatisReplicationCheckHandler
[INFO] Tests run: 34, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.655 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestRatisReplicationCheckHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestRatisUnhealthyReplicationCheckHandler
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.379 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestRatisUnhealthyReplicationCheckHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestMismatchedReplicasHandler
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.330 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestMismatchedReplicasHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestQuasiClosedStuckReplicationCheck
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.316 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestQuasiClosedStuckReplicationCheck
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestVulnerableUnhealthyReplicasHandler
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.353 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestVulnerableUnhealthyReplicasHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestEmptyContainerHandler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.303 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestEmptyContainerHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestQuasiClosedContainerHandler
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.348 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestQuasiClosedContainerHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestECReplicationCheckHandler
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.343 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestECReplicationCheckHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.health.TestDeletingContainerHandler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.326 s -- in org.apache.hadoop.hdds.scm.container.replication.health.TestDeletingContainerHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestQuasiClosedStuckReplicaCount
[INFO] Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.324 s -- in org.apache.hadoop.hdds.scm.container.replication.TestQuasiClosedStuckReplicaCount
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestQuasiClosedStuckUnderReplicationHandler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.348 s -- in org.apache.hadoop.hdds.scm.container.replication.TestQuasiClosedStuckUnderReplicationHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerUtil
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.471 s -- in org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerUtil
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerMetrics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.809 s -- in org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerMetrics
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerEventHandler
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.478 s -- in org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerEventHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestUnderReplicatedProcessor
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.576 s -- in org.apache.hadoop.hdds.scm.container.replication.TestUnderReplicatedProcessor
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestRatisUnderReplicationHandler
[INFO] Tests run: 26, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.101 s -- in org.apache.hadoop.hdds.scm.container.replication.TestRatisUnderReplicationHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestDatanodeCommandCountUpdatedHandler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.279 s -- in org.apache.hadoop.hdds.scm.container.replication.TestDatanodeCommandCountUpdatedHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerScenarios
[INFO] Tests run: 37, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.384 s -- in org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerScenarios
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestECUnderReplicationHandler
[INFO] Tests run: 37, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.411 s -- in org.apache.hadoop.hdds.scm.container.replication.TestECUnderReplicationHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestReplicationManager
[INFO] Tests run: 48, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.477 s -- in org.apache.hadoop.hdds.scm.container.replication.TestReplicationManager
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestRatisOverReplicationHandler
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.750 s -- in org.apache.hadoop.hdds.scm.container.replication.TestRatisOverReplicationHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestOverReplicatedProcessor
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.528 s -- in org.apache.hadoop.hdds.scm.container.replication.TestOverReplicatedProcessor
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestContainerReplicaPendingOps
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.927 s -- in org.apache.hadoop.hdds.scm.container.replication.TestContainerReplicaPendingOps
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestECOverReplicationHandler
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.703 s -- in org.apache.hadoop.hdds.scm.container.replication.TestECOverReplicationHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestRatisMisReplicationHandler
[INFO] Tests run: 27, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.586 s -- in org.apache.hadoop.hdds.scm.container.replication.TestRatisMisReplicationHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestECMisReplicationHandler
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.513 s -- in org.apache.hadoop.hdds.scm.container.replication.TestECMisReplicationHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerActionsHandler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.307 s -- in org.apache.hadoop.hdds.scm.container.TestContainerActionsHandler
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerReplica
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.254 s -- in org.apache.hadoop.hdds.scm.container.TestContainerReplica
[INFO] Running org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementRandom
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.055 s -- in org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementRandom
[INFO] Running org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementCapacity
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.273 s -- in org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementCapacity
[INFO] Running org.apache.hadoop.hdds.scm.container.placement.algorithms.TestContainerPlacementStatusDefault
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.060 s -- in org.apache.hadoop.hdds.scm.container.placement.algorithms.TestContainerPlacementStatusDefault
[INFO] Running org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementRackScatter
[WARNING] Tests run: 99, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 4.539 s -- in org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementRackScatter
[INFO] Running org.apache.hadoop.hdds.scm.container.placement.algorithms.TestContainerPlacementFactory
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.098 s -- in org.apache.hadoop.hdds.scm.container.placement.algorithms.TestContainerPlacementFactory
[INFO] Running org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementRackAware
[WARNING] Tests run: 130, Failures: 0, Errors: 0, Skipped: 16, Time elapsed: 4.744 s -- in org.apache.hadoop.hdds.scm.container.placement.algorithms.TestSCMContainerPlacementRackAware
[INFO] Running org.apache.hadoop.ozone.container.common.TestEndPoint
[INFO] Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.389 s -- in org.apache.hadoop.ozone.container.common.TestEndPoint
[INFO] Running org.apache.hadoop.ozone.container.placement.TestDatanodeMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.080 s -- in org.apache.hadoop.ozone.container.placement.TestDatanodeMetrics
[INFO] Running org.apache.hadoop.ozone.container.placement.TestContainerPlacement
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.28 s -- in org.apache.hadoop.ozone.container.placement.TestContainerPlacement
[INFO] 
[INFO] Results:
[INFO] 
[WARNING] Tests run: 1218, Failures: 0, Errors: 0, Skipped: 19
[INFO] 
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ hdds-server-scm ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/classes/hdds-server-scm.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ hdds-server-scm ---
[INFO] 
[INFO] -----------------------< org.apache.ozone:ozone >-----------------------
[INFO] Building Apache Ozone 2.1.0-SNAPSHOT                             [23/50]
[INFO]   from hadoop-ozone/pom.xml
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/target/ozone-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone ---
[INFO] Skipping pom project
[INFO] 
[INFO] --------------< org.apache.ozone:ozone-interface-client >---------------
[INFO] Building Apache Ozone Client Interface 2.1.0-SNAPSHOT            [24/50]
[INFO]   from hadoop-ozone/interface-client/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-interface-client ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-interface-client ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-interface-client ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc-OmGrpc) @ ozone-interface-client ---
[INFO] Compiling 4 proto file(s) to /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/generated-sources/protobuf/java
[INFO] 
[INFO] --- protobuf:0.6.1:compile-custom (compile-protoc-OmGrpc) @ ozone-interface-client ---
[INFO] Compiling 4 proto file(s) to /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/generated-sources/protobuf/java
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc3) @ ozone-interface-client ---
[INFO] Compiling 4 proto file(s) to /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/generated-sources/protobuf/java/proto3
[INFO] 
[INFO] --- antrun:3.1.0:run (default) @ ozone-interface-client ---
[INFO] Executing tasks
[INFO]      [move] Moving 4 files to /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/generated-sources/protobuf
[INFO] Executed tasks
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-interface-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-interface-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-interface-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-interface-client ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-interface-client ---
[INFO] Copying 1 resource
[INFO] Copying 4 resources
[INFO] Copying 4 resources
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-interface-client ---
[INFO] Compiling 11 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/generated-sources/protobuf/java/org/apache/hadoop/ozone/protocol/proto3/OzoneManagerProtocolProtos.java: /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/generated-sources/protobuf/java/org/apache/hadoop/ozone/protocol/proto3/OzoneManagerProtocolProtos.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/generated-sources/protobuf/java/org/apache/hadoop/ozone/protocol/proto3/OzoneManagerProtocolProtos.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc-OmGrpc) @ ozone-interface-client ---
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile-custom (compile-protoc-OmGrpc) @ ozone-interface-client ---
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc3) @ ozone-interface-client ---
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-interface-client ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-interface-client ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-interface-client ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-interface-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-interface-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-interface-client ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/ozone-interface-client-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-interface-client ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-interface-client ---
[INFO] No dependency problems found
[INFO] 
[INFO] --- proto-backwards-compatibility:1.0.7:backwards-compatibility-check (default) @ ozone-interface-client ---
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/protolock-bin/protolock status --lockdir=/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/classes
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/protolock-bin/protolock commit --lockdir=/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/classes
[INFO] Backwards compatibility check passed.
[INFO] 
[INFO] -------------------< org.apache.ozone:ozone-common >--------------------
[INFO] Building Apache Ozone Common 2.1.0-SNAPSHOT                      [25/50]
[INFO]   from hadoop-ozone/common/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-common ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/common/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-common ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/common/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-common ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/common/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-common ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- hadoops:3.4.1:version-info (version-info) @ ozone-common ---
[INFO] SCM: GIT
[INFO] Computed MD5: 872ffdbe287e7801b41b162576aa59f
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-common ---
[INFO] Copying 0 resource
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] The encoding used to copy filtered properties files have not been set. This means that the same encoding will be used to copy filtered properties files as when copying other filtered resources. This might not be what you want! Run your build with --debug to see which files might be affected. Read more at https://maven.apache.org/plugins/maven-resources-plugin/examples/filtering-properties-files.html
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-common ---
[INFO] Compiling 176 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/acl/RequestContext.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/security/acl/RequestContext.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/lock/OzoneManagerLock.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/common/src/main/java/org/apache/hadoop/ozone/om/lock/OzoneManagerLock.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-common ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-common ---
[INFO] Compiling 36 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/helpers/TestOmKeyLocationInfoGroup.java: /home/runner/work/ozone/ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/helpers/TestOmKeyLocationInfoGroup.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/helpers/TestOmKeyLocationInfoGroup.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/ha/TestOMFailoverProxyProvider.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/ha/TestOMFailoverProxyProvider.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-common ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-common ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-common ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-common ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/common/target/ozone-common-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-common ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/common/target/ozone-common-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-common ---
[INFO] No dependency problems found
[INFO] 
[INFO] -------------------< org.apache.ozone:ozone-client >--------------------
[INFO] Building Apache Ozone Client 2.1.0-SNAPSHOT                      [26/50]
[INFO]   from hadoop-ozone/client/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-client ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/client/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-client ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/client/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-client ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/client/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-client ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-client ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-client ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/client/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-client ---
[INFO] Compiling 50 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/ObjectStore.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/ObjectStore.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/OzoneBucket.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/OzoneBucket.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-client ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/client/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-client ---
[INFO] Compiling 22 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/client/src/test/java/org/apache/hadoop/ozone/client/TestOzoneClient.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/client/src/test/java/org/apache/hadoop/ozone/client/TestOzoneClient.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/client/src/test/java/org/apache/hadoop/ozone/client/MockDatanodeStorage.java: /home/runner/work/ozone/ozone/hadoop-ozone/client/src/test/java/org/apache/hadoop/ozone/client/MockDatanodeStorage.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/client/src/test/java/org/apache/hadoop/ozone/client/MockDatanodeStorage.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-client ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-client ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-client ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/client/target/ozone-client-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-client ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/client/target/ozone-client-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-client ---
[INFO] No dependency problems found
[INFO] 
[INFO] --------------< org.apache.ozone:ozone-filesystem-common >--------------
[INFO] Building Apache Ozone FileSystem Common 2.1.0-SNAPSHOT           [27/50]
[INFO]   from hadoop-ozone/ozonefs-common/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-filesystem-common ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-filesystem-common ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-filesystem-common ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-filesystem-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-filesystem-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-filesystem-common ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-filesystem-common ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-filesystem-common ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-filesystem-common ---
[INFO] Compiling 31 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/BasicOzoneFileSystem.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/OzoneDelegationTokenRenewer.java: /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/OzoneDelegationTokenRenewer.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/main/java/org/apache/hadoop/fs/ozone/OzoneDelegationTokenRenewer.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-filesystem-common ---
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-filesystem-common ---
[INFO] Compiling 5 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/test/java/org/apache/hadoop/fs/ozone/TestBasicOzoneFileSystems.java: /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/test/java/org/apache/hadoop/fs/ozone/TestBasicOzoneFileSystems.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/src/test/java/org/apache/hadoop/fs/ozone/TestBasicOzoneFileSystems.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-filesystem-common ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-filesystem-common ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-filesystem-common ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-filesystem-common ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/ozone-filesystem-common-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-filesystem-common ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/ozone-filesystem-common-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-filesystem-common ---
[INFO] No dependency problems found
[INFO] 
[INFO] -----------------< org.apache.ozone:ozone-filesystem >------------------
[INFO] Building Apache Ozone FileSystem 2.1.0-SNAPSHOT                  [28/50]
[INFO]   from hadoop-ozone/ozonefs/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-filesystem ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-filesystem ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-filesystem ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-filesystem ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-filesystem ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-filesystem ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-filesystem ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-filesystem ---
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-filesystem ---
[INFO] Compiling 7 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- dependency:3.8.1:list (deplist) @ ozone-filesystem ---
[INFO] Can't extract module name from hadoop-shaded-protobuf_3_25-1.4.0.jar: hadoop.shaded.protobuf.3.25: Invalid module name: '3' is not a Java identifier
[INFO] Can't extract module name from hdds-interface-admin-2.1.0-SNAPSHOT.jar: hdds.interface.admin: Invalid module name: 'interface' is not a Java identifier
[INFO] Can't extract module name from hdds-interface-client-2.1.0-SNAPSHOT.jar: hdds.interface.client: Invalid module name: 'interface' is not a Java identifier
[INFO] Can't extract module name from ozone-interface-client-2.1.0-SNAPSHOT.jar: ozone.interface.client: Invalid module name: 'interface' is not a Java identifier
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-filesystem ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-filesystem ---
[INFO] No sources to compile
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-filesystem ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-filesystem ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-filesystem ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-filesystem ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/ozone-filesystem-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-filesystem ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/ozone-filesystem-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-filesystem ---
[INFO] No dependency problems found
[INFO] 
[INFO] ------------------< org.apache.ozone:ozone-cli-shell >------------------
[INFO] Building Apache Ozone CLI Shell 2.1.0-SNAPSHOT                   [29/50]
[INFO]   from hadoop-ozone/cli-shell/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-cli-shell ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-cli-shell ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-cli-shell ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-cli-shell ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-cli-shell ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-cli-shell ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-cli-shell ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-cli-shell ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-cli-shell ---
[INFO] Compiling 122 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/src/main/java/org/apache/hadoop/ozone/shell/ReplicationOptions.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/src/main/java/org/apache/hadoop/ozone/shell/ReplicationOptions.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/src/main/java/org/apache/hadoop/ozone/shell/token/TokenOption.java: /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/src/main/java/org/apache/hadoop/ozone/shell/token/TokenOption.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/src/main/java/org/apache/hadoop/ozone/shell/token/TokenOption.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-cli-shell ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-cli-shell ---
[INFO] Compiling 5 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[project]'
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-cli-shell ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-cli-shell ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/target/classes/ozone-cli-shell.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-cli-shell ---
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-cli-shell ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/target/ozone-cli-shell-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-cli-shell ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/target/ozone-cli-shell-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-cli-shell ---
[INFO] No dependency problems found
[INFO] 
[INFO] ------------------< org.apache.ozone:ozone-cli-admin >------------------
[INFO] Building Apache Ozone CLI Admin 2.1.0-SNAPSHOT                   [30/50]
[INFO]   from hadoop-ozone/cli-admin/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-cli-admin ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-cli-admin ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-cli-admin ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-cli-admin ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-cli-admin ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-cli-admin ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-cli-admin ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-cli-admin ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-cli-admin ---
[INFO] Compiling 94 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] Writing META-INF/services/org.apache.hadoop.hdds.cli.AdminSubcommand
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/src/main/java/org/apache/hadoop/ozone/admin/om/OMAdmin.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/src/main/java/org/apache/hadoop/ozone/admin/om/OMAdmin.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-cli-admin ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-cli-admin ---
[INFO] Compiling 16 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/src/test/java/org/apache/hadoop/hdds/scm/cli/container/TestInfoSubCommand.java: /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/src/test/java/org/apache/hadoop/hdds/scm/cli/container/TestInfoSubCommand.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/src/test/java/org/apache/hadoop/hdds/scm/cli/container/TestInfoSubCommand.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-cli-admin ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-cli-admin ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/target/classes/ozone-cli-admin.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-cli-admin ---
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-cli-admin ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/target/ozone-cli-admin-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-cli-admin ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/target/ozone-cli-admin-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-cli-admin ---
[INFO] No dependency problems found
[INFO] 
[INFO] ---------------------< org.apache.ozone:ozone-csi >---------------------
[INFO] Building Apache Ozone CSI service 2.1.0-SNAPSHOT                 [31/50]
[INFO]   from hadoop-ozone/csi/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-csi ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/csi/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-csi ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/csi/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-csi ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc) @ ozone-csi ---
[INFO] Compiling 1 proto file(s) to /home/runner/work/ozone/ozone/hadoop-ozone/csi/target/generated-sources/java
[INFO] 
[INFO] --- protobuf:0.6.1:compile-custom (compile-protoc) @ ozone-csi ---
[INFO] Compiling 1 proto file(s) to /home/runner/work/ozone/ozone/hadoop-ozone/csi/target/generated-sources/java
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-csi ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-csi ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-csi ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-csi ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-csi ---
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-csi ---
[INFO] Compiling 9 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc) @ ozone-csi ---
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/csi/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile-custom (compile-protoc) @ ozone-csi ---
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/csi/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-csi ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-csi ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-csi ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-csi ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/classes/ozone-csi.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-csi ---
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-csi ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/csi/target/ozone-csi-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-csi ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-csi ---
[INFO] No dependency problems found
[INFO] 
[INFO] --- proto-backwards-compatibility:1.0.7:backwards-compatibility-check (default) @ ozone-csi ---
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-ozone/csi/target/protolock-bin/protolock status --lockdir=/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/classes
[INFO] protolock cmd line: /home/runner/work/ozone/ozone/hadoop-ozone/csi/target/protolock-bin/protolock commit --lockdir=/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/classes --protoroot=/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/classes
[INFO] Backwards compatibility check passed.
[INFO] 
[INFO] ------------------< org.apache.ozone:ozone-datanode >-------------------
[INFO] Building Apache Ozone Datanode 2.1.0-SNAPSHOT                    [32/50]
[INFO]   from hadoop-ozone/datanode/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-datanode ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/datanode/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-datanode ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/datanode/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-datanode ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/datanode/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-datanode ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-datanode ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-datanode ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-datanode ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-datanode ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/datanode/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-datanode ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-datanode ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-datanode ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-datanode ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-datanode ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/datanode/target/classes/ozone-datanode.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-datanode ---
[INFO] 
[INFO] --------------< org.apache.ozone:ozone-interface-storage >--------------
[INFO] Building Apache Ozone Storage Interface 2.1.0-SNAPSHOT           [33/50]
[INFO]   from hadoop-ozone/interface-storage/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-interface-storage ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-interface-storage ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-interface-storage ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- protobuf:0.6.1:compile (compile-protoc) @ ozone-interface-storage ---
[INFO] Compiling 1 proto file(s) to /home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/generated-sources/protobuf/java
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-interface-storage ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-interface-storage ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-interface-storage ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-interface-storage ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-interface-storage ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/src/main/resources
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-interface-storage ---
[INFO] Compiling 8 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- protobuf:0.6.1:test-compile (compile-protoc) @ ozone-interface-storage ---
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/src/test/proto does not exist. Review the configuration or consider disabling the plugin.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-interface-storage ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-interface-storage ---
[INFO] Compiling 8 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-interface-storage ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-interface-storage ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-interface-storage ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-interface-storage ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/ozone-interface-storage-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-interface-storage ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/ozone-interface-storage-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-interface-storage ---
[INFO] No dependency problems found
[INFO] 
[INFO] -------------------< org.apache.ozone:ozone-manager >-------------------
[INFO] Building Apache Ozone Manager Server 2.1.0-SNAPSHOT              [34/50]
[INFO]   from hadoop-ozone/ozone-manager/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-manager ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-manager ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-manager ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-manager ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-manager ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-manager ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-manager ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-manager ---
[INFO] Copying 7 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-manager ---
[INFO] Compiling 387 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[WARNING] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/ha/OMHANodeDetails.java:[311,50] non-varargs call of varargs method with inexact argument type for last parameter;
  cast to java.lang.Object for a varargs call
  cast to java.lang.Object[] for a non-varargs call and to suppress this warning
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/ratis/OzoneManagerRatisServer.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/ratis/OzoneManagerRatisServer.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- aspectj:1.14.1:compile (default) @ ozone-manager ---
[INFO] Showing AJC message detail for messages of types: [error, warning, fail]
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-manager ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/../../hdds/common/src/main/resources
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-manager ---
[INFO] Compiling 234 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[WARNING] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestOMMetadataReader.java:[50,62] non-varargs call of varargs method with inexact argument type for last parameter;
  cast to java.lang.String for a varargs call
  cast to java.lang.String[] for a non-varargs call and to suppress this warning
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/OMRequestTestUtils.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/OMRequestTestUtils.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestBucketUtilizationMetrics.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestBucketUtilizationMetrics.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-manager ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-manager ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/classes/ozone-manager.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-manager ---
[INFO] 
[INFO] --- dependency:3.8.1:unpack (copy-common-html) @ ozone-manager ---
[INFO] Configured Artifact: org.apache.ozone:hdds-server-framework:?:jar
[INFO] Configured Artifact: org.apache.ozone:hdds-docs:?:jar
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-manager ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/ozone-manager-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-manager ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/ozone-manager-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-manager ---
[INFO] No dependency problems found
[INFO] 
[INFO] --------------------< org.apache.ozone:ozone-freon >--------------------
[INFO] Building Apache Ozone Freon 2.1.0-SNAPSHOT                       [35/50]
[INFO]   from hadoop-ozone/freon/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-freon ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/freon/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-freon ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/freon/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-freon ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/freon/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-freon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-freon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-freon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-freon ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-freon ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/freon/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-freon ---
[INFO] Compiling 54 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] Writing META-INF/services/org.apache.hadoop.ozone.freon.FreonSubcommand
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/freon/src/main/java/org/apache/hadoop/ozone/freon/BaseFreonGenerator.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/freon/src/main/java/org/apache/hadoop/ozone/freon/BaseFreonGenerator.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/freon/src/main/java/org/apache/hadoop/ozone/freon/RangeKeysGenerator.java: /home/runner/work/ozone/ozone/hadoop-ozone/freon/src/main/java/org/apache/hadoop/ozone/freon/RangeKeysGenerator.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/freon/src/main/java/org/apache/hadoop/ozone/freon/RangeKeysGenerator.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-freon ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/freon/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-freon ---
[INFO] Compiling 4 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[project]'
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-freon ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-freon ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/freon/target/classes/ozone-freon.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-freon ---
[INFO] 
[INFO] ----------------< org.apache.ozone:ozone-httpfsgateway >----------------
[INFO] Building Apache Ozone HttpFS 2.1.0-SNAPSHOT                      [36/50]
[INFO]   from hadoop-ozone/httpfsgateway/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-httpfsgateway ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-httpfsgateway ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-httpfsgateway ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-httpfsgateway ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-httpfsgateway ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-httpfsgateway ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-httpfsgateway ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-httpfsgateway ---
[INFO] Copying 1 resource
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] The encoding used to copy filtered properties files have not been set. This means that the same encoding will be used to copy filtered properties files as when copying other filtered resources. This might not be what you want! Run your build with --debug to see which files might be affected. Read more at https://maven.apache.org/plugins/maven-resources-plugin/examples/filtering-properties-files.html
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-httpfsgateway ---
[INFO] Compiling 63 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/src/main/java/org/apache/ozone/fs/http/server/HttpFSServer.java:[834,29] non-varargs call of varargs method with inexact argument type for last parameter;
  cast to java.lang.Object for a varargs call
  cast to java.lang.Object[] for a non-varargs call and to suppress this warning
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/src/main/java/org/apache/ozone/fs/http/server/FSOperations.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/src/main/java/org/apache/ozone/fs/http/server/FSOperations.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/src/main/java/org/apache/ozone/lib/wsrs/ParametersProvider.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/src/main/java/org/apache/ozone/lib/wsrs/ParametersProvider.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- antrun:3.1.0:run (create-web-xmls) @ ozone-httpfsgateway ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/target/test-classes/webapp
[INFO]      [copy] Copying 1 file to /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/target/test-classes/webapp
[INFO] Executed tasks
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-httpfsgateway ---
[INFO] Copying 1 resource
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] The encoding used to copy filtered properties files have not been set. This means that the same encoding will be used to copy filtered properties files as when copying other filtered resources. This might not be what you want! Run your build with --debug to see which files might be affected. Read more at https://maven.apache.org/plugins/maven-resources-plugin/examples/filtering-properties-files.html
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-httpfsgateway ---
[INFO] Compiling 1 source file with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-httpfsgateway ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-httpfsgateway ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/target/classes/ozone-httpfsgateway.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-httpfsgateway ---
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-httpfsgateway ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/target/ozone-httpfsgateway-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-httpfsgateway ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/target/ozone-httpfsgateway-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-httpfsgateway ---
[INFO] No dependency problems found
[INFO] 
[INFO] -------------------< org.apache.ozone:ozone-insight >-------------------
[INFO] Building Apache Ozone Insight Tool 2.1.0-SNAPSHOT                [37/50]
[INFO]   from hadoop-ozone/insight/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-insight ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/insight/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-insight ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/insight/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-insight ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/insight/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-insight ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-insight ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-insight ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-insight ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-insight ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/insight/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-insight ---
[INFO] Compiling 28 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/datanode/PipelineComponentUtil.java: /home/runner/work/ozone/ozone/hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/datanode/PipelineComponentUtil.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/datanode/PipelineComponentUtil.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/ConfigurationSubCommand.java: /home/runner/work/ozone/ozone/hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/ConfigurationSubCommand.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/ConfigurationSubCommand.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-insight ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-insight ---
[INFO] Compiling 3 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-insight ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-insight ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/insight/target/classes/ozone-insight.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-insight ---
[INFO] 
[INFO] ----------------< org.apache.ozone:ozone-reconcodegen >-----------------
[INFO] Building Apache Ozone Recon CodeGen 2.1.0-SNAPSHOT               [38/50]
[INFO]   from hadoop-ozone/recon-codegen/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-reconcodegen ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-reconcodegen ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-reconcodegen ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-reconcodegen ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-reconcodegen ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-reconcodegen ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-reconcodegen ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-reconcodegen ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-reconcodegen ---
[INFO] Compiling 12 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] /home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/src/main/java/org/apache/ozone/recon/schema/ContainerSchemaDefinition.java:[82,52] non-varargs call of varargs method with inexact argument type for last parameter;
  cast to java.lang.Object for a varargs call
  cast to java.lang.Object[] for a non-varargs call and to suppress this warning
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-reconcodegen ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-reconcodegen ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-reconcodegen ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-reconcodegen ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-reconcodegen ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-reconcodegen ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/target/ozone-reconcodegen-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-reconcodegen ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-reconcodegen ---
[INFO] No dependency problems found
[INFO] 
[INFO] --------------------< org.apache.ozone:ozone-recon >--------------------
[INFO] Building Apache Ozone Recon 2.1.0-SNAPSHOT                       [39/50]
[INFO]   from hadoop-ozone/recon/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-recon ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/recon/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-recon ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/recon/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-recon ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- build-helper:3.6.1:add-source (add-source) @ ozone-recon ---
[INFO] Source directory: /home/runner/work/ozone/ozone/hadoop-ozone/recon/target/generated-sources/java added.
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-recon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-recon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-recon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- exec:3.5.1:java (default) @ ozone-recon ---
[INFO] 
[INFO] --- frontend:1.15.1:install-node-and-npm (Install node and npm locally to the project) @ ozone-recon ---
[INFO] Skipping execution.
[INFO] 
[INFO] --- frontend:1.15.1:npx (set pnpm@8.15.7 store path) @ ozone-recon ---
[INFO] Skipping execution.
[INFO] 
[INFO] --- frontend:1.15.1:npx (install frontend dependencies) @ ozone-recon ---
[INFO] Skipping execution.
[INFO] 
[INFO] --- frontend:1.15.1:npx (Build frontend) @ ozone-recon ---
[INFO] Skipping execution.
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-recon ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-recon ---
[INFO] Copying 167 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- resources:3.3.0:copy-resources (Copy frontend build to target) @ ozone-recon ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/main/resources/webapps/recon/ozone-recon-web/build
[INFO] 
[INFO] --- resources:3.3.0:copy-resources (Copy frontend static files to target) @ ozone-recon ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/main/resources/webapps/recon/ozone-recon-web/build/static
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-recon ---
[INFO] Compiling 242 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[WARNING] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/upgrade/InitialConstraintUpgradeAction.java:[89,13] non-varargs call of varargs method with inexact argument type for last parameter;
  cast to java.lang.Object for a varargs call
  cast to java.lang.Object[] for a non-varargs call and to suppress this warning
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/ReconRestServletModule.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/ReconRestServletModule.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/ReconControllerModule.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/ReconControllerModule.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-recon ---
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-recon ---
[INFO] Compiling 69 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[artifactId]'
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/filters/TestAdminFilter.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/filters/TestAdminFilter.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/OMMetadataManagerTestUtils.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/OMMetadataManagerTestUtils.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-recon ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-recon ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/ozone-recon.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-recon ---
[INFO] 
[INFO] ---------------< org.apache.ozone:ozone-s3-secret-store >---------------
[INFO] Building Apache Ozone S3 Secret Store 2.1.0-SNAPSHOT             [40/50]
[INFO]   from hadoop-ozone/s3-secret-store/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-s3-secret-store ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-s3-secret-store ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-s3-secret-store ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-s3-secret-store ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-s3-secret-store ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-s3-secret-store ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-s3-secret-store ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-s3-secret-store ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-s3-secret-store ---
[INFO] Compiling 11 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-s3-secret-store ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-s3-secret-store ---
[INFO] Compiling 1 source file with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/src/test/java/org/apache/hadoop/ozone/s3/remote/vault/TestVaultS3SecretStore.java: /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/src/test/java/org/apache/hadoop/ozone/s3/remote/vault/TestVaultS3SecretStore.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/src/test/java/org/apache/hadoop/ozone/s3/remote/vault/TestVaultS3SecretStore.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-s3-secret-store ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-s3-secret-store ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-s3-secret-store ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-s3-secret-store ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/target/ozone-s3-secret-store-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-s3-secret-store ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/s3-secret-store/target/ozone-s3-secret-store-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-s3-secret-store ---
[INFO] No dependency problems found
[INFO] 
[INFO] ------------------< org.apache.ozone:ozone-s3gateway >------------------
[INFO] Building Apache Ozone S3 Gateway 2.1.0-SNAPSHOT                  [41/50]
[INFO]   from hadoop-ozone/s3gateway/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-s3gateway ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-s3gateway ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-s3gateway ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-s3gateway ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-s3gateway ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-s3gateway ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-s3gateway ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-s3gateway ---
[INFO] Copying 6 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-s3gateway ---
[INFO] Compiling 94 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-s3gateway ---
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-s3gateway ---
[INFO] Compiling 64 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/protocolPB/TestGrpcOmTransport.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/protocolPB/TestGrpcOmTransport.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/client/OzoneVolumeStub.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/client/OzoneVolumeStub.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-s3gateway ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-s3gateway ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/classes/ozone-s3gateway.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-s3gateway ---
[INFO] 
[INFO] --- dependency:3.8.1:unpack (copy-common-html) @ ozone-s3gateway ---
[INFO] Configured Artifact: org.apache.ozone:hdds-server-framework:?:jar
[INFO] Configured Artifact: org.apache.ozone:hdds-docs:?:jar
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-s3gateway ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/ozone-s3gateway-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-s3gateway ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/ozone-s3gateway-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-s3gateway ---
[INFO] No dependency problems found
[INFO] 
[INFO] --------------------< org.apache.ozone:ozone-tools >--------------------
[INFO] Building Apache Ozone Tools 2.1.0-SNAPSHOT                       [42/50]
[INFO]   from hadoop-ozone/tools/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-tools ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/tools/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-tools ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/tools/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-tools ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/tools/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-tools ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-tools ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-tools ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-tools ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-tools ---
[INFO] Copying 3 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-tools ---
[INFO] Compiling 116 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] Writing META-INF/services/org.apache.hadoop.hdds.cli.RepairSubcommand
[INFO] Writing META-INF/services/org.apache.hadoop.hdds.cli.DebugSubcommand
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/main/java/org/apache/hadoop/ozone/repair/om/quota/QuotaRepair.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/main/java/org/apache/hadoop/ozone/repair/om/quota/QuotaRepair.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/main/java/org/apache/hadoop/ozone/debug/ldb/DBScanner.java: /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/main/java/org/apache/hadoop/ozone/debug/ldb/DBScanner.java uses unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/main/java/org/apache/hadoop/ozone/debug/ldb/DBScanner.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-tools ---
[INFO] Copying 4 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-tools ---
[INFO] Compiling 13 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[WARNING] The following options were not recognized by any processor: '[project]'
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/test/java/org/apache/hadoop/ozone/debug/audit/parser/TestAuditParser.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/test/java/org/apache/hadoop/ozone/debug/audit/parser/TestAuditParser.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/test/java/org/apache/hadoop/ozone/debug/audit/parser/TestAuditParser.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/tools/src/test/java/org/apache/hadoop/ozone/debug/audit/parser/TestAuditParser.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-tools ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-tools ---
[INFO] Wrote classpath file '/home/runner/work/ozone/ozone/hadoop-ozone/tools/target/classes/ozone-tools.classpath'.
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-tools ---
[INFO] 
[INFO] --------------------< org.apache.ozone:ozone-dist >---------------------
[INFO] Building Apache Ozone Distribution 2.1.0-SNAPSHOT                [43/50]
[INFO]   from hadoop-ozone/dist/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-dist ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-dist ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/dist/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-dist ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-dist ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-dist ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-dist ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-dist ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-dist ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-dist ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:copy-resources (copy-compose-files) @ ozone-dist ---
[INFO] Copying 191 resources
[INFO] 
[INFO] --- resources:3.3.0:copy-resources (copy-and-filter-dockerfile) @ ozone-dist ---
[INFO] Copying 1 resource
[INFO] 
[INFO] --- resources:3.3.0:copy-resources (copy-k8s) @ ozone-dist ---
[INFO] Copying 188 resources
[INFO] 
[INFO] --- resources:3.3.0:copy-resources (copy-smoketest-files) @ ozone-dist ---
[INFO] Copying 157 resources
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-dist ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-dist ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-dist ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- exec:3.5.1:exec (dist) @ ozone-dist ---

Current directory /home/runner/work/ozone/ozone/hadoop-ozone/dist/target

$ rm -rf ozone-2.1.0-SNAPSHOT
$ mkdir ozone-2.1.0-SNAPSHOT
$ cd ozone-2.1.0-SNAPSHOT
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/main/license/bin/NOTICE.txt NOTICE.txt
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/main/license/bin/LICENSE.txt LICENSE.txt
$ cp -pr /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/main/license/bin/licenses licenses
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/recon/src/main/resources/webapps/recon/ozone-recon-web/LICENSE licenses/LICENSE-ozone-recon.txt
$ cp -p /home/runner/work/ozone/ozone/README.md .
$ cp -p /home/runner/work/ozone/ozone/HISTORY.md .
$ cp -p /home/runner/work/ozone/ozone/SECURITY.md .
$ cp -p /home/runner/work/ozone/ozone/CONTRIBUTING.md .
$ mkdir -p ./share/ozone/classpath
$ mkdir -p ./share/ozone/lib
$ mkdir -p ./share/ozone/web
$ mkdir -p ./bin
$ mkdir -p ./sbin
$ mkdir -p ./etc
$ mkdir -p ./libexec
$ mkdir -p ./log
$ mkdir -p ./temp
$ mkdir -p ./tests
$ cp -r /home/runner/work/ozone/ozone/hadoop-hdds/common/src/main/conf/ etc/hadoop
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/conf/om-audit-log4j2.properties etc/hadoop
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/conf/dn-audit-log4j2.properties etc/hadoop
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/conf/dn-container-log4j2.properties etc/hadoop
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/conf/scm-audit-log4j2.properties etc/hadoop
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/conf/s3g-audit-log4j2.properties etc/hadoop
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/conf/ozone-site.xml etc/hadoop
$ cp -f /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/conf/log4j.properties etc/hadoop
$ cp /home/runner/work/ozone/ozone/hadoop-hdds/common/src/main/resources/network-topology-default.xml etc/hadoop
$ cp /home/runner/work/ozone/ozone/hadoop-hdds/common/src/main/resources/network-topology-nodegroup.xml etc/hadoop
$ cp -r /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/main/dockerlibexec/. libexec/
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/ozone/ozone bin/
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/ozone/ozone-config.sh libexec/
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/ozone/ozone-functions.sh libexec/
$ cp -r /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/shellprofile.d libexec/
$ cp -r /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/upgrade libexec/
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/hdds/hadoop-daemons.sh sbin/
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/hdds/workers.sh sbin/
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/ozone/start-ozone.sh sbin/
$ cp /home/runner/work/ozone/ozone/hadoop-ozone/dist/src/shell/ozone/stop-ozone.sh sbin/
$ cp -r /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/network-tests/src/test/blockade tests
$ cp -r /home/runner/work/ozone/ozone/dev-support/byteman share/ozone/
$ cp -p -R /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/compose .
$ cp -p -r /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/smoketest .
$ cp -p -r /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/k8s kubernetes
$ cp -p -r /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/Dockerfile .
$ mkdir compose/_keytabs
$ cp -p /home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/classes/hdds-server-scm.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/cli-admin/target/classes/ozone-cli-admin.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/cli-shell/target/classes/ozone-cli-shell.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/csi/target/classes/ozone-csi.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/datanode/target/classes/ozone-datanode.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/freon/target/classes/ozone-freon.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/httpfsgateway/target/classes/ozone-httpfsgateway.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/insight/target/classes/ozone-insight.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/classes/ozone-manager.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/ozone-recon.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/classes/ozone-s3gateway.classpath share/ozone/classpath/
$ cp -p /home/runner/work/ozone/ozone/hadoop-ozone/tools/target/classes/ozone-tools.classpath share/ozone/classpath/
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-dist ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-dist ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-omitted-jars) @ ozone-dist ---
[INFO] 
[INFO] ----------------< org.apache.ozone:ozone-mini-cluster >-----------------
[INFO] Building Apache Ozone Mini Cluster 2.1.0-SNAPSHOT                [44/50]
[INFO]   from hadoop-ozone/mini-cluster/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-mini-cluster ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-mini-cluster ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-mini-cluster ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-mini-cluster ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-mini-cluster ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-mini-cluster ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-mini-cluster ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-mini-cluster ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-mini-cluster ---
[INFO] Compiling 6 source files with javac [debug release 8] to target/classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/src/main/java/org/apache/hadoop/ozone/MiniOzoneClusterImpl.java: /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/src/main/java/org/apache/hadoop/ozone/MiniOzoneClusterImpl.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/src/main/java/org/apache/hadoop/ozone/MiniOzoneClusterImpl.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-mini-cluster ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/src/test/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-mini-cluster ---
[INFO] No sources to compile
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-mini-cluster ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-mini-cluster ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-mini-cluster ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-mini-cluster ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/target/ozone-mini-cluster-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-mini-cluster ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/mini-cluster/target/ozone-mini-cluster-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-mini-cluster ---
[INFO] No dependency problems found
[INFO] 
[INFO] --------------< org.apache.ozone:ozone-integration-test >---------------
[INFO] Building Apache Ozone Integration Tests 2.1.0-SNAPSHOT           [45/50]
[INFO]   from hadoop-ozone/integration-test/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-integration-test ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-integration-test ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-integration-test ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-integration-test ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-integration-test ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-integration-test ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-integration-test ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-integration-test ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-integration-test ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-integration-test ---
[INFO] Copying 22 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-integration-test ---
[INFO] Compiling 313 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneDatanodeShell.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneDatanodeShell.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestListKeys.java: Some input files use unchecked or unsafe operations.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestListKeys.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-integration-test ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.hdds.scm.container.TestContainerStateManagerIntegration
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 90.86 s -- in org.apache.hadoop.hdds.scm.container.TestContainerStateManagerIntegration
[INFO] Running org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerIntegration
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.77 s -- in org.apache.hadoop.hdds.scm.container.replication.TestReplicationManagerIntegration
[INFO] Running org.apache.hadoop.ozone.container.metrics.TestContainerMetrics
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.63 s -- in org.apache.hadoop.ozone.container.metrics.TestContainerMetrics
[INFO] Running org.apache.hadoop.ozone.container.server.TestSecureContainerServer
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.13 s -- in org.apache.hadoop.ozone.container.server.TestSecureContainerServer
[INFO] Running org.apache.hadoop.ozone.container.server.TestContainerServer
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.01 s -- in org.apache.hadoop.ozone.container.server.TestContainerServer
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestFinalizeBlock
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 71.34 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestFinalizeBlock
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerHandler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.20 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestBlockDeletion
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 140.5 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestBlockDeletion
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestRefreshVolumeUsageHandler
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.68 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestRefreshVolumeUsageHandler
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerByPipeline
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.20 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestCloseContainerByPipeline
[INFO] Running org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestDeleteContainerHandler
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 119.2 s -- in org.apache.hadoop.ozone.container.common.statemachine.commandhandler.TestDeleteContainerHandler
[INFO] Running org.apache.hadoop.ozone.container.common.transport.server.ratis.TestCSMMetrics
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.60 s -- in org.apache.hadoop.ozone.container.common.transport.server.ratis.TestCSMMetrics
[INFO] Running org.apache.hadoop.ozone.container.TestContainerReplication
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 200.7 s -- in org.apache.hadoop.ozone.container.TestContainerReplication
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 71.60 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainer
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestSecureOzoneContainer
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.65 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestSecureOzoneContainer
[INFO] Running org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainerWithTLS
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 57.97 s -- in org.apache.hadoop.ozone.container.ozoneimpl.TestOzoneContainerWithTLS
[INFO] Running org.apache.hadoop.ozone.container.TestContainerReportHandlingWithHA
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 94.40 s -- in org.apache.hadoop.ozone.container.TestContainerReportHandlingWithHA
[INFO] Running org.apache.hadoop.ozone.container.TestECContainerRecovery
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 91.31 s -- in org.apache.hadoop.ozone.container.TestECContainerRecovery
[INFO] Running org.apache.hadoop.ozone.container.replication.TestContainerReplication
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.83 s -- in org.apache.hadoop.ozone.container.replication.TestContainerReplication
[INFO] Running org.apache.hadoop.ozone.container.TestContainerReportHandling
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 57.93 s -- in org.apache.hadoop.ozone.container.TestContainerReportHandling
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 78, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-integration-test ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-integration-test ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-integration-test ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/ozone-integration-test-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-integration-test ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/ozone-integration-test-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-integration-test ---
[INFO] No dependency problems found
[INFO] 
[INFO] ------------< org.apache.ozone:ozone-fault-injection-test >-------------
[INFO] Building Apache Ozone Fault Injection Tests 2.1.0-SNAPSHOT       [46/50]
[INFO]   from hadoop-ozone/fault-injection-test/pom.xml
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-fault-injection-test ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-fault-injection-test ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-fault-injection-test ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-fault-injection-test ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-fault-injection-test ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-fault-injection-test ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-fault-injection-test ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-fault-injection-test ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-fault-injection-test ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-fault-injection-test ---
[WARNING] JAR will be empty - no content was marked for inclusion!
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/target/ozone-fault-injection-test-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-fault-injection-test ---
[INFO] Skipping pom project
[INFO] 
[INFO] -----------------< org.apache.ozone:mini-chaos-tests >------------------
[INFO] Building Apache Ozone Mini Ozone Chaos Tests 2.1.0-SNAPSHOT      [47/50]
[INFO]   from hadoop-ozone/fault-injection-test/mini-chaos-tests/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ mini-chaos-tests ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/mini-chaos-tests/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ mini-chaos-tests ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/mini-chaos-tests/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ mini-chaos-tests ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/mini-chaos-tests/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ mini-chaos-tests ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ mini-chaos-tests ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ mini-chaos-tests ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ mini-chaos-tests ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ mini-chaos-tests ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/mini-chaos-tests/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ mini-chaos-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ mini-chaos-tests ---
[INFO] Copying 2 resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ mini-chaos-tests ---
[INFO] Compiling 22 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/mini-chaos-tests/src/test/java/org/apache/hadoop/ozone/failure/Failures.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/mini-chaos-tests/src/test/java/org/apache/hadoop/ozone/failure/Failures.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ mini-chaos-tests ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ mini-chaos-tests ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ mini-chaos-tests ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ mini-chaos-tests ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/mini-chaos-tests/target/mini-chaos-tests-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ mini-chaos-tests ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/mini-chaos-tests/target/mini-chaos-tests-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ mini-chaos-tests ---
[INFO] No dependency problems found
[INFO] 
[INFO] ----------------< org.apache.ozone:ozone-network-tests >----------------
[INFO] Building Apache Ozone Network Tests 2.1.0-SNAPSHOT               [48/50]
[INFO]   from hadoop-ozone/fault-injection-test/network-tests/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-network-tests ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/network-tests/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-network-tests ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/network-tests/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-network-tests ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/network-tests/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-network-tests ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-network-tests ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-network-tests ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-network-tests ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-network-tests ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/network-tests/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- resources:3.3.0:copy-resources (copy-resources) @ ozone-network-tests ---
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-network-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-network-tests ---
[INFO] Not copying test resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-network-tests ---
[INFO] Skipped
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-network-tests ---
[INFO] No tests to run.
[INFO] Skipped
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-network-tests ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-network-tests ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-network-tests ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/fault-injection-test/network-tests/target/ozone-network-tests-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-network-tests ---
[INFO] Skipping packaging of the test-jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-network-tests ---
[INFO] No dependency problems found
[INFO] 
[INFO] -----------< org.apache.ozone:ozone-integration-test-recon >------------
[INFO] Building Apache Ozone Recon Integration Tests 2.1.0-SNAPSHOT     [49/50]
[INFO]   from hadoop-ozone/integration-test-recon/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-integration-test-recon ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-recon/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-integration-test-recon ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-recon/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-integration-test-recon ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test-recon/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-integration-test-recon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-integration-test-recon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-integration-test-recon ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-integration-test-recon ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-integration-test-recon ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-recon/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-integration-test-recon ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-integration-test-recon ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-integration-test-recon ---
[INFO] Compiling 13 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-recon/src/test/java/org/apache/hadoop/ozone/recon/TestReconAndAdminContainerCLI.java: Some input files use or override a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-recon/src/test/java/org/apache/hadoop/ozone/recon/TestReconAndAdminContainerCLI.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-integration-test-recon ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-integration-test-recon ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-integration-test-recon ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-integration-test-recon ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-recon/target/ozone-integration-test-recon-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-integration-test-recon ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-recon/target/ozone-integration-test-recon-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-integration-test-recon ---
[INFO] No dependency problems found
[INFO] 
[INFO] -------------< org.apache.ozone:ozone-integration-test-s3 >-------------
[INFO] Building Apache Ozone S3 Integration Tests 2.1.0-SNAPSHOT        [50/50]
[INFO]   from hadoop-ozone/integration-test-s3/pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- antrun:3.1.0:run (create-testdirs) @ ozone-integration-test-s3 ---
[INFO] Executing tasks
[INFO]     [mkdir] Created dir: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/target/test-dir
[INFO] Executed tasks
[INFO] 
[INFO] --- sortpom:3.0.1:verify (default) @ ozone-integration-test-s3 ---
[INFO] Verifying file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/pom.xml
[INFO] 
[INFO] --- jacoco:0.8.13:prepare-agent (default-prepare-agent) @ ozone-integration-test-s3 ---
[INFO] argLine set to -javaagent:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.13/org.jacoco.agent-0.8.13-runtime.jar=destfile=/home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/target/jacoco.exec,includes=org.apache.hadoop.hdds.*:org.apache.hadoop.ozone.*:org.apache.hadoop.fs.ozone.*:org.apache.ozone.*
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (banned-rocksdb-imports) @ ozone-integration-test-s3 ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-imports) @ ozone-integration-test-s3 ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 1: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 2: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 3: org.apache.maven.plugins.enforcer.RestrictImports passed
[WARNING] EXPERIMENTAL FEATURE enabled. You have enabled full-compilation-unit parsing. Please be aware that experimental features might get removed or changed. Please share your feedback!
[INFO] Rule 4: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 5: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 6: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] Rule 7: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- enforcer:3.5.0:enforce (ban-annotations) @ ozone-integration-test-s3 ---
[INFO] Rule 0: org.apache.maven.plugins.enforcer.RestrictImports passed
[INFO] 
[INFO] --- remote-resources:3.3.0:process (default) @ ozone-integration-test-s3 ---
[INFO] Preparing remote bundle org.apache.ozone:ozone-dev-support:2.1.0-SNAPSHOT
[INFO] Copying 2 resources from 1 bundle.
[INFO] 
[INFO] --- resources:3.3.0:resources (default-resources) @ ozone-integration-test-s3 ---
[INFO] skip non existing resourceDirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/src/main/resources
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ ozone-integration-test-s3 ---
[INFO] No sources to compile
[INFO] 
[INFO] --- resources:3.3.0:testResources (default-testResources) @ ozone-integration-test-s3 ---
[INFO] Copying 1 resource
[INFO] Copying 2 resources
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ ozone-integration-test-s3 ---
[INFO] Compiling 9 source files with javac [debug release 8] to target/test-classes
[WARNING] source value 8 is obsolete and will be removed in a future release
[WARNING] target value 8 is obsolete and will be removed in a future release
[WARNING] To suppress warnings about obsolete options, use -Xlint:-options.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/src/test/java/org/apache/hadoop/ozone/s3/awssdk/v1/AbstractS3SDKV1Tests.java: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/src/test/java/org/apache/hadoop/ozone/s3/awssdk/v1/AbstractS3SDKV1Tests.java uses or overrides a deprecated API.
[INFO] /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/src/test/java/org/apache/hadoop/ozone/s3/awssdk/v1/AbstractS3SDKV1Tests.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- surefire:3.5.2:test (default-test) @ ozone-integration-test-s3 ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] --- dependency:3.8.1:build-classpath (add-classpath-descriptor) @ ozone-integration-test-s3 ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- dependency:3.8.1:copy-dependencies (copy-jars) @ ozone-integration-test-s3 ---
[INFO] Skipping plugin execution
[INFO] 
[INFO] --- jar:3.4.2:jar (default-jar) @ ozone-integration-test-s3 ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/target/ozone-integration-test-s3-2.1.0-SNAPSHOT.jar
[INFO] 
[INFO] --- jar:3.4.2:test-jar (default) @ ozone-integration-test-s3 ---
[INFO] Building jar: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test-s3/target/ozone-integration-test-s3-2.1.0-SNAPSHOT-tests.jar
[INFO] 
[INFO] --- dependency:3.8.1:analyze-only (analyze) @ ozone-integration-test-s3 ---
[INFO] No dependency problems found
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for Apache Ozone Main 2.1.0-SNAPSHOT:
[INFO] 
[INFO] Apache Ozone Main .................................. SUCCESS [  1.415 s]
[INFO] Apache Ozone Dev Support ........................... SUCCESS [  2.092 s]
[INFO] Apache Ozone HDDS .................................. SUCCESS [  0.269 s]
[INFO] Apache Ozone Annotation Processing ................. SUCCESS [  1.294 s]
[INFO] Apache Ozone HDDS Config ........................... SUCCESS [  1.665 s]
[INFO] Apache Ozone HDDS Client Interface ................. SUCCESS [ 11.100 s]
[INFO] Apache Ozone HDDS Admin Interface .................. SUCCESS [  2.822 s]
[INFO] Apache Ozone HDDS Test Utils ....................... SUCCESS [  1.200 s]
[INFO] Apache Ozone HDDS Hadoop Client dependencies ....... SUCCESS [  0.088 s]
[INFO] Apache Ozone HDDS Common ........................... SUCCESS [ 11.348 s]
[INFO] Apache Ozone HDDS Erasurecode ...................... SUCCESS [  0.804 s]
[INFO] Apache Ozone HDDS Client ........................... SUCCESS [  1.702 s]
[INFO] Apache Ozone HDDS Server Interface ................. SUCCESS [  3.927 s]
[INFO] Apache Ozone HDDS Managed RocksDB .................. SUCCESS [  0.843 s]
[INFO] Apache Ozone HDDS RocksDB Tools .................... SUCCESS [ 33.088 s]
[INFO] Apache Ozone Checkpoint Differ for RocksDB ......... SUCCESS [  1.173 s]
[INFO] Apache Ozone HDDS Server Framework ................. SUCCESS [  5.995 s]
[INFO] Apache Ozone Documentation ......................... SUCCESS [  5.921 s]
[INFO] Apache Ozone HDDS Container Service ................ FAILURE [08:20 min]
[INFO] Apache Ozone HDDS Crypto ........................... SUCCESS [  0.098 s]
[INFO] Apache Ozone HDDS Crypto - Default ................. SUCCESS [  0.080 s]
[INFO] Apache Ozone HDDS SCM Server ....................... FAILURE [04:36 min]
[INFO] Apache Ozone ....................................... SUCCESS [  0.151 s]
[INFO] Apache Ozone Client Interface ...................... SUCCESS [ 22.081 s]
[INFO] Apache Ozone Common ................................ SUCCESS [  4.459 s]
[INFO] Apache Ozone Client ................................ SUCCESS [  1.558 s]
[INFO] Apache Ozone FileSystem Common ..................... SUCCESS [  1.022 s]
[INFO] Apache Ozone FileSystem ............................ SUCCESS [  0.812 s]
[INFO] Apache Ozone CLI Shell ............................. SUCCESS [  1.214 s]
[INFO] Apache Ozone CLI Admin ............................. SUCCESS [  1.936 s]
[INFO] Apache Ozone CSI service ........................... SUCCESS [  3.475 s]
[INFO] Apache Ozone Datanode .............................. FAILURE [  0.118 s]
[INFO] Apache Ozone Storage Interface ..................... SUCCESS [  1.026 s]
[INFO] Apache Ozone Manager Server ........................ SUCCESS [ 15.535 s]
[INFO] Apache Ozone Freon ................................. FAILURE [  1.751 s]
[INFO] Apache Ozone HttpFS ................................ SUCCESS [  1.153 s]
[INFO] Apache Ozone Insight Tool .......................... FAILURE [  0.893 s]
[INFO] Apache Ozone Recon CodeGen ......................... SUCCESS [  0.632 s]
[INFO] Apache Ozone Recon ................................. FAILURE [  5.633 s]
[INFO] Apache Ozone S3 Secret Store ....................... SUCCESS [  0.668 s]
[INFO] Apache Ozone S3 Gateway ............................ SUCCESS [  2.065 s]
[INFO] Apache Ozone Tools ................................. FAILURE [  1.763 s]
[INFO] Apache Ozone Distribution .......................... FAILURE [  4.012 s]
[INFO] Apache Ozone Mini Cluster .......................... SUCCESS [  0.481 s]
[INFO] Apache Ozone Integration Tests ..................... SUCCESS [21:53 min]
[INFO] Apache Ozone Fault Injection Tests ................. SUCCESS [  0.195 s]
[INFO] Apache Ozone Mini Ozone Chaos Tests ................ SUCCESS [  3.378 s]
[INFO] Apache Ozone Network Tests ......................... SUCCESS [  0.292 s]
[INFO] Apache Ozone Recon Integration Tests ............... SUCCESS [  1.698 s]
[INFO] Apache Ozone S3 Integration Tests .................. SUCCESS [  1.423 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  37:37 min
[INFO] Finished at: 2025-06-20T07:36:17Z
[INFO] ------------------------------------------------------------------------
[INFO] 862 goals, 862 executed
[INFO] 
[INFO] Publishing build scan...
[INFO] https://develocity.apache.org/s/d6yqbvxrp7frw
[INFO] 
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:3.5.2:test (default-test) on project hdds-container-service: 
[ERROR] 
[ERROR] See /home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/surefire-reports for the individual test results.
[ERROR] See dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream.
[ERROR] -> [Help 1]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-dependency-plugin:3.8.1:copy-dependencies (copy-jars) on project hdds-server-scm: Artifact 'org.apache.ozone:hdds-container-service:jar:2.1.0-SNAPSHOT:compile' has not been packaged yet (is a directory). When used on reactor artifact, copy should be executed after packaging: see MDEP-187. -> [Help 2]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-dependency-plugin:3.8.1:copy-dependencies (copy-jars) on project ozone-datanode: Artifact 'org.apache.ozone:hdds-container-service:jar:2.1.0-SNAPSHOT:runtime' has not been packaged yet (is a directory). When used on reactor artifact, copy should be executed after packaging: see MDEP-187. -> [Help 2]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-dependency-plugin:3.8.1:copy-dependencies (copy-jars) on project ozone-freon: Artifact 'org.apache.ozone:hdds-container-service:jar:2.1.0-SNAPSHOT:compile' has not been packaged yet (is a directory). When used on reactor artifact, copy should be executed after packaging: see MDEP-187. -> [Help 2]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-dependency-plugin:3.8.1:copy-dependencies (copy-jars) on project ozone-insight: Artifact 'org.apache.ozone:hdds-container-service:jar:2.1.0-SNAPSHOT:compile' has not been packaged yet (is a directory). When used on reactor artifact, copy should be executed after packaging: see MDEP-187. -> [Help 2]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-dependency-plugin:3.8.1:copy-dependencies (copy-jars) on project ozone-recon: Artifact 'org.apache.ozone:hdds-container-service:jar:2.1.0-SNAPSHOT:compile' has not been packaged yet (is a directory). When used on reactor artifact, copy should be executed after packaging: see MDEP-187. -> [Help 2]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-dependency-plugin:3.8.1:copy-dependencies (copy-jars) on project ozone-tools: Artifact 'org.apache.ozone:hdds-container-service:jar:2.1.0-SNAPSHOT:compile' has not been packaged yet (is a directory). When used on reactor artifact, copy should be executed after packaging: see MDEP-187. -> [Help 2]
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-dependency-plugin:3.8.1:copy-dependencies (copy-omitted-jars) on project ozone-dist: Artifact 'org.apache.ozone:hdds-container-service:jar:2.1.0-SNAPSHOT:runtime' has not been packaged yet (is a directory). When used on reactor artifact, copy should be executed after packaging: see MDEP-187. -> [Help 2]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <args> -rf :hdds-container-service
[INFO] Build failures were ignored.
