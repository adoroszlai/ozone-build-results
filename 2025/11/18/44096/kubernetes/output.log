rm: cannot remove '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/result/*': No such file or directory

#### Executing tests of getting-started #####


**** Modifying Kubernetes resources file for test ****

   (mounting current Ozone directory to the containers, scheduling containers to one node, ...)

WARNING: this test can be executed only with local Kubernetes cluster
   (source dir should be available from K8s nodes)


**** Deleting existing k8s resources ****

E1118 10:02:05.545799    3507 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.572173    3507 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.590930    3507 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.592700    3507 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found
E1118 10:02:05.699308    3542 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.710057    3542 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.711378    3542 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.712625    3542 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found
E1118 10:02:05.796948    3549 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.798860    3549 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.800647    3549 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.802489    3549 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found
E1118 10:02:05.886700    3556 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.888214    3556 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.889849    3556 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.891539    3556 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
service "kubernetes" deleted from default namespace
E1118 10:02:05.965308    3580 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.987294    3580 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.988673    3580 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:05.990293    3580 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
configmap "kube-root-ca.crt" deleted from default namespace
E1118 10:02:06.091792    3592 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.100594    3592 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.103108    3592 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.104835    3592 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found
E1118 10:02:06.192210    3598 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.193201    3598 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.195856    3598 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.197606    3598 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found
E1118 10:02:06.274808    3604 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.275807    3604 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.278014    3604 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.279917    3604 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found

**** Applying k8s resources from getting-started ****

E1118 10:02:06.553863    3613 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.563398    3613 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
configmap/config created
service/datanode created
service/datanode-public created
service/httpfs created
service/httpfs-public created
service/om created
service/om-public created
service/recon created
service/recon-public created
service/s3g created
service/s3g-public created
service/scm created
service/scm-public created
statefulset.apps/datanode created
statefulset.apps/httpfs created
statefulset.apps/om created
statefulset.apps/recon created
statefulset.apps/s3g created
statefulset.apps/scm created

**** Waiting until the k8s cluster is running ****

E1118 10:02:06.769166    3659 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.793761    3659 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.795860    3659 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.797818    3659 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found in default namespace.
E1118 10:02:06.851476    3717 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.871976    3717 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.874083    3717 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:06.875459    3717 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
0 pods are running. Waiting for more.
1 'all_pods_are_running' is failed...
E1118 10:02:09.953262    4384 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:09.954240    4384 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:09.956900    4384 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:09.958542    4384 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found in default namespace.
E1118 10:02:10.009763    4394 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:10.035291    4394 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:10.036708    4394 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:10.038454    4394 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
0 pods are running. Waiting for more.
2 'all_pods_are_running' is failed...
E1118 10:02:13.177354    4901 memcache.go:287] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:13.235907    4901 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
E1118 10:02:13.238917    4901 memcache.go:121] "Unhandled Error" err="couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request"
No resources found in default namespace.
0 pods are running. Waiting for more.
3 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
4 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
5 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
6 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
7 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
8 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
9 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
10 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
11 'all_pods_are_running' is failed...
5 / 7 pods are running
12 'all_pods_are_running' is failed...
7 / 8 pods are running
13 'all_pods_are_running' is failed...
7 / 8 pods are running
14 'all_pods_are_running' is failed...
7 / 8 pods are running
15 'all_pods_are_running' is failed...
7 / 8 pods are running
16 'all_pods_are_running' is failed...
Defaulted container "scm" out of: scm, init (init)
1 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
2 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
3 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
4 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
5 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
6 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
2025-11-18 10:03:14 INFO  SCMSafeModeManager:159 - SCM exiting safe mode.
2025-11-18 10:03:13 INFO  BaseHttpServer:357 - HTTP server of ozoneManager listening at http://om-0:9874

**** Cluster is up and running ****


**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Basic :: Smoketest ozone cluster startup                                      
==============================================================================
Check webui static resources                                          | PASS |
------------------------------------------------------------------------------
Basic Freon smoketest                                                 | PASS |
------------------------------------------------------------------------------
Basic :: Smoketest ozone cluster startup                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init)
tar: Removing leading `/' from member names
Unable to find image 'ghcr.io/apache/ozone-runner:20250625-2-jdk21' locally
20250625-2-jdk21: Pulling from apache/ozone-runner
446f83f14b23: Pulling fs layer
05031e12e66b: Pulling fs layer
a0d7c998436e: Pulling fs layer
b86f775fe6a7: Pulling fs layer
e3d7d9db1686: Pulling fs layer
4bfd14da3275: Pulling fs layer
63273913212c: Pulling fs layer
e0bd0fcdff28: Pulling fs layer
160e70adc3b5: Pulling fs layer
95af4d3086dc: Pulling fs layer
769472d26684: Pulling fs layer
bb9073af6edc: Pulling fs layer
92e1a6f355f8: Pulling fs layer
8f6416002b1d: Pulling fs layer
41234bfb1195: Pulling fs layer
b75b95baa8e3: Pulling fs layer
122942b2173c: Pulling fs layer
f5af012ec5f1: Pulling fs layer
8d00bc5b2817: Pulling fs layer
e41b27f95d08: Pulling fs layer
6991af0fb345: Pulling fs layer
4f4fb700ef54: Pulling fs layer
b86f775fe6a7: Waiting
e3d7d9db1686: Waiting
8f6416002b1d: Waiting
41234bfb1195: Waiting
4bfd14da3275: Waiting
b75b95baa8e3: Waiting
63273913212c: Waiting
122942b2173c: Waiting
e0bd0fcdff28: Waiting
f5af012ec5f1: Waiting
160e70adc3b5: Waiting
8d00bc5b2817: Waiting
95af4d3086dc: Waiting
e41b27f95d08: Waiting
769472d26684: Waiting
92e1a6f355f8: Waiting
bb9073af6edc: Waiting
6991af0fb345: Waiting
4f4fb700ef54: Waiting
a0d7c998436e: Verifying Checksum
a0d7c998436e: Download complete
05031e12e66b: Verifying Checksum
05031e12e66b: Download complete
b86f775fe6a7: Verifying Checksum
b86f775fe6a7: Download complete
446f83f14b23: Verifying Checksum
446f83f14b23: Download complete
63273913212c: Verifying Checksum
63273913212c: Download complete
4bfd14da3275: Verifying Checksum
4bfd14da3275: Download complete
e3d7d9db1686: Verifying Checksum
e3d7d9db1686: Download complete
e0bd0fcdff28: Verifying Checksum
e0bd0fcdff28: Download complete
160e70adc3b5: Download complete
95af4d3086dc: Verifying Checksum
95af4d3086dc: Download complete
bb9073af6edc: Verifying Checksum
bb9073af6edc: Download complete
92e1a6f355f8: Verifying Checksum
92e1a6f355f8: Download complete
8f6416002b1d: Verifying Checksum
8f6416002b1d: Download complete
41234bfb1195: Verifying Checksum
41234bfb1195: Download complete
b75b95baa8e3: Verifying Checksum
b75b95baa8e3: Download complete
122942b2173c: Verifying Checksum
122942b2173c: Download complete
f5af012ec5f1: Download complete
8d00bc5b2817: Verifying Checksum
8d00bc5b2817: Download complete
e41b27f95d08: Verifying Checksum
e41b27f95d08: Download complete
6991af0fb345: Verifying Checksum
6991af0fb345: Download complete
4f4fb700ef54: Verifying Checksum
4f4fb700ef54: Download complete
769472d26684: Verifying Checksum
769472d26684: Download complete
446f83f14b23: Pull complete
05031e12e66b: Pull complete
a0d7c998436e: Pull complete
b86f775fe6a7: Pull complete
e3d7d9db1686: Pull complete
4bfd14da3275: Pull complete
63273913212c: Pull complete
e0bd0fcdff28: Pull complete
160e70adc3b5: Pull complete
95af4d3086dc: Pull complete
769472d26684: Pull complete
bb9073af6edc: Pull complete
92e1a6f355f8: Pull complete
8f6416002b1d: Pull complete
41234bfb1195: Pull complete
b75b95baa8e3: Pull complete
122942b2173c: Pull complete
f5af012ec5f1: Pull complete
8d00bc5b2817: Pull complete
e41b27f95d08: Pull complete
6991af0fb345: Pull complete
4f4fb700ef54: Pull complete
Digest: sha256:c4d41c7f4f89502f750d86a6b5c40528c68274d1a70fa7adee03c96b1be1bb5b
Status: Downloaded newer image for ghcr.io/apache/ozone-runner:20250625-2-jdk21
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/output.xml
Log:     /rebot-output/log.html
Report:  /rebot-output/report.html
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/getting-started/result/rebot-dqnKMl/log.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/getting-started/result/log.html'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/getting-started/result/rebot-dqnKMl/output.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/getting-started/result/output.xml'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/getting-started/result/rebot-dqnKMl/report.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/getting-started/result/report.html'

**** Collecting container logs ****

Defaulted container "scm" out of: scm, init (init)

**** Deleting k8s resources ****

configmap "config" deleted from default namespace
service "datanode" deleted from default namespace
service "datanode-public" deleted from default namespace
service "httpfs" deleted from default namespace
service "httpfs-public" deleted from default namespace
service "om" deleted from default namespace
service "om-public" deleted from default namespace
service "recon" deleted from default namespace
service "recon-public" deleted from default namespace
service "s3g" deleted from default namespace
service "s3g-public" deleted from default namespace
service "scm" deleted from default namespace
service "scm-public" deleted from default namespace
statefulset.apps "datanode" deleted from default namespace
statefulset.apps "httpfs" deleted from default namespace
statefulset.apps "om" deleted from default namespace
statefulset.apps "recon" deleted from default namespace
statefulset.apps "s3g" deleted from default namespace
statefulset.apps "scm" deleted from default namespace

**** Regenerating original Kubernetes resource files ****


#### Executing tests of minikube #####


**** Modifying Kubernetes resources file for test ****

   (mounting current Ozone directory to the containers, scheduling containers to one node, ...)

WARNING: this test can be executed only with local Kubernetes cluster
   (source dir should be available from K8s nodes)


**** Deleting existing k8s resources ****

No resources found
No resources found
No resources found
service "kubernetes" deleted from default namespace
configmap "kube-root-ca.crt" deleted from default namespace
pod "datanode-2" deleted from default namespace
pod "datanode-1" deleted from default namespace
pod "datanode-0" deleted from default namespace
pod "om-0" deleted from default namespace
pod "s3g-0" deleted from default namespace
pod "scm-0" deleted from default namespace
pod "httpfs-0" deleted from default namespace
pod "recon-0" deleted from default namespace
No resources found
No resources found

**** Applying k8s resources from minikube ****

configmap/config created
service/datanode created
service/datanode-public created
service/httpfs created
service/httpfs-public created
service/om created
service/om-public created
service/recon created
service/recon-public created
service/s3g created
service/s3g-public created
service/scm created
service/scm-public created
statefulset.apps/datanode created
statefulset.apps/httpfs created
statefulset.apps/om created
statefulset.apps/recon created
statefulset.apps/s3g created
statefulset.apps/scm created

**** Waiting until the k8s cluster is running ****

No resources found in default namespace.
0 pods are running. Waiting for more.
1 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
2 'all_pods_are_running' is failed...
4 / 7 pods are running
3 'all_pods_are_running' is failed...
7 / 8 pods are running
4 'all_pods_are_running' is failed...
7 / 8 pods are running
5 'all_pods_are_running' is failed...
7 / 8 pods are running
6 'all_pods_are_running' is failed...
Defaulted container "scm" out of: scm, init (init)
1 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
2 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
3 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
4 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
5 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
6 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
2025-11-18 10:04:33 INFO  SCMSafeModeManager:159 - SCM exiting safe mode.
2025-11-18 10:04:30 INFO  BaseHttpServer:357 - HTTP server of ozoneManager listening at http://om-0:9874

**** Cluster is up and running ****


**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Basic :: Smoketest ozone cluster startup                                      
==============================================================================
Check webui static resources                                          | PASS |
------------------------------------------------------------------------------
Basic Freon smoketest                                                 | PASS |
------------------------------------------------------------------------------
Basic :: Smoketest ozone cluster startup                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init)
tar: Removing leading `/' from member names
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/output.xml
Log:     /rebot-output/log.html
Report:  /rebot-output/report.html
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/minikube/result/rebot-1sOASI/log.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/minikube/result/log.html'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/minikube/result/rebot-1sOASI/output.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/minikube/result/output.xml'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/minikube/result/rebot-1sOASI/report.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/minikube/result/report.html'

**** Collecting container logs ****

Defaulted container "scm" out of: scm, init (init)

**** Deleting k8s resources ****

configmap "config" deleted from default namespace
service "datanode" deleted from default namespace
service "datanode-public" deleted from default namespace
service "httpfs" deleted from default namespace
service "httpfs-public" deleted from default namespace
service "om" deleted from default namespace
service "om-public" deleted from default namespace
service "recon" deleted from default namespace
service "recon-public" deleted from default namespace
service "s3g" deleted from default namespace
service "s3g-public" deleted from default namespace
service "scm" deleted from default namespace
service "scm-public" deleted from default namespace
statefulset.apps "datanode" deleted from default namespace
statefulset.apps "httpfs" deleted from default namespace
statefulset.apps "om" deleted from default namespace
statefulset.apps "recon" deleted from default namespace
statefulset.apps "s3g" deleted from default namespace
statefulset.apps "scm" deleted from default namespace

**** Regenerating original Kubernetes resource files ****


#### Executing tests of ozone-dev #####


**** Modifying Kubernetes resources file for test ****

   (mounting current Ozone directory to the containers, scheduling containers to one node, ...)

WARNING: this test can be executed only with local Kubernetes cluster
   (source dir should be available from K8s nodes)


**** Deleting existing k8s resources ****

No resources found
No resources found
No resources found
service "kubernetes" deleted from default namespace
configmap "kube-root-ca.crt" deleted from default namespace
pod "datanode-1" deleted from default namespace
pod "datanode-0" deleted from default namespace
pod "datanode-2" deleted from default namespace
pod "om-0" deleted from default namespace
pod "s3g-0" deleted from default namespace
pod "scm-0" deleted from default namespace
pod "httpfs-0" deleted from default namespace
pod "recon-0" deleted from default namespace
No resources found
No resources found

**** Applying k8s resources from ozone-dev ****

serviceaccount/prometheus-operator created
Warning: rbac.authorization.k8s.io/v1beta1 ClusterRole is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRole
clusterrole.rbac.authorization.k8s.io/prometheus-default created
Warning: rbac.authorization.k8s.io/v1beta1 ClusterRoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRoleBinding
clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator-default created
configmap/config created
configmap/prometheusconf created
service/datanode created
service/datanode-public created
service/httpfs created
service/httpfs-public created
service/jaeger created
service/jaeger-public created
service/om created
service/om-public created
service/prometheus created
service/recon created
service/recon-public created
service/s3g created
service/s3g-public created
service/scm created
service/scm-public created
deployment.apps/prometheus created
statefulset.apps/datanode created
statefulset.apps/httpfs created
statefulset.apps/jaeger created
statefulset.apps/om created
statefulset.apps/recon created
statefulset.apps/s3g created
statefulset.apps/scm created

**** Waiting until the k8s cluster is running ****

No resources found in default namespace.
0 pods are running. Waiting for more.
1 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
2 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
3 'all_pods_are_running' is failed...
5 / 9 pods are running
4 'all_pods_are_running' is failed...
9 / 10 pods are running
5 'all_pods_are_running' is failed...
9 / 10 pods are running
6 'all_pods_are_running' is failed...
Defaulted container "scm" out of: scm, init (init)
1 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
2 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
3 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
4 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
5 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
2025-11-18 10:05:32 INFO  SCMSafeModeManager:159 - SCM exiting safe mode.
2025-11-18 10:05:31 INFO  BaseHttpServer:357 - HTTP server of ozoneManager listening at http://om-0:9874

**** Cluster is up and running ****


**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Basic :: Smoketest ozone cluster startup                                      
==============================================================================
Check webui static resources                                          | PASS |
------------------------------------------------------------------------------
Basic Freon smoketest                                                 | PASS |
------------------------------------------------------------------------------
Basic :: Smoketest ozone cluster startup                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init)
tar: Removing leading `/' from member names
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/output.xml
Log:     /rebot-output/log.html
Report:  /rebot-output/report.html
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-dev/result/rebot-9bRFBG/log.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-dev/result/log.html'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-dev/result/rebot-9bRFBG/output.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-dev/result/output.xml'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-dev/result/rebot-9bRFBG/report.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-dev/result/report.html'

**** Collecting container logs ****

Defaulted container "scm" out of: scm, init (init)

**** Deleting k8s resources ****

serviceaccount "prometheus-operator" deleted from default namespace
Warning: rbac.authorization.k8s.io/v1beta1 ClusterRole is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRole
clusterrole.rbac.authorization.k8s.io "prometheus-default" deleted
Warning: rbac.authorization.k8s.io/v1beta1 ClusterRoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRoleBinding
clusterrolebinding.rbac.authorization.k8s.io "prometheus-operator-default" deleted
configmap "config" deleted from default namespace
configmap "prometheusconf" deleted from default namespace
service "datanode" deleted from default namespace
service "datanode-public" deleted from default namespace
service "httpfs" deleted from default namespace
service "httpfs-public" deleted from default namespace
service "jaeger" deleted from default namespace
service "jaeger-public" deleted from default namespace
service "om" deleted from default namespace
service "om-public" deleted from default namespace
service "prometheus" deleted from default namespace
service "recon" deleted from default namespace
service "recon-public" deleted from default namespace
service "s3g" deleted from default namespace
service "s3g-public" deleted from default namespace
service "scm" deleted from default namespace
service "scm-public" deleted from default namespace
deployment.apps "prometheus" deleted from default namespace
statefulset.apps "datanode" deleted from default namespace
statefulset.apps "httpfs" deleted from default namespace
statefulset.apps "jaeger" deleted from default namespace
statefulset.apps "om" deleted from default namespace
statefulset.apps "recon" deleted from default namespace
statefulset.apps "s3g" deleted from default namespace
statefulset.apps "scm" deleted from default namespace

**** Regenerating original Kubernetes resource files ****


#### Executing tests of ozone-ha #####


**** Modifying Kubernetes resources file for test ****

   (mounting current Ozone directory to the containers, scheduling containers to one node, ...)

WARNING: this test can be executed only with local Kubernetes cluster
   (source dir should be available from K8s nodes)


**** Deleting existing k8s resources ****

No resources found
No resources found
No resources found
service "kubernetes" deleted from default namespace
configmap "kube-root-ca.crt" deleted from default namespace
pod "datanode-2" deleted from default namespace
pod "datanode-1" deleted from default namespace
pod "datanode-0" deleted from default namespace
pod "prometheus-79f5678f86-rwbsd" deleted from default namespace
pod "jaeger-0" deleted from default namespace
pod "om-0" deleted from default namespace
pod "s3g-0" deleted from default namespace
pod "httpfs-0" deleted from default namespace
pod "recon-0" deleted from default namespace
pod "scm-0" deleted from default namespace
No resources found
No resources found

**** Applying k8s resources from ozone-ha ****

configmap/config created
service/datanode created
service/httpfs created
service/om created
service/recon created
service/s3g created
service/scm created
statefulset.apps/datanode created
statefulset.apps/httpfs created
statefulset.apps/om created
statefulset.apps/recon created
statefulset.apps/s3g created
statefulset.apps/scm created

**** Waiting until the k8s cluster is running ****

No resources found in default namespace.
0 pods are running. Waiting for more.
1 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
2 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
3 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
4 'all_pods_are_running' is failed...
1 pods are running. Waiting for more.
5 'all_pods_are_running' is failed...
4 / 7 pods are running
6 'all_pods_are_running' is failed...
4 / 7 pods are running
7 'all_pods_are_running' is failed...
5 / 7 pods are running
8 'all_pods_are_running' is failed...
6 / 8 pods are running
9 'all_pods_are_running' is failed...
6 / 8 pods are running
10 'all_pods_are_running' is failed...
8 / 9 pods are running
11 'all_pods_are_running' is failed...
8 / 9 pods are running
12 'all_pods_are_running' is failed...
8 / 9 pods are running
13 'all_pods_are_running' is failed...
8 / 9 pods are running
14 'all_pods_are_running' is failed...
8 / 9 pods are running
15 'all_pods_are_running' is failed...
9 / 10 pods are running
16 'all_pods_are_running' is failed...
9 / 10 pods are running
17 'all_pods_are_running' is failed...
9 / 10 pods are running
18 'all_pods_are_running' is failed...
9 / 10 pods are running
19 'all_pods_are_running' is failed...
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
1 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
2 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
3 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
4 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
2025-11-18 10:07:09 INFO  SCMSafeModeManager:159 - SCM exiting safe mode.
2025-11-18 10:06:52 INFO  BaseHttpServer:357 - HTTP server of ozoneManager listening at http://om-0:9874

**** Cluster is up and running ****


**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init), bootstrap (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Basic :: Smoketest ozone cluster startup                                      
==============================================================================
Check webui static resources                                          | PASS |
------------------------------------------------------------------------------
Basic Freon smoketest                                                 | PASS |
------------------------------------------------------------------------------
Basic :: Smoketest ozone cluster startup                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
tar: Removing leading `/' from member names
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/output.xml
Log:     /rebot-output/log.html
Report:  /rebot-output/report.html
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-ha/result/rebot-pPM2kM/log.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-ha/result/log.html'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-ha/result/rebot-pPM2kM/output.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-ha/result/output.xml'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-ha/result/rebot-pPM2kM/report.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone-ha/result/report.html'

**** Collecting container logs ****

Defaulted container "scm" out of: scm, init (init), bootstrap (init)
Defaulted container "scm" out of: scm, init (init), bootstrap (init)
Defaulted container "scm" out of: scm, init (init), bootstrap (init)

**** Deleting k8s resources ****

configmap "config" deleted from default namespace
service "datanode" deleted from default namespace
service "httpfs" deleted from default namespace
service "om" deleted from default namespace
service "recon" deleted from default namespace
service "s3g" deleted from default namespace
service "scm" deleted from default namespace
statefulset.apps "datanode" deleted from default namespace
statefulset.apps "httpfs" deleted from default namespace
statefulset.apps "om" deleted from default namespace
statefulset.apps "recon" deleted from default namespace
statefulset.apps "s3g" deleted from default namespace
statefulset.apps "scm" deleted from default namespace

**** Regenerating original Kubernetes resource files ****


#### Executing tests of ozone #####


**** Modifying Kubernetes resources file for test ****

   (mounting current Ozone directory to the containers, scheduling containers to one node, ...)

WARNING: this test can be executed only with local Kubernetes cluster
   (source dir should be available from K8s nodes)


**** Deleting existing k8s resources ****

No resources found
No resources found
No resources found
service "kubernetes" deleted from default namespace
configmap "kube-root-ca.crt" deleted from default namespace
pod "datanode-1" deleted from default namespace
pod "datanode-0" deleted from default namespace
pod "datanode-2" deleted from default namespace
pod "httpfs-0" deleted from default namespace
pod "om-0" deleted from default namespace
pod "recon-0" deleted from default namespace
pod "s3g-0" deleted from default namespace
pod "scm-0" deleted from default namespace
pod "scm-1" deleted from default namespace
pod "scm-2" deleted from default namespace
persistentvolumeclaim "data-httpfs-0" deleted from default namespace
persistentvolumeclaim "data-datanode-0" deleted from default namespace
persistentvolumeclaim "data-om-0" deleted from default namespace
persistentvolumeclaim "data-recon-0" deleted from default namespace
persistentvolumeclaim "data-s3g-0" deleted from default namespace
persistentvolumeclaim "data-scm-0" deleted from default namespace
persistentvolumeclaim "data-datanode-1" deleted from default namespace
persistentvolumeclaim "data-datanode-2" deleted from default namespace
persistentvolumeclaim "data-scm-1" deleted from default namespace
persistentvolumeclaim "data-scm-2" deleted from default namespace
persistentvolume "pvc-4a404bed-4fc2-4fed-8dee-99b1be0c120a" deleted
persistentvolume "pvc-fc330ebc-f1ea-4912-9191-5ee89869ac1a" deleted
persistentvolume "pvc-bce64dea-fa82-437d-8247-261ac1a57f05" deleted
persistentvolume "pvc-8a524ae9-4674-4747-9cfa-2f866eef9e87" deleted
persistentvolume "pvc-ae477f32-9669-43db-9b31-860ebe75e512" deleted
persistentvolume "pvc-c9cf4ce5-9f23-4ee8-b215-bb07c8732333" deleted
persistentvolume "pvc-3350a85b-ca75-4ec5-a775-43b46cb550e3" deleted
persistentvolume "pvc-67262db3-3109-44bc-b000-9984e89ee6f3" deleted
persistentvolume "pvc-550fbf31-eeba-4afe-8005-ce7589b97f86" deleted
persistentvolume "pvc-28985a1b-ed6d-4265-9448-b9deeeaa4ac9" deleted

**** Applying k8s resources from ozone ****

configmap/config created
service/datanode created
service/httpfs created
service/om created
service/recon created
service/s3g created
service/scm created
statefulset.apps/datanode created
statefulset.apps/httpfs created
statefulset.apps/om created
statefulset.apps/recon created
statefulset.apps/s3g created
statefulset.apps/scm created

**** Waiting until the k8s cluster is running ****

No resources found in default namespace.
0 pods are running. Waiting for more.
1 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
2 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
3 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
4 'all_pods_are_running' is failed...
No resources found in default namespace.
0 pods are running. Waiting for more.
5 'all_pods_are_running' is failed...
1 pods are running. Waiting for more.
6 'all_pods_are_running' is failed...
2 pods are running. Waiting for more.
7 'all_pods_are_running' is failed...
4 / 7 pods are running
8 'all_pods_are_running' is failed...
4 / 7 pods are running
9 'all_pods_are_running' is failed...
4 / 7 pods are running
10 'all_pods_are_running' is failed...
6 / 8 pods are running
11 'all_pods_are_running' is failed...
7 / 8 pods are running
12 'all_pods_are_running' is failed...
Defaulted container "scm" out of: scm, init (init)
1 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
2 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
3 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
4 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
5 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
6 'grep_log scm-0 SCM exiting safe mode.' is failed...
Defaulted container "scm" out of: scm, init (init)
2025-11-18 10:08:34 INFO  SCMSafeModeManager:159 - SCM exiting safe mode.
2025-11-18 10:08:33 INFO  BaseHttpServer:357 - HTTP server of ozoneManager listening at http://om-0:9874

**** Cluster is up and running ****


**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init)
tar: Removing leading `/' from member names

**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init)
tar: Removing leading `/' from member names
pod "datanode-0" deleted from default namespace
pod "datanode-1" deleted from default namespace
pod "datanode-2" deleted from default namespace

**** Waiting until the k8s cluster is running ****

6 / 7 pods are running
1 'all_pods_are_running' is failed...
Defaulted container "scm" out of: scm, init (init)
2025-11-18 10:08:34 INFO  SCMSafeModeManager:159 - SCM exiting safe mode.
2025-11-18 10:08:33 INFO  BaseHttpServer:357 - HTTP server of ozoneManager listening at http://om-0:9874

**** Cluster is up and running ****


**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init)
tar: Removing leading `/' from member names

**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | FAIL |
255 != 0
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | FAIL |
3 tests, 2 passed, 1 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init)
tar: Removing leading `/' from member names

**** Executing robot tests scm-0 ****

Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
Defaulted container "scm" out of: scm, init (init)
Unable to use a TTY - input is not a terminal or the right kind of file
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | FAIL |
255 != 0
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | FAIL |
1 test, 0 passed, 1 failed
==============================================================================
Output:  /tmp/report/output.xml
Log:     /tmp/report/log.html
Report:  /tmp/report/report.html
Defaulted container "scm" out of: scm, init (init)
tar: Removing leading `/' from member names
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/output.xml
Log:     /rebot-output/log.html
Report:  /rebot-output/report.html
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone/result/rebot-SR5gcS/log.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone/result/log.html'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone/result/rebot-SR5gcS/output.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone/result/output.xml'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone/result/rebot-SR5gcS/report.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/ozone/result/report.html'

**** Collecting container logs ****

Defaulted container "scm" out of: scm, init (init)

**** Deleting k8s resources ****

configmap "config" deleted from default namespace
service "datanode" deleted from default namespace
service "httpfs" deleted from default namespace
service "om" deleted from default namespace
service "recon" deleted from default namespace
service "s3g" deleted from default namespace
service "scm" deleted from default namespace
statefulset.apps "datanode" deleted from default namespace
statefulset.apps "httpfs" deleted from default namespace
statefulset.apps "om" deleted from default namespace
statefulset.apps "recon" deleted from default namespace
statefulset.apps "s3g" deleted from default namespace
statefulset.apps "scm" deleted from default namespace

**** Regenerating original Kubernetes resource files ****

To use Ozone please mount ozone folder to /opt/hadoop
Log:     /rebot-output/log.html
Report:  /rebot-output/report.html
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/result/rebot-77TV2i/log.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/result/log.html'
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/result/rebot-77TV2i/report.html' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.2.0-SNAPSHOT/kubernetes/examples/result/report.html'
