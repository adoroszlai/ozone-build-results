Using Docker Compose v2
Executing test compatibility/test.sh
Error: Could not find or load main class org.apache.ozone.test.JacocoServer
Caused by: java.lang.ClassNotFoundException: org.apache.ozone.test.JacocoServer
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
WARNING: HADOOP_OPTS has been deprecated by OZONE_OPTS.
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Dn :: Test datanode compatibility                                             
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Dn :: Test datanode compatibility                                     | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-001.xml
==============================================================================
Om :: Test om compatibility                                                   
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Rejects Atomic Key Rewrite                                            | PASS |
------------------------------------------------------------------------------
Om :: Test om compatibility                                           | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-002.xml
==============================================================================
Recon :: Test recon compatibility                                             
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Recon :: Test recon compatibility                                     | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-003.xml
==============================================================================
Scm :: Test scm compatibility                                                 
==============================================================================
Picks up command line options                                         | PASS |
------------------------------------------------------------------------------
Scm :: Test scm compatibility                                         | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-004.xml
==============================================================================
Dn-One-Rocksdb :: Test merge rocksdb in datanode compatibility                
==============================================================================
Create a container and check container schema version                 | PASS |
------------------------------------------------------------------------------
Dn-One-Rocksdb :: Test merge rocksdb in datanode compatibility        | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/compatibility/result/robot-005.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/compatibility.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/rebot-YKIDL4/compatibility.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility.xml'
removed 'compatibility/result/robot-001.xml'
removed 'compatibility/result/robot-002.xml'
removed 'compatibility/result/robot-003.xml'
removed 'compatibility/result/robot-004.xml'
removed 'compatibility/result/robot-005.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility'
renamed 'compatibility/result/dn-audit-5b8b1bbef756.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/dn-audit-5b8b1bbef756.log'
renamed 'compatibility/result/docker-compatibility-datanode-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-datanode-1.log'
renamed 'compatibility/result/docker-compatibility-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-om-1.log'
renamed 'compatibility/result/docker-compatibility-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-recon-1.log'
renamed 'compatibility/result/docker-compatibility-s3g-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-s3g-1.log'
renamed 'compatibility/result/docker-compatibility-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/docker-compatibility-scm-1.log'
renamed 'compatibility/result/om-audit-3069109e5bb8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/om-audit-3069109e5bb8.log'
renamed 'compatibility/result/om-sys-audit-3069109e5bb8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/om-sys-audit-3069109e5bb8.log'
renamed 'compatibility/result/s3g-audit-91493912abe8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/s3g-audit-91493912abe8.log'
renamed 'compatibility/result/scm-audit-b9479f4325bf.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/compatibility/scm-audit-b9479f4325bf.log'
Executing test ozone-csi/test.sh
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Error response from daemon: container 148e3283f5a513e4d256d8622ef6177af93c5598b4f94910f0400cc5c56a4ba7 is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
Timed out waiting on scm 9860 to become available
ERROR: Test execution of ozone-csi/test.sh is FAILED!!!!
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-csi'
renamed 'ozone-csi/result/docker-ozone-csi-csi-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-csi-1.log'
renamed 'ozone-csi/result/docker-ozone-csi-datanode-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-datanode-1.log'
renamed 'ozone-csi/result/docker-ozone-csi-datanode-2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-datanode-2.log'
renamed 'ozone-csi/result/docker-ozone-csi-datanode-3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-datanode-3.log'
renamed 'ozone-csi/result/docker-ozone-csi-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-om-1.log'
renamed 'ozone-csi/result/docker-ozone-csi-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-scm-1.log'
Executing test ozone-om-prepare/test.sh
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/ozone-om-prepare/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/ozone-om-prepare/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/ozone-om-prepare/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/ozone-om-prepare/data/om2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/ozone-om-prepare/data/om1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/ozone-om-prepare/data/om3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/ozone-om-prepare/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/ozone-om-prepare/data': Operation not permitted
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 227
SCM is out of safe mode.
Could not determine or connect to OM Leader.
Waiting for OM leader for service omservice
SECONDS: 9
Found OM leader for service omservice: om3 : LEADER (om3)
Replaced OM order with om3,om2,om1 in ozone-om-prepare-scm-1
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | PASS |
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-001.xml
==============================================================================
Om-Cancel-Prepare :: Smoke test for ozone manager cancel prepare              
==============================================================================
Cancel Ozone Manager Prepare                                          | PASS |
------------------------------------------------------------------------------
Test write operations                                                 | PASS |
------------------------------------------------------------------------------
Om-Cancel-Prepare :: Smoke test for ozone manager cancel prepare      | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-002.xml
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | PASS |
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-003.xml
==============================================================================
Om-Prepared :: Smoke test to test that OMs are prepared in an OM HA cluster.  
==============================================================================
Test create volume fails                                              | PASS |
------------------------------------------------------------------------------
Test list volumes succeeds                                            | PASS |
------------------------------------------------------------------------------
Om-Prepared :: Smoke test to test that OMs are prepared in an OM H... | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-004.xml
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is out of safe mode.
Found OM leader for service omservice: om2 : LEADER (om2)
Replaced OM order with om2,om3,om1 in ozone-om-prepare-scm-1
==============================================================================
Om-Prepared :: Smoke test to test that OMs are prepared in an OM HA cluster.  
==============================================================================
Test create volume fails                                              | PASS |
------------------------------------------------------------------------------
Test list volumes succeeds                                            | PASS |
------------------------------------------------------------------------------
Om-Prepared :: Smoke test to test that OMs are prepared in an OM H... | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-005.xml
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is out of safe mode.
Found OM leader for service omservice: om1 : LEADER (om1)
Replaced OM order with om1,om3,om2 in ozone-om-prepare-scm-1
==============================================================================
Loaddata :: Smoketest ozone cluster startup                                   
==============================================================================
Create a volume, bucket and key                                       | PASS |
------------------------------------------------------------------------------
Loaddata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-006.xml
==============================================================================
Readdata :: Smoketest ozone cluster startup                                   
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
Readdata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-007.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/ozone-om-prepare.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/rebot-UFXYtN/ozone-om-prepare.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare.xml'
removed 'ozone-om-prepare/result/robot-001.xml'
removed 'ozone-om-prepare/result/robot-002.xml'
removed 'ozone-om-prepare/result/robot-003.xml'
removed 'ozone-om-prepare/result/robot-004.xml'
removed 'ozone-om-prepare/result/robot-005.xml'
removed 'ozone-om-prepare/result/robot-006.xml'
removed 'ozone-om-prepare/result/robot-007.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare'
renamed 'ozone-om-prepare/result/dn-audit-63e3497b3ba5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-63e3497b3ba5.log'
renamed 'ozone-om-prepare/result/dn-audit-8532f85c3705.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-8532f85c3705.log'
renamed 'ozone-om-prepare/result/dn-audit-892210b67b63.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-892210b67b63.log'
renamed 'ozone-om-prepare/result/dn-audit-9a653dd11638.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-9a653dd11638.log'
renamed 'ozone-om-prepare/result/dn-audit-aaeca1d789e3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-aaeca1d789e3.log'
renamed 'ozone-om-prepare/result/dn-audit-d0a9e03eb718.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-d0a9e03eb718.log'
renamed 'ozone-om-prepare/result/dn-audit-de30aa1377c6.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-de30aa1377c6.log'
renamed 'ozone-om-prepare/result/dn-audit-ed22503d273c.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-ed22503d273c.log'
renamed 'ozone-om-prepare/result/dn-audit-f0b985f21974.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-f0b985f21974.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-dn1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-dn1-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-dn2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-dn2-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-dn3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-dn3-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-om1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-om1-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-om2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-om2-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-om3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-om3-1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-scm-1.log'
renamed 'ozone-om-prepare/result/om-audit-0a0e80c7a5f6.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-0a0e80c7a5f6.log'
renamed 'ozone-om-prepare/result/om-audit-1b23a471c0d0.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-1b23a471c0d0.log'
renamed 'ozone-om-prepare/result/om-audit-62aecf2c180a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-62aecf2c180a.log'
renamed 'ozone-om-prepare/result/om-audit-8db618d0e0f2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-8db618d0e0f2.log'
renamed 'ozone-om-prepare/result/om-audit-9099e5f5ced2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-9099e5f5ced2.log'
renamed 'ozone-om-prepare/result/om-audit-b88d8c182990.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-b88d8c182990.log'
renamed 'ozone-om-prepare/result/om-audit-ba415cfca927.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-ba415cfca927.log'
renamed 'ozone-om-prepare/result/om-audit-c09bddc9c5e2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-c09bddc9c5e2.log'
renamed 'ozone-om-prepare/result/om-audit-ffed5acce447.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-ffed5acce447.log'
renamed 'ozone-om-prepare/result/om-sys-audit-0a0e80c7a5f6.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-0a0e80c7a5f6.log'
renamed 'ozone-om-prepare/result/om-sys-audit-1b23a471c0d0.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-1b23a471c0d0.log'
renamed 'ozone-om-prepare/result/om-sys-audit-62aecf2c180a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-62aecf2c180a.log'
renamed 'ozone-om-prepare/result/om-sys-audit-8db618d0e0f2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-8db618d0e0f2.log'
renamed 'ozone-om-prepare/result/om-sys-audit-9099e5f5ced2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-9099e5f5ced2.log'
renamed 'ozone-om-prepare/result/om-sys-audit-b88d8c182990.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-b88d8c182990.log'
renamed 'ozone-om-prepare/result/om-sys-audit-ba415cfca927.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-ba415cfca927.log'
renamed 'ozone-om-prepare/result/om-sys-audit-c09bddc9c5e2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-c09bddc9c5e2.log'
renamed 'ozone-om-prepare/result/om-sys-audit-ffed5acce447.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/om-sys-audit-ffed5acce447.log'
renamed 'ozone-om-prepare/result/scm-audit-199cb722b662.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-199cb722b662.log'
renamed 'ozone-om-prepare/result/scm-audit-b6c4d6729c7c.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-b6c4d6729c7c.log'
renamed 'ozone-om-prepare/result/scm-audit-db34b3cc02c9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-db34b3cc02c9.log'
Executing test ozone-topology/test.sh
Using Docker Compose v2
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Error response from daemon: container fa9077497c247d4e18592a9fa523149f5ae1456a5e88841a763df1080215ea8a is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
Timed out waiting on scm 9860 to become available
ERROR: Test execution of ozone-topology/test.sh is FAILED!!!!
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_1-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_2-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_3-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_4-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_4-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_5-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_5-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-datanode_6-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-datanode_6-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-om-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-recon-1.log'
renamed 'ozone-topology/result/docker-ozone-topology-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology-scm-1.log'
Executing test ozonescripts/test.sh
Using Docker Compose v2
Port 22 is available on scm
Port 22 is available on om
Port 22 is available on datanode
No OM HA service, no need to wait
Using Docker Compose v2
+ docker-compose ps
+ docker compose --progress quiet ps
+ grep datanode
+ awk '{print $1}'
+ xargs -n1 docker inspect --format '{{ .Config.Hostname }}'
+ docker-compose ps
+ docker compose --progress quiet ps
+ grep ozonescripts
+ awk '{print $1}'
+ xargs -I CONTAINER -n1 docker exec CONTAINER cp /opt/hadoop/etc/hadoop/workers /etc/hadoop/workers
+ docker-compose exec -T scm /opt/hadoop/bin/ozone scm --init
+ docker compose --progress quiet exec -T scm /opt/hadoop/bin/ozone scm --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2025-03-04 04:15:40,016 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 80822ea057e7/172.20.0.2
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 2.0.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.2.jar:/opt/hadoop/share/ozone/lib/guava-32.1.3-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.37.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.29.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-io-2.18.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.6.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.27.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.17.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.17.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.25.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.25.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.25.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.1.2.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.25.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.10.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.30.2-GA.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/hdds-config-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.7-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.24.2.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.40.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.4.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.7.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.4.1.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_25-1.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.26.jar:/opt/hadoop/share/ozone/lib/jnr-constants-0.10.4.jar:/opt/hadoop/share/ozone/lib/jnr-posix-3.1.20.jar:/opt/hadoop/share/ozone/lib/jnr-ffi-2.2.17.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13-native.jar:/opt/hadoop/share/ozone/lib/asm-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-commons-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-analysis-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-tree-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-util-9.7.1.jar:/opt/hadoop/share/ozone/lib/jnr-a64asm-1.0.0.jar:/opt/hadoop/share/ozone/lib/jnr-x86asm-1.0.2.jar:/opt/hadoop/share/ozone/lib/gson-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.11.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.24.2.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.12.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.1.2.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.46.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.46.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.46.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.46.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.17.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.3.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.5.4.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-classes-epoll-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web
STARTUP_MSG:   build = https://github.com/apache/ozone/4c28c7f62d670e5d7fbffa6b017052b75f2c5d50
STARTUP_MSG:   java = 21.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.data.dir=file:///tmp/hadoop-hadoop/dfs/data, hdds.datanode.delete.container.timeout=60s, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.read.threadpool=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.auto-compaction-small-sst-file.interval.minutes=120, hdds.datanode.rocksdb.auto-compaction-small-sst-file.threads=1, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.event.timeout=12m, hdds.scm.replication.event.timeout.datanode.offset=6m, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.hbase.enhancements.allowed=false, ozone.http.basedir=/tmp/ozone_http, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.ksm.address=ksm, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=5s, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=1, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2025-03-04 04:15:40,037 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [SIGHUP, SIGINT, SIGTERM]
2025-03-04 04:15:40,064 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-03-04 04:15:40,215 [main] INFO reflections.Reflections: Reflections took 136 ms to scan 3 urls, producing 128 keys and 286 values
2025-03-04 04:15:40,292 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-03-04 04:15:40,293 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-03-04 04:15:40,652 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-03-04 04:15:40,653 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2025-03-04 04:15:40,653 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2025-03-04 04:15:40,700 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-03-04 04:15:40,720 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2025-03-04 04:15:40,772 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2025-03-04 04:15:40,773 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2025-03-04 04:15:40,774 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2025-03-04 04:15:40,774 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2025-03-04 04:15:40,774 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2025-03-04 04:15:40,774 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2025-03-04 04:15:40,775 [main] INFO server.GrpcService: raft.grpc.message.size.max = 34603008 (custom)
2025-03-04 04:15:40,775 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2025-03-04 04:15:40,775 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-03-04 04:15:40,782 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2025-03-04 04:15:40,782 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-03-04 04:15:40,785 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2025-03-04 04:15:40,785 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2025-03-04 04:15:40,913 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2025-03-04 04:15:40,914 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-03-04 04:15:40,914 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2025-03-04 04:15:40,914 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-03-04 04:15:40,917 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-03-04 04:15:40,918 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2025-03-04 04:15:40,918 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2025-03-04 04:15:40,934 [main] INFO server.RaftServer: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: addNew group-59B40D1FC711:[f44f8c74-7caf-4a51-a16b-9ef6a49fafc3|80822ea057e7:9894] returns group-59B40D1FC711:java.util.concurrent.CompletableFuture@4f82663e[Not completed]
2025-03-04 04:15:40,943 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: new RaftServerImpl for group-59B40D1FC711:[f44f8c74-7caf-4a51-a16b-9ef6a49fafc3|80822ea057e7:9894] with SCMStateMachine:uninitialized
2025-03-04 04:15:40,944 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-03-04 04:15:40,945 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2025-03-04 04:15:40,945 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2025-03-04 04:15:40,945 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2025-03-04 04:15:40,945 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2025-03-04 04:15:40,945 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2025-03-04 04:15:40,945 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2025-03-04 04:15:40,950 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: ConfigurationManager, init=conf: {index: -1, cur=peers:[f44f8c74-7caf-4a51-a16b-9ef6a49fafc3|80822ea057e7:9894]|listeners:[], old=null}, confs=<EMPTY_MAP>
2025-03-04 04:15:40,953 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2025-03-04 04:15:40,955 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2025-03-04 04:15:40,958 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2025-03-04 04:15:40,958 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2025-03-04 04:15:40,960 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2025-03-04 04:15:40,960 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2025-03-04 04:15:41,086 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2025-03-04 04:15:41,088 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2025-03-04 04:15:41,089 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2025-03-04 04:15:41,089 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2025-03-04 04:15:41,089 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2025-03-04 04:15:41,090 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2025-03-04 04:15:41,091 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2025-03-04 04:15:41,092 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2025-03-04 04:15:41,092 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2025-03-04 04:15:41,099 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/149f9752-dae6-4936-834a-59b40d1fc711 does not exist. Creating ...
2025-03-04 04:15:41,105 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/149f9752-dae6-4936-834a-59b40d1fc711/in_use.lock acquired by nodename 38@80822ea057e7
2025-03-04 04:15:41,111 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/149f9752-dae6-4936-834a-59b40d1fc711 has been successfully formatted.
2025-03-04 04:15:41,113 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO ha.SCMStateMachine: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: initialize group-59B40D1FC711
2025-03-04 04:15:41,114 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2025-03-04 04:15:41,120 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2025-03-04 04:15:41,121 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-03-04 04:15:41,122 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2025-03-04 04:15:41,122 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2025-03-04 04:15:41,125 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-03-04 04:15:41,128 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2025-03-04 04:15:41,129 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2025-03-04 04:15:41,129 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-03-04 04:15:41,131 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO util.AwaitToRun: Thread[#34,f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-cacheEviction-AwaitToRun,5,main] started
2025-03-04 04:15:41,135 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/149f9752-dae6-4936-834a-59b40d1fc711
2025-03-04 04:15:41,135 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2025-03-04 04:15:41,136 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2025-03-04 04:15:41,137 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2025-03-04 04:15:41,137 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2025-03-04 04:15:41,138 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2025-03-04 04:15:41,138 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2025-03-04 04:15:41,139 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2025-03-04 04:15:41,139 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2025-03-04 04:15:41,141 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2025-03-04 04:15:41,146 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2025-03-04 04:15:41,147 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2025-03-04 04:15:41,147 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2025-03-04 04:15:41,148 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2025-03-04 04:15:41,153 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2025-03-04 04:15:41,153 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2025-03-04 04:15:41,157 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: start as a follower, conf=conf: {index: -1, cur=peers:[f44f8c74-7caf-4a51-a16b-9ef6a49fafc3|80822ea057e7:9894]|listeners:[], old=null}
2025-03-04 04:15:41,157 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: changes role from      null to FOLLOWER at term 0 for startAsFollower
2025-03-04 04:15:41,158 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO impl.RoleInfo: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: start f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState
2025-03-04 04:15:41,159 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2025-03-04 04:15:41,159 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2025-03-04 04:15:41,160 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59B40D1FC711,id=f44f8c74-7caf-4a51-a16b-9ef6a49fafc3
2025-03-04 04:15:41,160 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO util.JmxRegister: register mxBean class org.apache.ratis.server.impl.RaftServerJmxAdapter as Ratis:service=RaftServer,group=group-59B40D1FC711,id=f44f8c74-7caf-4a51-a16b-9ef6a49fafc3
2025-03-04 04:15:41,162 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2025-03-04 04:15:41,162 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-remove.enabled = true (default)
2025-03-04 04:15:41,163 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2025-03-04 04:15:41,163 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2025-03-04 04:15:41,163 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2025-03-04 04:15:41,164 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2025-03-04 04:15:41,167 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: Successfully started.
2025-03-04 04:15:41,167 [main] INFO server.RaftServer: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: start RPC server
2025-03-04 04:15:41,202 [main] INFO server.GrpcService: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: GrpcService started, listening on 9894
2025-03-04 04:15:41,204 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: Started
2025-03-04 04:15:46,299 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState] INFO impl.FollowerState: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5141650911ns, electionTimeout:5138ms
2025-03-04 04:15:46,299 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState] INFO impl.RoleInfo: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: shutdown f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState
2025-03-04 04:15:46,300 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2025-03-04 04:15:46,302 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2025-03-04 04:15:46,302 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-FollowerState] INFO impl.RoleInfo: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: start f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1
2025-03-04 04:15:46,304 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO impl.LeaderElection: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for conf: {index: -1, cur=peers:[f44f8c74-7caf-4a51-a16b-9ef6a49fafc3|80822ea057e7:9894]|listeners:[], old=null}
2025-03-04 04:15:46,305 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO impl.LeaderElection: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2025-03-04 04:15:46,310 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO impl.LeaderElection: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for conf: {index: -1, cur=peers:[f44f8c74-7caf-4a51-a16b-9ef6a49fafc3|80822ea057e7:9894]|listeners:[], old=null}
2025-03-04 04:15:46,310 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO impl.LeaderElection: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2025-03-04 04:15:46,310 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO impl.RoleInfo: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: shutdown f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1
2025-03-04 04:15:46,311 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2025-03-04 04:15:46,314 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2025-03-04 04:15:46,316 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-03-04 04:15:46,316 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2025-03-04 04:15:46,319 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2025-03-04 04:15:46,319 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2025-03-04 04:15:46,319 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2025-03-04 04:15:46,323 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2025-03-04 04:15:46,324 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2025-03-04 04:15:46,324 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2025-03-04 04:15:46,325 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.log-metadata.enabled = true (default)
2025-03-04 04:15:46,325 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2025-03-04 04:15:46,325 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2025-03-04 04:15:46,326 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO impl.RoleInfo: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: start f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderStateImpl
2025-03-04 04:15:46,326 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: set firstElectionSinceStartup to false for becomeLeader
2025-03-04 04:15:46,327 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: change Leader from null to f44f8c74-7caf-4a51-a16b-9ef6a49fafc3 at term 1 for becomeLeader, leader elected after 5373ms
2025-03-04 04:15:46,338 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-SegmentedRaftLogWorker: Starting segment from index:0
2025-03-04 04:15:46,350 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2025-03-04 04:15:46,350 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderElection1] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: set configuration conf: {index: 0, cur=peers:[f44f8c74-7caf-4a51-a16b-9ef6a49fafc3|80822ea057e7:9894]|listeners:[], old=null}
2025-03-04 04:15:46,360 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/149f9752-dae6-4936-834a-59b40d1fc711/current/log_inprogress_0
2025-03-04 04:15:46,368 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-StateMachineUpdater] INFO server.RaftServer$Division: Leader f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderStateImpl is ready since appliedIndex == startIndex == 0
2025-03-04 04:15:47,205 [main] INFO server.RaftServer: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: close
2025-03-04 04:15:47,206 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO server.RaftServer$Division: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711: shutdown
2025-03-04 04:15:47,206 [main] INFO server.GrpcService: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: shutdown server GrpcServerProtocolService now
2025-03-04 04:15:47,206 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-59B40D1FC711,id=f44f8c74-7caf-4a51-a16b-9ef6a49fafc3
2025-03-04 04:15:47,206 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO impl.RoleInfo: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: shutdown f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-LeaderStateImpl
2025-03-04 04:15:47,209 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO impl.PendingRequests: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-PendingRequests: sendNotLeaderResponses
2025-03-04 04:15:47,211 [main] INFO server.GrpcService: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: shutdown server GrpcServerProtocolService successfully
2025-03-04 04:15:47,212 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO impl.StateMachineUpdater: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-StateMachineUpdater: set stopIndex = 0
2025-03-04 04:15:47,212 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-StateMachineUpdater] INFO impl.StateMachineUpdater: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-StateMachineUpdater: Took a snapshot at index 0
2025-03-04 04:15:47,212 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-StateMachineUpdater] INFO impl.StateMachineUpdater: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2025-03-04 04:15:47,214 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-StateMachineUpdater] INFO impl.StateMachineUpdater: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-StateMachineUpdater: closing SCMStateMachine, lastApplied=(t:1, i:0)
2025-03-04 04:15:47,215 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-cacheEviction-AwaitToRun] INFO util.AwaitToRun: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2025-03-04 04:15:47,365 [f44f8c74-7caf-4a51-a16b-9ef6a49fafc3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: f44f8c74-7caf-4a51-a16b-9ef6a49fafc3@group-59B40D1FC711-SegmentedRaftLogWorker close()
2025-03-04 04:15:47,370 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-f44f8c74-7caf-4a51-a16b-9ef6a49fafc3: Stopped
2025-03-04 04:15:47,371 [main] INFO server.StorageContainerManager: Enabled Ratis!
2025-03-04 04:15:47,371 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-149f9752-dae6-4936-834a-59b40d1fc711; layoutVersion=8; scmId=f44f8c74-7caf-4a51-a16b-9ef6a49fafc3
2025-03-04 04:15:47,372 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at 80822ea057e7/172.20.0.2
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
+ docker compose --progress quiet exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
d0ce23ef2d32: Warning: Permanently added 'd0ce23ef2d32' (ED25519) to the list of known hosts.
d0ce23ef2d32: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om' (ED25519) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm' (ED25519) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
+ sleep 10
+ docker-compose exec -T om /opt/hadoop/bin/ozone om --init
+ docker compose --progress quiet exec -T om /opt/hadoop/bin/ozone om --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2025-03-04 04:16:09,206 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting OzoneManager
STARTUP_MSG:   host = 63e24277efff/172.20.0.4
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 2.0.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.2.jar:/opt/hadoop/share/ozone/lib/guava-32.1.3-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.37.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.29.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.17.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.18.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.58.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.58.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.23.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.58.0.jar:/opt/hadoop/share/ozone/lib/grpc-util-1.58.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.26.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.58.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.27.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.17.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.24.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.1.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.6.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.25.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.25.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.25.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.4.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.1.2.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.25.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.17.jar:/opt/hadoop/share/ozone/lib/hdds-config-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.40.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.4.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_25-1.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.26.jar:/opt/hadoop/share/ozone/lib/jnr-constants-0.10.4.jar:/opt/hadoop/share/ozone/lib/jnr-posix-3.1.20.jar:/opt/hadoop/share/ozone/lib/jnr-ffi-2.2.17.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13.jar:/opt/hadoop/share/ozone/lib/jffi-1.3.13-native.jar:/opt/hadoop/share/ozone/lib/asm-commons-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-analysis-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-tree-9.7.1.jar:/opt/hadoop/share/ozone/lib/asm-util-9.7.1.jar:/opt/hadoop/share/ozone/lib/jnr-a64asm-1.0.0.jar:/opt/hadoop/share/ozone/lib/jnr-x86asm-1.0.2.jar:/opt/hadoop/share/ozone/lib/gson-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.11.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.24.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.1.2.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.46.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.46.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.46.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.46.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/ozone-client-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ozone-common-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.58.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.22.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.58.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.12.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.16.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/joda-time-2.12.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.6.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.80.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.57.v20241219.jar:/opt/hadoop/share/ozone/lib/reflections-0.10.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.30.2-GA.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.17.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.65.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.65.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.65.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.65.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.65.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.65.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.65.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/asm-9.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.3.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.11.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.5.4.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-text-1.12.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.55.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-classes-epoll-4.1.109.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-3.6.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-2.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web
STARTUP_MSG:   build = https://github.com/apache/ozone/4c28c7f62d670e5d7fbffa6b017052b75f2c5d50
STARTUP_MSG:   java = 21.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.keep.log.file.num=10, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.max.log.file.size=100MB, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=100000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.token.enabled=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.data.dir=file:///tmp/hadoop-hadoop/dfs/data, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.dns.interface=default, hdds.datanode.dns.nameserver=default, hdds.datanode.du.refresh.period=1h, hdds.datanode.handler.count=10, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=1GB, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.threadpool=10, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.use.datanode.hostname=false, hdds.datanode.volume.min.free.space=100MB, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.retries=2147483647, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.watch.type=ALL_COMMITTED, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=30s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=100000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, hdds.xframe.enabled=true, hdds.xframe.value=SAMEORIGIN, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.max.count=0, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.hbase.enhancements.allowed=false, ozone.client.incremental.chunk.list=false, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.key.write.concurrency=1, ozone.client.list.cache=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.server-defaults.validity.period.ms=3600000, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.stream.putblock.piggybacking=false, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.hbase.enhancements.allowed=false, ozone.http.basedir=/tmp/ozone_http, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.ksm.address=ksm, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.db.max.open.files=-1, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=READ, LIST, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.init.default.layout.version=-1, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lease.hard.limit=7d, ozone.om.lease.soft.limit=60s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.read.threadpool=10, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.server.list.max.size=1000, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=5s, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4MB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.s3g.webadmin.http-address=0.0.0.0:19878, ozone.s3g.webadmin.http-bind-host=0.0.0.0, ozone.s3g.webadmin.http.enabled=true, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.read.threadpool=10, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.client.read.threadpool=10, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.list.max.count=4096, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data/metadata, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.datanode.read.threadpool=10, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.read.threadpool=1, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=1, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deep.cleaning.enabled=false, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.volume.io.percentiles.intervals.seconds=60, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.lag.threshold=0, recon.om.delta.update.limit=50000, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2025-03-04 04:16:09,227 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [SIGHUP, SIGINT, SIGTERM]
2025-03-04 04:16:09,647 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
2025-03-04 04:16:09,663 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMSystemAudit to [].
2025-03-04 04:16:09,751 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2025-03-04 04:16:09,775 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.20.0.4:9862
2025-03-04 04:16:09,775 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2025-03-04 04:16:09,775 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
2025-03-04 04:16:10,136 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2025-03-04 04:16:10,212 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created fail-over proxy for protocol ScmBlockLocationProtocolPB with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.20.0.2:9863]
OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-149f9752-dae6-4936-834a-59b40d1fc711;layoutVersion=8
2025-03-04 04:16:10,351 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down OzoneManager at 63e24277efff/172.20.0.4
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
+ docker compose --progress quiet exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
d0ce23ef2d32: Warning: Permanently added 'd0ce23ef2d32' (ED25519) to the list of known hosts.
d0ce23ef2d32: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
d0ce23ef2d32: datanode is running as process 92.  Stop it first.
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om' (ED25519) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm' (ED25519) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
scm: scm is running as process 720.  Stop it first.
Using Docker Compose v2
xargs: warning: options --max-args and --replace/-I/-i are mutually exclusive, ignoring previous --max-args value
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      7 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     12 ?        S      0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups
     92 ?        Sl     0:09 /usr/local/jdk-21.0.2/bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dlog4j.configurationFile=/etc/hadoop/dn-audit-log4j2.properties,/etc/hadoop/dn-container-log4j2.properties -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dorg.apache.ratis.thirdparty.io.netty.tryReflectionSetAccessible=true --add-opens java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED -XX:ParallelGCThreads=8 -Dhadoop.log.dir=/var/log/hadoop -Dhadoop.log.file=ozone-hadoop-datanode-d0ce23ef2d32.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.HddsDatanodeService
    338 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      7 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     12 ?        S      0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups
    323 ?        Sl     0:09 /usr/local/jdk-21.0.2/bin/java -Dproc_om -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dorg.apache.ratis.thirdparty.io.netty.tryReflectionSetAccessible=true -Dlog4j.configurationFile=/etc/hadoop/om-audit-log4j2.properties --add-opens java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED -XX:ParallelGCThreads=8 -Dhadoop.log.dir=/var/log/hadoop -Dhadoop.log.file=ozone-hadoop-om-63e24277efff.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.om.OzoneManagerStarter
    419 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      7 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     12 ?        S      0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups
    720 ?        Sl     0:11 /usr/local/jdk-21.0.2/bin/java -Dproc_scm -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dorg.apache.ratis.thirdparty.io.netty.tryReflectionSetAccessible=true -Dlog4j.configurationFile=/etc/hadoop/scm-audit-log4j2.properties --add-opens java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-exports java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED -XX:ParallelGCThreads=8 -Dhadoop.log.dir=/var/log/hadoop -Dhadoop.log.file=ozone-hadoop-scm-80822ea057e7.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter
   1742 ?        Rs     0:00 ps xa
==============================================================================
Single Node :: Smoketest for one datanode                                     
==============================================================================
Basic Freon smoketest for one datanode                                | PASS |
------------------------------------------------------------------------------
Single Node :: Smoketest for one datanode                             | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-001.xml
==============================================================================
Pipeline :: Test ozone admin pipeline command                                 
==============================================================================
List pipelines                                                        | PASS |
------------------------------------------------------------------------------
List pipeline with json option                                        | PASS |
------------------------------------------------------------------------------
List pipelines with explicit host                                     | PASS |
------------------------------------------------------------------------------
List pipelines with explicit host and json option                     | PASS |
------------------------------------------------------------------------------
Deactivate pipeline                                                   | PASS |
------------------------------------------------------------------------------
Activate pipeline                                                     | PASS |
------------------------------------------------------------------------------
Close pipeline                                                        | PASS |
------------------------------------------------------------------------------
Incomplete command                                                    | PASS |
------------------------------------------------------------------------------
Create pipeline                                                       | PASS |
------------------------------------------------------------------------------
Pipeline :: Test ozone admin pipeline command                         | PASS |
9 tests, 9 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-002.xml
Using Docker Compose v2
Stopping datanodes
d0ce23ef2d32: Warning: Permanently added 'd0ce23ef2d32' (ED25519) to the list of known hosts.
d0ce23ef2d32: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Stopping Ozone Manager nodes [om]
om: Warning: Permanently added 'om' (ED25519) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
Stopping storage container manager nodes [scm]
scm: Warning: Permanently added 'scm' (ED25519) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/ozonescripts.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/rebot-POpkos/ozonescripts.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts.xml'
removed 'ozonescripts/result/robot-001.xml'
removed 'ozonescripts/result/robot-002.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts'
renamed 'ozonescripts/result/dn-audit-d0ce23ef2d32.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/dn-audit-d0ce23ef2d32.log'
renamed 'ozonescripts/result/docker-ozonescripts-datanode-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts-datanode-1.log'
renamed 'ozonescripts/result/docker-ozonescripts-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts-om-1.log'
renamed 'ozonescripts/result/docker-ozonescripts-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts-scm-1.log'
renamed 'ozonescripts/result/om-audit-63e24277efff.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/om-audit-63e24277efff.log'
renamed 'ozonescripts/result/om-sys-audit-63e24277efff.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/om-sys-audit-63e24277efff.log'
renamed 'ozonescripts/result/ozone-hadoop-datanode-d0ce23ef2d32.out' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/ozone-hadoop-datanode-d0ce23ef2d32.out'
renamed 'ozonescripts/result/ozone-hadoop-om-63e24277efff.out' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/ozone-hadoop-om-63e24277efff.out'
renamed 'ozonescripts/result/ozone-hadoop-om-63e24277efff.out.1' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/ozone-hadoop-om-63e24277efff.out.1'
renamed 'ozonescripts/result/ozone-hadoop-scm-80822ea057e7.out' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/ozone-hadoop-scm-80822ea057e7.out'
renamed 'ozonescripts/result/scm-audit-80822ea057e7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonescripts/scm-audit-80822ea057e7.log'
Executing test ozonesecure-ha/test-s3g-virtual-host.sh
Using Docker Compose v2
Port 88 is available on kdc
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Error response from daemon: container e5bc57802cdb793afb8b3fc5ceb72db0cd6832d55e2cfccd5e3b70bd77a934b8 is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
service "scm1.org" is not running
Port 9860 is not available on scm1.org yet
Timed out waiting on scm1.org 9860 to become available
ERROR: Test execution of ozonesecure-ha/test-s3g-virtual-host.sh is FAILED!!!!
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-datanode1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-datanode1-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-datanode2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-datanode2-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-datanode3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-datanode3-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-httpfs-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-httpfs-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-kdc-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-kdc-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-kms-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-kms-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-om1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-om1-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-om2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-om2-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-om3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-om3-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-recon-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-s3g-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-s3g-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-scm1.org-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-scm1.org-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-scm2.org-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-scm2.org-1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha-scm3.org-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha-scm3.org-1.log'
renamed 'ozonesecure-ha/result/kms-audit.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/kms-audit.log'
Executing test ozonesecure/test-vault.sh
Using Docker Compose v2
Port 88 is available on kdc
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
service "scm" is not running
Port 9860 is not available on scm yet
Timed out waiting on scm 9860 to become available
ERROR: Test execution of ozonesecure/test-vault.sh is FAILED!!!!
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault'
renamed 'ozonesecure/result/docker-ozonesecure-datanode-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-datanode-1.log'
renamed 'ozonesecure/result/docker-ozonesecure-datanode-2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-datanode-2.log'
renamed 'ozonesecure/result/docker-ozonesecure-datanode-3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-datanode-3.log'
renamed 'ozonesecure/result/docker-ozonesecure-httpfs-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-httpfs-1.log'
renamed 'ozonesecure/result/docker-ozonesecure-kdc-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-kdc-1.log'
renamed 'ozonesecure/result/docker-ozonesecure-kms-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-kms-1.log'
renamed 'ozonesecure/result/docker-ozonesecure-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-om-1.log'
renamed 'ozonesecure/result/docker-ozonesecure-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-recon-1.log'
renamed 'ozonesecure/result/docker-ozonesecure-s3g-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-s3g-1.log'
renamed 'ozonesecure/result/docker-ozonesecure-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-scm-1.log'
renamed 'ozonesecure/result/docker-ozonesecure-vault-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure-vault-1.log'
renamed 'ozonesecure/result/kms-audit.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/kms-audit.log'
renamed 'ozonesecure/result/om-audit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/om-audit-om.log'
renamed 'ozonesecure/result/om-sys-audit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/ozonesecure/vault/om-sys-audit-om.log'
Executing test restart/test.sh
Using Docker Compose v2
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/restart/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/restart/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/restart/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/restart/data/om': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/restart/data/recon': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/restart/data/s3g': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/restart/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/restart/data': Operation not permitted
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-001.xml
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-002.xml
==============================================================================
Generate-Chunk :: Test freon chunk generation commands                        
==============================================================================
DN Chunk Generator                                                    | PASS |
------------------------------------------------------------------------------
Generate-Chunk :: Test freon chunk generation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-003.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-004.xml
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 238
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 237
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-005.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-006.xml
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-007.xml
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-008.xml
==============================================================================
Generate-Chunk :: Test freon chunk generation commands                        
==============================================================================
DN Chunk Generator                                                    | PASS |
------------------------------------------------------------------------------
Generate-Chunk :: Test freon chunk generation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-009.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-010.xml
To use Ozone please mount ozone folder to /opt/hadoop
Output:  /rebot-output/restart.xml
renamed '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/rebot-UWNpH3/restart.xml' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart.xml'
removed 'restart/result/robot-001.xml'
removed 'restart/result/robot-002.xml'
removed 'restart/result/robot-003.xml'
removed 'restart/result/robot-004.xml'
removed 'restart/result/robot-005.xml'
removed 'restart/result/robot-006.xml'
removed 'restart/result/robot-007.xml'
removed 'restart/result/robot-008.xml'
removed 'restart/result/robot-009.xml'
removed 'restart/result/robot-010.xml'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart'
renamed 'restart/result/dn-audit-02d2b474f8c9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/dn-audit-02d2b474f8c9.log'
renamed 'restart/result/dn-audit-3fa453595620.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/dn-audit-3fa453595620.log'
renamed 'restart/result/dn-audit-436716d1aaef.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/dn-audit-436716d1aaef.log'
renamed 'restart/result/dn-audit-54b6d00c1e5b.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/dn-audit-54b6d00c1e5b.log'
renamed 'restart/result/dn-audit-868448be131f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/dn-audit-868448be131f.log'
renamed 'restart/result/dn-audit-e4c490bff43c.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/dn-audit-e4c490bff43c.log'
renamed 'restart/result/docker-restart-dn1-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/docker-restart-dn1-1.log'
renamed 'restart/result/docker-restart-dn2-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/docker-restart-dn2-1.log'
renamed 'restart/result/docker-restart-dn3-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/docker-restart-dn3-1.log'
renamed 'restart/result/docker-restart-om-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/docker-restart-om-1.log'
renamed 'restart/result/docker-restart-recon-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/docker-restart-recon-1.log'
renamed 'restart/result/docker-restart-s3g-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/docker-restart-s3g-1.log'
renamed 'restart/result/docker-restart-scm-1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/docker-restart-scm-1.log'
renamed 'restart/result/om-audit-0848c3e1f59c.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/om-audit-0848c3e1f59c.log'
renamed 'restart/result/om-audit-4330bda67e98.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/om-audit-4330bda67e98.log'
renamed 'restart/result/om-sys-audit-0848c3e1f59c.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/om-sys-audit-0848c3e1f59c.log'
renamed 'restart/result/om-sys-audit-4330bda67e98.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/om-sys-audit-4330bda67e98.log'
renamed 'restart/result/s3g-audit-0cd1bae4e948.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/s3g-audit-0cd1bae4e948.log'
renamed 'restart/result/s3g-audit-6c11f0849dc0.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/s3g-audit-6c11f0849dc0.log'
renamed 'restart/result/scm-audit-4c8aacc31e21.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/scm-audit-4c8aacc31e21.log'
renamed 'restart/result/scm-audit-dc6ebf4be154.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/restart/scm-audit-dc6ebf4be154.log'
Executing test upgrade/testlib.sh
Using Docker Compose v2
find: ‘upgrade/result’: No such file or directory
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/upgrade'
mkdir: created directory '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-2.0.0-SNAPSHOT/compose/result/upgrade/testlib'
mv: cannot stat 'upgrade/result/*': No such file or directory
removed directory '/tmp/robot-data-EsVPmk'
