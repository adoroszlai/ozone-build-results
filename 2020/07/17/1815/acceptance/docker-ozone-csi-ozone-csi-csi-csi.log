Attaching to ozone-csi_datanode_3, ozone-csi_datanode_1, ozone-csi_scm_1, ozone-csi_datanode_2, ozone-csi_csi_1, ozone-csi_om_1
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-07-17 21:05:19,905 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 7590e64a1d9b/172.18.0.6
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/3571d7e72688b008c2667997cb4d824ccc9a8a3e ; compiled by 'runner' on 2020-07-17T20:56Z
datanode_1  | STARTUP_MSG:   java = 11.0.7
datanode_1  | ************************************************************/
datanode_1  | 2020-07-17 21:05:19,947 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-07-17 21:05:21,106 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-07-17 21:05:21,883 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-07-17 21:05:22,829 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-07-17 21:05:22,829 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-07-17 21:05:23,187 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:7590e64a1d9b ip:172.18.0.6
datanode_1  | 2020-07-17 21:05:23,763 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-07-17 21:05:23,785 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-07-17 21:05:23,828 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-07-17 21:05:23,878 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-07-17 21:05:24,059 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-07-17 21:05:27,640 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-07-17 21:05:27,812 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-07-17 21:05:28,344 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-07-17 21:05:28,361 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-07-17 21:05:28,361 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-17 21:05:28,362 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-07-17 21:05:28,362 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-07-17 21:05:29,389 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-17 21:05:29,395 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-07-17 21:05:30,392 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-07-17 21:05:30,506 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1  | 2020-07-17 21:05:30,605 [main] INFO util.log: Logging initialized @16013ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-07-17 21:05:30,998 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-07-17 21:05:31,003 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-07-17 21:05:31,046 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-07-17 21:05:31,054 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2020-07-17 21:05:31,057 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2020-07-17 21:05:31,057 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2020-07-17 21:05:31,228 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-07-17 21:05:31,242 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_1  | 2020-07-17 21:05:31,427 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-07-17 21:05:31,441 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-07-17 21:05:31,446 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1  | 2020-07-17 21:05:31,583 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2dd3d39d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-07-17 21:05:31,609 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7eae55{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-07-17 21:05:32,018 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2f99d8c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-10938123936399892034.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-07-17 21:05:32,054 [main] INFO server.AbstractConnector: Started ServerConnector@7f305f34{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-07-17 21:05:32,061 [main] INFO server.Server: Started @17479ms
datanode_1  | 2020-07-17 21:05:32,070 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-07-17 21:05:32,073 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-07-17 21:05:32,077 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-07-17 21:05:32,171 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1dc4147f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-07-17 21:05:32,846 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-07-17 21:05:35,316 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-17 21:05:36,317 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-17 21:05:37,318 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-17 21:05:37,983 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-07-17 21:05:37,989 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-07-17 21:05:37,991 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 5efa9984-03c1-40be-9434-f6a87d9b0f89 at port 9858
datanode_1  | 2020-07-17 21:05:38,066 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 5efa9984-03c1-40be-9434-f6a87d9b0f89: start RPC server
datanode_1  | 2020-07-17 21:05:38,229 [Datanode State Machine Thread - 0] INFO server.GrpcService: 5efa9984-03c1-40be-9434-f6a87d9b0f89: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-07-17 21:05:43,346 [Command processor thread] INFO impl.RaftServerProxy: 5efa9984-03c1-40be-9434-f6a87d9b0f89: addNew group-4D4002DFAD76:[5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858] returns group-4D4002DFAD76:java.util.concurrent.CompletableFuture@75276bfe[Not completed]
datanode_1  | 2020-07-17 21:05:43,454 [pool-19-thread-1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89: new RaftServerImpl for group-4D4002DFAD76:[5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-07-17 21:05:43,462 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-07-17 21:05:43,466 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-07-17 21:05:43,466 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-07-17 21:05:43,467 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-07-17 21:05:43,475 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-07-17 21:05:43,500 [pool-19-thread-1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76: ConfigurationManager, init=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-07-17 21:05:43,505 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-17 21:05:43,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-07-17 21:05:43,537 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b2b59173-adf0-4631-a570-4d4002dfad76 does not exist. Creating ...
datanode_1  | 2020-07-17 21:05:43,561 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b2b59173-adf0-4631-a570-4d4002dfad76/in_use.lock acquired by nodename 6@7590e64a1d9b
datanode_1  | 2020-07-17 21:05:43,570 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b2b59173-adf0-4631-a570-4d4002dfad76 has been successfully formatted.
datanode_1  | 2020-07-17 21:05:43,596 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-4D4002DFAD76: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-07-17 21:05:43,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2020-07-17 21:05:43,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-07-17 21:05:43,622 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-07-17 21:05:43,629 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-17 21:05:43,639 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-17 21:05:43,664 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76
datanode_1  | 2020-07-17 21:05:43,745 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-07-17 21:05:43,762 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b2b59173-adf0-4631-a570-4d4002dfad76
datanode_1  | 2020-07-17 21:05:43,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-07-17 21:05:43,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-07-17 21:05:43,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-17 21:05:43,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-07-17 21:05:43,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-07-17 21:05:43,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-07-17 21:05:43,802 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-07-17 21:05:43,809 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-07-17 21:05:43,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-07-17 21:05:43,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-07-17 21:05:43,904 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-17 21:05:43,927 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-17 21:05:43,936 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-07-17 21:05:43,947 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-07-17 21:05:43,957 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-07-17 21:05:43,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-07-17 21:05:43,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-07-17 21:05:44,083 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76
datanode_1  | 2020-07-17 21:05:44,114 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76
datanode_1  | 2020-07-17 21:05:44,157 [pool-19-thread-1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76: start as a follower, conf=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858], old=null
datanode_1  | 2020-07-17 21:05:44,158 [pool-19-thread-1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-07-17 21:05:44,161 [pool-19-thread-1] INFO impl.RoleInfo: 5efa9984-03c1-40be-9434-f6a87d9b0f89: start FollowerState
datanode_1  | 2020-07-17 21:05:44,186 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4D4002DFAD76,id=5efa9984-03c1-40be-9434-f6a87d9b0f89
datanode_1  | 2020-07-17 21:05:44,194 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76
datanode_1  | 2020-07-17 21:05:44,343 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "b2b59173-adf0-4631-a570-4d4002dfad76"
datanode_1  | uuid128 {
datanode_1  |   mostSigBits: -5569385438148278735
datanode_1  |   leastSigBits: -6525630922738389642
datanode_1  | }
datanode_1  | .
datanode_1  | 2020-07-17 21:05:44,344 [Command processor thread] INFO impl.RaftServerProxy: 5efa9984-03c1-40be-9434-f6a87d9b0f89: addNew group-391C4BE1FF91:[5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858] returns group-391C4BE1FF91:java.util.concurrent.CompletableFuture@13fa9587[Not completed]
datanode_1  | 2020-07-17 21:05:44,359 [pool-19-thread-1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89: new RaftServerImpl for group-391C4BE1FF91:[5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-07-17 21:05:44,372 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-07-17 21:05:44,375 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-07-17 21:05:44,377 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-07-17 21:05:44,377 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-07-17 21:05:44,377 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-07-17 21:05:44,377 [pool-19-thread-1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91: ConfigurationManager, init=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-07-17 21:05:44,378 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-17 21:05:44,378 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-07-17 21:05:44,381 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91 does not exist. Creating ...
datanode_1  | 2020-07-17 21:05:44,385 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91/in_use.lock acquired by nodename 6@7590e64a1d9b
datanode_1  | 2020-07-17 21:05:44,389 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91 has been successfully formatted.
datanode_1  | 2020-07-17 21:05:44,389 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-391C4BE1FF91: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-07-17 21:05:44,397 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2020-07-17 21:05:44,397 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-07-17 21:05:44,398 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-07-17 21:05:44,398 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-17 21:05:44,398 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-17 21:05:44,398 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91
datanode_1  | 2020-07-17 21:05:44,399 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-07-17 21:05:44,399 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91
datanode_1  | 2020-07-17 21:05:44,401 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-07-17 21:05:44,402 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-07-17 21:05:44,408 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-17 21:05:44,417 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-07-17 21:05:44,428 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-07-17 21:05:44,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-07-17 21:05:44,433 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-07-17 21:05:44,433 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-07-17 21:05:44,433 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-07-17 21:05:44,435 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-07-17 21:05:44,449 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-17 21:05:44,451 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-17 21:05:44,488 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-07-17 21:05:44,488 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-07-17 21:05:44,488 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-07-17 21:05:44,489 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-07-17 21:05:44,489 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-07-17 21:05:44,498 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91
datanode_1  | 2020-07-17 21:05:44,499 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91
datanode_1  | 2020-07-17 21:05:44,501 [pool-19-thread-1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91: start as a follower, conf=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null
datanode_1  | 2020-07-17 21:05:44,513 [pool-19-thread-1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-07-17 21:05:44,513 [pool-19-thread-1] INFO impl.RoleInfo: 5efa9984-03c1-40be-9434-f6a87d9b0f89: start FollowerState
datanode_1  | 2020-07-17 21:05:44,531 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-391C4BE1FF91,id=5efa9984-03c1-40be-9434-f6a87d9b0f89
datanode_1  | 2020-07-17 21:05:44,540 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91
datanode_1  | 2020-07-17 21:05:46,200 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ddc5e8bb-d651-4c69-9d91-391c4be1ff91"
datanode_1  | uuid128 {
datanode_1  |   mostSigBits: -2466309327463297943
datanode_1  |   leastSigBits: -7092825144436850799
datanode_1  | }
datanode_1  | .
datanode_1  | 2020-07-17 21:05:47,741 [grpc-default-executor-0] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_1  | 2020-07-17 21:05:47,753 [grpc-default-executor-0] INFO impl.RoleInfo: 5efa9984-03c1-40be-9434-f6a87d9b0f89: shutdown FollowerState
datanode_1  | 2020-07-17 21:05:47,753 [Thread-24] INFO impl.FollowerState: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-07-17 21:05:47,753 [grpc-default-executor-0] INFO impl.RoleInfo: 5efa9984-03c1-40be-9434-f6a87d9b0f89: start FollowerState
datanode_1  | 2020-07-17 21:05:48,059 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-391C4BE1FF91 with new leaderId: d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_1  | 2020-07-17 21:05:48,070 [grpc-default-executor-0] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91: change Leader from null to d33d3495-faf3-4493-bca1-3f9f1e4f50f6 at term 1 for appendEntries, leader elected after 3662ms
datanode_1  | 2020-07-17 21:05:48,187 [grpc-default-executor-0] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91: set configuration 0: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null at 0
datanode_1  | 2020-07-17 21:05:48,202 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-07-17 21:05:48,495 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-391C4BE1FF91-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91/current/log_inprogress_0
datanode_1  | 2020-07-17 21:05:49,274 [Thread-22] INFO impl.FollowerState: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-FollowerState: change to CANDIDATE, lastRpcTime:5113ms, electionTimeout:5103ms
datanode_1  | 2020-07-17 21:05:49,275 [Thread-22] INFO impl.RoleInfo: 5efa9984-03c1-40be-9434-f6a87d9b0f89: shutdown FollowerState
datanode_1  | 2020-07-17 21:05:49,275 [Thread-22] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-07-17 21:05:49,277 [Thread-22] INFO impl.RoleInfo: 5efa9984-03c1-40be-9434-f6a87d9b0f89: start LeaderElection
datanode_1  | 2020-07-17 21:05:49,288 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO impl.LeaderElection: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1: begin an election at term 1 for -1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858], old=null
datanode_1  | 2020-07-17 21:05:49,289 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO impl.RoleInfo: 5efa9984-03c1-40be-9434-f6a87d9b0f89: shutdown LeaderElection
datanode_1  | 2020-07-17 21:05:49,290 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-07-17 21:05:49,290 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4D4002DFAD76 with new leaderId: 5efa9984-03c1-40be-9434-f6a87d9b0f89
datanode_1  | 2020-07-17 21:05:49,290 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76: change Leader from null to 5efa9984-03c1-40be-9434-f6a87d9b0f89 at term 1 for becomeLeader, leader elected after 5694ms
datanode_1  | 2020-07-17 21:05:49,337 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-07-17 21:05:49,338 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-07-17 21:05:49,341 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76
datanode_1  | 2020-07-17 21:05:49,344 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-07-17 21:05:49,357 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-07-17 21:05:49,373 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-07-17 21:05:49,374 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-07-17 21:05:49,374 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-07-17 21:05:49,381 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO impl.RoleInfo: 5efa9984-03c1-40be-9434-f6a87d9b0f89: start LeaderState
datanode_1  | 2020-07-17 21:05:49,399 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-07-17 21:05:49,402 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b2b59173-adf0-4631-a570-4d4002dfad76/current/log_inprogress_0
datanode_1  | 2020-07-17 21:05:49,413 [5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76-LeaderElection1] INFO impl.RaftServerImpl: 5efa9984-03c1-40be-9434-f6a87d9b0f89@group-4D4002DFAD76: set configuration 0: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858], old=null at 0
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-07-17 21:05:19,754 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 0f59356465c0/172.18.0.4
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
csi_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
csi_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
csi_1       | 2020-07-17 21:05:15,338 [main] INFO csi.CsiServer: STARTUP_MSG: 
csi_1       | /************************************************************
csi_1       | STARTUP_MSG: Starting CsiServer
csi_1       | STARTUP_MSG:   host = b243e5d400b0/172.18.0.2
csi_1       | STARTUP_MSG:   args = []
csi_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
csi_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-1.17.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.18.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.29.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.29.0.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.19.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.29.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.29.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.29.0.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.29.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.29.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-util-3.11.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/protobuf-java-3.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-csi-0.6.0-SNAPSHOT.jar
csi_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/3571d7e72688b008c2667997cb4d824ccc9a8a3e ; compiled by 'runner' on 2020-07-17T20:56Z
csi_1       | STARTUP_MSG:   java = 11.0.7
csi_1       | ************************************************************/
csi_1       | 2020-07-17 21:05:15,400 [main] INFO csi.CsiServer: registered UNIX signal handlers for [TERM, HUP, INT]
csi_1       | 2020-07-17 21:05:23,868 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:24,869 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:25,870 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:26,870 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:27,871 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:28,872 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:29,873 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:30,874 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:31,874 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:32,875 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:35,880 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:36,881 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:37,882 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:38,883 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:39,884 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:40,884 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:41,886 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:42,898 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:43,899 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:44,900 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:44,901 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From b243e5d400b0/172.18.0.2 to om:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy16.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover after sleeping for 4000ms.
csi_1       | 2020-07-17 21:05:49,902 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:50,904 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:51,917 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-17 21:05:55,036 [epollEventLoopGroup-2-1] WARN bootstrap.ServerBootstrap: Unknown channel option 'SO_KEEPALIVE' for channel '[id: 0x05f3821b]'
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/3571d7e72688b008c2667997cb4d824ccc9a8a3e ; compiled by 'runner' on 2020-07-17T20:56Z
datanode_2  | STARTUP_MSG:   java = 11.0.7
datanode_2  | ************************************************************/
datanode_2  | 2020-07-17 21:05:19,834 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-07-17 21:05:21,167 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-07-17 21:05:21,824 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-07-17 21:05:22,721 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-07-17 21:05:22,721 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-07-17 21:05:23,216 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:0f59356465c0 ip:172.18.0.4
datanode_2  | 2020-07-17 21:05:24,061 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-07-17 21:05:24,075 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-07-17 21:05:24,095 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-07-17 21:05:24,118 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-07-17 21:05:24,351 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-07-17 21:05:28,284 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-07-17 21:05:28,446 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-07-17 21:05:28,981 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-07-17 21:05:29,030 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-07-17 21:05:29,031 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-17 21:05:29,033 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-07-17 21:05:29,037 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-07-17 21:05:29,972 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-17 21:05:29,979 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-07-17 21:05:30,835 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-07-17 21:05:30,941 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2  | 2020-07-17 21:05:31,060 [main] INFO util.log: Logging initialized @16463ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-07-17 21:05:31,449 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-07-17 21:05:31,453 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-07-17 21:05:31,476 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-07-17 21:05:31,477 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-07-17 21:05:31,484 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-07-17 21:05:31,484 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-07-17 21:05:31,622 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-07-17 21:05:31,627 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_2  | 2020-07-17 21:05:31,768 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-07-17 21:05:31,789 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-07-17 21:05:31,790 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-07-17 21:05:31,862 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7ec13984{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-07-17 21:05:31,872 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2dd3d39d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-07-17 21:05:32,227 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@71fb8301{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-147798644322796941.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-07-17 21:05:32,271 [main] INFO server.AbstractConnector: Started ServerConnector@6ce2e079{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-07-17 21:05:32,271 [main] INFO server.Server: Started @17675ms
datanode_2  | 2020-07-17 21:05:32,286 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-07-17 21:05:32,286 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-07-17 21:05:32,291 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-07-17 21:05:32,361 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5dd7881a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-07-17 21:05:32,994 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-07-17 21:05:35,602 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-17 21:05:36,603 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-17 21:05:37,619 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From 0f59356465c0/172.18.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:42028 remote=scm/172.18.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:42028 remote=scm/172.18.0.5:9861]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2  | 2020-07-17 21:05:37,983 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-07-17 21:05:37,989 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-07-17 21:05:37,989 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d33d3495-faf3-4493-bca1-3f9f1e4f50f6 at port 9858
datanode_2  | 2020-07-17 21:05:38,056 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: start RPC server
datanode_2  | 2020-07-17 21:05:38,230 [Datanode State Machine Thread - 1] INFO server.GrpcService: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-07-17 21:05:41,607 [Command processor thread] INFO impl.RaftServerProxy: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: addNew group-EBE6F67EBB85:[d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858] returns group-EBE6F67EBB85:java.util.concurrent.CompletableFuture@114a2603[Not completed]
datanode_2  | 2020-07-17 21:05:41,747 [pool-19-thread-1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: new RaftServerImpl for group-EBE6F67EBB85:[d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-17 21:05:41,751 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-07-17 21:05:41,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-07-17 21:05:41,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-17 21:05:41,757 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-07-17 21:05:41,757 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-17 21:05:41,767 [pool-19-thread-1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85: ConfigurationManager, init=-1: [d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-07-17 21:05:41,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-17 21:05:41,789 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-07-17 21:05:41,800 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ed0868ca-7864-4831-b584-ebe6f67ebb85 does not exist. Creating ...
datanode_2  | 2020-07-17 21:05:41,815 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ed0868ca-7864-4831-b584-ebe6f67ebb85/in_use.lock acquired by nodename 6@0f59356465c0
datanode_2  | 2020-07-17 21:05:41,825 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ed0868ca-7864-4831-b584-ebe6f67ebb85 has been successfully formatted.
datanode_2  | 2020-07-17 21:05:41,848 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-EBE6F67EBB85: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-07-17 21:05:41,849 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2020-07-17 21:05:41,866 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-07-17 21:05:41,880 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-07-17 21:05:41,891 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-17 21:05:41,893 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-17 21:05:41,934 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85
datanode_2  | 2020-07-17 21:05:41,991 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-07-17 21:05:42,013 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ed0868ca-7864-4831-b584-ebe6f67ebb85
datanode_2  | 2020-07-17 21:05:42,013 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-07-17 21:05:42,014 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-07-17 21:05:42,014 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-17 21:05:42,015 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-07-17 21:05:42,015 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-07-17 21:05:42,031 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-07-17 21:05:42,032 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-07-17 21:05:42,032 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-07-17 21:05:42,033 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-07-17 21:05:42,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-07-17 21:05:42,100 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-17 21:05:42,100 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-17 21:05:42,137 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-07-17 21:05:42,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-07-17 21:05:42,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-07-17 21:05:42,150 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-07-17 21:05:42,150 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-07-17 21:05:42,217 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85
datanode_2  | 2020-07-17 21:05:42,226 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85
datanode_2  | 2020-07-17 21:05:42,234 [pool-19-thread-1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85: start as a follower, conf=-1: [d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null
datanode_2  | 2020-07-17 21:05:42,241 [pool-19-thread-1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-07-17 21:05:42,242 [pool-19-thread-1] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: start FollowerState
datanode_2  | 2020-07-17 21:05:42,274 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EBE6F67EBB85,id=d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_2  | 2020-07-17 21:05:42,276 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85
datanode_2  | 2020-07-17 21:05:42,312 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "ed0868ca-7864-4831-b584-ebe6f67ebb85"
datanode_2  | uuid128 {
datanode_2  |   mostSigBits: -1366727268094425039
datanode_2  |   leastSigBits: -5366905478708282491
datanode_2  | }
datanode_2  | .
datanode_2  | 2020-07-17 21:05:42,329 [Command processor thread] INFO impl.RaftServerProxy: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: addNew group-391C4BE1FF91:[5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858] returns group-391C4BE1FF91:java.util.concurrent.CompletableFuture@9814323[Not completed]
datanode_2  | 2020-07-17 21:05:42,332 [pool-19-thread-1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: new RaftServerImpl for group-391C4BE1FF91:[5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-17 21:05:42,332 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-07-17 21:05:42,332 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-07-17 21:05:42,332 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-17 21:05:42,332 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-07-17 21:05:42,332 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-17 21:05:42,333 [pool-19-thread-1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91: ConfigurationManager, init=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-07-17 21:05:42,339 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-17 21:05:42,339 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-07-17 21:05:42,339 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91 does not exist. Creating ...
datanode_2  | 2020-07-17 21:05:42,341 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91/in_use.lock acquired by nodename 6@0f59356465c0
datanode_2  | 2020-07-17 21:05:42,345 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91 has been successfully formatted.
datanode_2  | 2020-07-17 21:05:42,349 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-391C4BE1FF91: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-07-17 21:05:42,349 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2020-07-17 21:05:42,349 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-07-17 21:05:42,349 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-07-17 21:05:42,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-07-17 21:05:22,542 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = bc4bafa3cadf/172.18.0.7
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/3571d7e72688b008c2667997cb4d824ccc9a8a3e ; compiled by 'runner' on 2020-07-17T20:56Z
datanode_3  | STARTUP_MSG:   java = 11.0.7
datanode_3  | ************************************************************/
datanode_3  | 2020-07-17 21:05:22,580 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-07-17 21:05:23,842 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-07-17 21:05:24,409 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-07-17 21:05:25,185 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-07-17 21:05:25,185 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-07-17 21:05:25,580 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:bc4bafa3cadf ip:172.18.0.7
datanode_3  | 2020-07-17 21:05:26,111 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-07-17 21:05:26,133 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-07-17 21:05:26,140 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-07-17 21:05:26,170 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-07-17 21:05:26,466 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-07-17 21:05:29,909 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-07-17 21:05:30,081 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-07-17 21:05:30,388 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-07-17 21:05:30,398 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-07-17 21:05:30,400 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-17 21:05:30,401 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-07-17 21:05:30,483 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-07-17 21:05:31,266 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-17 21:05:31,277 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-07-17 21:05:32,039 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-07-17 21:05:32,133 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2020-07-17 21:05:32,228 [main] INFO util.log: Logging initialized @14914ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-07-17 21:05:32,590 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-07-17 21:05:32,601 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-07-17 21:05:32,628 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-07-17 21:05:32,630 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-07-17 21:05:32,648 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-07-17 21:05:32,648 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-07-17 21:05:32,772 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-07-17 21:05:32,789 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_3  | 2020-07-17 21:05:32,939 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-07-17 21:05:32,939 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-07-17 21:05:32,942 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 2020-07-17 21:05:32,960 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2dd3d39d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-07-17 21:05:32,966 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7eae55{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-07-17 21:05:33,213 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2f99d8c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-11409033670861002681.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-07-17 21:05:33,227 [main] INFO server.AbstractConnector: Started ServerConnector@7f305f34{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-07-17 21:05:33,227 [main] INFO server.Server: Started @15913ms
datanode_3  | 2020-07-17 21:05:33,265 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-07-17 21:05:33,265 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-07-17 21:05:33,270 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-07-17 21:05:33,410 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fd3fbc0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-07-17 21:05:33,734 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-07-17 21:05:36,570 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-17 21:05:37,595 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From bc4bafa3cadf/172.18.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:50758 remote=scm/172.18.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:50758 remote=scm/172.18.0.5:9861]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3  | 2020-07-17 21:05:38,071 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-07-17 21:05:38,074 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-07-17 21:05:38,077 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 06c7fe9a-ea43-4249-af97-0cae133ce5d5 at port 9858
datanode_3  | 2020-07-17 21:05:38,174 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: start RPC server
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-07-17 21:05:24,925 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = c1027dd13c07/172.18.0.5
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-07-17 21:05:20,175 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = fab316fd0d8f/172.18.0.3
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/3571d7e72688b008c2667997cb4d824ccc9a8a3e ; compiled by 'runner' on 2020-07-17T20:56Z
scm_1       | STARTUP_MSG:   java = 11.0.7
scm_1       | ************************************************************/
scm_1       | 2020-07-17 21:05:25,018 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-07-17 21:05:25,850 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-07-17 21:05:26,149 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-b742fff7-2b23-485a-85c2-2ce9e2967b66;layoutVersion=0
scm_1       | 2020-07-17 21:05:26,245 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at c1027dd13c07/172.18.0.5
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-07-17 21:05:34,017 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = c1027dd13c07/172.18.0.5
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/3571d7e72688b008c2667997cb4d824ccc9a8a3e ; compiled by 'runner' on 2020-07-17T20:56Z
om_1        | STARTUP_MSG:   java = 11.0.7
om_1        | ************************************************************/
om_1        | 2020-07-17 21:05:20,234 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-07-17 21:05:24,361 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-07-17 21:05:24,732 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.3:9862
om_1        | 2020-07-17 21:05:24,733 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-07-17 21:05:24,780 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-17 21:05:26,863 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:27,864 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:28,865 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:29,865 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:30,867 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:31,882 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:32,883 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:33,884 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:34,885 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:35,885 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.5:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-17 21:05:35,887 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-b742fff7-2b23-485a-85c2-2ce9e2967b66;layoutVersion=0
om_1        | 2020-07-17 21:05:41,251 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at fab316fd0d8f/172.18.0.3
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-07-17 21:05:45,823 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = fab316fd0d8f/172.18.0.3
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | 2020-07-17 21:05:42,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-17 21:05:42,350 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91
datanode_2  | 2020-07-17 21:05:42,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-07-17 21:05:42,351 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91
datanode_2  | 2020-07-17 21:05:42,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-07-17 21:05:42,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-07-17 21:05:42,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-17 21:05:42,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-07-17 21:05:42,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-07-17 21:05:42,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-07-17 21:05:42,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-07-17 21:05:42,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-07-17 21:05:42,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-07-17 21:05:42,358 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-07-17 21:05:42,374 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-17 21:05:42,374 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-17 21:05:42,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-07-17 21:05:42,381 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-07-17 21:05:42,384 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-07-17 21:05:42,384 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-07-17 21:05:42,384 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-07-17 21:05:42,384 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91
datanode_2  | 2020-07-17 21:05:42,396 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91
datanode_2  | 2020-07-17 21:05:42,401 [pool-19-thread-1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91: start as a follower, conf=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null
datanode_2  | 2020-07-17 21:05:42,401 [pool-19-thread-1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-07-17 21:05:42,401 [pool-19-thread-1] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: start FollowerState
datanode_2  | 2020-07-17 21:05:42,416 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-391C4BE1FF91,id=d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_2  | 2020-07-17 21:05:42,416 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91
datanode_2  | 2020-07-17 21:05:46,060 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ddc5e8bb-d651-4c69-9d91-391c4be1ff91"
datanode_2  | uuid128 {
datanode_2  |   mostSigBits: -2466309327463297943
datanode_2  |   leastSigBits: -7092825144436850799
datanode_2  | }
datanode_2  | .
datanode_2  | 2020-07-17 21:05:47,318 [Thread-23] INFO impl.FollowerState: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-FollowerState: change to CANDIDATE, lastRpcTime:5075ms, electionTimeout:5068ms
datanode_2  | 2020-07-17 21:05:47,319 [Thread-23] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: shutdown FollowerState
datanode_2  | 2020-07-17 21:05:47,320 [Thread-23] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-07-17 21:05:47,322 [Thread-23] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: start LeaderElection
datanode_2  | 2020-07-17 21:05:47,343 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO impl.LeaderElection: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1: begin an election at term 1 for -1: [d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null
datanode_2  | 2020-07-17 21:05:47,344 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: shutdown LeaderElection
datanode_2  | 2020-07-17 21:05:47,345 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-07-17 21:05:47,345 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-EBE6F67EBB85 with new leaderId: d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_2  | 2020-07-17 21:05:47,346 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85: change Leader from null to d33d3495-faf3-4493-bca1-3f9f1e4f50f6 at term 1 for becomeLeader, leader elected after 5496ms
datanode_2  | 2020-07-17 21:05:47,349 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-07-17 21:05:47,361 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-07-17 21:05:47,363 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85
datanode_2  | 2020-07-17 21:05:47,386 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-07-17 21:05:47,387 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-07-17 21:05:47,397 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-07-17 21:05:47,407 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-07-17 21:05:47,407 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-07-17 21:05:47,467 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: start LeaderState
datanode_2  | 2020-07-17 21:05:47,533 [Thread-25] INFO impl.FollowerState: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-FollowerState: change to CANDIDATE, lastRpcTime:5131ms, electionTimeout:5106ms
datanode_2  | 2020-07-17 21:05:47,530 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-07-17 21:05:47,541 [Thread-25] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: shutdown FollowerState
datanode_2  | 2020-07-17 21:05:47,541 [Thread-25] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-07-17 21:05:47,541 [Thread-25] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: start LeaderElection
datanode_2  | 2020-07-17 21:05:47,580 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO impl.LeaderElection: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2: begin an election at term 1 for -1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null
datanode_2  | 2020-07-17 21:05:47,635 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-LeaderElection1] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85: set configuration 0: [d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null at 0
datanode_2  | 2020-07-17 21:05:47,804 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO impl.LeaderElection: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2: Election PASSED; received 1 response(s) [d33d3495-faf3-4493-bca1-3f9f1e4f50f6<-06c7fe9a-ea43-4249-af97-0cae133ce5d5#0:OK-t1] and 0 exception(s); d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91:t1, leader=null, voted=d33d3495-faf3-4493-bca1-3f9f1e4f50f6, raftlog=d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null
datanode_2  | 2020-07-17 21:05:47,810 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: shutdown LeaderElection
datanode_2  | 2020-07-17 21:05:47,811 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-07-17 21:05:47,811 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-391C4BE1FF91 with new leaderId: d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_2  | 2020-07-17 21:05:47,811 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91: change Leader from null to d33d3495-faf3-4493-bca1-3f9f1e4f50f6 at term 1 for becomeLeader, leader elected after 5461ms
datanode_2  | 2020-07-17 21:05:47,811 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-07-17 21:05:47,811 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-07-17 21:05:47,811 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91
datanode_2  | 2020-07-17 21:05:47,812 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-07-17 21:05:47,812 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-07-17 21:05:47,814 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-07-17 21:05:47,837 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-07-17 21:05:47,841 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-07-17 21:05:47,852 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-07-17 21:05:47,852 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-17 21:05:47,853 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-07-17 21:05:47,859 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-07-17 21:05:47,872 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-07-17 21:05:47,872 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-17 21:05:47,876 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91
datanode_2  | 2020-07-17 21:05:47,884 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-07-17 21:05:47,896 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-17 21:05:47,901 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-07-17 21:05:47,902 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-07-17 21:05:38,389 [Datanode State Machine Thread - 1] INFO server.GrpcService: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-07-17 21:05:42,646 [Command processor thread] INFO impl.RaftServerProxy: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: addNew group-3CA83CCFE928:[06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858] returns group-3CA83CCFE928:java.util.concurrent.CompletableFuture@610ebca9[Not completed]
datanode_3  | 2020-07-17 21:05:42,716 [pool-19-thread-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: new RaftServerImpl for group-3CA83CCFE928:[06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-07-17 21:05:42,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-07-17 21:05:42,724 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-07-17 21:05:42,724 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-07-17 21:05:42,725 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-07-17 21:05:42,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-07-17 21:05:42,747 [pool-19-thread-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928: ConfigurationManager, init=-1: [06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-07-17 21:05:42,755 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-17 21:05:42,773 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-07-17 21:05:42,777 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928 does not exist. Creating ...
datanode_3  | 2020-07-17 21:05:42,804 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928/in_use.lock acquired by nodename 6@bc4bafa3cadf
datanode_3  | 2020-07-17 21:05:42,816 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928 has been successfully formatted.
datanode_3  | 2020-07-17 21:05:42,837 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3CA83CCFE928: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-07-17 21:05:42,893 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2020-07-17 21:05:42,894 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-07-17 21:05:42,908 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-07-17 21:05:42,921 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-17 21:05:42,942 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-17 21:05:42,960 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928
datanode_3  | 2020-07-17 21:05:43,043 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-07-17 21:05:43,048 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928
datanode_3  | 2020-07-17 21:05:43,069 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-07-17 21:05:43,074 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-07-17 21:05:43,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-17 21:05:43,084 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-07-17 21:05:43,089 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-07-17 21:05:43,089 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-07-17 21:05:43,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-07-17 21:05:43,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-07-17 21:05:43,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-07-17 21:05:43,166 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-07-17 21:05:43,182 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-17 21:05:43,182 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-17 21:05:43,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-07-17 21:05:43,241 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-07-17 21:05:43,242 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-07-17 21:05:43,242 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-07-17 21:05:43,245 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-07-17 21:05:43,373 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928
datanode_3  | 2020-07-17 21:05:43,375 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928
datanode_3  | 2020-07-17 21:05:43,398 [pool-19-thread-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928: start as a follower, conf=-1: [06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858], old=null
datanode_3  | 2020-07-17 21:05:43,401 [pool-19-thread-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-07-17 21:05:43,405 [pool-19-thread-1] INFO impl.RoleInfo: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: start FollowerState
datanode_3  | 2020-07-17 21:05:43,431 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3CA83CCFE928,id=06c7fe9a-ea43-4249-af97-0cae133ce5d5
datanode_3  | 2020-07-17 21:05:43,432 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928
datanode_3  | 2020-07-17 21:05:43,559 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928"
datanode_3  | uuid128 {
datanode_3  |   mostSigBits: -2863471557557139201
datanode_3  |   leastSigBits: -7150523615085074136
datanode_3  | }
datanode_3  | .
datanode_3  | 2020-07-17 21:05:43,576 [Command processor thread] INFO impl.RaftServerProxy: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: addNew group-391C4BE1FF91:[5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858] returns group-391C4BE1FF91:java.util.concurrent.CompletableFuture@6ed6d698[Not completed]
datanode_3  | 2020-07-17 21:05:43,582 [pool-19-thread-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: new RaftServerImpl for group-391C4BE1FF91:[5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-07-17 21:05:43,585 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-07-17 21:05:43,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-07-17 21:05:43,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-07-17 21:05:43,596 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-07-17 21:05:43,596 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-07-17 21:05:43,596 [pool-19-thread-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91: ConfigurationManager, init=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-07-17 21:05:43,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-17 21:05:43,598 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-07-17 21:05:43,598 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91 does not exist. Creating ...
datanode_3  | 2020-07-17 21:05:43,601 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91/in_use.lock acquired by nodename 6@bc4bafa3cadf
datanode_3  | 2020-07-17 21:05:43,616 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91 has been successfully formatted.
datanode_3  | 2020-07-17 21:05:43,617 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-391C4BE1FF91: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-07-17 21:05:43,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2020-07-17 21:05:43,622 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-07-17 21:05:43,622 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-07-17 21:05:43,622 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-17 21:05:43,622 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-17 21:05:43,622 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/3571d7e72688b008c2667997cb4d824ccc9a8a3e ; compiled by 'runner' on 2020-07-17T20:56Z
om_1        | STARTUP_MSG:   java = 11.0.7
om_1        | ************************************************************/
om_1        | 2020-07-17 21:05:45,852 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-07-17 21:05:47,527 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-07-17 21:05:47,645 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.3:9862
om_1        | 2020-07-17 21:05:47,645 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-07-17 21:05:47,792 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-17 21:05:47,821 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-17 21:05:50,522 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-17 21:05:51,405 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-07-17 21:05:51,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-07-17 21:05:51,650 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-07-17 21:05:51,796 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-07-17 21:05:51,796 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-07-17 21:05:51,842 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.18.0.3:9862
om_1        | 2020-07-17 21:05:51,850 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-07-17 21:05:51,850 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-07-17 21:05:52,111 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-07-17 21:05:52,111 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1        | 2020-07-17 21:05:52,167 [Listener at om/9862] INFO util.log: Logging initialized @10574ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-07-17 21:05:52,533 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-07-17 21:05:52,550 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-07-17 21:05:52,566 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-07-17 21:05:52,575 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1        | 2020-07-17 21:05:52,580 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2020-07-17 21:05:52,580 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2020-07-17 21:05:52,731 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2020-07-17 21:05:52,739 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
om_1        | 2020-07-17 21:05:52,867 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-07-17 21:05:52,867 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2020-07-17 21:05:52,890 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1        | 2020-07-17 21:05:52,939 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@19c1f6f4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-07-17 21:05:52,941 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@53079ae6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2020-07-17 21:05:53,150 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@af04f09{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-17532801673246693312.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-07-17 21:05:53,169 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@4caf875c{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-07-17 21:05:53,172 [Listener at om/9862] INFO server.Server: Started @11579ms
om_1        | 2020-07-17 21:05:53,174 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-07-17 21:05:53,174 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-07-17 21:05:53,185 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-07-17 21:05:53,205 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@349aeec4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/3571d7e72688b008c2667997cb4d824ccc9a8a3e ; compiled by 'runner' on 2020-07-17T20:56Z
scm_1       | STARTUP_MSG:   java = 11.0.7
scm_1       | ************************************************************/
scm_1       | 2020-07-17 21:05:34,030 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-07-17 21:05:34,199 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-07-17 21:05:34,820 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-07-17 21:05:35,226 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@5922ae77
scm_1       | 2020-07-17 21:05:35,234 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-07-17 21:05:35,480 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-07-17 21:05:35,663 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-07-17 21:05:35,751 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-07-17 21:05:35,894 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 0
scm_1       | 2020-07-17 21:05:35,896 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-07-17 21:05:35,962 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-07-17 21:05:36,507 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-17 21:05:36,526 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-07-17 21:05:36,553 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-17 21:05:36,558 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-07-17 21:05:36,586 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-17 21:05:36,589 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-07-17 21:05:36,612 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-07-17 21:05:36,612 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1       | 2020-07-17 21:05:36,637 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @9106ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-07-17 21:05:36,716 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-07-17 21:05:36,729 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-07-17 21:05:36,734 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-07-17 21:05:36,735 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2020-07-17 21:05:36,735 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1       | 2020-07-17 21:05:36,735 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2020-07-17 21:05:36,803 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-07-17 21:05:36,933 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-07-17 21:05:36,984 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-07-17 21:05:36,984 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-07-17 21:05:37,299 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-07-17 21:05:37,307 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-17 21:05:37,313 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-07-17 21:05:37,413 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-07-17 21:05:37,414 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-07-17 21:05:37,418 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-17 21:05:37,436 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
datanode_3  | 2020-07-17 21:05:43,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-07-17 21:05:43,623 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91
datanode_3  | 2020-07-17 21:05:43,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-07-17 21:05:43,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-07-17 21:05:43,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-17 21:05:43,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-07-17 21:05:43,624 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-07-17 21:05:43,624 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-07-17 21:05:43,624 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-07-17 21:05:43,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-07-17 21:05:43,639 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-07-17 21:05:43,640 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-07-17 21:05:43,645 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-17 21:05:43,645 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-17 21:05:43,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-07-17 21:05:43,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-07-17 21:05:43,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-07-17 21:05:43,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-07-17 21:05:43,669 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-07-17 21:05:43,669 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91
datanode_3  | 2020-07-17 21:05:43,669 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91
datanode_3  | 2020-07-17 21:05:43,673 [pool-19-thread-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91: start as a follower, conf=-1: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null
datanode_3  | 2020-07-17 21:05:43,673 [pool-19-thread-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-07-17 21:05:43,674 [pool-19-thread-1] INFO impl.RoleInfo: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: start FollowerState
datanode_3  | 2020-07-17 21:05:43,675 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-391C4BE1FF91,id=06c7fe9a-ea43-4249-af97-0cae133ce5d5
datanode_3  | 2020-07-17 21:05:43,675 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91
datanode_3  | 2020-07-17 21:05:46,127 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ddc5e8bb-d651-4c69-9d91-391c4be1ff91"
datanode_3  | uuid128 {
datanode_3  |   mostSigBits: -2466309327463297943
datanode_3  |   leastSigBits: -7092825144436850799
datanode_3  | }
datanode_3  | .
datanode_3  | 2020-07-17 21:05:47,729 [grpc-default-executor-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_3  | 2020-07-17 21:05:47,733 [grpc-default-executor-1] INFO impl.RoleInfo: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: shutdown FollowerState
datanode_3  | 2020-07-17 21:05:47,736 [Thread-25] INFO impl.FollowerState: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2020-07-17 21:05:47,737 [grpc-default-executor-1] INFO impl.RoleInfo: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: start FollowerState
datanode_3  | 2020-07-17 21:05:48,008 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-391C4BE1FF91 with new leaderId: d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_3  | 2020-07-17 21:05:48,009 [grpc-default-executor-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91: change Leader from null to d33d3495-faf3-4493-bca1-3f9f1e4f50f6 at term 1 for appendEntries, leader elected after 4386ms
datanode_3  | 2020-07-17 21:05:48,148 [grpc-default-executor-1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91: set configuration 0: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null at 0
datanode_3  | 2020-07-17 21:05:48,222 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-07-17 21:05:48,472 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-391C4BE1FF91-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91/current/log_inprogress_0
datanode_3  | 2020-07-17 21:05:48,592 [Thread-23] INFO impl.FollowerState: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-FollowerState: change to CANDIDATE, lastRpcTime:5187ms, electionTimeout:5161ms
datanode_3  | 2020-07-17 21:05:48,593 [Thread-23] INFO impl.RoleInfo: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: shutdown FollowerState
datanode_3  | 2020-07-17 21:05:48,593 [Thread-23] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-07-17 21:05:48,595 [Thread-23] INFO impl.RoleInfo: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: start LeaderElection
datanode_3  | 2020-07-17 21:05:48,633 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO impl.LeaderElection: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1: begin an election at term 1 for -1: [06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858], old=null
datanode_3  | 2020-07-17 21:05:48,635 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO impl.RoleInfo: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: shutdown LeaderElection
scm_1       | 2020-07-17 21:05:37,461 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-07-17 21:05:37,461 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-07-17 21:05:37,466 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-17 21:05:37,484 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-07-17 21:05:37,522 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-07-17 21:05:37,546 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
scm_1       | 2020-07-17 21:05:37,646 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-07-17 21:05:37,646 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-07-17 21:05:37,652 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1       | 2020-07-17 21:05:37,695 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ee40b5c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-07-17 21:05:37,697 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10817f46{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-07-17 21:05:37,810 [IPC Server handler 3 on default port 9861] WARN ipc.Server: IPC Server handler 3 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.7:50758: output error
scm_1       | 2020-07-17 21:05:37,863 [IPC Server handler 3 on default port 9861] INFO ipc.Server: IPC Server handler 3 on default port 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-07-17 21:05:37,870 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.4:42028: output error
scm_1       | 2020-07-17 21:05:37,877 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-07-17 21:05:37,968 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5ab5924c{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-4023110323568139778.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-07-17 21:05:38,014 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@b06d46d{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-07-17 21:05:38,017 [Listener at 0.0.0.0/9860] INFO server.Server: Started @10486ms
scm_1       | 2020-07-17 21:05:38,035 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-07-17 21:05:38,036 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-07-17 21:05:38,143 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-07-17 21:05:38,220 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@32b112a1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-07-17 21:05:38,698 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/d33d3495-faf3-4493-bca1-3f9f1e4f50f6
scm_1       | 2020-07-17 21:05:38,722 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d33d3495-faf3-4493-bca1-3f9f1e4f50f6{ip: 172.18.0.4, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-17 21:05:38,793 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
scm_1       | 2020-07-17 21:05:38,794 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-07-17 21:05:38,794 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-07-17 21:05:38,841 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-17 21:05:38,854 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ed0868ca-7864-4831-b584-ebe6f67ebb85 to datanode:d33d3495-faf3-4493-bca1-3f9f1e4f50f6
datanode_3  | 2020-07-17 21:05:48,635 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-07-17 21:05:48,635 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3CA83CCFE928 with new leaderId: 06c7fe9a-ea43-4249-af97-0cae133ce5d5
datanode_3  | 2020-07-17 21:05:48,635 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928: change Leader from null to 06c7fe9a-ea43-4249-af97-0cae133ce5d5 at term 1 for becomeLeader, leader elected after 5743ms
datanode_3  | 2020-07-17 21:05:48,643 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-07-17 21:05:48,643 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-07-17 21:05:48,646 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928
datanode_3  | 2020-07-17 21:05:48,658 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-07-17 21:05:48,658 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-07-17 21:05:48,698 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-07-17 21:05:48,698 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-07-17 21:05:48,698 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-07-17 21:05:48,712 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO impl.RoleInfo: 06c7fe9a-ea43-4249-af97-0cae133ce5d5: start LeaderState
datanode_3  | 2020-07-17 21:05:48,731 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-07-17 21:05:48,737 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928/current/log_inprogress_0
datanode_3  | 2020-07-17 21:05:48,738 [06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928-LeaderElection1] INFO impl.RaftServerImpl: 06c7fe9a-ea43-4249-af97-0cae133ce5d5@group-3CA83CCFE928: set configuration 0: [06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858], old=null at 0
datanode_2  | 2020-07-17 21:05:47,911 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-07-17 21:05:47,912 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-17 21:05:47,921 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO impl.RoleInfo: d33d3495-faf3-4493-bca1-3f9f1e4f50f6: start LeaderState
datanode_2  | 2020-07-17 21:05:47,927 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-07-17 21:05:47,964 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-LeaderElection2] INFO impl.RaftServerImpl: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91: set configuration 0: [5efa9984-03c1-40be-9434-f6a87d9b0f89:172.18.0.6:9858, 06c7fe9a-ea43-4249-af97-0cae133ce5d5:172.18.0.7:9858, d33d3495-faf3-4493-bca1-3f9f1e4f50f6:172.18.0.4:9858], old=null at 0
datanode_2  | 2020-07-17 21:05:47,965 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-391C4BE1FF91-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ddc5e8bb-d651-4c69-9d91-391c4be1ff91/current/log_inprogress_0
datanode_2  | 2020-07-17 21:05:48,066 [d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d33d3495-faf3-4493-bca1-3f9f1e4f50f6@group-EBE6F67EBB85-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ed0868ca-7864-4831-b584-ebe6f67ebb85/current/log_inprogress_0
scm_1       | 2020-07-17 21:05:38,935 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ed0868ca-7864-4831-b584-ebe6f67ebb85, Nodes: d33d3495-faf3-4493-bca1-3f9f1e4f50f6{ip: 172.18.0.4, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-17T21:05:38.842813Z]
scm_1       | 2020-07-17 21:05:38,955 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
scm_1       | 2020-07-17 21:05:38,956 [RatisPipelineUtilsThread] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
scm_1       | 2020-07-17 21:05:38,956 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
scm_1       | 2020-07-17 21:05:39,493 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/06c7fe9a-ea43-4249-af97-0cae133ce5d5
scm_1       | 2020-07-17 21:05:39,494 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 06c7fe9a-ea43-4249-af97-0cae133ce5d5{ip: 172.18.0.7, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-17 21:05:39,495 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-17 21:05:39,495 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-07-17 21:05:39,502 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928 to datanode:06c7fe9a-ea43-4249-af97-0cae133ce5d5
scm_1       | 2020-07-17 21:05:39,502 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928, Nodes: 06c7fe9a-ea43-4249-af97-0cae133ce5d5{ip: 172.18.0.7, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-17T21:05:39.502277Z]
scm_1       | 2020-07-17 21:05:39,504 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1       | 2020-07-17 21:05:39,505 [RatisPipelineUtilsThread] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2020-07-17 21:05:39,505 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1       | 2020-07-17 21:05:40,282 [IPC Server handler 44 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/5efa9984-03c1-40be-9434-f6a87d9b0f89
scm_1       | 2020-07-17 21:05:40,282 [IPC Server handler 44 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 5efa9984-03c1-40be-9434-f6a87d9b0f89{ip: 172.18.0.6, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-17 21:05:40,283 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b2b59173-adf0-4631-a570-4d4002dfad76 to datanode:5efa9984-03c1-40be-9434-f6a87d9b0f89
scm_1       | 2020-07-17 21:05:40,283 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-17 21:05:40,283 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-07-17 21:05:40,283 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b2b59173-adf0-4631-a570-4d4002dfad76, Nodes: 5efa9984-03c1-40be-9434-f6a87d9b0f89{ip: 172.18.0.6, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-17T21:05:40.283092Z]
scm_1       | 2020-07-17 21:05:40,285 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-17 21:05:40,298 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ddc5e8bb-d651-4c69-9d91-391c4be1ff91 to datanode:06c7fe9a-ea43-4249-af97-0cae133ce5d5
scm_1       | 2020-07-17 21:05:40,298 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ddc5e8bb-d651-4c69-9d91-391c4be1ff91 to datanode:d33d3495-faf3-4493-bca1-3f9f1e4f50f6
scm_1       | 2020-07-17 21:05:40,303 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ddc5e8bb-d651-4c69-9d91-391c4be1ff91 to datanode:5efa9984-03c1-40be-9434-f6a87d9b0f89
scm_1       | 2020-07-17 21:05:40,307 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ddc5e8bb-d651-4c69-9d91-391c4be1ff91, Nodes: 06c7fe9a-ea43-4249-af97-0cae133ce5d5{ip: 172.18.0.7, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}d33d3495-faf3-4493-bca1-3f9f1e4f50f6{ip: 172.18.0.4, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}5efa9984-03c1-40be-9434-f6a87d9b0f89{ip: 172.18.0.6, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-17T21:05:40.298029Z]
scm_1       | 2020-07-17 21:05:40,308 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-17 21:05:42,313 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ed0868ca-7864-4831-b584-ebe6f67ebb85, Nodes: d33d3495-faf3-4493-bca1-3f9f1e4f50f6{ip: 172.18.0.4, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:d33d3495-faf3-4493-bca1-3f9f1e4f50f6, CreationTimestamp2020-07-17T21:05:38.842813Z] moved to OPEN state
scm_1       | 2020-07-17 21:05:42,350 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-07-17 21:05:42,365 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-07-17 21:05:42,365 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-07-17 21:05:42,365 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2020-07-17 21:05:43,345 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d842e7ca-2b5f-48ff-9cc4-3ca83ccfe928, Nodes: 06c7fe9a-ea43-4249-af97-0cae133ce5d5{ip: 172.18.0.7, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:06c7fe9a-ea43-4249-af97-0cae133ce5d5, CreationTimestamp2020-07-17T21:05:39.502277Z] moved to OPEN state
scm_1       | 2020-07-17 21:05:44,497 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b2b59173-adf0-4631-a570-4d4002dfad76, Nodes: 5efa9984-03c1-40be-9434-f6a87d9b0f89{ip: 172.18.0.6, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:5efa9984-03c1-40be-9434-f6a87d9b0f89, CreationTimestamp2020-07-17T21:05:40.283092Z] moved to OPEN state
scm_1       | 2020-07-17 21:05:47,817 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ddc5e8bb-d651-4c69-9d91-391c4be1ff91, Nodes: 06c7fe9a-ea43-4249-af97-0cae133ce5d5{ip: 172.18.0.7, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}d33d3495-faf3-4493-bca1-3f9f1e4f50f6{ip: 172.18.0.4, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}5efa9984-03c1-40be-9434-f6a87d9b0f89{ip: 172.18.0.6, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:d33d3495-faf3-4493-bca1-3f9f1e4f50f6, CreationTimestamp2020-07-17T21:05:40.298029Z] moved to OPEN state
