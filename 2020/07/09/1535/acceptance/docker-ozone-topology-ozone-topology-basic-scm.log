Attaching to ozone-topology_datanode_6_1, ozone-topology_datanode_5_1, ozone-topology_om_1, ozone-topology_datanode_1_1, ozone-topology_datanode_3_1, ozone-topology_datanode_2_1, ozone-topology_scm_1, ozone-topology_datanode_4_1
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-07-09 12:57:58,396 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = f9dca0969a2a/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-07-09 12:57:58,422 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-07-09 12:57:59,205 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-07-09 12:57:59,761 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-07-09 12:58:01,357 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-07-09 12:58:01,361 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-07-09 12:58:02,076 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f9dca0969a2a ip:10.5.0.5
datanode_2_1  | 2020-07-09 12:58:03,015 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-07-09 12:58:03,105 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-07-09 12:58:03,108 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-07-09 12:58:03,155 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-07-09 12:58:03,445 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-07-09 12:58:09,769 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-07-09 12:58:10,133 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-07-09 12:58:11,312 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-07-09 12:58:11,329 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-07-09 12:58:11,329 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-09 12:58:11,330 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-07-09 12:58:11,343 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-07-09 12:58:12,466 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-09 12:58:13,941 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-07-09 12:58:14,033 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-07-09 12:58:14,228 [main] INFO util.log: Logging initialized @17935ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-07-09 12:58:14,927 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-07-09 12:58:14,960 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-07-09 12:58:14,995 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-07-09 12:58:15,014 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-07-09 12:58:15,017 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-07-09 12:58:15,017 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-07-09 12:58:15,259 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-07-09 12:58:15,273 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-07-09 12:58:15,306 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-07-09 12:58:15,545 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-07-09 12:58:15,545 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-07-09 12:58:15,546 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2_1  | 2020-07-09 12:58:15,707 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@fcd0e8d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-07-09 12:58:15,707 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6d420cdd{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-07-09 12:58:16,216 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1c171746{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5362576981752813823.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-07-09 12:58:16,286 [main] INFO server.AbstractConnector: Started ServerConnector@3e753289{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-07-09 12:58:16,286 [main] INFO server.Server: Started @19993ms
datanode_2_1  | 2020-07-09 12:58:16,322 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-07-09 12:58:16,322 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-07-09 12:58:16,331 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-07-09 12:58:16,449 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4983b164] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-07-09 12:58:17,742 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-07-09 12:58:19,906 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-09 12:58:20,907 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-09 12:58:21,909 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-09 12:58:22,910 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-07-09 12:57:58,973 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = 2f7f9d59f361/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-07-09 12:57:59,009 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-07-09 12:58:00,139 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-07-09 12:58:01,113 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-07-09 12:58:02,592 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-07-09 12:58:02,592 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-07-09 12:58:03,200 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2f7f9d59f361 ip:10.5.0.6
datanode_3_1  | 2020-07-09 12:58:03,909 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-07-09 12:58:03,943 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-07-09 12:58:03,963 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-07-09 12:58:04,030 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-07-09 12:58:04,328 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-07-09 12:58:10,476 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-07-09 12:58:10,879 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-07-09 12:58:12,169 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-07-09 12:58:12,174 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-07-09 12:58:12,182 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-09 12:58:12,182 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-07-09 12:58:12,189 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-07-09 12:58:13,549 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-09 12:58:14,830 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-07-09 12:58:14,991 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-07-09 12:58:15,180 [main] INFO util.log: Logging initialized @18829ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-07-09 12:58:15,880 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-07-09 12:58:15,896 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-07-09 12:58:15,975 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-07-09 12:58:15,992 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-07-09 12:58:16,001 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-07-09 12:58:16,004 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-07-09 12:58:16,182 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-07-09 12:58:16,266 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-07-09 12:58:16,273 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-07-09 12:58:16,572 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-07-09 12:58:16,582 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-07-09 12:58:16,583 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3_1  | 2020-07-09 12:58:16,628 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32e697ac{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-07-09 12:58:16,644 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@655621fd{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-07-09 12:58:17,187 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7d1cb59f{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-17394728852826623271.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-07-09 12:58:17,262 [main] INFO server.AbstractConnector: Started ServerConnector@184de357{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-07-09 12:58:17,262 [main] INFO server.Server: Started @20912ms
datanode_3_1  | 2020-07-09 12:58:17,302 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-07-09 12:58:17,302 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-07-09 12:58:17,309 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-07-09 12:58:17,471 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a756c40] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-07-09 12:58:18,451 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-07-09 12:58:20,894 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-09 12:58:21,909 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-09 12:58:22,910 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-09 12:58:23,911 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-07-09 12:58:07,293 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = fa90418e03f2/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_5_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-07-09 12:58:07,329 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5_1  | 2020-07-09 12:58:08,932 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-07-09 12:58:09,658 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-07-09 12:58:10,676 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-07-09 12:58:10,676 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-07-09 12:58:11,383 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:fa90418e03f2 ip:10.5.0.8
datanode_5_1  | 2020-07-09 12:58:12,209 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-07-09 12:58:12,249 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-07-09 12:58:12,351 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-07-09 12:58:12,377 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-07-09 12:58:12,664 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-07-09 12:58:19,189 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-07-09 12:58:19,607 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-07-09 12:58:20,420 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-07-09 12:58:20,444 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-07-09 12:58:20,458 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-09 12:58:20,459 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-07-09 12:58:20,460 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-07-09 12:58:21,597 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-09 12:58:22,706 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-07-09 12:58:22,806 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-07-09 12:58:22,914 [main] INFO util.log: Logging initialized @22513ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-07-09 12:58:23,404 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-07-09 12:58:23,415 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-07-09 12:58:23,447 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-07-09 12:58:23,460 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-07-09 12:58:23,460 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-07-09 12:58:23,461 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-07-09 12:58:23,623 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-07-09 12:58:23,681 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-07-09 12:58:23,682 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-07-09 12:58:23,886 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-07-09 12:58:23,886 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-07-09 12:58:23,888 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5_1  | 2020-07-09 12:58:23,916 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77e9dca8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-07-09 12:58:23,918 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ab5214{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-07-09 12:58:24,237 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5368e981{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-12221382058855542539.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-07-09 12:58:24,273 [main] INFO server.AbstractConnector: Started ServerConnector@41d20f06{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-07-09 12:58:24,274 [main] INFO server.Server: Started @23873ms
datanode_5_1  | 2020-07-09 12:58:24,291 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-07-09 12:58:24,292 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-07-09 12:58:24,311 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-07-09 12:58:24,374 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ec89fc7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-07-09 12:58:25,084 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-07-09 12:58:27,612 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-07-09 12:58:28,613 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-07-09 12:58:29,768 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-07-09 12:58:29,774 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-07-09 12:58:29,781 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 92033663-29ab-425f-a545-52cd3236f459 at port 9858
datanode_5_1  | 2020-07-09 12:58:29,876 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 92033663-29ab-425f-a545-52cd3236f459: start RPC server
datanode_5_1  | 2020-07-09 12:58:30,274 [Datanode State Machine Thread - 0] INFO server.GrpcService: 92033663-29ab-425f-a545-52cd3236f459: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-07-09 12:58:33,538 [Command processor thread] INFO impl.RaftServerProxy: 92033663-29ab-425f-a545-52cd3236f459: addNew group-6A0810216920:[92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858] returns group-6A0810216920:java.util.concurrent.CompletableFuture@7c271c15[Not completed]
datanode_5_1  | 2020-07-09 12:58:33,584 [pool-19-thread-1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459: new RaftServerImpl for group-6A0810216920:[92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-07-09 12:58:33,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-07-09 12:58:33,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-09 12:58:33,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-07-09 12:58:33,592 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-07-09 12:58:33,592 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-09 12:58:33,617 [pool-19-thread-1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920: ConfigurationManager, init=-1: [92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-07-09 12:58:33,618 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-09 12:58:33,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-07-09 12:58:33,646 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c2a94176-be9a-46f8-b1e9-6a0810216920 does not exist. Creating ...
datanode_5_1  | 2020-07-09 12:58:33,665 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c2a94176-be9a-46f8-b1e9-6a0810216920/in_use.lock acquired by nodename 6@fa90418e03f2
datanode_5_1  | 2020-07-09 12:58:33,673 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c2a94176-be9a-46f8-b1e9-6a0810216920 has been successfully formatted.
datanode_5_1  | 2020-07-09 12:58:33,739 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-6A0810216920: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-07-09 12:58:33,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-07-09 12:58:33,774 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-07-09 12:58:33,788 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-07-09 12:58:33,814 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-09 12:58:33,821 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-09 12:58:33,843 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920
datanode_5_1  | 2020-07-09 12:58:33,972 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-07-09 12:58:34,012 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c2a94176-be9a-46f8-b1e9-6a0810216920
datanode_5_1  | 2020-07-09 12:58:34,035 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-07-09 12:58:34,036 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-09 12:58:34,049 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-09 12:58:34,049 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-07-09 12:58:34,050 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-07-09 12:58:34,051 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-07-09 12:58:34,056 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-07-09 12:58:34,063 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-07-09 12:58:34,065 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-07-09 12:58:34,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-07-09 12:58:34,201 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-09 12:58:34,203 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-09 12:58:34,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-07-09 12:58:34,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-07-09 12:58:34,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-07-09 12:58:34,270 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-07-09 12:58:34,291 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-09 12:58:34,428 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920
datanode_5_1  | 2020-07-09 12:58:34,465 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920
datanode_5_1  | 2020-07-09 12:58:34,494 [pool-19-thread-1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920: start as a follower, conf=-1: [92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-09 12:58:34,498 [pool-19-thread-1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-07-09 12:58:34,505 [pool-19-thread-1] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: start FollowerState
datanode_5_1  | 2020-07-09 12:58:34,530 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A0810216920,id=92033663-29ab-425f-a545-52cd3236f459
datanode_5_1  | 2020-07-09 12:58:34,532 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920
datanode_5_1  | 2020-07-09 12:58:34,713 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "c2a94176-be9a-46f8-b1e9-6a0810216920"
datanode_5_1  | uuid128 {
datanode_2_1  | 2020-07-09 12:58:23,911 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-09 12:58:24,912 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-09 12:58:25,912 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-09 12:58:26,913 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-09 12:58:27,914 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-09 12:58:28,960 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | java.net.SocketTimeoutException: Call From f9dca0969a2a/10.5.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:54316 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:54316 remote=scm/10.5.0.71:9861]
datanode_2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2_1  | 2020-07-09 12:58:29,591 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-07-09 12:58:29,602 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-07-09 12:58:29,604 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 5b661712-7375-48d1-a708-209005b3fd5d at port 9858
datanode_2_1  | 2020-07-09 12:58:29,767 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 5b661712-7375-48d1-a708-209005b3fd5d: start RPC server
datanode_2_1  | 2020-07-09 12:58:30,144 [Datanode State Machine Thread - 1] INFO server.GrpcService: 5b661712-7375-48d1-a708-209005b3fd5d: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-07-09 12:58:33,698 [Command processor thread] INFO impl.RaftServerProxy: 5b661712-7375-48d1-a708-209005b3fd5d: addNew group-401162C631B8:[5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858] returns group-401162C631B8:java.util.concurrent.CompletableFuture@20c63bf[Not completed]
datanode_2_1  | 2020-07-09 12:58:33,790 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d: new RaftServerImpl for group-401162C631B8:[5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-07-09 12:58:33,803 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-07-09 12:58:33,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-09 12:58:33,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-07-09 12:58:33,818 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-07-09 12:58:33,818 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-09 12:58:33,838 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8: ConfigurationManager, init=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-07-09 12:58:33,850 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-09 12:58:33,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  |   mostSigBits: -4419929581027703048
datanode_5_1  |   leastSigBits: -5626849676559816416
datanode_5_1  | }
datanode_5_1  | .
datanode_5_1  | 2020-07-09 12:58:34,721 [Command processor thread] INFO impl.RaftServerProxy: 92033663-29ab-425f-a545-52cd3236f459: addNew group-A8F191A5483B:[5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858] returns group-A8F191A5483B:java.util.concurrent.CompletableFuture@72a6021d[Not completed]
datanode_5_1  | 2020-07-09 12:58:34,786 [pool-19-thread-1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459: new RaftServerImpl for group-A8F191A5483B:[5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-07-09 12:58:34,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-07-09 12:58:34,800 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-09 12:58:34,805 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-07-09 12:58:34,810 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-07-09 12:58:34,810 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-09 12:58:34,811 [pool-19-thread-1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B: ConfigurationManager, init=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-07-09 12:58:34,811 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-09 12:58:34,811 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-07-09 12:58:34,813 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b does not exist. Creating ...
datanode_5_1  | 2020-07-09 12:58:34,857 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b/in_use.lock acquired by nodename 6@fa90418e03f2
datanode_5_1  | 2020-07-09 12:58:34,861 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b has been successfully formatted.
datanode_5_1  | 2020-07-09 12:58:34,886 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A8F191A5483B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-07-09 12:58:34,886 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-07-09 12:58:34,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-07-09 12:58:34,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-07-09 12:58:34,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-09 12:58:34,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-09 12:58:34,887 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B
datanode_5_1  | 2020-07-09 12:58:34,889 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-07-09 12:58:34,889 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b
datanode_5_1  | 2020-07-09 12:58:34,890 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-07-09 12:58:34,895 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-09 12:58:34,900 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-09 12:58:34,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-07-09 12:58:34,905 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-07-09 12:58:34,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-07-09 12:58:34,913 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-07-09 12:58:34,913 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-07-09 12:58:34,919 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-07-09 12:58:34,930 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-07-09 12:58:34,941 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-09 12:58:34,947 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-09 12:58:34,948 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-07-09 12:58:34,949 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-07-09 12:58:34,953 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-07-09 12:58:34,954 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-07-09 12:58:34,954 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-09 12:58:34,957 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B
datanode_5_1  | 2020-07-09 12:58:34,959 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B
datanode_5_1  | 2020-07-09 12:58:34,966 [pool-19-thread-1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B: start as a follower, conf=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-09 12:58:35,009 [pool-19-thread-1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-07-09 12:58:35,009 [pool-19-thread-1] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: start FollowerState
datanode_3_1  | 2020-07-09 12:58:24,911 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-09 12:58:25,912 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-09 12:58:26,914 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-09 12:58:27,915 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-09 12:58:28,974 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3_1  | java.net.SocketTimeoutException: Call From 2f7f9d59f361/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:47450 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:47450 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-07-09 12:58:29,691 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-07-09 12:58:29,700 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-07-09 12:58:29,713 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 244a4af8-fd38-45a2-a163-d1fbc0b9f246 at port 9858
datanode_3_1  | 2020-07-09 12:58:29,898 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: start RPC server
datanode_3_1  | 2020-07-09 12:58:30,285 [Datanode State Machine Thread - 1] INFO server.GrpcService: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-07-09 12:58:34,738 [Command processor thread] INFO impl.RaftServerProxy: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: addNew group-8E9927188952:[244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858] returns group-8E9927188952:java.util.concurrent.CompletableFuture@b815bcb[Not completed]
datanode_3_1  | 2020-07-09 12:58:34,910 [pool-19-thread-1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: new RaftServerImpl for group-8E9927188952:[244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-07-09 12:58:34,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-07-09 12:58:34,966 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-07-09 12:58:34,966 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-07-09 12:58:34,967 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-07-09 12:58:34,977 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-09 12:58:35,055 [pool-19-thread-1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952: ConfigurationManager, init=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-07-09 12:58:35,129 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-09 12:58:35,136 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-07-09 12:58:35,154 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/901c3569-661a-498d-99db-8e9927188952 does not exist. Creating ...
datanode_5_1  | 2020-07-09 12:58:35,013 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A8F191A5483B,id=92033663-29ab-425f-a545-52cd3236f459
datanode_5_1  | 2020-07-09 12:58:35,020 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B
datanode_5_1  | 2020-07-09 12:58:38,905 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2bd839a3-0596-42cf-9c72-a8f191a5483b"
datanode_5_1  | uuid128 {
datanode_5_1  |   mostSigBits: 3159338510936589007
datanode_5_1  |   leastSigBits: -7173485500963665861
datanode_5_1  | }
datanode_5_1  | .
datanode_5_1  | 2020-07-09 12:58:39,576 [Thread-22] INFO impl.FollowerState: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-FollowerState: change to CANDIDATE, lastRpcTime:5070ms, electionTimeout:5038ms
datanode_5_1  | 2020-07-09 12:58:39,577 [Thread-22] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: shutdown FollowerState
datanode_5_1  | 2020-07-09 12:58:39,578 [Thread-22] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-07-09 12:58:39,579 [Thread-22] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: start LeaderElection
datanode_5_1  | 2020-07-09 12:58:39,599 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO impl.LeaderElection: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1: begin an election at term 1 for -1: [92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-09 12:58:39,600 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: shutdown LeaderElection
datanode_5_1  | 2020-07-09 12:58:39,601 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-07-09 12:58:39,602 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6A0810216920 with new leaderId: 92033663-29ab-425f-a545-52cd3236f459
datanode_5_1  | 2020-07-09 12:58:39,602 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920: change Leader from null to 92033663-29ab-425f-a545-52cd3236f459 at term 1 for becomeLeader, leader elected after 5859ms
datanode_5_1  | 2020-07-09 12:58:39,618 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-07-09 12:58:39,619 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-07-09 12:58:39,627 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920
datanode_5_1  | 2020-07-09 12:58:39,633 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-09 12:58:39,634 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-07-09 12:58:39,656 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-07-09 12:58:39,664 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-07-09 12:58:39,666 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-07-09 12:58:39,729 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: start LeaderState
datanode_5_1  | 2020-07-09 12:58:39,789 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-07-09 12:58:39,899 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-LeaderElection1] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920: set configuration 0: [92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-07-09 12:58:40,045 [Thread-24] INFO impl.FollowerState: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-FollowerState: change to CANDIDATE, lastRpcTime:5035ms, electionTimeout:5024ms
datanode_5_1  | 2020-07-09 12:58:40,048 [Thread-24] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: shutdown FollowerState
datanode_5_1  | 2020-07-09 12:58:40,048 [Thread-24] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-07-09 12:58:40,049 [Thread-24] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: start LeaderElection
datanode_5_1  | 2020-07-09 12:58:40,103 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO impl.LeaderElection: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2: begin an election at term 1 for -1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-09 12:58:40,263 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO impl.LeaderElection: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2: Election PASSED; received 1 response(s) [92033663-29ab-425f-a545-52cd3236f459<-933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d#0:OK-t1] and 0 exception(s); 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B:t1, leader=null, voted=92033663-29ab-425f-a545-52cd3236f459, raftlog=92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-09 12:58:40,269 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: shutdown LeaderElection
datanode_5_1  | 2020-07-09 12:58:40,269 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-07-09 12:58:40,270 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A8F191A5483B with new leaderId: 92033663-29ab-425f-a545-52cd3236f459
datanode_5_1  | 2020-07-09 12:58:40,270 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B: change Leader from null to 92033663-29ab-425f-a545-52cd3236f459 at term 1 for becomeLeader, leader elected after 5383ms
datanode_5_1  | 2020-07-09 12:58:40,270 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-07-09 12:58:35,243 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/901c3569-661a-498d-99db-8e9927188952/in_use.lock acquired by nodename 6@2f7f9d59f361
datanode_3_1  | 2020-07-09 12:58:35,283 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/901c3569-661a-498d-99db-8e9927188952 has been successfully formatted.
datanode_3_1  | 2020-07-09 12:58:35,350 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-8E9927188952: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-07-09 12:58:35,381 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-07-09 12:58:35,390 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-07-09 12:58:35,404 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-07-09 12:58:35,445 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-09 12:58:35,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-09 12:58:35,503 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952
datanode_3_1  | 2020-07-09 12:58:35,643 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-07-09 12:58:35,728 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/901c3569-661a-498d-99db-8e9927188952
datanode_3_1  | 2020-07-09 12:58:35,732 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-07-09 12:58:35,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-09 12:58:35,741 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-09 12:58:35,748 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-07-09 12:58:35,748 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-07-09 12:58:35,782 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-07-09 12:58:35,788 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-07-09 12:58:35,791 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-07-09 12:58:35,792 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-07-09 12:58:35,895 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-07-09 12:58:35,990 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-09 12:58:36,014 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-09 12:58:36,054 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-07-09 12:58:36,066 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-07-09 12:58:36,071 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-07-09 12:58:36,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-07-09 12:58:36,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-07-09 12:58:36,284 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952
datanode_3_1  | 2020-07-09 12:58:36,329 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952
datanode_3_1  | 2020-07-09 12:58:36,331 [pool-19-thread-1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952: start as a follower, conf=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858], old=null
datanode_3_1  | 2020-07-09 12:58:36,350 [pool-19-thread-1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-07-09 12:58:36,358 [pool-19-thread-1] INFO impl.RoleInfo: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: start FollowerState
datanode_3_1  | 2020-07-09 12:58:36,414 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E9927188952,id=244a4af8-fd38-45a2-a163-d1fbc0b9f246
datanode_3_1  | 2020-07-09 12:58:36,416 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952
datanode_3_1  | 2020-07-09 12:58:36,559 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "901c3569-661a-498d-99db-8e9927188952"
datanode_3_1  | uuid128 {
datanode_3_1  |   mostSigBits: -8062510506099193459
datanode_3_1  |   leastSigBits: -7360132377569883822
datanode_3_1  | }
datanode_3_1  | .
datanode_3_1  | 2020-07-09 12:58:36,575 [Command processor thread] INFO impl.RaftServerProxy: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: addNew group-72AA12A76166:[244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858] returns group-72AA12A76166:java.util.concurrent.CompletableFuture@4879a9e4[Not completed]
datanode_3_1  | 2020-07-09 12:58:36,599 [pool-19-thread-1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: new RaftServerImpl for group-72AA12A76166:[244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-07-09 12:58:36,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-07-09 12:58:36,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-07-09 12:58:36,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-07-09 12:58:36,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-07-09 12:58:36,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-09 12:58:36,608 [pool-19-thread-1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166: ConfigurationManager, init=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-07-09 12:58:36,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-07-09 12:58:06,473 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 5a12dab3071c/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-07-09 12:58:07,550 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = 00679385a616/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | 2020-07-09 12:58:36,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-07-09 12:58:36,608 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166 does not exist. Creating ...
datanode_3_1  | 2020-07-09 12:58:36,623 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166/in_use.lock acquired by nodename 6@2f7f9d59f361
datanode_3_1  | 2020-07-09 12:58:36,626 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166 has been successfully formatted.
datanode_3_1  | 2020-07-09 12:58:36,627 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-72AA12A76166: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-07-09 12:58:36,630 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-07-09 12:58:36,644 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-07-09 12:58:36,644 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-07-09 12:58:36,644 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-09 12:58:36,644 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-09 12:58:36,645 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166
datanode_3_1  | 2020-07-09 12:58:36,649 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-07-09 12:58:36,675 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166
datanode_3_1  | 2020-07-09 12:58:36,677 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-07-09 12:58:36,677 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-09 12:58:36,677 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-09 12:58:36,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-07-09 12:58:36,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-07-09 12:58:36,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-07-09 12:58:36,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-07-09 12:58:36,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-07-09 12:58:36,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-07-09 12:58:36,679 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-07-09 12:58:36,689 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-09 12:58:36,697 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-09 12:58:36,699 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-07-09 12:58:36,700 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-07-09 12:58:36,700 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-07-09 12:58:36,700 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-07-09 12:58:36,700 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-07-09 12:58:36,700 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166
datanode_3_1  | 2020-07-09 12:58:36,702 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166
datanode_3_1  | 2020-07-09 12:58:36,704 [pool-19-thread-1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166: start as a follower, conf=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null
datanode_3_1  | 2020-07-09 12:58:36,711 [pool-19-thread-1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-07-09 12:58:36,711 [pool-19-thread-1] INFO impl.RoleInfo: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: start FollowerState
datanode_3_1  | 2020-07-09 12:58:36,728 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72AA12A76166,id=244a4af8-fd38-45a2-a163-d1fbc0b9f246
datanode_3_1  | 2020-07-09 12:58:36,728 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166
datanode_3_1  | 2020-07-09 12:58:40,080 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "77944dd0-83a5-418c-9111-72aa12a76166"
datanode_3_1  | uuid128 {
datanode_3_1  |   mostSigBits: 8616597545023783308
datanode_3_1  |   leastSigBits: -7993481788822953626
datanode_3_1  | }
datanode_3_1  | .
datanode_3_1  | 2020-07-09 12:58:41,194 [grpc-default-executor-0] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:27bef0a1-05cf-4615-b519-87864850b753
datanode_3_1  | 2020-07-09 12:58:41,195 [grpc-default-executor-0] INFO impl.RoleInfo: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: shutdown FollowerState
datanode_3_1  | 2020-07-09 12:58:41,195 [Thread-25] INFO impl.FollowerState: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3_1  | 2020-07-09 12:58:41,196 [grpc-default-executor-0] INFO impl.RoleInfo: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: start FollowerState
datanode_3_1  | 2020-07-09 12:58:41,548 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-72AA12A76166 with new leaderId: 27bef0a1-05cf-4615-b519-87864850b753
datanode_3_1  | 2020-07-09 12:58:41,557 [grpc-default-executor-0] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166: change Leader from null to 27bef0a1-05cf-4615-b519-87864850b753 at term 1 for appendEntries, leader elected after 4917ms
datanode_3_1  | 2020-07-09 12:58:41,590 [Thread-23] INFO impl.FollowerState: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-FollowerState: change to CANDIDATE, lastRpcTime:5232ms, electionTimeout:5192ms
datanode_3_1  | 2020-07-09 12:58:41,594 [Thread-23] INFO impl.RoleInfo: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: shutdown FollowerState
datanode_3_1  | 2020-07-09 12:58:41,596 [Thread-23] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-07-09 12:58:41,601 [Thread-23] INFO impl.RoleInfo: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: start LeaderElection
datanode_3_1  | 2020-07-09 12:58:41,629 [grpc-default-executor-0] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166: set configuration 0: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null at 0
datanode_3_1  | 2020-07-09 12:58:41,633 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO impl.LeaderElection: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1: begin an election at term 1 for -1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858], old=null
datanode_3_1  | 2020-07-09 12:58:41,655 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO impl.RoleInfo: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: shutdown LeaderElection
datanode_3_1  | 2020-07-09 12:58:41,656 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-07-09 12:58:41,668 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8E9927188952 with new leaderId: 244a4af8-fd38-45a2-a163-d1fbc0b9f246
datanode_3_1  | 2020-07-09 12:58:41,670 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952: change Leader from null to 244a4af8-fd38-45a2-a163-d1fbc0b9f246 at term 1 for becomeLeader, leader elected after 6318ms
datanode_3_1  | 2020-07-09 12:58:41,683 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-07-09 12:58:41,697 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-07-09 12:58:41,688 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-07-09 12:58:41,708 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952
datanode_3_1  | 2020-07-09 12:58:41,737 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-09 12:58:41,738 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-07-09 12:58:41,757 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-07-09 12:58:41,765 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-07-09 12:58:41,765 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-07-09 12:58:41,800 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO impl.RoleInfo: 244a4af8-fd38-45a2-a163-d1fbc0b9f246: start LeaderState
datanode_3_1  | 2020-07-09 12:58:41,810 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-07-09 12:58:41,829 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-LeaderElection1] INFO impl.RaftServerImpl: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952: set configuration 0: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-07-09 12:58:41,983 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-8E9927188952-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/901c3569-661a-498d-99db-8e9927188952/current/log_inprogress_0
datanode_3_1  | 2020-07-09 12:58:41,989 [244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 244a4af8-fd38-45a2-a163-d1fbc0b9f246@group-72AA12A76166-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166/current/log_inprogress_0
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-07-09 12:58:07,588 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-07-09 12:58:09,186 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-07-09 12:58:09,815 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-07-09 12:58:11,134 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-07-09 12:58:11,134 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-07-09 12:58:11,946 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:00679385a616 ip:10.5.0.7
datanode_4_1  | 2020-07-09 12:58:12,898 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-07-09 12:58:12,933 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-07-09 12:58:12,976 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-07-09 12:58:13,056 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-07-09 12:58:13,462 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-07-09 12:58:19,325 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-07-09 12:58:19,702 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-07-09 12:58:20,496 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-07-09 12:58:20,515 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-07-09 12:58:20,524 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-09 12:58:20,525 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-07-09 12:58:20,538 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-07-09 12:58:21,254 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-09 12:58:22,308 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-07-09 12:58:22,388 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-07-09 12:58:22,490 [main] INFO util.log: Logging initialized @21870ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-07-09 12:58:22,953 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-07-09 12:58:22,967 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-07-09 12:58:22,994 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-07-09 12:58:23,007 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-07-09 12:58:23,007 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-07-09 12:58:23,013 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-07-09 12:58:23,156 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-07-09 12:58:23,177 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-07-09 12:58:23,191 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-07-09 12:58:23,344 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-07-09 12:58:23,349 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-07-09 12:58:23,350 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_4_1  | 2020-07-09 12:58:23,387 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77e9dca8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-07-09 12:58:23,409 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ab5214{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-07-09 12:58:23,679 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5368e981{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13695911244133306308.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-07-09 12:58:23,713 [main] INFO server.AbstractConnector: Started ServerConnector@41d20f06{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-07-09 12:58:23,713 [main] INFO server.Server: Started @23094ms
datanode_4_1  | 2020-07-09 12:58:23,728 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-07-09 12:58:23,728 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-07-09 12:58:23,734 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-07-09 12:58:23,841 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e353b62] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-07-09 12:58:24,481 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-07-09 12:58:26,931 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-09 12:58:27,931 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-09 12:58:28,947 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From 00679385a616/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:39408 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 2020-07-09 12:58:33,890 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/1aae0153-d0b5-46a8-8e3b-401162c631b8 does not exist. Creating ...
datanode_2_1  | 2020-07-09 12:58:33,922 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/1aae0153-d0b5-46a8-8e3b-401162c631b8/in_use.lock acquired by nodename 6@f9dca0969a2a
datanode_2_1  | 2020-07-09 12:58:33,939 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/1aae0153-d0b5-46a8-8e3b-401162c631b8 has been successfully formatted.
datanode_2_1  | 2020-07-09 12:58:33,970 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-401162C631B8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-07-09 12:58:33,971 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-07-09 12:58:33,974 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-07-09 12:58:33,993 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-07-09 12:58:34,009 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-09 12:58:34,014 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-09 12:58:34,053 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8
datanode_2_1  | 2020-07-09 12:58:34,107 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-09 12:58:34,161 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/1aae0153-d0b5-46a8-8e3b-401162c631b8
datanode_2_1  | 2020-07-09 12:58:34,162 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-07-09 12:58:34,163 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-09 12:58:34,163 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-09 12:58:34,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-07-09 12:58:34,182 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-07-09 12:58:34,183 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-07-09 12:58:34,184 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-07-09 12:58:34,188 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-07-09 12:58:34,189 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-07-09 12:58:34,288 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-07-09 12:58:34,331 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-09 12:58:34,345 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-09 12:58:34,383 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-07-09 12:58:34,384 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-07-09 12:58:34,384 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-07-09 12:58:34,385 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-07-09 12:58:34,385 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-07-09 12:58:34,592 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8
datanode_2_1  | 2020-07-09 12:58:34,711 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8
datanode_2_1  | 2020-07-09 12:58:34,713 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8: start as a follower, conf=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-09 12:58:34,726 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-07-09 12:58:34,727 [pool-19-thread-1] INFO impl.RoleInfo: 5b661712-7375-48d1-a708-209005b3fd5d: start FollowerState
datanode_2_1  | 2020-07-09 12:58:34,888 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-401162C631B8,id=5b661712-7375-48d1-a708-209005b3fd5d
datanode_2_1  | 2020-07-09 12:58:34,899 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8
datanode_2_1  | 2020-07-09 12:58:35,052 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "1aae0153-d0b5-46a8-8e3b-401162c631b8"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: 1922475550429234856
datanode_2_1  |   leastSigBits: -8197888253282078280
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-07-09 12:58:35,053 [Command processor thread] INFO impl.RaftServerProxy: 5b661712-7375-48d1-a708-209005b3fd5d: addNew group-A8F191A5483B:[5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858] returns group-A8F191A5483B:java.util.concurrent.CompletableFuture@1e094346[Not completed]
datanode_2_1  | 2020-07-09 12:58:35,243 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d: new RaftServerImpl for group-A8F191A5483B:[5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-07-09 12:58:35,308 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-07-09 12:58:35,317 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-09 12:58:35,322 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-07-09 12:58:35,323 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-07-09 12:58:35,323 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-09 12:58:35,323 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B: ConfigurationManager, init=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_4_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:39408 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_4_1  | 2020-07-09 12:58:29,634 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-07-09 12:58:29,640 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-07-09 12:58:29,643 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8daff4b0-5959-4951-b3a1-58b111d6a2a7 at port 9858
datanode_4_1  | 2020-07-09 12:58:29,707 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: start RPC server
datanode_4_1  | 2020-07-09 12:58:30,084 [Datanode State Machine Thread - 1] INFO server.GrpcService: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-07-09 12:58:35,069 [Command processor thread] INFO impl.RaftServerProxy: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: addNew group-3D3E5264121E:[8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858] returns group-3D3E5264121E:java.util.concurrent.CompletableFuture@723545c0[Not completed]
datanode_4_1  | 2020-07-09 12:58:35,349 [pool-19-thread-1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: new RaftServerImpl for group-3D3E5264121E:[8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-09 12:58:35,371 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-07-09 12:58:35,394 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-07-09 12:58:35,394 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-07-09 12:58:35,395 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-09 12:58:35,395 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-09 12:58:35,446 [pool-19-thread-1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E: ConfigurationManager, init=-1: [8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-09 12:58:35,446 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-09 12:58:35,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-09 12:58:35,460 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bd5a4449-6575-4b77-94d7-3d3e5264121e does not exist. Creating ...
datanode_4_1  | 2020-07-09 12:58:35,481 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bd5a4449-6575-4b77-94d7-3d3e5264121e/in_use.lock acquired by nodename 6@00679385a616
datanode_4_1  | 2020-07-09 12:58:35,491 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bd5a4449-6575-4b77-94d7-3d3e5264121e has been successfully formatted.
datanode_4_1  | 2020-07-09 12:58:35,563 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3D3E5264121E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-07-09 12:58:35,568 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-07-09 12:58:35,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-07-09 12:58:35,601 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-07-09 12:58:35,634 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-09 12:58:35,636 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-09 12:58:35,688 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E
datanode_4_1  | 2020-07-09 12:58:35,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-07-09 12:58:06,559 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-07-09 12:58:11,580 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-07-09 12:58:12,086 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-07-09 12:58:12,094 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-07-09 12:58:12,632 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-09 12:58:15,443 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:16,444 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:17,445 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:18,446 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:19,446 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:20,447 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:21,448 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:22,449 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:23,450 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:24,450 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-09 12:58:24,452 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-6a1e266b-b522-4082-8503-f8c18ec7fa4a;layoutVersion=0
om_1          | 2020-07-09 12:58:30,679 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 5a12dab3071c/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-07-09 12:58:37,054 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 5a12dab3071c/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-07-09 12:58:37,099 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-07-09 12:58:41,516 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-07-09 12:58:41,823 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-07-09 12:58:41,823 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-07-09 12:58:42,023 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-09 12:58:42,079 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-09 12:58:44,160 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-09 12:58:45,413 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-07-09 12:58:45,440 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-07-09 12:58:45,705 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-07-09 12:58:45,798 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-07-09 12:58:45,798 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1          | 2020-07-09 12:58:45,855 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
om_1          | 2020-07-09 12:58:45,866 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-07-09 12:58:45,867 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-07-09 12:58:46,106 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-07-09 12:58:46,107 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1          | 2020-07-09 12:58:46,152 [Listener at om/9862] INFO util.log: Logging initialized @14794ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-07-09 12:58:46,312 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-07-09 12:58:46,316 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-07-09 12:58:05,537 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = ac703be53cac/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | 2020-07-09 12:58:40,270 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-07-09 12:58:40,270 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B
datanode_5_1  | 2020-07-09 12:58:40,271 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-09 12:58:40,271 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-07-09 12:58:40,271 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-07-09 12:58:40,286 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-07-09 12:58:40,286 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-07-09 12:58:40,330 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-07-09 12:58:40,331 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-09 12:58:40,332 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-07-09 12:58:40,341 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-07-09 12:58:40,358 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-07-09 12:58:40,368 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-09 12:58:40,368 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B
datanode_5_1  | 2020-07-09 12:58:40,372 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-07-09 12:58:40,412 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-09 12:58:40,412 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-07-09 12:58:40,412 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-07-09 12:58:40,412 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-07-09 12:58:40,413 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-09 12:58:40,420 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO impl.RoleInfo: 92033663-29ab-425f-a545-52cd3236f459: start LeaderState
datanode_5_1  | 2020-07-09 12:58:40,429 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-07-09 12:58:40,441 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-LeaderElection2] INFO impl.RaftServerImpl: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B: set configuration 0: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-07-09 12:58:40,817 [92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b/current/log_inprogress_0
datanode_5_1  | 2020-07-09 12:58:40,839 [92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 92033663-29ab-425f-a545-52cd3236f459@group-6A0810216920-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c2a94176-be9a-46f8-b1e9-6a0810216920/current/log_inprogress_0
datanode_5_1  | 2020-07-09 12:59:40,778 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1,entriesCount=1,lastEntry=(t:1, i:0)
datanode_5_1  | 2020-07-09 12:59:54,498 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=7,entriesCount=1,lastEntry=(t:1, i:1)
datanode_5_1  | 2020-07-09 12:59:54,589 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=8,entriesCount=1,lastEntry=(t:1, i:2)
datanode_5_1  | 2020-07-09 12:59:55,687 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:3)
datanode_5_1  | 2020-07-09 12:59:55,699 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:4)
datanode_5_1  | 2020-07-09 12:59:58,249 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:5)
datanode_5_1  | 2020-07-09 12:59:58,257 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=13,entriesCount=1,lastEntry=(t:1, i:6)
datanode_4_1  | 2020-07-09 12:58:35,880 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/bd5a4449-6575-4b77-94d7-3d3e5264121e
datanode_4_1  | 2020-07-09 12:58:35,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-07-09 12:58:35,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-09 12:58:35,910 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-09 12:58:35,910 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-07-09 12:58:35,910 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-07-09 12:58:35,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-07-09 12:58:35,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-07-09 12:58:35,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-07-09 12:58:35,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-07-09 12:58:36,165 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-07-09 12:58:36,195 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-09 12:58:36,199 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-09 12:58:36,211 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-07-09 12:58:36,238 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-07-09 12:58:36,239 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-07-09 12:58:36,239 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-07-09 12:58:36,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-07-09 12:58:36,428 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E
datanode_4_1  | 2020-07-09 12:58:36,482 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E
datanode_4_1  | 2020-07-09 12:58:36,491 [pool-19-thread-1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E: start as a follower, conf=-1: [8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null
datanode_4_1  | 2020-07-09 12:58:36,509 [pool-19-thread-1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-07-09 12:58:36,541 [pool-19-thread-1] INFO impl.RoleInfo: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: start FollowerState
datanode_4_1  | 2020-07-09 12:58:36,577 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3D3E5264121E,id=8daff4b0-5959-4951-b3a1-58b111d6a2a7
datanode_4_1  | 2020-07-09 12:58:36,578 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E
datanode_4_1  | 2020-07-09 12:58:36,661 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "bd5a4449-6575-4b77-94d7-3d3e5264121e"
datanode_4_1  | uuid128 {
datanode_4_1  |   mostSigBits: -4802450970611725449
datanode_4_1  |   leastSigBits: -7721635698223869410
datanode_4_1  | }
datanode_4_1  | .
datanode_4_1  | 2020-07-09 12:58:36,665 [Command processor thread] INFO impl.RaftServerProxy: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: addNew group-72AA12A76166:[244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858] returns group-72AA12A76166:java.util.concurrent.CompletableFuture@345339ab[Not completed]
datanode_4_1  | 2020-07-09 12:58:36,699 [pool-19-thread-1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: new RaftServerImpl for group-72AA12A76166:[244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-09 12:58:36,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-07-09 12:58:36,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-07-09 12:58:36,702 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-07-09 12:58:36,702 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-09 12:58:36,703 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-09 12:58:36,704 [pool-19-thread-1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166: ConfigurationManager, init=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-09 12:58:36,708 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-09 12:58:36,708 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-09 12:58:36,709 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166 does not exist. Creating ...
datanode_4_1  | 2020-07-09 12:58:36,715 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166/in_use.lock acquired by nodename 6@00679385a616
datanode_4_1  | 2020-07-09 12:58:36,725 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166 has been successfully formatted.
datanode_4_1  | 2020-07-09 12:58:36,727 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-72AA12A76166: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-07-09 12:58:36,734 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-07-09 12:58:36,734 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-07-09 12:58:36,734 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-07-09 12:58:36,734 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-09 12:59:58,264 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:7)
datanode_5_1  | 2020-07-09 12:59:58,276 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:8)
datanode_5_1  | 2020-07-09 13:00:00,828 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:9)
datanode_5_1  | 2020-07-09 13:00:00,840 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=18,entriesCount=1,lastEntry=(t:1, i:10)
datanode_5_1  | 2020-07-09 13:00:00,859 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:11)
datanode_5_1  | 2020-07-09 13:00:00,869 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:12)
datanode_5_1  | 2020-07-09 13:00:03,623 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:13)
datanode_5_1  | 2020-07-09 13:00:03,635 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=23,entriesCount=1,lastEntry=(t:1, i:14)
datanode_5_1  | 2020-07-09 13:00:03,641 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:15)
datanode_5_1  | 2020-07-09 13:00:03,647 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:16)
datanode_5_1  | 2020-07-09 13:00:06,423 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:17)
datanode_5_1  | 2020-07-09 13:00:06,439 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=28,entriesCount=1,lastEntry=(t:1, i:18)
datanode_5_1  | 2020-07-09 13:00:06,447 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=29,entriesCount=1,lastEntry=(t:1, i:19)
datanode_5_1  | 2020-07-09 13:00:06,463 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:20)
datanode_5_1  | 2020-07-09 13:00:09,002 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:21)
datanode_5_1  | 2020-07-09 13:00:09,013 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=33,entriesCount=1,lastEntry=(t:1, i:22)
datanode_5_1  | 2020-07-09 13:00:09,016 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=34,entriesCount=1,lastEntry=(t:1, i:23)
datanode_5_1  | 2020-07-09 13:00:09,031 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:24)
datanode_5_1  | 2020-07-09 13:00:11,572 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:25)
datanode_5_1  | 2020-07-09 13:00:11,581 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:26)
datanode_5_1  | 2020-07-09 13:00:11,593 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=39,entriesCount=1,lastEntry=(t:1, i:27)
datanode_5_1  | 2020-07-09 13:00:11,608 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:28)
datanode_5_1  | 2020-07-09 13:00:14,212 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:29)
om_1          | 2020-07-09 12:58:46,323 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-07-09 12:58:46,325 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1          | 2020-07-09 12:58:46,333 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-07-09 12:58:46,333 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-07-09 12:58:46,374 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-07-09 12:58:46,387 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-07-09 12:58:46,388 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-07-09 12:58:46,450 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-07-09 12:58:46,450 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-07-09 12:58:46,455 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1          | 2020-07-09 12:58:46,523 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@50e8ed74{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-07-09 12:58:46,523 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@103478b8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-07-09 12:58:46,618 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1293f8d7{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-16070721033740735437.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-07-09 12:58:46,634 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@36ecf9f6{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-07-09 12:58:46,634 [Listener at om/9862] INFO server.Server: Started @15275ms
om_1          | 2020-07-09 12:58:46,648 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-07-09 12:58:46,648 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-07-09 12:58:46,658 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-07-09 12:58:46,670 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7744195] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2020-07-09 12:58:50,306 [IPC Server handler 99 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-60936 for user:hadoop
om_1          | 2020-07-09 12:58:50,338 [IPC Server handler 0 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-21665 for user:hadoop
om_1          | 2020-07-09 12:58:50,350 [IPC Server handler 2 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-46082 for user:hadoop
om_1          | 2020-07-09 12:58:50,355 [IPC Server handler 4 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-27163 for user:hadoop
om_1          | 2020-07-09 12:58:50,361 [IPC Server handler 6 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-47057 for user:hadoop
datanode_5_1  | 2020-07-09 13:00:14,222 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=43,entriesCount=1,lastEntry=(t:1, i:30)
datanode_5_1  | 2020-07-09 13:00:14,239 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=44,entriesCount=1,lastEntry=(t:1, i:31)
datanode_5_1  | 2020-07-09 13:00:14,248 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:32)
datanode_5_1  | 2020-07-09 13:00:19,505 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=48,entriesCount=1,lastEntry=(t:1, i:33)
datanode_5_1  | 2020-07-09 13:00:19,518 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=49,entriesCount=1,lastEntry=(t:1, i:34)
datanode_5_1  | 2020-07-09 13:00:19,518 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:35)
datanode_5_1  | 2020-07-09 13:00:19,538 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:36)
datanode_5_1  | 2020-07-09 13:00:22,173 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=53,entriesCount=1,lastEntry=(t:1, i:37)
datanode_5_1  | 2020-07-09 13:00:22,173 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=54,entriesCount=1,lastEntry=(t:1, i:38)
datanode_5_1  | 2020-07-09 13:00:22,181 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:39)
datanode_5_1  | 2020-07-09 13:00:22,187 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:40)
datanode_5_1  | 2020-07-09 13:00:24,874 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=58,entriesCount=1,lastEntry=(t:1, i:41)
datanode_5_1  | 2020-07-09 13:00:24,884 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=59,entriesCount=1,lastEntry=(t:1, i:42)
datanode_5_1  | 2020-07-09 13:00:24,894 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:43)
datanode_5_1  | 2020-07-09 13:00:24,915 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:44)
datanode_5_1  | 2020-07-09 13:00:27,467 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=63,entriesCount=1,lastEntry=(t:1, i:45)
datanode_5_1  | 2020-07-09 13:00:27,471 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=64,entriesCount=1,lastEntry=(t:1, i:46)
datanode_5_1  | 2020-07-09 13:00:27,481 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:47)
datanode_5_1  | 2020-07-09 13:00:27,490 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:48)
datanode_5_1  | 2020-07-09 13:00:30,029 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=68,entriesCount=1,lastEntry=(t:1, i:49)
datanode_5_1  | 2020-07-09 13:00:30,033 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=69,entriesCount=1,lastEntry=(t:1, i:50)
datanode_5_1  | 2020-07-09 13:00:30,042 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:51)
datanode_5_1  | 2020-07-09 13:00:30,048 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:52)
datanode_4_1  | 2020-07-09 12:58:36,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-09 12:58:36,735 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166
datanode_4_1  | 2020-07-09 12:58:36,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-07-09 12:58:36,737 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166
datanode_4_1  | 2020-07-09 12:58:36,737 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-07-09 12:58:36,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-09 12:58:36,755 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-09 12:58:36,755 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-07-09 12:58:36,755 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-07-09 12:58:36,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-07-09 12:58:36,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-07-09 12:58:36,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-07-09 12:58:36,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-07-09 12:58:36,757 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-07-09 12:58:36,758 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-09 12:58:36,759 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-09 12:58:36,761 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-07-09 12:58:36,761 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-07-09 12:58:36,762 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-07-09 12:58:36,762 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-07-09 12:58:36,764 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-07-09 12:58:36,765 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166
datanode_4_1  | 2020-07-09 12:58:36,766 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166
datanode_4_1  | 2020-07-09 12:58:36,769 [pool-19-thread-1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166: start as a follower, conf=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null
datanode_4_1  | 2020-07-09 12:58:36,772 [pool-19-thread-1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-07-09 12:58:36,772 [pool-19-thread-1] INFO impl.RoleInfo: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: start FollowerState
datanode_4_1  | 2020-07-09 12:58:36,802 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72AA12A76166,id=8daff4b0-5959-4951-b3a1-58b111d6a2a7
datanode_4_1  | 2020-07-09 12:58:36,825 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166
datanode_4_1  | 2020-07-09 12:58:40,403 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "77944dd0-83a5-418c-9111-72aa12a76166"
datanode_4_1  | uuid128 {
datanode_4_1  |   mostSigBits: 8616597545023783308
datanode_4_1  |   leastSigBits: -7993481788822953626
datanode_4_1  | }
datanode_4_1  | .
datanode_4_1  | 2020-07-09 12:58:41,205 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:27bef0a1-05cf-4615-b519-87864850b753
datanode_4_1  | 2020-07-09 12:58:41,206 [grpc-default-executor-0] INFO impl.RoleInfo: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: shutdown FollowerState
datanode_4_1  | 2020-07-09 12:58:41,206 [Thread-25] INFO impl.FollowerState: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 2020-07-09 12:58:41,206 [grpc-default-executor-0] INFO impl.RoleInfo: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: start FollowerState
datanode_4_1  | 2020-07-09 12:58:41,478 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-72AA12A76166 with new leaderId: 27bef0a1-05cf-4615-b519-87864850b753
datanode_4_1  | 2020-07-09 12:58:41,478 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166: change Leader from null to 27bef0a1-05cf-4615-b519-87864850b753 at term 1 for appendEntries, leader elected after 4743ms
datanode_4_1  | 2020-07-09 12:58:41,627 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166: set configuration 0: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-07-09 12:58:41,636 [Thread-23] INFO impl.FollowerState: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-FollowerState: change to CANDIDATE, lastRpcTime:5095ms, electionTimeout:5051ms
datanode_4_1  | 2020-07-09 12:58:41,637 [Thread-23] INFO impl.RoleInfo: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: shutdown FollowerState
datanode_4_1  | 2020-07-09 12:58:41,637 [Thread-23] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-07-09 12:58:41,639 [Thread-23] INFO impl.RoleInfo: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: start LeaderElection
datanode_4_1  | 2020-07-09 12:58:41,687 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO impl.LeaderElection: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1: begin an election at term 1 for -1: [8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null
datanode_4_1  | 2020-07-09 12:58:41,691 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO impl.RoleInfo: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: shutdown LeaderElection
datanode_4_1  | 2020-07-09 12:58:41,704 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-07-09 12:58:41,705 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3D3E5264121E with new leaderId: 8daff4b0-5959-4951-b3a1-58b111d6a2a7
datanode_4_1  | 2020-07-09 12:58:41,713 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E: change Leader from null to 8daff4b0-5959-4951-b3a1-58b111d6a2a7 at term 1 for becomeLeader, leader elected after 6141ms
datanode_4_1  | 2020-07-09 12:58:41,716 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-07-09 12:58:41,724 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-07-09 12:58:41,687 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-07-09 12:58:41,725 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E
datanode_4_1  | 2020-07-09 12:58:41,797 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-09 12:58:41,798 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-07-09 12:58:41,820 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-07-09 12:58:41,820 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-07-09 12:58:41,822 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-07-09 12:58:41,846 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO impl.RoleInfo: 8daff4b0-5959-4951-b3a1-58b111d6a2a7: start LeaderState
datanode_4_1  | 2020-07-09 12:58:41,860 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-07-09 12:58:41,878 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-LeaderElection1] INFO impl.RaftServerImpl: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E: set configuration 0: [8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-07-09 12:58:42,081 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-3D3E5264121E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bd5a4449-6575-4b77-94d7-3d3e5264121e/current/log_inprogress_0
datanode_4_1  | 2020-07-09 12:58:42,083 [8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8daff4b0-5959-4951-b3a1-58b111d6a2a7@group-72AA12A76166-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166/current/log_inprogress_0
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-07-09 12:58:05,584 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-07-09 12:58:07,351 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-07-09 12:58:08,179 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-07-09 12:58:09,102 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-07-09 12:58:09,102 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-07-09 12:58:09,775 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:ac703be53cac ip:10.5.0.4
datanode_1_1  | 2020-07-09 12:58:10,575 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-07-09 12:58:10,601 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-07-09 12:58:10,604 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-07-09 12:58:10,702 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-07-09 12:58:10,889 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-07-09 12:58:17,321 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-07-09 12:58:17,708 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-07-09 12:58:18,742 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-07-09 12:58:18,749 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-07-09 12:58:18,784 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-09 12:58:18,796 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-07-09 12:58:18,802 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-07-09 12:58:19,788 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-09 12:58:20,954 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-07-09 12:58:21,084 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-07-09 12:58:21,218 [main] INFO util.log: Logging initialized @22116ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-07-09 12:58:21,743 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-07-09 12:58:21,755 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-07-09 12:58:21,783 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-07-09 12:58:21,786 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-07-09 12:58:21,789 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-07-09 12:58:21,789 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-07-09 12:58:21,938 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-07-09 12:58:21,980 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-07-09 12:58:21,988 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-07-09 12:58:22,145 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-07-09 12:58:22,152 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-07-09 12:58:22,153 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1_1  | 2020-07-09 12:58:22,183 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77e9dca8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-07-09 12:58:22,184 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ab5214{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-07-09 12:58:22,508 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5368e981{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-8937412187058740226.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-07-09 12:58:22,605 [main] INFO server.AbstractConnector: Started ServerConnector@41d20f06{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-07-09 12:58:22,610 [main] INFO server.Server: Started @23508ms
datanode_1_1  | 2020-07-09 12:58:22,665 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-07-09 12:58:22,665 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-07-09 12:58:22,672 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-07-09 12:58:22,729 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c1c4f29] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-07-09 12:58:23,479 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-07-09 12:58:26,034 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-09 12:58:27,035 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-09 12:58:28,036 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-09 12:58:29,062 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1_1  | java.net.SocketTimeoutException: Call From ac703be53cac/10.5.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:43074 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:43074 remote=scm/10.5.0.71:9861]
datanode_1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1_1  | 2020-07-09 12:58:29,639 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-07-09 12:58:29,641 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-07-09 12:58:29,646 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 27bef0a1-05cf-4615-b519-87864850b753 at port 9858
datanode_1_1  | 2020-07-09 12:58:29,853 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 27bef0a1-05cf-4615-b519-87864850b753: start RPC server
datanode_1_1  | 2020-07-09 12:58:30,199 [Datanode State Machine Thread - 1] INFO server.GrpcService: 27bef0a1-05cf-4615-b519-87864850b753: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-07-09 12:58:34,047 [Command processor thread] INFO impl.RaftServerProxy: 27bef0a1-05cf-4615-b519-87864850b753: addNew group-17B618627637:[27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858] returns group-17B618627637:java.util.concurrent.CompletableFuture@71104d90[Not completed]
datanode_1_1  | 2020-07-09 12:58:34,113 [pool-19-thread-1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753: new RaftServerImpl for group-17B618627637:[27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-07-09 12:58:34,145 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-07-09 12:58:34,151 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-07-09 12:58:34,151 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-07-09 12:58:34,152 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-07-09 12:58:34,153 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-07-09 12:58:34,174 [pool-19-thread-1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637: ConfigurationManager, init=-1: [27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-07-09 12:58:34,178 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-09 12:58:34,188 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-07-09 12:58:34,203 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0e9bdad4-4bd2-44e0-8a8f-17b618627637 does not exist. Creating ...
datanode_1_1  | 2020-07-09 12:58:34,230 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0e9bdad4-4bd2-44e0-8a8f-17b618627637/in_use.lock acquired by nodename 6@ac703be53cac
datanode_1_1  | 2020-07-09 12:58:34,236 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0e9bdad4-4bd2-44e0-8a8f-17b618627637 has been successfully formatted.
datanode_1_1  | 2020-07-09 12:58:34,310 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-17B618627637: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-07-09 12:58:34,312 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-07-09 12:58:34,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-07-09 12:58:34,389 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-07-09 12:58:34,397 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-09 12:58:34,443 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-09 12:58:35,323 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-09 12:58:35,329 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-07-09 12:58:35,333 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b does not exist. Creating ...
datanode_2_1  | 2020-07-09 12:58:35,338 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b/in_use.lock acquired by nodename 6@f9dca0969a2a
datanode_2_1  | 2020-07-09 12:58:35,347 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b has been successfully formatted.
datanode_2_1  | 2020-07-09 12:58:35,348 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A8F191A5483B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-07-09 12:58:35,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-07-09 12:58:35,361 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-07-09 12:58:35,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-07-09 12:58:35,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-09 12:58:35,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-09 12:58:35,370 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B
datanode_2_1  | 2020-07-09 12:58:35,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-09 12:58:35,374 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b
datanode_2_1  | 2020-07-09 12:58:35,375 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-07-09 12:58:35,376 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-09 12:58:35,376 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-09 12:58:35,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-07-09 12:58:35,388 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-07-09 12:58:35,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-07-09 12:58:35,394 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-07-09 12:58:35,394 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-07-09 12:58:35,394 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-07-09 12:58:35,405 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-07-09 12:58:35,406 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-09 12:58:35,417 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-09 12:58:35,469 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-07-09 12:58:35,470 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-07-09 12:58:35,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-07-09 12:58:35,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-07-09 12:58:35,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-07-09 12:58:35,473 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B
datanode_2_1  | 2020-07-09 12:58:35,474 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B
datanode_2_1  | 2020-07-09 12:58:35,481 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B: start as a follower, conf=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null
datanode_2_1  | 2020-07-09 12:58:35,487 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-07-09 12:58:35,493 [pool-19-thread-1] INFO impl.RoleInfo: 5b661712-7375-48d1-a708-209005b3fd5d: start FollowerState
datanode_2_1  | 2020-07-09 12:58:35,502 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A8F191A5483B,id=5b661712-7375-48d1-a708-209005b3fd5d
datanode_2_1  | 2020-07-09 12:58:35,502 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B
datanode_2_1  | 2020-07-09 12:58:38,950 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2bd839a3-0596-42cf-9c72-a8f191a5483b"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: 3159338510936589007
datanode_2_1  |   leastSigBits: -7173485500963665861
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-07-09 12:58:39,853 [Thread-23] INFO impl.FollowerState: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-FollowerState: change to CANDIDATE, lastRpcTime:5126ms, electionTimeout:5073ms
datanode_2_1  | 2020-07-09 12:58:39,854 [Thread-23] INFO impl.RoleInfo: 5b661712-7375-48d1-a708-209005b3fd5d: shutdown FollowerState
datanode_2_1  | 2020-07-09 12:58:39,854 [Thread-23] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-07-09 12:58:39,857 [Thread-23] INFO impl.RoleInfo: 5b661712-7375-48d1-a708-209005b3fd5d: start LeaderElection
datanode_2_1  | 2020-07-09 12:58:39,861 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO impl.LeaderElection: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1: begin an election at term 1 for -1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-09 12:58:39,862 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO impl.RoleInfo: 5b661712-7375-48d1-a708-209005b3fd5d: shutdown LeaderElection
datanode_2_1  | 2020-07-09 12:58:39,863 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-07-09 12:58:39,863 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-401162C631B8 with new leaderId: 5b661712-7375-48d1-a708-209005b3fd5d
datanode_2_1  | 2020-07-09 12:58:39,865 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8: change Leader from null to 5b661712-7375-48d1-a708-209005b3fd5d at term 1 for becomeLeader, leader elected after 5891ms
datanode_2_1  | 2020-07-09 12:58:39,886 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-07-09 12:58:39,886 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-07-09 12:58:39,888 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8
datanode_2_1  | 2020-07-09 12:58:39,898 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-09 12:58:39,913 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-07-09 12:58:39,927 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-07-09 12:58:39,927 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-07-09 12:58:39,928 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-07-09 12:58:39,949 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO impl.RoleInfo: 5b661712-7375-48d1-a708-209005b3fd5d: start LeaderState
datanode_2_1  | 2020-07-09 12:58:40,070 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-07-09 12:58:40,187 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-LeaderElection1] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8: set configuration 0: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-07-09 12:58:40,293 [grpc-default-executor-0] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:92033663-29ab-425f-a545-52cd3236f459
datanode_2_1  | 2020-07-09 12:58:40,294 [grpc-default-executor-0] INFO impl.RoleInfo: 5b661712-7375-48d1-a708-209005b3fd5d: shutdown FollowerState
datanode_2_1  | 2020-07-09 12:58:40,294 [grpc-default-executor-0] INFO impl.RoleInfo: 5b661712-7375-48d1-a708-209005b3fd5d: start FollowerState
datanode_2_1  | 2020-07-09 12:58:40,294 [Thread-25] INFO impl.FollowerState: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 2020-07-09 12:58:40,559 [5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5b661712-7375-48d1-a708-209005b3fd5d@group-401162C631B8-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/1aae0153-d0b5-46a8-8e3b-401162c631b8/current/log_inprogress_0
datanode_2_1  | 2020-07-09 12:58:40,754 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A8F191A5483B with new leaderId: 92033663-29ab-425f-a545-52cd3236f459
datanode_2_1  | 2020-07-09 12:58:40,754 [grpc-default-executor-0] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B: change Leader from null to 92033663-29ab-425f-a545-52cd3236f459 at term 1 for appendEntries, leader elected after 5406ms
datanode_2_1  | 2020-07-09 12:58:40,779 [grpc-default-executor-0] INFO impl.RaftServerImpl: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B: set configuration 0: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null at 0
datanode_2_1  | 2020-07-09 12:58:40,790 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-07-09 12:58:40,799 [5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5b661712-7375-48d1-a708-209005b3fd5d@group-A8F191A5483B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b/current/log_inprogress_0
datanode_1_1  | 2020-07-09 12:58:34,466 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637
datanode_1_1  | 2020-07-09 12:58:34,528 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-09 12:58:34,661 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0e9bdad4-4bd2-44e0-8a8f-17b618627637
datanode_1_1  | 2020-07-09 12:58:34,662 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-07-09 12:58:34,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-09 12:58:34,671 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-09 12:58:34,673 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-07-09 12:58:34,697 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-09 12:58:34,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-07-09 12:58:34,703 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-07-09 12:58:34,714 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-07-09 12:58:34,715 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-07-09 12:58:34,914 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-07-09 12:58:35,035 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-09 12:58:35,039 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-09 12:58:35,051 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-07-09 12:58:35,067 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-07-09 12:58:35,067 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-07-09 12:58:35,068 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-07-09 12:58:35,068 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-07-09 12:58:35,224 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637
datanode_1_1  | 2020-07-09 12:58:35,293 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637
datanode_1_1  | 2020-07-09 12:58:35,344 [pool-19-thread-1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637: start as a follower, conf=-1: [27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858], old=null
datanode_1_1  | 2020-07-09 12:58:35,350 [pool-19-thread-1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-07-09 12:58:35,370 [pool-19-thread-1] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: start FollowerState
datanode_1_1  | 2020-07-09 12:58:35,540 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-17B618627637,id=27bef0a1-05cf-4615-b519-87864850b753
datanode_1_1  | 2020-07-09 12:58:35,542 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637
datanode_1_1  | 2020-07-09 12:58:35,663 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "0e9bdad4-4bd2-44e0-8a8f-17b618627637"
datanode_1_1  | uuid128 {
datanode_1_1  |   mostSigBits: 1052675543261136096
datanode_1_1  |   leastSigBits: -8462519103945279945
datanode_1_1  | }
datanode_1_1  | .
datanode_1_1  | 2020-07-09 12:58:35,670 [Command processor thread] INFO impl.RaftServerProxy: 27bef0a1-05cf-4615-b519-87864850b753: addNew group-72AA12A76166:[244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858] returns group-72AA12A76166:java.util.concurrent.CompletableFuture@70bdd893[Not completed]
datanode_1_1  | 2020-07-09 12:58:35,672 [pool-19-thread-1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753: new RaftServerImpl for group-72AA12A76166:[244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-07-09 12:58:35,697 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-07-09 12:58:35,697 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-07-09 12:58:35,698 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-07-09 12:58:35,698 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-07-09 12:58:35,698 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-07-09 12:58:35,699 [pool-19-thread-1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166: ConfigurationManager, init=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-07-09 12:58:35,705 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-09 12:58:35,705 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-07-09 12:58:35,709 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166 does not exist. Creating ...
datanode_1_1  | 2020-07-09 12:58:35,735 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166/in_use.lock acquired by nodename 6@ac703be53cac
datanode_1_1  | 2020-07-09 12:58:35,741 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166 has been successfully formatted.
datanode_1_1  | 2020-07-09 12:58:35,743 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-72AA12A76166: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-07-09 12:58:35,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-07-09 12:58:35,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-07-09 12:58:35,744 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-07-09 12:58:14,390 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = 82da7d7760e8/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | 2020-07-09 12:58:35,744 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-09 12:58:35,744 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-09 12:58:35,744 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166
datanode_1_1  | 2020-07-09 12:58:35,744 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-09 12:58:35,745 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166
datanode_1_1  | 2020-07-09 12:58:35,749 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-07-09 12:58:35,753 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-09 12:58:35,753 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-09 12:58:35,757 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-07-09 12:58:35,757 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-09 12:58:35,757 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-07-09 12:58:35,757 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-07-09 12:58:35,758 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-07-09 12:58:35,758 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-07-09 12:58:35,758 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-07-09 12:58:35,762 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-09 12:58:35,762 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-09 12:58:35,780 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-07-09 12:58:35,780 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-07-09 12:58:35,780 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-07-09 12:58:35,780 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-07-09 12:58:35,780 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-07-09 12:58:35,780 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166
datanode_1_1  | 2020-07-09 12:58:35,781 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166
datanode_1_1  | 2020-07-09 12:58:35,789 [pool-19-thread-1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166: start as a follower, conf=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null
datanode_1_1  | 2020-07-09 12:58:35,789 [pool-19-thread-1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-07-09 12:58:35,789 [pool-19-thread-1] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: start FollowerState
datanode_1_1  | 2020-07-09 12:58:35,792 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-72AA12A76166,id=27bef0a1-05cf-4615-b519-87864850b753
datanode_1_1  | 2020-07-09 12:58:35,792 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166
datanode_1_1  | 2020-07-09 12:58:40,383 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "77944dd0-83a5-418c-9111-72aa12a76166"
datanode_1_1  | uuid128 {
datanode_1_1  |   mostSigBits: 8616597545023783308
datanode_1_1  |   leastSigBits: -7993481788822953626
datanode_1_1  | }
datanode_1_1  | .
datanode_1_1  | 2020-07-09 12:58:40,529 [Thread-23] INFO impl.FollowerState: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-FollowerState: change to CANDIDATE, lastRpcTime:5159ms, electionTimeout:5033ms
datanode_1_1  | 2020-07-09 12:58:40,531 [Thread-23] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: shutdown FollowerState
datanode_1_1  | 2020-07-09 12:58:40,531 [Thread-23] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-07-09 12:58:40,533 [Thread-23] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: start LeaderElection
datanode_1_1  | 2020-07-09 12:58:40,553 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO impl.LeaderElection: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1: begin an election at term 1 for -1: [27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858], old=null
datanode_1_1  | 2020-07-09 12:58:40,554 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: shutdown LeaderElection
datanode_1_1  | 2020-07-09 12:58:40,555 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-07-09 12:58:40,555 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-17B618627637 with new leaderId: 27bef0a1-05cf-4615-b519-87864850b753
datanode_1_1  | 2020-07-09 12:58:40,556 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637: change Leader from null to 27bef0a1-05cf-4615-b519-87864850b753 at term 1 for becomeLeader, leader elected after 6243ms
datanode_1_1  | 2020-07-09 12:58:40,587 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-07-09 12:58:40,596 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-07-09 12:58:40,617 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637
datanode_1_1  | 2020-07-09 12:58:40,639 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-09 12:58:40,639 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-07-09 12:58:40,664 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-07-09 12:58:40,697 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-07-09 12:58:40,699 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-07-09 12:58:40,718 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: start LeaderState
datanode_1_1  | 2020-07-09 12:58:40,801 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-07-09 12:58:40,881 [Thread-25] INFO impl.FollowerState: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-FollowerState: change to CANDIDATE, lastRpcTime:5091ms, electionTimeout:5075ms
datanode_1_1  | 2020-07-09 12:58:40,882 [Thread-25] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: shutdown FollowerState
datanode_1_1  | 2020-07-09 12:58:40,882 [Thread-25] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-07-09 12:58:40,882 [Thread-25] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: start LeaderElection
datanode_1_1  | 2020-07-09 12:58:40,969 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-LeaderElection1] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637: set configuration 0: [27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-07-09 12:58:40,955 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO impl.LeaderElection: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2: begin an election at term 1 for -1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null
datanode_1_1  | 2020-07-09 12:58:41,274 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO impl.LeaderElection: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2: Election PASSED; received 1 response(s) [27bef0a1-05cf-4615-b519-87864850b753<-244a4af8-fd38-45a2-a163-d1fbc0b9f246#0:OK-t1] and 0 exception(s); 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166:t1, leader=null, voted=27bef0a1-05cf-4615-b519-87864850b753, raftlog=27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null
datanode_1_1  | 2020-07-09 12:58:41,282 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: shutdown LeaderElection
datanode_1_1  | 2020-07-09 12:58:41,289 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-07-09 12:58:41,318 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-72AA12A76166 with new leaderId: 27bef0a1-05cf-4615-b519-87864850b753
datanode_1_1  | 2020-07-09 12:58:41,326 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166: change Leader from null to 27bef0a1-05cf-4615-b519-87864850b753 at term 1 for becomeLeader, leader elected after 5574ms
datanode_1_1  | 2020-07-09 12:58:41,326 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-07-09 12:58:41,327 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-07-09 12:58:41,327 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166
datanode_1_1  | 2020-07-09 12:58:41,327 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-09 12:58:41,327 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-07-09 12:58:41,328 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-07-09 12:58:41,328 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-07-09 12:58:41,328 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-07-09 12:58:41,350 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1_1  | 2020-07-09 12:58:41,350 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-09 12:58:41,350 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1_1  | 2020-07-09 12:58:41,353 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-07-09 12:58:41,363 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-07-09 12:58:41,363 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-07-09 12:58:41,366 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166
datanode_1_1  | 2020-07-09 12:58:41,404 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1_1  | 2020-07-09 12:58:41,404 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-09 12:58:41,405 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1_1  | 2020-07-09 12:58:41,405 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-07-09 12:58:41,405 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-07-09 12:58:41,405 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-07-09 12:58:41,406 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO impl.RoleInfo: 27bef0a1-05cf-4615-b519-87864850b753: start LeaderState
datanode_1_1  | 2020-07-09 12:58:41,429 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-07-09 12:58:41,434 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-LeaderElection2] INFO impl.RaftServerImpl: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166: set configuration 0: [244a4af8-fd38-45a2-a163-d1fbc0b9f246:10.5.0.6:9858, 27bef0a1-05cf-4615-b519-87864850b753:10.5.0.4:9858, 8daff4b0-5959-4951-b3a1-58b111d6a2a7:10.5.0.7:9858], old=null at 0
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-07-09 12:58:14,516 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-07-09 12:58:15,640 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-09 12:58:15,995 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-6a1e266b-b522-4082-8503-f8c18ec7fa4a;layoutVersion=0
scm_1         | 2020-07-09 12:58:16,165 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at 82da7d7760e8/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-07-09 12:58:25,861 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = 82da7d7760e8/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-07-09 12:58:25,880 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-07-09 12:58:26,017 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-09 12:58:26,214 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-09 12:58:26,361 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@46cc127b
scm_1         | 2020-07-09 12:58:26,362 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-07-09 12:58:26,670 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-07-09 12:58:27,017 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-07-09 12:58:27,167 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-07-09 12:58:27,332 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-07-09 12:58:27,334 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-07-09 12:58:27,388 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1         | 2020-07-09 12:58:27,887 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-09 12:58:27,905 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-07-09 12:58:27,976 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-09 12:58:27,977 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-07-09 12:58:27,996 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-09 12:58:27,996 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-07-09 12:58:28,019 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-07-09 12:58:28,019 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1         | 2020-07-09 12:58:28,055 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @9829ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-07-09 12:58:28,141 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-07-09 12:58:28,160 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-07-09 12:58:28,168 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-07-09 12:58:28,174 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1         | 2020-07-09 12:58:28,174 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2020-07-09 12:58:28,174 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2020-07-09 12:58:28,222 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-07-09 12:58:28,241 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-07-09 12:58:28,361 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-07-09 12:58:28,418 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-07-09 12:58:28,418 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-07-09 12:58:28,706 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-07-09 12:58:28,708 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-07-09 12:58:28,709 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-07-09 12:58:28,767 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-07-09 12:58:28,770 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-07-09 12:58:28,770 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-07-09 12:58:07,817 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = 7f928d5fb79b/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | 2020-07-09 13:00:32,576 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=73,entriesCount=1,lastEntry=(t:1, i:53)
datanode_5_1  | 2020-07-09 13:00:32,591 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=74,entriesCount=1,lastEntry=(t:1, i:54)
datanode_5_1  | 2020-07-09 13:00:32,604 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:55)
datanode_5_1  | 2020-07-09 13:00:32,616 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:56)
datanode_5_1  | 2020-07-09 13:00:35,403 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=78,entriesCount=1,lastEntry=(t:1, i:57)
datanode_5_1  | 2020-07-09 13:00:35,413 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:58)
datanode_5_1  | 2020-07-09 13:00:35,418 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:59)
datanode_5_1  | 2020-07-09 13:00:35,428 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:60)
datanode_5_1  | 2020-07-09 13:00:37,963 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:61)
datanode_5_1  | 2020-07-09 13:00:37,974 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:62)
datanode_5_1  | 2020-07-09 13:00:37,980 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:63)
datanode_5_1  | 2020-07-09 13:00:37,987 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:64)
datanode_5_1  | 2020-07-09 13:00:40,598 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=88,entriesCount=1,lastEntry=(t:1, i:65)
datanode_5_1  | 2020-07-09 13:00:40,609 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:66)
datanode_5_1  | 2020-07-09 13:00:40,611 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:67)
datanode_5_1  | 2020-07-09 13:00:40,625 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:68)
datanode_5_1  | 2020-07-09 13:00:43,352 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=93,entriesCount=1,lastEntry=(t:1, i:69)
datanode_5_1  | 2020-07-09 13:00:43,362 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:70)
datanode_5_1  | 2020-07-09 13:00:43,371 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:71)
datanode_5_1  | 2020-07-09 13:00:43,378 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:72)
datanode_5_1  | 2020-07-09 13:00:46,336 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:73)
datanode_5_1  | 2020-07-09 13:00:46,346 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:74)
scm_1         | 2020-07-09 12:58:28,771 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-07-09 12:58:28,828 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-07-09 12:58:28,828 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1         | 2020-07-09 12:58:28,834 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-07-09 12:58:28,853 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1         | 2020-07-09 12:58:28,871 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-07-09 12:58:28,883 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1         | 2020-07-09 12:58:29,035 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-07-09 12:58:29,037 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-07-09 12:58:29,041 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1         | 2020-07-09 12:58:29,081 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5e193ef5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2020-07-09 12:58:29,085 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79ca7bea{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2020-07-09 12:58:29,300 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.4:43074: output error
scm_1         | 2020-07-09 12:58:29,301 [IPC Server handler 3 on default port 9861] WARN ipc.Server: IPC Server handler 3 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:47450: output error
scm_1         | 2020-07-09 12:58:29,302 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-09 12:58:29,302 [IPC Server handler 3 on default port 9861] INFO ipc.Server: IPC Server handler 3 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-09 12:58:29,328 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:39408: output error
scm_1         | 2020-07-09 12:58:29,330 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-09 12:58:29,329 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.5:54316: output error
scm_1         | 2020-07-09 12:58:29,345 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_5_1  | 2020-07-09 13:00:46,350 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:75)
datanode_5_1  | 2020-07-09 13:00:46,375 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:76)
datanode_5_1  | 2020-07-09 13:00:48,908 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:77)
datanode_5_1  | 2020-07-09 13:00:48,917 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:78)
datanode_5_1  | 2020-07-09 13:00:48,927 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:79)
datanode_5_1  | 2020-07-09 13:00:48,927 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=106,entriesCount=1,lastEntry=(t:1, i:80)
datanode_5_1  | 2020-07-09 13:00:51,449 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=108,entriesCount=1,lastEntry=(t:1, i:81)
datanode_5_1  | 2020-07-09 13:00:51,457 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:82)
datanode_5_1  | 2020-07-09 13:00:51,459 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:83)
datanode_5_1  | 2020-07-09 13:00:51,476 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:84)
datanode_5_1  | 2020-07-09 13:00:54,242 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:85)
datanode_5_1  | 2020-07-09 13:00:54,255 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:86)
datanode_5_1  | 2020-07-09 13:00:54,266 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=115,entriesCount=1,lastEntry=(t:1, i:87)
datanode_5_1  | 2020-07-09 13:00:54,277 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=116,entriesCount=1,lastEntry=(t:1, i:88)
datanode_5_1  | 2020-07-09 13:00:56,819 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=118,entriesCount=1,lastEntry=(t:1, i:89)
datanode_5_1  | 2020-07-09 13:00:56,831 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:90)
datanode_5_1  | 2020-07-09 13:00:56,868 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:91)
datanode_5_1  | 2020-07-09 13:00:59,397 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:92)
datanode_5_1  | 2020-07-09 13:00:59,406 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=123,entriesCount=1,lastEntry=(t:1, i:93)
datanode_5_1  | 2020-07-09 13:00:59,422 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:94)
datanode_5_1  | 2020-07-09 13:00:59,433 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:95)
datanode_5_1  | 2020-07-09 13:01:01,976 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:96)
datanode_5_1  | 2020-07-09 13:01:01,987 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=128,entriesCount=1,lastEntry=(t:1, i:97)
datanode_1_1  | 2020-07-09 12:58:41,469 [27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 27bef0a1-05cf-4615-b519-87864850b753@group-17B618627637-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0e9bdad4-4bd2-44e0-8a8f-17b618627637/current/log_inprogress_0
datanode_1_1  | 2020-07-09 12:58:41,469 [27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 27bef0a1-05cf-4615-b519-87864850b753@group-72AA12A76166-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/77944dd0-83a5-418c-9111-72aa12a76166/current/log_inprogress_0
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/f7a0d0746fa18ca39b893f499c4ef57da137858c ; compiled by 'runner' on 2020-07-09T12:35Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-07-09 12:58:07,896 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-07-09 12:58:09,511 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-07-09 12:58:10,382 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-07-09 12:58:11,265 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-07-09 12:58:11,265 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-07-09 12:58:11,921 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:7f928d5fb79b ip:10.5.0.9
datanode_6_1  | 2020-07-09 12:58:12,928 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-07-09 12:58:12,989 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-07-09 12:58:13,025 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-07-09 12:58:13,098 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-07-09 12:58:13,330 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-07-09 12:58:19,331 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-07-09 12:58:19,625 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-07-09 12:58:20,457 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-07-09 12:58:20,457 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-07-09 12:58:20,463 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-09 12:58:20,466 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-07-09 12:58:20,467 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-07-09 12:58:21,808 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-09 12:58:22,778 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-07-09 12:58:22,873 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 2020-07-09 12:58:22,981 [main] INFO util.log: Logging initialized @22154ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-07-09 12:58:23,458 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-07-09 12:58:23,478 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-07-09 12:58:23,517 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-07-09 12:58:23,526 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_6_1  | 2020-07-09 12:58:23,526 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 2020-07-09 12:58:23,529 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 2020-07-09 12:58:23,643 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-07-09 12:58:23,686 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-07-09 12:58:23,692 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-07-09 12:58:23,896 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-07-09 12:58:23,914 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-07-09 12:58:23,918 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_6_1  | 2020-07-09 12:58:23,984 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@67e6eb52{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-07-09 12:58:23,987 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b98225c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-07-09 12:58:24,346 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1ba35152{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-1479210278507704957.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-07-09 12:58:24,377 [main] INFO server.AbstractConnector: Started ServerConnector@76b305e1{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-07-09 12:58:24,379 [main] INFO server.Server: Started @23553ms
datanode_6_1  | 2020-07-09 12:58:24,433 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-07-09 12:58:24,433 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-07-09 12:58:24,447 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-07-09 12:58:24,546 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f2cc290] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-07-09 12:58:25,183 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-07-09 12:58:27,731 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-09 12:58:28,733 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-09 12:58:29,591 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-07-09 12:58:29,611 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-07-09 12:58:29,618 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d at port 9858
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-09 12:58:29,443 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7433ca19{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-15523979339053806730.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1         | 2020-07-09 12:58:29,947 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4faf1f4{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1         | 2020-07-09 12:58:29,947 [Listener at 0.0.0.0/9860] INFO server.Server: Started @11721ms
scm_1         | 2020-07-09 12:58:30,000 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2020-07-09 12:58:30,000 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2020-07-09 12:58:30,018 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1         | 2020-07-09 12:58:30,114 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@586728e8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2020-07-09 12:58:30,750 [IPC Server handler 10 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/92033663-29ab-425f-a545-52cd3236f459
scm_1         | 2020-07-09 12:58:30,751 [IPC Server handler 10 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 92033663-29ab-425f-a545-52cd3236f459{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-09 12:58:30,808 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:30,805 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d
scm_1         | 2020-07-09 12:58:30,866 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-09 12:58:30,871 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:30,826 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
scm_1         | 2020-07-09 12:58:30,878 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
scm_1         | 2020-07-09 12:58:30,958 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c2a94176-be9a-46f8-b1e9-6a0810216920 to datanode:92033663-29ab-425f-a545-52cd3236f459
scm_1         | 2020-07-09 12:58:30,849 [IPC Server handler 12 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/5b661712-7375-48d1-a708-209005b3fd5d
scm_1         | 2020-07-09 12:58:31,006 [IPC Server handler 12 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 5b661712-7375-48d1-a708-209005b3fd5d{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-09 12:58:31,006 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:31,061 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
scm_1         | 2020-07-09 12:58:31,071 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/27bef0a1-05cf-4615-b519-87864850b753
scm_1         | 2020-07-09 12:58:31,080 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 27bef0a1-05cf-4615-b519-87864850b753{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-09 12:58:31,089 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:31,097 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
scm_1         | 2020-07-09 12:58:31,173 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:31,173 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1         | 2020-07-09 12:58:31,292 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c2a94176-be9a-46f8-b1e9-6a0810216920, Nodes: 92033663-29ab-425f-a545-52cd3236f459{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-09T12:58:30.924760Z]
scm_1         | 2020-07-09 12:58:31,508 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=1aae0153-d0b5-46a8-8e3b-401162c631b8 to datanode:5b661712-7375-48d1-a708-209005b3fd5d
scm_1         | 2020-07-09 12:58:31,546 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 1aae0153-d0b5-46a8-8e3b-401162c631b8, Nodes: 5b661712-7375-48d1-a708-209005b3fd5d{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-09T12:58:31.508047Z]
scm_1         | 2020-07-09 12:58:31,547 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e to datanode:933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d
scm_1         | 2020-07-09 12:58:31,554 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e, Nodes: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-09T12:58:31.547335Z]
scm_1         | 2020-07-09 12:58:31,557 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0e9bdad4-4bd2-44e0-8a8f-17b618627637 to datanode:27bef0a1-05cf-4615-b519-87864850b753
datanode_6_1  | 2020-07-09 12:58:29,705 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: start RPC server
datanode_6_1  | 2020-07-09 12:58:29,967 [Datanode State Machine Thread - 0] INFO server.GrpcService: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-07-09 12:58:33,734 [Command processor thread] INFO impl.RaftServerProxy: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: addNew group-CE7E265C7B6E:[933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858] returns group-CE7E265C7B6E:java.util.concurrent.CompletableFuture@591d2b07[Not completed]
datanode_6_1  | 2020-07-09 12:58:33,841 [pool-19-thread-1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: new RaftServerImpl for group-CE7E265C7B6E:[933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-07-09 12:58:33,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-07-09 12:58:33,894 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-07-09 12:58:33,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-07-09 12:58:33,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-09 12:58:33,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-09 12:58:33,924 [pool-19-thread-1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E: ConfigurationManager, init=-1: [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-07-09 12:58:33,929 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-09 12:58:33,932 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-07-09 12:58:33,978 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e does not exist. Creating ...
datanode_6_1  | 2020-07-09 12:58:33,993 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e/in_use.lock acquired by nodename 6@7f928d5fb79b
datanode_6_1  | 2020-07-09 12:58:34,006 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e has been successfully formatted.
datanode_6_1  | 2020-07-09 12:58:34,090 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-CE7E265C7B6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-07-09 12:58:34,091 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-07-09 12:58:34,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-07-09 12:58:34,144 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-07-09 12:58:34,189 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-09 12:58:34,197 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-09 12:58:34,223 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E
datanode_6_1  | 2020-07-09 12:58:34,309 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-07-09 12:58:34,336 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e
datanode_6_1  | 2020-07-09 12:58:34,336 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-07-09 12:58:34,337 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-09 12:58:34,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-09 12:58:34,377 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-09 12:58:34,385 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-07-09 12:58:34,386 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-07-09 12:58:34,405 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-09 12:58:34,405 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-07-09 12:58:34,406 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-07-09 12:58:34,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-07-09 12:58:34,574 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-09 12:58:34,580 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-09 12:58:34,634 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-07-09 12:58:34,658 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-09 12:58:34,684 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-07-09 12:58:34,686 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-07-09 12:58:34,687 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-07-09 12:58:35,045 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E
datanode_6_1  | 2020-07-09 12:58:35,088 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E
datanode_6_1  | 2020-07-09 12:58:35,182 [pool-19-thread-1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E: start as a follower, conf=-1: [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858], old=null
datanode_6_1  | 2020-07-09 12:58:35,223 [pool-19-thread-1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-07-09 12:58:35,238 [pool-19-thread-1] INFO impl.RoleInfo: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: start FollowerState
datanode_6_1  | 2020-07-09 12:58:35,317 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE7E265C7B6E,id=933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d
datanode_6_1  | 2020-07-09 12:58:35,322 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E
datanode_5_1  | 2020-07-09 13:01:01,989 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=129,entriesCount=1,lastEntry=(t:1, i:98)
datanode_5_1  | 2020-07-09 13:01:02,000 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=130,entriesCount=1,lastEntry=(t:1, i:99)
datanode_5_1  | 2020-07-09 13:01:09,922 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:100)
datanode_5_1  | 2020-07-09 13:01:09,929 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:101)
datanode_5_1  | 2020-07-09 13:01:09,933 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=136,entriesCount=1,lastEntry=(t:1, i:102)
datanode_5_1  | 2020-07-09 13:01:09,944 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:103)
datanode_5_1  | 2020-07-09 13:01:12,541 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:104)
datanode_5_1  | 2020-07-09 13:01:12,546 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:105)
datanode_5_1  | 2020-07-09 13:01:12,551 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=141,entriesCount=1,lastEntry=(t:1, i:106)
datanode_5_1  | 2020-07-09 13:01:12,556 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=142,entriesCount=1,lastEntry=(t:1, i:107)
datanode_5_1  | 2020-07-09 13:01:15,081 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:108)
datanode_5_1  | 2020-07-09 13:01:15,089 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:109)
datanode_5_1  | 2020-07-09 13:01:15,101 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=146,entriesCount=1,lastEntry=(t:1, i:110)
datanode_5_1  | 2020-07-09 13:01:15,106 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:111)
datanode_5_1  | 2020-07-09 13:01:17,638 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:112)
datanode_5_1  | 2020-07-09 13:01:17,644 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:113)
datanode_5_1  | 2020-07-09 13:01:17,646 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=151,entriesCount=1,lastEntry=(t:1, i:114)
datanode_5_1  | 2020-07-09 13:01:17,666 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=152,entriesCount=1,lastEntry=(t:1, i:115)
datanode_5_1  | 2020-07-09 13:01:20,269 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:116)
datanode_5_1  | 2020-07-09 13:01:20,274 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:117)
datanode_5_1  | 2020-07-09 13:01:20,281 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=156,entriesCount=1,lastEntry=(t:1, i:118)
datanode_5_1  | 2020-07-09 13:01:22,879 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:119)
datanode_5_1  | 2020-07-09 13:01:22,887 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=159,entriesCount=1,lastEntry=(t:1, i:120)
datanode_5_1  | 2020-07-09 13:01:22,893 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:121)
datanode_5_1  | 2020-07-09 13:01:22,905 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=161,entriesCount=1,lastEntry=(t:1, i:122)
datanode_5_1  | 2020-07-09 13:01:25,429 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:123)
datanode_5_1  | 2020-07-09 13:01:25,435 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=164,entriesCount=1,lastEntry=(t:1, i:124)
datanode_5_1  | 2020-07-09 13:01:25,441 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=165,entriesCount=1,lastEntry=(t:1, i:125)
datanode_5_1  | 2020-07-09 13:01:25,449 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=166,entriesCount=1,lastEntry=(t:1, i:126)
datanode_5_1  | 2020-07-09 13:01:28,103 [java.util.concurrent.ThreadPoolExecutor$Worker@139ac242[State = -1, empty queue]] WARN server.GrpcLogAppender: 92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B->5b661712-7375-48d1-a708-209005b3fd5d-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:127)
datanode_5_1  | 2020-07-09 13:03:28,529 [Thread-199] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-653CE482696C->92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B, cid=221, seq=0, Watch-ALL_COMMITTED(128), Message:<EMPTY>, reply=RaftClientReply:client-653CE482696C->92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B, cid=221, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 221 and log index 128 is not yet replicated to ALL_COMMITTED, logIndex=128, commits[92033663-29ab-425f-a545-52cd3236f459:c171, 5b661712-7375-48d1-a708-209005b3fd5d:c127, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:c171]
datanode_5_1  | 2020-07-09 13:03:43,527 [Thread-207] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-0A88859D0E75->92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B, cid=226, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-0A88859D0E75->92033663-29ab-425f-a545-52cd3236f459@group-A8F191A5483B, cid=226, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 226 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[92033663-29ab-425f-a545-52cd3236f459:c175, 5b661712-7375-48d1-a708-209005b3fd5d:c127, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:c175]
scm_1         | 2020-07-09 12:58:31,573 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0e9bdad4-4bd2-44e0-8a8f-17b618627637, Nodes: 27bef0a1-05cf-4615-b519-87864850b753{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-09T12:58:31.557108Z]
scm_1         | 2020-07-09 12:58:31,575 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 4 nodes. Healthy nodes 4
scm_1         | 2020-07-09 12:58:31,635 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2bd839a3-0596-42cf-9c72-a8f191a5483b to datanode:92033663-29ab-425f-a545-52cd3236f459
scm_1         | 2020-07-09 12:58:31,665 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2bd839a3-0596-42cf-9c72-a8f191a5483b to datanode:5b661712-7375-48d1-a708-209005b3fd5d
scm_1         | 2020-07-09 12:58:31,666 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2bd839a3-0596-42cf-9c72-a8f191a5483b to datanode:933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d
scm_1         | 2020-07-09 12:58:31,666 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2bd839a3-0596-42cf-9c72-a8f191a5483b, Nodes: 92033663-29ab-425f-a545-52cd3236f459{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}5b661712-7375-48d1-a708-209005b3fd5d{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-09T12:58:31.635087Z]
scm_1         | 2020-07-09 12:58:31,667 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 1
scm_1         | 2020-07-09 12:58:31,675 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/244a4af8-fd38-45a2-a163-d1fbc0b9f246
scm_1         | 2020-07-09 12:58:31,681 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 244a4af8-fd38-45a2-a163-d1fbc0b9f246{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-09 12:58:31,693 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:31,693 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:31,701 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=901c3569-661a-498d-99db-8e9927188952 to datanode:244a4af8-fd38-45a2-a163-d1fbc0b9f246
scm_1         | 2020-07-09 12:58:31,701 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 901c3569-661a-498d-99db-8e9927188952, Nodes: 244a4af8-fd38-45a2-a163-d1fbc0b9f246{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-09T12:58:31.701155Z]
scm_1         | 2020-07-09 12:58:31,702 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
scm_1         | 2020-07-09 12:58:31,707 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 2
scm_1         | 2020-07-09 12:58:31,953 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/8daff4b0-5959-4951-b3a1-58b111d6a2a7
scm_1         | 2020-07-09 12:58:31,954 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8daff4b0-5959-4951-b3a1-58b111d6a2a7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-09 12:58:31,958 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:31,954 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=bd5a4449-6575-4b77-94d7-3d3e5264121e to datanode:8daff4b0-5959-4951-b3a1-58b111d6a2a7
scm_1         | 2020-07-09 12:58:31,961 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:31,962 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: bd5a4449-6575-4b77-94d7-3d3e5264121e, Nodes: 8daff4b0-5959-4951-b3a1-58b111d6a2a7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-09T12:58:31.954598Z]
scm_1         | 2020-07-09 12:58:31,963 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-09 12:58:31,966 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=77944dd0-83a5-418c-9111-72aa12a76166 to datanode:8daff4b0-5959-4951-b3a1-58b111d6a2a7
scm_1         | 2020-07-09 12:58:31,972 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=77944dd0-83a5-418c-9111-72aa12a76166 to datanode:27bef0a1-05cf-4615-b519-87864850b753
scm_1         | 2020-07-09 12:58:31,973 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=77944dd0-83a5-418c-9111-72aa12a76166 to datanode:244a4af8-fd38-45a2-a163-d1fbc0b9f246
scm_1         | 2020-07-09 12:58:31,973 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 77944dd0-83a5-418c-9111-72aa12a76166, Nodes: 8daff4b0-5959-4951-b3a1-58b111d6a2a7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}27bef0a1-05cf-4615-b519-87864850b753{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}244a4af8-fd38-45a2-a163-d1fbc0b9f246{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-09T12:58:31.966745Z]
scm_1         | 2020-07-09 12:58:31,974 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-09 12:58:34,454 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c2a94176-be9a-46f8-b1e9-6a0810216920, Nodes: 92033663-29ab-425f-a545-52cd3236f459{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:92033663-29ab-425f-a545-52cd3236f459, CreationTimestamp2020-07-09T12:58:30.924760Z] moved to OPEN state
scm_1         | 2020-07-09 12:58:34,460 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-09 12:58:34,469 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-09 12:58:34,970 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 1aae0153-d0b5-46a8-8e3b-401162c631b8, Nodes: 5b661712-7375-48d1-a708-209005b3fd5d{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:5b661712-7375-48d1-a708-209005b3fd5d, CreationTimestamp2020-07-09T12:58:31.508047Z] moved to OPEN state
scm_1         | 2020-07-09 12:58:34,971 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-09 12:58:34,977 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-09 12:58:35,122 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e, Nodes: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d, CreationTimestamp2020-07-09T12:58:31.547335Z] moved to OPEN state
scm_1         | 2020-07-09 12:58:35,123 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-09 12:58:35,123 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-09 12:58:35,609 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 0e9bdad4-4bd2-44e0-8a8f-17b618627637, Nodes: 27bef0a1-05cf-4615-b519-87864850b753{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:27bef0a1-05cf-4615-b519-87864850b753, CreationTimestamp2020-07-09T12:58:31.557108Z] moved to OPEN state
scm_1         | 2020-07-09 12:58:35,618 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-09 12:58:35,618 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-09 12:58:36,332 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 901c3569-661a-498d-99db-8e9927188952, Nodes: 244a4af8-fd38-45a2-a163-d1fbc0b9f246{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:244a4af8-fd38-45a2-a163-d1fbc0b9f246, CreationTimestamp2020-07-09T12:58:31.701155Z] moved to OPEN state
scm_1         | 2020-07-09 12:58:36,332 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-09 12:58:36,332 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-09 12:58:36,538 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: bd5a4449-6575-4b77-94d7-3d3e5264121e, Nodes: 8daff4b0-5959-4951-b3a1-58b111d6a2a7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:8daff4b0-5959-4951-b3a1-58b111d6a2a7, CreationTimestamp2020-07-09T12:58:31.954598Z] moved to OPEN state
scm_1         | 2020-07-09 12:58:36,539 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-09 12:58:36,539 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-09 12:58:40,274 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 2bd839a3-0596-42cf-9c72-a8f191a5483b, Nodes: 92033663-29ab-425f-a545-52cd3236f459{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}5b661712-7375-48d1-a708-209005b3fd5d{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:92033663-29ab-425f-a545-52cd3236f459, CreationTimestamp2020-07-09T12:58:31.635087Z] moved to OPEN state
scm_1         | 2020-07-09 12:58:40,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1         | 2020-07-09 12:58:40,275 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-09 12:58:40,276 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-07-09 12:58:40,276 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1         | 2020-07-09 12:58:40,276 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1         | 2020-07-09 12:58:41,370 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 77944dd0-83a5-418c-9111-72aa12a76166, Nodes: 8daff4b0-5959-4951-b3a1-58b111d6a2a7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}27bef0a1-05cf-4615-b519-87864850b753{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}244a4af8-fd38-45a2-a163-d1fbc0b9f246{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:27bef0a1-05cf-4615-b519-87864850b753, CreationTimestamp2020-07-09T12:58:31.966745Z] moved to OPEN state
scm_1         | 2020-07-09 12:58:54,404 [IPC Server handler 31 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:58:58,222 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:00,810 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:03,405 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:03,515 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:03,597 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:06,173 [IPC Server handler 31 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:06,249 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:06,324 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:06,432 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:08,987 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:11,564 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:14,133 [IPC Server handler 31 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:14,205 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:16,775 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:16,851 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:19,403 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:19,498 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:22,060 [IPC Server handler 31 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:22,142 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:24,705 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:24,795 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:24,871 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:27,444 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:30,011 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:32,569 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:35,137 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:35,242 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:35,339 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:35,391 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:37,951 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:40,517 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:40,584 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:43,151 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:43,224 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:43,287 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:43,341 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:45,902 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:45,965 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:46,038 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:46,097 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:46,193 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:46,246 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:46,333 [IPC Server handler 51 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:48,891 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:51,443 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:53,995 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:54,094 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:54,175 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:54,240 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:56,806 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 12:59:59,388 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:01,954 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:04,527 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:04,602 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:04,693 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:04,774 [IPC Server handler 58 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:07,304 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:09,857 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:09,910 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:12,459 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:12,529 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:15,074 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:17,653 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:20,193 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:20,261 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:22,801 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:22,858 [IPC Server handler 75 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:25,448 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:27,401 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-09 13:00:27,402 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-09 13:00:27,988 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:28,033 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:28,098 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:38,178 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:00:53,293 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:01:08,380 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:01:13,495 [IPC Server handler 55 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:01:23,635 [IPC Server handler 66 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:01:38,750 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:01:43,814 [IPC Server handler 75 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:01:43,868 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:01:53,995 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:02:09,090 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:02:14,135 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:02:24,213 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:02:27,403 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-09 13:02:27,403 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-09 13:02:39,323 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:02:54,424 [IPC Server handler 55 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:02:59,485 [IPC Server handler 66 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-09 12:58:35,411 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e"
datanode_6_1  | uuid128 {
datanode_6_1  |   mostSigBits: 2705856414948871071
datanode_6_1  |   leastSigBits: -5551585399436182674
datanode_6_1  | }
datanode_6_1  | .
datanode_6_1  | 2020-07-09 12:58:35,421 [Command processor thread] INFO impl.RaftServerProxy: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: addNew group-A8F191A5483B:[5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858] returns group-A8F191A5483B:java.util.concurrent.CompletableFuture@3f7600f2[Not completed]
datanode_6_1  | 2020-07-09 12:58:35,467 [pool-19-thread-1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: new RaftServerImpl for group-A8F191A5483B:[5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-07-09 12:58:35,470 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-07-09 12:58:35,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-07-09 12:58:35,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-07-09 12:58:35,474 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-09 12:58:35,474 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-09 12:58:35,474 [pool-19-thread-1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B: ConfigurationManager, init=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-07-09 12:58:35,477 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-09 12:58:35,478 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-07-09 12:58:35,485 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b does not exist. Creating ...
datanode_6_1  | 2020-07-09 12:58:35,493 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b/in_use.lock acquired by nodename 6@7f928d5fb79b
datanode_6_1  | 2020-07-09 12:58:35,500 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b has been successfully formatted.
datanode_6_1  | 2020-07-09 12:58:35,500 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A8F191A5483B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-07-09 12:58:35,540 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-07-09 12:58:35,541 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-07-09 12:58:35,542 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-07-09 12:58:35,546 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-09 12:58:35,546 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-09 12:58:35,547 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B
datanode_6_1  | 2020-07-09 12:58:35,549 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-07-09 12:58:35,549 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b
datanode_6_1  | 2020-07-09 12:58:35,555 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-07-09 12:58:35,560 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-09 12:58:35,561 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-09 12:58:35,561 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-09 12:58:35,565 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-07-09 12:58:35,572 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-07-09 12:58:35,576 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-09 12:58:35,576 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-07-09 12:58:35,577 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-07-09 12:58:35,579 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-07-09 12:58:35,613 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-09 12:58:35,613 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-09 12:58:35,614 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-07-09 12:58:35,614 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-09 12:58:35,617 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-07-09 12:58:35,617 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-07-09 12:58:35,618 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-07-09 12:58:35,621 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B
datanode_6_1  | 2020-07-09 12:58:35,622 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B
datanode_6_1  | 2020-07-09 12:58:35,625 [pool-19-thread-1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B: start as a follower, conf=-1: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null
datanode_6_1  | 2020-07-09 12:58:35,646 [pool-19-thread-1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1         | 2020-07-09 13:03:01,997 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:03:12,103 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:03:27,175 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:03:32,226 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-09 13:03:40,284 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1         | 2020-07-09 13:03:40,300 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5
scm_1         | 2020-07-09 13:03:40,303 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6
scm_1         | 2020-07-09 13:03:40,303 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 17 milliseconds for processing 11 containers.
scm_1         | 2020-07-09 13:03:40,305 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7
scm_1         | 2020-07-09 13:03:40,307 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8
scm_1         | 2020-07-09 13:03:40,308 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9
scm_1         | 2020-07-09 13:03:40,308 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #10
scm_1         | 2020-07-09 13:03:40,308 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #11
scm_1         | 2020-07-09 13:03:40,309 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1         | 2020-07-09 13:03:40,309 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
scm_1         | 2020-07-09 13:03:40,309 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3
scm_1         | 2020-07-09 13:03:40,309 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4
scm_1         | 2020-07-09 13:03:42,317 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-09 12:58:35,647 [pool-19-thread-1] INFO impl.RoleInfo: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: start FollowerState
datanode_6_1  | 2020-07-09 12:58:35,655 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A8F191A5483B,id=933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d
datanode_6_1  | 2020-07-09 12:58:35,664 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B
datanode_6_1  | 2020-07-09 12:58:38,841 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2bd839a3-0596-42cf-9c72-a8f191a5483b"
datanode_6_1  | uuid128 {
datanode_6_1  |   mostSigBits: 3159338510936589007
datanode_6_1  |   leastSigBits: -7173485500963665861
datanode_6_1  | }
datanode_6_1  | .
datanode_6_1  | 2020-07-09 12:58:40,239 [grpc-default-executor-0] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:92033663-29ab-425f-a545-52cd3236f459
datanode_6_1  | 2020-07-09 12:58:40,239 [grpc-default-executor-0] INFO impl.RoleInfo: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: shutdown FollowerState
datanode_6_1  | 2020-07-09 12:58:40,239 [grpc-default-executor-0] INFO impl.RoleInfo: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: start FollowerState
datanode_6_1  | 2020-07-09 12:58:40,239 [Thread-24] INFO impl.FollowerState: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 2020-07-09 12:58:40,418 [Thread-22] INFO impl.FollowerState: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-FollowerState: change to CANDIDATE, lastRpcTime:5180ms, electionTimeout:5172ms
datanode_6_1  | 2020-07-09 12:58:40,426 [Thread-22] INFO impl.RoleInfo: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: shutdown FollowerState
datanode_6_1  | 2020-07-09 12:58:40,426 [Thread-22] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-07-09 12:58:40,428 [Thread-22] INFO impl.RoleInfo: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: start LeaderElection
datanode_6_1  | 2020-07-09 12:58:40,474 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO impl.LeaderElection: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1: begin an election at term 1 for -1: [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858], old=null
datanode_6_1  | 2020-07-09 12:58:40,475 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO impl.RoleInfo: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: shutdown LeaderElection
datanode_6_1  | 2020-07-09 12:58:40,475 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-07-09 12:58:40,496 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CE7E265C7B6E with new leaderId: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d
datanode_6_1  | 2020-07-09 12:58:40,497 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E: change Leader from null to 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d at term 1 for becomeLeader, leader elected after 6406ms
datanode_6_1  | 2020-07-09 12:58:40,520 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-07-09 12:58:40,551 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-07-09 12:58:40,573 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E
datanode_6_1  | 2020-07-09 12:58:40,588 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-09 12:58:40,589 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-07-09 12:58:40,641 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-07-09 12:58:40,645 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-07-09 12:58:40,646 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-07-09 12:58:40,699 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO impl.RoleInfo: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d: start LeaderState
datanode_6_1  | 2020-07-09 12:58:40,784 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A8F191A5483B with new leaderId: 92033663-29ab-425f-a545-52cd3236f459
datanode_6_1  | 2020-07-09 12:58:40,801 [grpc-default-executor-0] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B: change Leader from null to 92033663-29ab-425f-a545-52cd3236f459 at term 1 for appendEntries, leader elected after 5283ms
datanode_6_1  | 2020-07-09 12:58:40,909 [grpc-default-executor-0] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B: set configuration 0: [5b661712-7375-48d1-a708-209005b3fd5d:10.5.0.5:9858, 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858, 92033663-29ab-425f-a545-52cd3236f459:10.5.0.8:9858], old=null at 0
datanode_6_1  | 2020-07-09 12:58:40,914 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-09 12:58:40,885 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-09 12:58:41,003 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-LeaderElection1] INFO impl.RaftServerImpl: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E: set configuration 0: [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-07-09 12:58:41,699 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-A8F191A5483B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2bd839a3-0596-42cf-9c72-a8f191a5483b/current/log_inprogress_0
datanode_6_1  | 2020-07-09 12:58:41,720 [933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 933b1a3c-1e3c-4fd8-9c66-d11e2611ae0d@group-CE7E265C7B6E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/258d2212-ba3d-4b9f-b2f4-ce7e265c7b6e/current/log_inprogress_0
