Attaching to ozone-topology_datanode_6_1, ozone-topology_datanode_3_1, ozone-topology_datanode_1_1, ozone-topology_scm_1, ozone-topology_datanode_2_1, ozone-topology_om_1, ozone-topology_datanode_5_1, ozone-topology_datanode_4_1
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-07-11 12:59:59,718 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = 5ac4a93c0ed2/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:35Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-07-11 12:59:59,792 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-07-11 13:00:01,730 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-07-11 13:00:02,608 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-07-11 13:00:04,066 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-07-11 13:00:04,066 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-07-11 13:00:04,803 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:5ac4a93c0ed2 ip:10.5.0.5
datanode_2_1  | 2020-07-11 13:00:05,787 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-07-11 13:00:05,805 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-07-11 13:00:05,896 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-07-11 13:00:05,949 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-07-11 13:00:06,298 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-07-11 13:00:13,106 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-07-11 13:00:13,432 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-07-11 13:00:14,382 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-07-11 13:00:14,410 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-07-11 13:00:14,411 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-11 13:00:14,412 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-07-11 13:00:14,412 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-07-11 13:00:16,428 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-11 13:00:17,947 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-07-11 13:00:18,073 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-07-11 13:00:18,268 [main] INFO util.log: Logging initialized @25898ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-07-11 13:00:18,963 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-07-11 13:00:18,990 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-07-11 13:00:19,029 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-07-11 13:00:19,035 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-07-11 13:00:19,035 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-07-11 13:00:19,035 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-07-11 13:00:19,264 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-07-11 13:00:19,351 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-07-11 13:00:19,379 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-07-11 13:00:19,757 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-07-11 13:00:19,770 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-07-11 13:00:19,771 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2_1  | 2020-07-11 13:00:19,874 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@fcd0e8d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-07-11 13:00:19,892 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6d420cdd{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-07-11 13:00:20,453 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1c171746{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16240305896312764872.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-07-11 13:00:20,521 [main] INFO server.AbstractConnector: Started ServerConnector@3e753289{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-07-11 13:00:20,526 [main] INFO server.Server: Started @28156ms
datanode_2_1  | 2020-07-11 13:00:20,582 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-07-11 13:00:20,583 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-07-11 13:00:20,588 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-07-11 13:00:20,765 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e64654e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-07-11 13:00:22,134 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-07-11 13:00:24,434 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-11 13:00:25,435 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-11 13:00:26,436 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-11 13:00:27,439 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-11 13:00:28,441 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-11 13:00:29,442 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-11 13:00:30,477 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | java.net.SocketTimeoutException: Call From 5ac4a93c0ed2/10.5.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:50908 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:50908 remote=scm/10.5.0.71:9861]
datanode_2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2_1  | 2020-07-11 13:00:31,639 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-07-11 13:00:31,652 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-07-11 13:00:31,658 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 625dea95-7dac-4161-bb51-3704ae488e41 at port 9858
datanode_2_1  | 2020-07-11 13:00:31,858 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 625dea95-7dac-4161-bb51-3704ae488e41: start RPC server
datanode_2_1  | 2020-07-11 13:00:32,589 [Datanode State Machine Thread - 1] INFO server.GrpcService: 625dea95-7dac-4161-bb51-3704ae488e41: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-07-11 13:00:42,278 [grpc-default-executor-0] INFO impl.RaftServerProxy: 625dea95-7dac-4161-bb51-3704ae488e41: addNew group-935C756C8BF7:[625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858] returns group-935C756C8BF7:java.util.concurrent.CompletableFuture@f1a9d63[Not completed]
datanode_2_1  | 2020-07-11 13:00:42,427 [pool-19-thread-1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41: new RaftServerImpl for group-935C756C8BF7:[625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-07-11 13:00:42,430 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-07-11 13:00:42,444 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-11 13:00:42,445 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-07-11 13:00:42,447 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-07-11 13:00:42,451 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-11 13:00:42,489 [pool-19-thread-1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7: ConfigurationManager, init=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-07-11 13:00:42,504 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-11 13:00:42,513 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-07-11 13:00:42,531 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7 does not exist. Creating ...
datanode_2_1  | 2020-07-11 13:00:42,584 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7/in_use.lock acquired by nodename 6@5ac4a93c0ed2
datanode_2_1  | 2020-07-11 13:00:42,595 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7 has been successfully formatted.
datanode_2_1  | 2020-07-11 13:00:42,650 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-935C756C8BF7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-07-11 13:00:42,679 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-07-11 13:00:42,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-07-11 13:00:42,733 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-07-11 13:00:42,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-11 13:00:42,758 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-11 13:00:42,784 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7
datanode_2_1  | 2020-07-11 13:00:43,073 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-11 13:00:43,152 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7
datanode_2_1  | 2020-07-11 13:00:43,152 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-07-11 13:00:43,183 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-11 13:00:43,211 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-11 13:00:43,211 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-07-11 13:00:43,228 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-07-11 13:00:43,250 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-07-11 13:00:43,251 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-07-11 13:00:43,271 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-07-11 13:00:43,299 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-07-11 13:00:43,543 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-07-11 13:00:43,611 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-11 13:00:43,611 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-11 13:00:43,656 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-07-11 13:00:43,674 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-07-11 13:00:43,674 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-07-11 13:00:43,685 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-07-11 13:00:43,686 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-07-11 13:00:44,015 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7
datanode_2_1  | 2020-07-11 13:00:44,045 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7
datanode_2_1  | 2020-07-11 13:00:44,122 [pool-19-thread-1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7: start as a follower, conf=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
datanode_2_1  | 2020-07-11 13:00:44,141 [pool-19-thread-1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-07-11 13:00:44,144 [pool-19-thread-1] INFO impl.RoleInfo: 625dea95-7dac-4161-bb51-3704ae488e41: start FollowerState
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-07-11 13:00:01,316 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = c6927fdffdce/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-07-11 13:00:02,957 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = 2cf63ffee0c6/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:35Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-07-11 13:00:03,090 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-07-11 13:00:04,885 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-07-11 13:00:05,857 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-07-11 13:00:07,074 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-07-11 13:00:07,074 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-07-11 13:00:07,740 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2cf63ffee0c6 ip:10.5.0.6
datanode_3_1  | 2020-07-11 13:00:08,657 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-07-11 13:00:08,667 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-07-11 13:00:08,753 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-07-11 13:00:08,808 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-07-11 13:00:09,001 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-07-11 13:00:16,635 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-07-11 13:00:17,043 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-07-11 13:00:18,070 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-07-11 13:00:18,081 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:35Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-07-11 13:00:01,442 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-07-11 13:00:03,313 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-07-11 13:00:04,092 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-07-11 13:00:05,309 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-07-11 13:00:05,309 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-07-11 13:00:05,945 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c6927fdffdce ip:10.5.0.4
datanode_1_1  | 2020-07-11 13:00:07,035 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-07-11 13:00:07,078 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-07-11 13:00:07,092 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-07-11 13:00:07,205 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-07-11 13:00:07,582 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-07-11 13:00:14,634 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-07-11 13:00:15,172 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-07-11 13:00:16,152 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-07-11 13:00:16,235 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-07-11 13:00:16,236 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-11 13:00:16,239 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-07-11 13:00:16,283 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-07-11 13:00:18,161 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-11 13:00:19,843 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-07-11 13:00:20,021 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-07-11 13:00:20,233 [main] INFO util.log: Logging initialized @26365ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-07-11 13:00:20,935 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-07-11 13:00:20,952 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-07-11 13:00:20,994 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-07-11 13:00:21,023 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-07-11 13:00:21,023 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-07-11 13:00:21,024 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-07-11 13:00:21,209 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-07-11 13:00:21,303 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-07-11 13:00:21,305 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-07-11 13:00:21,532 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-07-11 13:00:21,533 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-07-11 13:00:21,540 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1_1  | 2020-07-11 13:00:21,609 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77e9dca8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-07-11 13:00:21,621 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ab5214{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-07-11 13:00:22,156 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5368e981{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-14658401676789551699.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-07-11 13:00:22,215 [main] INFO server.AbstractConnector: Started ServerConnector@41d20f06{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-07-11 13:00:22,218 [main] INFO server.Server: Started @28350ms
datanode_3_1  | 2020-07-11 13:00:18,082 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-11 13:00:18,083 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-07-11 13:00:18,083 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-07-11 13:00:19,357 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-11 13:00:21,267 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-07-11 13:00:21,459 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-07-11 13:00:21,634 [main] INFO util.log: Logging initialized @26691ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-07-11 13:00:22,262 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-07-11 13:00:22,311 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-07-11 13:00:22,362 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-07-11 13:00:22,387 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-07-11 13:00:22,387 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-07-11 13:00:22,387 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-07-11 13:00:22,604 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-07-11 13:00:22,645 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-07-11 13:00:22,683 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-07-11 13:00:23,112 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-07-11 13:00:23,122 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-07-11 13:00:23,127 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3_1  | 2020-07-11 13:00:23,254 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@21e484b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-07-11 13:00:23,261 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b85edeb{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-07-11 13:00:23,779 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@370a8b6e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16089891491478481951.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-07-11 13:00:23,837 [main] INFO server.AbstractConnector: Started ServerConnector@3193e21d{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-07-11 13:00:23,840 [main] INFO server.Server: Started @28898ms
datanode_3_1  | 2020-07-11 13:00:23,866 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-07-11 13:00:23,866 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-07-11 13:00:23,872 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-07-11 13:00:24,019 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@30a46404] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-07-11 13:00:25,092 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-07-11 13:00:27,195 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-11 13:00:28,196 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-11 13:00:29,197 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-11 13:00:30,236 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | 2020-07-11 13:00:44,189 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-935C756C8BF7,id=625dea95-7dac-4161-bb51-3704ae488e41
datanode_2_1  | 2020-07-11 13:00:44,194 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7
datanode_2_1  | 2020-07-11 13:00:44,631 [grpc-default-executor-0] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:778068fc-db62-4104-91e2-4af6f16647b1
datanode_2_1  | 2020-07-11 13:00:44,636 [grpc-default-executor-0] INFO impl.RoleInfo: 625dea95-7dac-4161-bb51-3704ae488e41: shutdown FollowerState
datanode_2_1  | 2020-07-11 13:00:44,636 [Thread-24] INFO impl.FollowerState: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 2020-07-11 13:00:44,638 [grpc-default-executor-0] INFO impl.RoleInfo: 625dea95-7dac-4161-bb51-3704ae488e41: start FollowerState
datanode_2_1  | 2020-07-11 13:00:45,870 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-935C756C8BF7 with new leaderId: 778068fc-db62-4104-91e2-4af6f16647b1
datanode_2_1  | 2020-07-11 13:00:45,871 [grpc-default-executor-0] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7: change Leader from null to 778068fc-db62-4104-91e2-4af6f16647b1 at term 1 for appendEntries, leader elected after 3192ms
datanode_2_1  | 2020-07-11 13:00:46,030 [grpc-default-executor-0] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7: set configuration 0: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null at 0
datanode_2_1  | 2020-07-11 13:00:46,069 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-07-11 13:00:46,399 [625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 625dea95-7dac-4161-bb51-3704ae488e41@group-935C756C8BF7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7/current/log_inprogress_0
datanode_2_1  | 2020-07-11 13:01:05,977 [pool-19-thread-1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41: new RaftServerImpl for group-FE7B82AFE6A9:[625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-07-11 13:01:05,978 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-07-11 13:01:05,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-11 13:01:05,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-07-11 13:01:05,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-07-11 13:01:05,983 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-11 13:01:05,983 [pool-19-thread-1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9: ConfigurationManager, init=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-07-11 13:01:05,986 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-11 13:01:05,986 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-07-11 13:01:05,987 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2ad4cb44-feeb-494b-b0df-fe7b82afe6a9 does not exist. Creating ...
datanode_2_1  | 2020-07-11 13:01:05,988 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2ad4cb44-feeb-494b-b0df-fe7b82afe6a9/in_use.lock acquired by nodename 6@5ac4a93c0ed2
datanode_2_1  | 2020-07-11 13:01:05,990 [Command processor thread] INFO impl.RaftServerProxy: 625dea95-7dac-4161-bb51-3704ae488e41: addNew group-FE7B82AFE6A9:[625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858] returns group-FE7B82AFE6A9:java.util.concurrent.CompletableFuture@6f038a0a[Not completed]
datanode_2_1  | 2020-07-11 13:01:05,997 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2ad4cb44-feeb-494b-b0df-fe7b82afe6a9 has been successfully formatted.
datanode_2_1  | 2020-07-11 13:01:05,999 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-FE7B82AFE6A9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-07-11 13:01:06,006 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-07-11 13:01:06,035 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-07-11 13:01:06,036 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-07-11 13:01:06,036 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-11 13:01:06,036 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-11 13:01:06,036 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9
datanode_2_1  | 2020-07-11 13:01:06,037 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-11 13:01:06,037 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2ad4cb44-feeb-494b-b0df-fe7b82afe6a9
datanode_2_1  | 2020-07-11 13:01:06,037 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-07-11 13:01:06,038 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-11 13:01:06,038 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-11 13:01:06,038 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-07-11 13:01:06,038 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-07-11 13:01:06,039 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-07-11 13:01:06,047 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-07-11 13:01:06,048 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-07-11 13:01:06,049 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-07-11 13:01:06,050 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-07-11 13:01:06,061 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-11 13:01:06,062 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-11 13:01:06,062 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-07-11 13:01:06,062 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-07-11 13:01:06,063 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-07-11 13:01:06,063 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-07-11 13:01:06,063 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-07-11 13:01:06,063 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9
datanode_2_1  | 2020-07-11 13:01:06,067 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9
datanode_2_1  | 2020-07-11 13:01:06,072 [pool-19-thread-1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9: start as a follower, conf=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-11 13:01:06,077 [pool-19-thread-1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-07-11 13:01:06,078 [pool-19-thread-1] INFO impl.RoleInfo: 625dea95-7dac-4161-bb51-3704ae488e41: start FollowerState
datanode_2_1  | 2020-07-11 13:01:06,091 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FE7B82AFE6A9,id=625dea95-7dac-4161-bb51-3704ae488e41
datanode_2_1  | 2020-07-11 13:01:06,091 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9
datanode_2_1  | 2020-07-11 13:01:06,111 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "2ad4cb44-feeb-494b-b0df-fe7b82afe6a9"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: 3086315141850679627
datanode_2_1  |   leastSigBits: -5701558796800760151
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-07-11 13:01:11,320 [Thread-42] INFO impl.FollowerState: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-FollowerState: change to CANDIDATE, lastRpcTime:5242ms, electionTimeout:5191ms
datanode_3_1  | java.net.SocketTimeoutException: Call From 2cf63ffee0c6/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:59568 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:59568 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-07-11 13:00:31,487 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-07-11 13:00:31,496 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-07-11 13:00:31,498 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3a24eea4-be0f-479e-b9a5-49c648d4b7fb at port 9858
datanode_3_1  | 2020-07-11 13:00:31,729 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: start RPC server
datanode_3_1  | 2020-07-11 13:00:32,402 [Datanode State Machine Thread - 1] INFO server.GrpcService: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-07-11 13:00:37,302 [Command processor thread] INFO impl.RaftServerProxy: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: addNew group-1E47685A59F3:[3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858] returns group-1E47685A59F3:java.util.concurrent.CompletableFuture@65e2e450[Not completed]
datanode_3_1  | 2020-07-11 13:00:37,503 [pool-19-thread-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: new RaftServerImpl for group-1E47685A59F3:[3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-07-11 13:00:37,504 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-07-11 13:00:37,524 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-11 13:01:11,320 [Thread-42] INFO impl.RoleInfo: 625dea95-7dac-4161-bb51-3704ae488e41: shutdown FollowerState
datanode_2_1  | 2020-07-11 13:01:11,321 [Thread-42] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-07-11 13:01:11,324 [Thread-42] INFO impl.RoleInfo: 625dea95-7dac-4161-bb51-3704ae488e41: start LeaderElection
datanode_2_1  | 2020-07-11 13:01:11,332 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO impl.LeaderElection: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1: begin an election at term 1 for -1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-11 13:01:11,334 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO impl.RoleInfo: 625dea95-7dac-4161-bb51-3704ae488e41: shutdown LeaderElection
datanode_2_1  | 2020-07-11 13:01:11,334 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-07-11 13:01:11,335 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FE7B82AFE6A9 with new leaderId: 625dea95-7dac-4161-bb51-3704ae488e41
datanode_2_1  | 2020-07-11 13:01:11,337 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9: change Leader from null to 625dea95-7dac-4161-bb51-3704ae488e41 at term 1 for becomeLeader, leader elected after 5336ms
datanode_2_1  | 2020-07-11 13:01:11,341 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-07-11 13:01:11,341 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-07-11 13:01:11,343 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9
datanode_2_1  | 2020-07-11 13:01:11,346 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-11 13:01:11,346 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-07-11 13:01:11,353 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-07-11 13:01:11,354 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-07-11 13:01:11,355 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-07-11 13:01:11,360 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO impl.RoleInfo: 625dea95-7dac-4161-bb51-3704ae488e41: start LeaderState
datanode_2_1  | 2020-07-11 13:01:11,363 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-07-11 13:01:11,365 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2ad4cb44-feeb-494b-b0df-fe7b82afe6a9/current/log_inprogress_0
datanode_2_1  | 2020-07-11 13:01:11,366 [625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9-LeaderElection1] INFO impl.RaftServerImpl: 625dea95-7dac-4161-bb51-3704ae488e41@group-FE7B82AFE6A9: set configuration 0: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858], old=null at 0
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-07-11 13:00:00,794 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = 71bcb4fe6b2b/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:35Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-07-11 13:00:00,864 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-07-11 13:00:02,767 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-07-11 13:00:03,663 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-07-11 13:00:04,922 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-07-11 13:00:04,922 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-07-11 13:00:05,638 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:71bcb4fe6b2b ip:10.5.0.7
datanode_4_1  | 2020-07-11 13:00:06,645 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-07-11 13:00:06,710 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-07-11 13:00:06,753 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-07-11 13:00:06,857 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-07-11 13:00:07,295 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-07-11 13:00:14,356 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-07-11 13:00:15,006 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-07-11 13:00:15,975 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-07-11 13:00:15,982 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-07-11 13:00:16,003 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-11 13:00:16,003 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-07-11 13:00:16,005 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-07-11 13:00:17,900 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-11 13:00:19,428 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-07-11 13:00:19,551 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-07-11 13:00:19,735 [main] INFO util.log: Logging initialized @26642ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-07-11 13:00:20,508 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-07-11 13:00:20,525 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-07-11 13:00:20,573 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-07-11 13:00:20,607 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-07-11 13:00:20,616 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-07-11 13:00:20,616 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-07-11 13:00:20,841 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-07-11 13:00:20,876 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-07-11 13:00:20,895 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-07-11 13:00:21,277 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-07-11 13:00:21,277 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-07-11 13:00:21,316 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_4_1  | 2020-07-11 13:00:21,424 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77e9dca8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-07-11 13:00:21,431 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ab5214{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-07-11 13:00:21,909 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5368e981{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-2490307444570610731.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-07-11 13:00:21,988 [main] INFO server.AbstractConnector: Started ServerConnector@41d20f06{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-07-11 13:00:21,989 [main] INFO server.Server: Started @28896ms
datanode_4_1  | 2020-07-11 13:00:22,011 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-07-11 13:00:22,011 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-07-11 13:00:22,019 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-07-11 13:00:22,130 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@773378e5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-07-11 13:00:37,524 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-07-11 13:00:37,525 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-07-11 13:00:37,531 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-11 13:00:37,555 [pool-19-thread-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3: ConfigurationManager, init=-1: [3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-07-11 13:00:37,573 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-11 13:00:37,614 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-07-11 13:00:37,616 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/be63d3e2-2f7a-45fd-9815-1e47685a59f3 does not exist. Creating ...
datanode_3_1  | 2020-07-11 13:00:37,643 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/be63d3e2-2f7a-45fd-9815-1e47685a59f3/in_use.lock acquired by nodename 6@2cf63ffee0c6
datanode_3_1  | 2020-07-11 13:00:37,654 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/be63d3e2-2f7a-45fd-9815-1e47685a59f3 has been successfully formatted.
datanode_3_1  | 2020-07-11 13:00:37,693 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-1E47685A59F3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-07-11 13:00:37,699 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-07-11 13:00:37,717 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-07-11 13:00:37,768 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-07-11 13:00:37,774 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-11 13:00:37,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-11 13:00:37,806 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3
datanode_3_1  | 2020-07-11 13:00:37,954 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-07-11 13:00:37,991 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/be63d3e2-2f7a-45fd-9815-1e47685a59f3
datanode_3_1  | 2020-07-11 13:00:37,992 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-07-11 13:00:38,000 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-11 13:00:38,001 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-11 13:00:38,001 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-07-11 13:00:38,002 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-07-11 13:00:38,010 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-07-11 13:00:38,011 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-07-11 13:00:38,012 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-07-11 13:00:38,032 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-07-11 13:00:38,187 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-07-11 13:00:38,223 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-11 13:00:38,223 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-11 13:00:38,260 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-07-11 13:00:38,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-07-11 13:00:38,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-07-11 13:00:38,318 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-07-11 13:00:38,318 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-07-11 13:00:38,513 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3
datanode_3_1  | 2020-07-11 13:00:38,535 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3
datanode_3_1  | 2020-07-11 13:00:38,591 [pool-19-thread-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3: start as a follower, conf=-1: [3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
datanode_3_1  | 2020-07-11 13:00:38,591 [pool-19-thread-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-07-11 13:00:38,592 [pool-19-thread-1] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: start FollowerState
datanode_3_1  | 2020-07-11 13:00:38,686 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1E47685A59F3,id=3a24eea4-be0f-479e-b9a5-49c648d4b7fb
datanode_3_1  | 2020-07-11 13:00:38,710 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3
datanode_3_1  | 2020-07-11 13:00:38,802 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "be63d3e2-2f7a-45fd-9815-1e47685a59f3"
datanode_3_1  | uuid128 {
datanode_3_1  |   mostSigBits: -4727702215396276739
datanode_3_1  |   leastSigBits: -7488045513391318541
datanode_3_1  | }
datanode_3_1  | .
datanode_3_1  | 2020-07-11 13:00:38,805 [Command processor thread] INFO impl.RaftServerProxy: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: addNew group-935C756C8BF7:[625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858] returns group-935C756C8BF7:java.util.concurrent.CompletableFuture@5fca8754[Not completed]
datanode_3_1  | 2020-07-11 13:00:38,813 [pool-19-thread-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: new RaftServerImpl for group-935C756C8BF7:[625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-07-11 13:00:38,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-07-11 13:00:38,814 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-07-11 13:00:38,814 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-07-11 13:00:38,815 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-07-11 13:00:38,815 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-11 13:00:38,815 [pool-19-thread-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7: ConfigurationManager, init=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-07-11 13:00:38,816 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-11 13:00:38,816 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-07-11 13:00:38,822 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7 does not exist. Creating ...
datanode_3_1  | 2020-07-11 13:00:38,826 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7/in_use.lock acquired by nodename 6@2cf63ffee0c6
datanode_3_1  | 2020-07-11 13:00:38,830 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7 has been successfully formatted.
datanode_3_1  | 2020-07-11 13:00:38,832 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-935C756C8BF7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-07-11 13:00:38,833 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-07-11 13:00:38,833 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-07-11 13:00:38,833 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-07-11 13:00:23,440 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-07-11 13:00:25,637 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-11 13:00:26,638 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-11 13:00:27,639 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-11 13:00:28,640 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-11 13:00:38,833 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-11 13:00:38,834 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-11 13:00:38,834 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7
datanode_3_1  | 2020-07-11 13:00:38,835 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-07-11 13:00:38,838 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7
datanode_3_1  | 2020-07-11 13:00:38,838 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-07-11 13:00:38,838 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-11 13:00:38,839 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-11 13:00:38,839 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-07-11 13:00:38,839 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-07-11 13:00:38,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-07-11 13:00:38,843 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-07-11 13:00:38,843 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-07-11 13:00:38,844 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-07-11 13:00:38,846 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-07-11 13:00:38,851 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-11 13:00:38,853 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-11 13:00:38,853 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-07-11 13:00:38,854 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-07-11 13:00:38,854 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-07-11 13:00:38,854 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-07-11 13:00:38,854 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-07-11 13:00:38,854 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7
datanode_3_1  | 2020-07-11 13:00:38,859 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7
datanode_3_1  | 2020-07-11 13:00:38,863 [pool-19-thread-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7: start as a follower, conf=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
datanode_3_1  | 2020-07-11 13:00:38,863 [pool-19-thread-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-07-11 13:00:38,866 [pool-19-thread-1] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: start FollowerState
datanode_3_1  | 2020-07-11 13:00:38,867 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-935C756C8BF7,id=3a24eea4-be0f-479e-b9a5-49c648d4b7fb
datanode_3_1  | 2020-07-11 13:00:38,867 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7
datanode_3_1  | 2020-07-11 13:00:42,971 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 625dea95-7dac-4161-bb51-3704ae488e41{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_3_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.890764463s. [buffered_nanos=1769606579, remote_addr=/10.5.0.5:9858]
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_3_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_3_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_4_1  | 2020-07-11 13:00:29,680 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From 71bcb4fe6b2b/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:60920 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_4_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:60920 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_4_1  | 2020-07-11 13:00:31,639 [Datanode State Machine Thread - 2] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-07-11 13:00:31,659 [Datanode State Machine Thread - 2] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-07-11 13:00:31,678 [Datanode State Machine Thread - 2] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 778068fc-db62-4104-91e2-4af6f16647b1 at port 9858
datanode_4_1  | 2020-07-11 13:00:31,868 [Datanode State Machine Thread - 2] INFO impl.RaftServerProxy: 778068fc-db62-4104-91e2-4af6f16647b1: start RPC server
datanode_4_1  | 2020-07-11 13:00:32,514 [Datanode State Machine Thread - 2] INFO server.GrpcService: 778068fc-db62-4104-91e2-4af6f16647b1: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-07-11 13:00:37,461 [Command processor thread] INFO impl.RaftServerProxy: 778068fc-db62-4104-91e2-4af6f16647b1: addNew group-B4881F4B13D0:[778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858] returns group-B4881F4B13D0:java.util.concurrent.CompletableFuture@7c271c15[Not completed]
datanode_4_1  | 2020-07-11 13:00:37,594 [pool-19-thread-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1: new RaftServerImpl for group-B4881F4B13D0:[778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-11 13:00:37,596 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-07-11 13:00:37,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-07-11 13:00:37,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-07-11 13:00:37,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-11 13:00:37,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-11 13:00:37,649 [pool-19-thread-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0: ConfigurationManager, init=-1: [778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-11 13:00:37,649 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-11 13:00:37,681 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-11 13:00:37,695 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/1bfd57a4-1af7-4204-8a51-b4881f4b13d0 does not exist. Creating ...
datanode_4_1  | 2020-07-11 13:00:37,723 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/1bfd57a4-1af7-4204-8a51-b4881f4b13d0/in_use.lock acquired by nodename 6@71bcb4fe6b2b
datanode_4_1  | 2020-07-11 13:00:37,751 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/1bfd57a4-1af7-4204-8a51-b4881f4b13d0 has been successfully formatted.
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-07-11 13:00:00,594 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | /************************************************************
datanode_1_1  | 2020-07-11 13:00:22,228 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | 2020-07-11 13:00:37,810 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-B4881F4B13D0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_6_1  | 2020-07-11 13:00:01,799 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | 2020-07-11 13:00:22,228 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-07-11 13:00:37,811 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_6_1  | /************************************************************
om_1          | 2020-07-11 12:59:59,420 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_5_1  | STARTUP_MSG:   host = ae22b1cc5a40/10.5.0.8
datanode_1_1  | 2020-07-11 13:00:22,245 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
scm_1         | 2020-07-11 13:00:11,617 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_4_1  | 2020-07-11 13:00:37,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
om_1          | /************************************************************
datanode_5_1  | STARTUP_MSG:   args = []
datanode_1_1  | 2020-07-11 13:00:22,538 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@773378e5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | /************************************************************
datanode_4_1  | 2020-07-11 13:00:37,865 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_6_1  | STARTUP_MSG:   host = d1b8ef127e89/10.5.0.9
om_1          | STARTUP_MSG: Starting OzoneManager
datanode_5_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | 2020-07-11 13:00:23,669 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
scm_1         | STARTUP_MSG: Starting StorageContainerManager
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_6_1  | STARTUP_MSG:   args = []
datanode_4_1  | 2020-07-11 13:00:37,866 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1          | STARTUP_MSG:   host = 2926616db2d8/10.5.0.70
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | 2020-07-11 13:00:25,971 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | STARTUP_MSG:   host = 75d30ea6abb5/10.5.0.71
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | 2020-07-11 13:00:37,868 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1          | STARTUP_MSG:   args = [--init]
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:35Z
datanode_1_1  | 2020-07-11 13:00:26,972 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | STARTUP_MSG:   args = [--init]
datanode_3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.890764463s. [buffered_nanos=1769606579, remote_addr=/10.5.0.5:9858]
datanode_4_1  | 2020-07-11 13:00:37,923 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_4_1  | 2020-07-11 13:00:38,018 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:35Z
datanode_5_1  | 2020-07-11 13:00:00,686 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-07-11 13:00:27,973 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
datanode_4_1  | 2020-07-11 13:00:38,066 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/1bfd57a4-1af7-4204-8a51-b4881f4b13d0
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | 2020-07-11 13:00:02,681 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-07-11 13:00:28,974 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:36Z
om_1          | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_4_1  | 2020-07-11 13:00:38,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | ************************************************************/
datanode_5_1  | 2020-07-11 13:00:03,573 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | ************************************************************/
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:35Z
datanode_1_1  | 2020-07-11 13:00:30,044 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_4_1  | 2020-07-11 13:00:38,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-11 13:00:01,859 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5_1  | 2020-07-11 13:00:05,009 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-07-11 12:59:59,481 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | java.net.SocketTimeoutException: Call From c6927fdffdce/10.5.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:36546 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_4_1  | 2020-07-11 13:00:38,106 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-11 13:00:03,699 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-07-11 13:00:05,010 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
om_1          | 2020-07-11 13:00:06,198 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
scm_1         | ************************************************************/
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_4_1  | 2020-07-11 13:00:38,106 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-11 13:00:04,892 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-07-11 13:00:05,683 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:ae22b1cc5a40 ip:10.5.0.8
om_1          | 2020-07-11 13:00:06,564 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
scm_1         | 2020-07-11 13:00:11,766 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	... 18 more
datanode_4_1  | 2020-07-11 13:00:38,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-07-11 13:00:06,518 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-07-11 13:00:06,587 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
om_1          | 2020-07-11 13:00:06,566 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
scm_1         | 2020-07-11 13:00:12,735 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 2020-07-11 13:00:43,788 [Thread-23] INFO impl.FollowerState: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-FollowerState: change to CANDIDATE, lastRpcTime:5196ms, electionTimeout:5165ms
datanode_4_1  | 2020-07-11 13:00:38,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-07-11 13:00:06,522 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-07-11 13:00:06,627 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
om_1          | 2020-07-11 13:00:06,986 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-11 13:00:13,236 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-7f57641f-6b14-406b-b3cb-b054ea4b9886;layoutVersion=0
datanode_1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 2020-07-11 13:00:43,792 [Thread-23] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: shutdown FollowerState
datanode_4_1  | 2020-07-11 13:00:38,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-11 13:00:07,386 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d1b8ef127e89 ip:10.5.0.9
datanode_5_1  | 2020-07-11 13:00:06,656 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
om_1          | 2020-07-11 13:00:10,176 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2020-07-11 13:00:13,318 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 2020-07-11 13:00:43,792 [Thread-23] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-07-11 13:00:38,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-07-11 13:00:08,434 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-07-11 13:00:06,708 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
om_1          | 2020-07-11 13:00:11,177 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | /************************************************************
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 2020-07-11 13:00:43,797 [Thread-23] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: start LeaderElection
datanode_4_1  | 2020-07-11 13:00:38,113 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-07-11 13:00:08,456 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-07-11 13:00:07,220 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
om_1          | 2020-07-11 13:00:12,178 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at 75d30ea6abb5/10.5.0.71
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 2020-07-11 13:00:43,848 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO impl.LeaderElection: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1: begin an election at term 1 for -1: [3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
datanode_4_1  | 2020-07-11 13:00:38,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-07-11 13:00:08,519 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-07-11 13:00:14,393 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1          | 2020-07-11 13:00:13,179 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | ************************************************************/
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 2020-07-11 13:00:43,850 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: shutdown LeaderElection
datanode_4_1  | 2020-07-11 13:00:38,278 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-11 13:00:08,566 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-07-11 13:00:14,973 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om_1          | 2020-07-11 13:00:14,180 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | Enabled profiling in kernel
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 2020-07-11 13:00:43,850 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-07-11 13:00:38,278 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-11 13:00:09,032 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-07-11 13:00:16,036 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
om_1          | 2020-07-11 13:00:15,181 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 2020-07-11 13:00:43,851 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-1E47685A59F3 with new leaderId: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb
datanode_4_1  | 2020-07-11 13:00:38,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-07-11 13:00:15,765 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-07-11 13:00:16,044 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
om_1          | 2020-07-11 13:00:16,365 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 2020-07-11 13:00:43,865 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3: change Leader from null to 3a24eea4-be0f-479e-b9a5-49c648d4b7fb at term 1 for becomeLeader, leader elected after 6157ms
datanode_4_1  | 2020-07-11 13:00:38,327 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-11 13:00:16,373 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-07-11 13:00:16,059 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1          | 2020-07-11 13:00:17,366 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | 2020-07-11 13:00:26,462 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_1_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 2020-07-11 13:00:43,899 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-07-11 13:00:38,330 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-07-11 13:00:17,436 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-07-11 13:00:16,062 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
om_1          | 2020-07-11 13:00:18,366 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | /************************************************************
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 2020-07-11 13:00:43,915 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-07-11 13:00:38,335 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-07-11 13:00:17,453 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-07-11 13:00:16,065 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
om_1          | 2020-07-11 13:00:19,368 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | STARTUP_MSG: Starting StorageContainerManager
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 2020-07-11 13:00:43,920 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3
datanode_4_1  | 2020-07-11 13:00:38,336 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-07-11 13:00:17,454 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-11 13:00:18,178 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1          | 2020-07-11 13:00:19,370 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
scm_1         | STARTUP_MSG:   host = 75d30ea6abb5/10.5.0.71
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 2020-07-11 13:00:43,944 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-11 13:00:38,556 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0
datanode_6_1  | 2020-07-11 13:00:17,455 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-07-11 13:00:19,706 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
om_1          | 2020-07-11 13:00:25,372 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | STARTUP_MSG:   args = []
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 2020-07-11 13:00:43,949 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-07-11 13:00:38,606 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0
datanode_6_1  | 2020-07-11 13:00:17,456 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-07-11 13:00:19,843 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1          | 2020-07-11 13:00:26,372 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 2020-07-11 13:00:44,005 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-07-11 13:00:38,612 [pool-19-thread-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0: start as a follower, conf=-1: [778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858], old=null
datanode_6_1  | 2020-07-11 13:00:18,389 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-11 13:00:19,998 [main] INFO util.log: Logging initialized @27050ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-07-11 13:00:27,373 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
datanode_3_1  | 2020-07-11 13:00:44,017 [Thread-25] INFO impl.FollowerState: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-FollowerState: change to CANDIDATE, lastRpcTime:5150ms, electionTimeout:5138ms
datanode_4_1  | 2020-07-11 13:00:38,631 [pool-19-thread-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-07-11 13:00:19,900 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-07-11 13:00:20,798 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-07-11 13:00:28,374 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:35Z
datanode_3_1  | 2020-07-11 13:00:44,018 [Thread-25] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: shutdown FollowerState
datanode_4_1  | 2020-07-11 13:00:38,634 [pool-19-thread-1] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: start FollowerState
datanode_6_1  | 2020-07-11 13:00:20,050 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-07-11 13:00:20,844 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
om_1          | 2020-07-11 13:00:29,375 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | 2020-07-11 13:00:44,018 [Thread-25] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-07-11 13:00:38,667 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B4881F4B13D0,id=778068fc-db62-4104-91e2-4af6f16647b1
datanode_6_1  | 2020-07-11 13:00:20,386 [main] INFO util.log: Logging initialized @26104ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-07-11 13:00:20,908 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-7f57641f-6b14-406b-b3cb-b054ea4b9886;layoutVersion=0
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | ************************************************************/
datanode_3_1  | 2020-07-11 13:00:44,018 [Thread-25] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: start LeaderElection
datanode_4_1  | 2020-07-11 13:00:38,669 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0
datanode_6_1  | 2020-07-11 13:00:21,307 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-07-11 13:00:20,938 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
om_1          | 2020-07-11 13:00:30,412 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-07-11 13:00:26,477 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-07-11 13:00:44,019 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-07-11 13:00:38,790 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "1bfd57a4-1af7-4204-8a51-b4881f4b13d0"
datanode_6_1  | 2020-07-11 13:00:21,334 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-07-11 13:00:20,946 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | /************************************************************
datanode_1_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:36546 remote=scm/10.5.0.71:9861]
scm_1         | 2020-07-11 13:00:26,761 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3_1  | 2020-07-11 13:00:44,060 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | uuid128 {
datanode_6_1  | 2020-07-11 13:00:21,376 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-07-11 13:00:20,946 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 2926616db2d8/10.5.0.70
datanode_1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
scm_1         | 2020-07-11 13:00:27,132 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3_1  | 2020-07-11 13:00:44,070 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-LeaderElection2] INFO impl.LeaderElection: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-LeaderElection2: begin an election at term 1 for -1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
datanode_4_1  |   mostSigBits: 2016864570470515204
datanode_6_1  | 2020-07-11 13:00:21,396 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-07-11 13:00:21,250 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | ************************************************************/
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
scm_1         | 2020-07-11 13:00:27,305 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@46cc127b
datanode_3_1  | 2020-07-11 13:00:44,596 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: start LeaderState
datanode_4_1  |   leastSigBits: -8479798126628367408
datanode_6_1  | 2020-07-11 13:00:21,405 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-07-11 13:00:21,342 [main] INFO http.HttpServer2: Jetty bound to port 9882
om_1          | Enabled profiling in kernel
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
scm_1         | 2020-07-11 13:00:27,306 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_3_1  | 2020-07-11 13:00:44,604 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "c0d3e745-7f7a-4b01-abb7-935c756c8bf7"
datanode_4_1  | }
datanode_6_1  | 2020-07-11 13:00:21,406 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-07-11 13:00:21,347 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
scm_1         | 2020-07-11 13:00:27,463 [main] INFO node.SCMNodeManager: Entering startup safe mode.
datanode_3_1  | uuid128 {
datanode_4_1  | .
datanode_6_1  | 2020-07-11 13:00:21,709 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-07-11 13:00:21,611 [main] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
scm_1         | 2020-07-11 13:00:27,617 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
datanode_3_1  |   mostSigBits: -4552040512663958783
datanode_4_1  | 2020-07-11 13:00:38,795 [Command processor thread] INFO impl.RaftServerProxy: 778068fc-db62-4104-91e2-4af6f16647b1: addNew group-935C756C8BF7:[625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858] returns group-935C756C8BF7:java.util.concurrent.CompletableFuture@72a6021d[Not completed]
datanode_6_1  | 2020-07-11 13:00:21,741 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-07-11 13:00:21,611 [main] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-07-11 13:00:38,990 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
scm_1         | 2020-07-11 13:00:27,672 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
datanode_3_1  |   leastSigBits: -6073223547169502217
datanode_4_1  | 2020-07-11 13:00:38,813 [pool-19-thread-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1: new RaftServerImpl for group-935C756C8BF7:[625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-07-11 13:00:21,771 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-07-11 13:00:21,612 [main] INFO server.session: node0 Scavenging every 600000ms
om_1          | /************************************************************
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
scm_1         | 2020-07-11 13:00:27,772 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
datanode_3_1  | }
datanode_4_1  | 2020-07-11 13:00:38,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-07-11 13:00:22,093 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-07-11 13:00:21,688 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77e9dca8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | STARTUP_MSG: Starting OzoneManager
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
scm_1         | 2020-07-11 13:00:27,775 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
datanode_3_1  | .
datanode_4_1  | 2020-07-11 13:00:38,814 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-07-11 13:00:22,116 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-07-11 13:00:21,710 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ab5214{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | STARTUP_MSG:   host = 2926616db2d8/10.5.0.70
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
scm_1         | 2020-07-11 13:00:27,839 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
datanode_3_1  | 2020-07-11 13:00:44,881 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-07-11 13:00:38,815 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-07-11 13:00:22,118 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5_1  | 2020-07-11 13:00:22,388 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5368e981{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4623757190385041829.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
om_1          | STARTUP_MSG:   args = []
datanode_1_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
scm_1         | 2020-07-11 13:00:28,582 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3_1  | 2020-07-11 13:00:45,130 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-LeaderElection1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3: set configuration 0: [3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null at 0
datanode_4_1  | 2020-07-11 13:00:38,816 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-11 13:00:22,261 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77e9dca8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-07-11 13:00:22,462 [main] INFO server.AbstractConnector: Started ServerConnector@41d20f06{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
scm_1         | 2020-07-11 13:00:28,613 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
datanode_3_1  | 2020-07-11 13:00:45,487 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-1E47685A59F3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/be63d3e2-2f7a-45fd-9815-1e47685a59f3/current/log_inprogress_0
datanode_4_1  | 2020-07-11 13:00:38,834 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-11 13:00:22,274 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ab5214{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-07-11 13:00:22,463 [main] INFO server.Server: Started @29515ms
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
scm_1         | 2020-07-11 13:00:28,696 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3_1  | 2020-07-11 13:00:45,792 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-LeaderElection2] INFO impl.LeaderElection: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-LeaderElection2: Election REJECTED; received 2 response(s) [3a24eea4-be0f-479e-b9a5-49c648d4b7fb<-625dea95-7dac-4161-bb51-3704ae488e41#0:FAIL-t1, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb<-778068fc-db62-4104-91e2-4af6f16647b1#0:FAIL-t1] and 0 exception(s); 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7:t1, leader=null, voted=3a24eea4-be0f-479e-b9a5-49c648d4b7fb, raftlog=3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
datanode_4_1  | 2020-07-11 13:00:38,838 [pool-19-thread-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7: ConfigurationManager, init=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-07-11 13:00:22,793 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5368e981{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-8870314635845540772.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-07-11 13:00:22,478 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2af6198686d81daa3ad0513f723118637d2945cf ; compiled by 'runner' on 2020-07-11T12:36Z
scm_1         | 2020-07-11 13:00:28,698 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
datanode_3_1  | 2020-07-11 13:00:45,793 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-LeaderElection2] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_4_1  | 2020-07-11 13:00:38,839 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-11 13:00:22,847 [main] INFO server.AbstractConnector: Started ServerConnector@41d20f06{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-07-11 13:00:22,478 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-07-11 13:00:31,754 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
om_1          | STARTUP_MSG:   java = 11.0.6
scm_1         | 2020-07-11 13:00:28,738 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3_1  | 2020-07-11 13:00:45,798 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-LeaderElection2] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: shutdown LeaderElection
datanode_4_1  | 2020-07-11 13:00:38,841 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-07-11 13:00:22,856 [main] INFO server.Server: Started @28574ms
datanode_5_1  | 2020-07-11 13:00:22,486 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-07-11 13:00:31,756 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
om_1          | ************************************************************/
scm_1         | 2020-07-11 13:00:28,739 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode_3_1  | 2020-07-11 13:00:45,798 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-LeaderElection2] INFO impl.RoleInfo: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb: start FollowerState
datanode_6_1  | 2020-07-11 13:00:22,870 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-07-11 13:00:22,585 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e3a7339] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-07-11 13:00:31,768 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 0e925a4a-a3be-400e-ae7d-aecf7064f65c at port 9858
om_1          | 2020-07-11 13:00:39,059 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-07-11 13:00:28,768 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_4_1  | 2020-07-11 13:00:38,843 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7 does not exist. Creating ...
datanode_6_1  | 2020-07-11 13:00:22,870 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-07-11 13:00:24,111 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-07-11 13:00:31,890 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: start RPC server
datanode_3_1  | 2020-07-11 13:00:45,899 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-935C756C8BF7 with new leaderId: 778068fc-db62-4104-91e2-4af6f16647b1
om_1          | 2020-07-11 13:00:44,745 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
scm_1         | 2020-07-11 13:00:28,768 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-07-11 13:00:38,862 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7/in_use.lock acquired by nodename 6@71bcb4fe6b2b
datanode_6_1  | 2020-07-11 13:00:22,897 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-07-11 13:00:26,259 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-11 13:00:32,575 [Datanode State Machine Thread - 1] INFO server.GrpcService: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-07-11 13:00:45,902 [grpc-default-executor-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7: change Leader from null to 778068fc-db62-4104-91e2-4af6f16647b1 at term 1 for appendEntries, leader elected after 7065ms
om_1          | 2020-07-11 13:00:45,346 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
scm_1         | 2020-07-11 13:00:28,796 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @12705ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-07-11 13:00:38,868 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7 has been successfully formatted.
datanode_6_1  | 2020-07-11 13:00:23,106 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@12d16ab9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-07-11 13:00:27,259 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-11 13:00:44,841 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: Failed requestVote 6e333534-afe2-4f15-8be5-338f0f6f06b9->0e925a4a-a3be-400e-ae7d-aecf7064f65c#0
datanode_3_1  | 2020-07-11 13:00:46,067 [grpc-default-executor-1] INFO impl.RaftServerImpl: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7: set configuration 0: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null at 0
om_1          | 2020-07-11 13:00:45,354 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
scm_1         | 2020-07-11 13:00:28,907 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-07-11 13:00:38,868 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-935C756C8BF7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-07-11 13:00:24,415 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-07-11 13:00:28,261 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | org.apache.ratis.protocol.GroupMismatchException: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: group-3EE7DF2A6792 not found.
datanode_3_1  | 2020-07-11 13:00:46,093 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-SegmentedRaftLogWorker: Starting segment from index:0
om_1          | 2020-07-11 13:00:45,725 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-11 13:00:28,924 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
datanode_4_1  | 2020-07-11 13:00:38,871 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
om_1          | 2020-07-11 13:00:45,839 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:127)
datanode_5_1  | 2020-07-11 13:00:29,262 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-11 13:00:26,635 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-11 13:00:27,636 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1         | 2020-07-11 13:00:28,931 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-07-11 13:00:49,204 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:274)
datanode_4_1  | 2020-07-11 13:00:38,872 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-07-11 13:00:28,638 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-11 13:00:46,095 [3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb@group-935C756C8BF7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7/current/log_inprogress_0
datanode_5_1  | 2020-07-11 13:00:30,289 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
scm_1         | 2020-07-11 13:00:28,934 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
om_1          | 2020-07-11 13:00:50,181 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:283)
datanode_4_1  | 2020-07-11 13:00:38,876 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-07-11 13:00:29,678 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5_1  | java.net.SocketTimeoutException: Call From ae22b1cc5a40/10.5.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:41192 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
scm_1         | 2020-07-11 13:00:28,934 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-07-11 13:00:50,210 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:278)
datanode_4_1  | 2020-07-11 13:00:38,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_6_1  | java.net.SocketTimeoutException: Call From d1b8ef127e89/10.5.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:43400 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
scm_1         | 2020-07-11 13:00:28,934 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-07-11 13:00:50,545 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:455)
datanode_4_1  | 2020-07-11 13:00:38,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm_1         | 2020-07-11 13:00:28,984 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-07-11 13:00:50,721 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:170)
datanode_4_1  | 2020-07-11 13:00:38,877 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7
datanode_5_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm_1         | 2020-07-11 13:00:29,034 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
om_1          | 2020-07-11 13:00:50,723 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
datanode_1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:325)
datanode_4_1  | 2020-07-11 13:00:38,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_6_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm_1         | 2020-07-11 13:00:29,192 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-07-11 13:00:50,842 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_4_1  | 2020-07-11 13:00:38,883 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
scm_1         | 2020-07-11 13:00:29,298 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-07-11 13:00:50,874 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:817)
datanode_6_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
scm_1         | 2020-07-11 13:00:29,298 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_4_1  | 2020-07-11 13:00:38,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
om_1          | 2020-07-11 13:00:50,882 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
scm_1         | 2020-07-11 13:00:29,676 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_4_1  | 2020-07-11 13:00:38,902 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
om_1          | 2020-07-11 13:00:51,254 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
scm_1         | 2020-07-11 13:00:29,716 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 2020-07-11 13:00:38,902 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1          | 2020-07-11 13:00:51,254 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
scm_1         | 2020-07-11 13:00:29,720 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 2020-07-11 13:00:38,903 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1          | 2020-07-11 13:00:51,321 [Listener at om/9862] INFO util.log: Logging initialized @20684ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
scm_1         | 2020-07-11 13:00:29,824 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-07-11 13:00:45,275 [grpc-default-executor-0] INFO impl.RaftServerProxy: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: addNew group-3EE7DF2A6792:[e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858] returns group-3EE7DF2A6792:java.util.concurrent.CompletableFuture@5e1a2646[Not completed]
om_1          | 2020-07-11 13:00:51,604 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
scm_1         | 2020-07-11 13:00:29,825 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
datanode_1_1  | 2020-07-11 13:00:45,582 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: new RaftServerImpl for group-3EE7DF2A6792:[e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-11 13:00:38,903 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
om_1          | 2020-07-11 13:00:51,617 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_5_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
scm_1         | 2020-07-11 13:00:29,826 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_1_1  | 2020-07-11 13:00:45,590 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-07-11 13:00:45,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1          | 2020-07-11 13:00:51,633 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-07-11 13:00:29,839 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 2020-07-11 13:00:38,904 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1          | 2020-07-11 13:00:51,638 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1_1  | 2020-07-11 13:00:45,602 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
scm_1         | 2020-07-11 13:00:30,123 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 2020-07-11 13:00:38,904 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1          | 2020-07-11 13:00:51,639 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1_1  | 2020-07-11 13:00:45,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1         | 2020-07-11 13:00:30,135 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_4_1  | 2020-07-11 13:00:38,904 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1          | 2020-07-11 13:00:51,639 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_1_1  | 2020-07-11 13:00:45,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1         | 2020-07-11 13:00:30,137 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_4_1  | 2020-07-11 13:00:38,904 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-07-11 13:00:38,906 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-07-11 13:00:38,922 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-11 13:00:45,629 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792: ConfigurationManager, init=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-07-11 13:00:45,648 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 2020-07-11 13:00:38,922 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-11 13:00:38,927 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-07-11 13:00:38,927 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-07-11 13:00:38,927 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1          | 2020-07-11 13:00:51,696 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-07-11 13:00:51,705 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-07-11 13:00:51,706 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-07-11 13:00:51,819 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:41192 remote=scm/10.5.0.71:9861]
datanode_5_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
scm_1         | 2020-07-11 13:00:30,138 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
scm_1         | 2020-07-11 13:00:30,242 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-07-11 13:00:30,244 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1         | 2020-07-11 13:00:30,393 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:60920
scm_1         | 2020-07-11 13:00:30,400 [IPC Server handler 7 on default port 9861] INFO ipc.Server: IPC Server handler 7 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:59568
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
om_1          | 2020-07-11 13:00:51,821 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
om_1          | 2020-07-11 13:00:51,826 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1          | 2020-07-11 13:00:51,862 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@50e8ed74{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-07-11 13:00:51,865 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@103478b8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-07-11 13:00:52,145 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1293f8d7{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-14127670841998206.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-07-11 13:00:52,175 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@36ecf9f6{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_5_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
scm_1         | 2020-07-11 13:00:30,394 [IPC Server handler 5 on default port 9861] INFO ipc.Server: IPC Server handler 5 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:43400
scm_1         | 2020-07-11 13:00:30,570 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-07-11 13:00:30,570 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-07-11 13:00:30,586 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1         | 2020-07-11 13:00:30,631 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@39133244{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_5_1  | 2020-07-11 13:00:31,417 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-07-11 13:00:31,420 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-07-11 13:00:31,430 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e67d091a-1583-4527-8ecf-5d5225cc2732 at port 9858
datanode_5_1  | 2020-07-11 13:00:31,650 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: e67d091a-1583-4527-8ecf-5d5225cc2732: start RPC server
datanode_5_1  | 2020-07-11 13:00:32,339 [Datanode State Machine Thread - 1] INFO server.GrpcService: e67d091a-1583-4527-8ecf-5d5225cc2732: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-07-11 13:00:42,303 [grpc-default-executor-0] INFO impl.RaftServerProxy: e67d091a-1583-4527-8ecf-5d5225cc2732: addNew group-3EE7DF2A6792:[e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858] returns group-3EE7DF2A6792:java.util.concurrent.CompletableFuture@7ae18ae6[Not completed]
datanode_5_1  | 2020-07-11 13:00:42,390 [pool-19-thread-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732: new RaftServerImpl for group-3EE7DF2A6792:[e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-07-11 13:00:42,399 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-07-11 13:00:42,407 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-11 13:00:42,414 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-07-11 13:00:42,418 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-07-11 13:00:45,673 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-07-11 13:00:45,684 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792 does not exist. Creating ...
datanode_1_1  | 2020-07-11 13:00:45,725 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792/in_use.lock acquired by nodename 6@c6927fdffdce
datanode_1_1  | 2020-07-11 13:00:45,737 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792 has been successfully formatted.
datanode_1_1  | 2020-07-11 13:00:45,804 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3EE7DF2A6792: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-07-11 13:00:45,809 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
om_1          | 2020-07-11 13:00:52,175 [Listener at om/9862] INFO server.Server: Started @21538ms
datanode_1_1  | 2020-07-11 13:00:45,817 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
scm_1         | 2020-07-11 13:00:30,638 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2017f6e6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-07-11 13:00:42,418 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-11 13:00:38,927 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
om_1          | 2020-07-11 13:00:52,185 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-07-11 13:00:45,842 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
scm_1         | 2020-07-11 13:00:30,962 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.5:50908: output error
datanode_5_1  | 2020-07-11 13:00:42,442 [pool-19-thread-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792: ConfigurationManager, init=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-11 13:00:38,928 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1          | 2020-07-11 13:00:52,189 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-07-11 13:00:45,848 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
scm_1         | 2020-07-11 13:00:30,963 [IPC Server handler 9 on default port 9861] WARN ipc.Server: IPC Server handler 9 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.8:41192: output error
datanode_5_1  | 2020-07-11 13:00:42,444 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-11 13:00:38,931 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7
om_1          | 2020-07-11 13:00:52,200 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
datanode_1_1  | 2020-07-11 13:00:45,860 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1         | 2020-07-11 13:00:30,964 [IPC Server handler 9 on default port 9861] INFO ipc.Server: IPC Server handler 9 on default port 9861 caught an exception
datanode_5_1  | 2020-07-11 13:00:42,474 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-11 13:00:38,941 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7
om_1          | 2020-07-11 13:00:52,263 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7744195] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-07-11 13:00:45,892 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792
datanode_6_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1         | java.nio.channels.AsynchronousCloseException
datanode_5_1  | 2020-07-11 13:00:42,475 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792 does not exist. Creating ...
datanode_4_1  | 2020-07-11 13:00:38,943 [pool-19-thread-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7: start as a follower, conf=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
om_1          | 2020-07-11 13:00:59,857 [IPC Server handler 0 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-10372 for user:hadoop
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 2020-07-11 13:00:42,514 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792/in_use.lock acquired by nodename 6@ae22b1cc5a40
datanode_4_1  | 2020-07-11 13:00:38,954 [pool-19-thread-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1          | 2020-07-11 13:00:59,907 [IPC Server handler 15 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-85640 for user:hadoop
datanode_1_1  | 2020-07-11 13:00:46,013 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_5_1  | 2020-07-11 13:00:42,528 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792 has been successfully formatted.
datanode_4_1  | 2020-07-11 13:00:38,954 [pool-19-thread-1] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: start FollowerState
om_1          | 2020-07-11 13:00:59,928 [IPC Server handler 23 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-20078 for user:hadoop
datanode_1_1  | 2020-07-11 13:00:46,079 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
datanode_5_1  | 2020-07-11 13:00:42,565 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3EE7DF2A6792: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-07-11 13:00:38,957 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-935C756C8BF7,id=778068fc-db62-4104-91e2-4af6f16647b1
om_1          | 2020-07-11 13:00:59,947 [IPC Server handler 21 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-60563 for user:hadoop
datanode_1_1  | 2020-07-11 13:00:46,082 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
datanode_5_1  | 2020-07-11 13:00:42,566 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
om_1          | 2020-07-11 13:00:59,965 [IPC Server handler 19 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-10357 for user:hadoop
datanode_1_1  | 2020-07-11 13:00:46,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
datanode_4_1  | 2020-07-11 13:00:38,968 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7
datanode_1_1  | 2020-07-11 13:00:46,091 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-11 13:00:46,096 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_4_1  | 2020-07-11 13:00:43,783 [Thread-24] INFO impl.FollowerState: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-FollowerState: change to CANDIDATE, lastRpcTime:5149ms, electionTimeout:5104ms
datanode_5_1  | 2020-07-11 13:00:42,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-07-11 13:00:46,102 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:43400 remote=scm/10.5.0.71:9861]
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
datanode_4_1  | 2020-07-11 13:00:43,802 [Thread-24] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: shutdown FollowerState
datanode_5_1  | 2020-07-11 13:00:42,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-07-11 13:00:46,105 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
datanode_4_1  | 2020-07-11 13:00:43,818 [Thread-24] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-07-11 13:00:42,658 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-11 13:00:46,107 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
datanode_4_1  | 2020-07-11 13:00:43,821 [Thread-24] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: start LeaderElection
datanode_5_1  | 2020-07-11 13:00:42,663 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-11 13:00:46,118 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
datanode_4_1  | 2020-07-11 13:00:43,939 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "c0d3e745-7f7a-4b01-abb7-935c756c8bf7"
datanode_5_1  | 2020-07-11 13:00:42,716 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792
datanode_1_1  | 2020-07-11 13:00:46,125 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_4_1  | uuid128 {
datanode_5_1  | 2020-07-11 13:00:42,858 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-11 13:00:46,354 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
datanode_4_1  |   mostSigBits: -4552040512663958783
datanode_5_1  | 2020-07-11 13:00:42,897 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792
datanode_1_1  | 2020-07-11 13:00:46,411 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  |   leastSigBits: -6073223547169502217
datanode_5_1  | 2020-07-11 13:00:42,926 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-07-11 13:00:46,420 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_4_1  | }
datanode_5_1  | 2020-07-11 13:00:42,927 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-11 13:00:46,458 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_4_1  | .
datanode_5_1  | 2020-07-11 13:00:42,935 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-11 13:00:46,470 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_4_1  | 2020-07-11 13:00:43,944 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO impl.LeaderElection: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1: begin an election at term 1 for -1: [778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858], old=null
datanode_5_1  | 2020-07-11 13:00:42,938 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-07-11 13:00:46,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_4_1  | 2020-07-11 13:00:43,952 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: shutdown LeaderElection
datanode_5_1  | 2020-07-11 13:00:42,939 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-11 13:00:46,483 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_4_1  | 2020-07-11 13:00:43,976 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-07-11 13:00:42,943 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
scm_1         | 2020-07-11 13:00:30,970 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
datanode_4_1  | 2020-07-11 13:00:43,982 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B4881F4B13D0 with new leaderId: 778068fc-db62-4104-91e2-4af6f16647b1
datanode_1_1  | 2020-07-11 13:00:46,486 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-11 13:00:42,947 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-11 13:00:31,436 [Datanode State Machine Thread - 2] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
scm_1         | java.nio.channels.AsynchronousCloseException
datanode_4_1  | 2020-07-11 13:00:43,987 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0: change Leader from null to 778068fc-db62-4104-91e2-4af6f16647b1 at term 1 for becomeLeader, leader elected after 6171ms
datanode_1_1  | 2020-07-11 13:00:46,684 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792
datanode_5_1  | 2020-07-11 13:00:42,953 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-07-11 13:00:31,448 [Datanode State Machine Thread - 2] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_4_1  | 2020-07-11 13:00:43,997 [Thread-26] INFO impl.FollowerState: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-FollowerState: change to CANDIDATE, lastRpcTime:5042ms, electionTimeout:5040ms
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
datanode_5_1  | 2020-07-11 13:00:42,955 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-07-11 13:00:31,472 [Datanode State Machine Thread - 2] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 6e333534-afe2-4f15-8be5-338f0f6f06b9 at port 9858
datanode_4_1  | 2020-07-11 13:00:44,008 [Thread-26] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: shutdown FollowerState
datanode_1_1  | 2020-07-11 13:00:46,716 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
datanode_5_1  | 2020-07-11 13:00:43,128 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-07-11 13:00:31,617 [Datanode State Machine Thread - 2] INFO impl.RaftServerProxy: 6e333534-afe2-4f15-8be5-338f0f6f06b9: start RPC server
datanode_4_1  | 2020-07-11 13:00:44,008 [Thread-26] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-07-11 13:00:46,763 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792: start as a follower, conf=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
datanode_5_1  | 2020-07-11 13:00:43,189 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-11 13:00:32,307 [Datanode State Machine Thread - 2] INFO server.GrpcService: 6e333534-afe2-4f15-8be5-338f0f6f06b9: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-07-11 13:00:46,764 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-07-11 13:00:44,008 [Thread-26] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: start LeaderElection
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_5_1  | 2020-07-11 13:00:43,191 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-11 13:00:36,635 [Command processor thread] INFO impl.RaftServerProxy: 6e333534-afe2-4f15-8be5-338f0f6f06b9: addNew group-68E1EC73325C:[6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858] returns group-68E1EC73325C:java.util.concurrent.CompletableFuture@57450f12[Not completed]
datanode_1_1  | 2020-07-11 13:00:46,771 [pool-19-thread-1] INFO impl.RoleInfo: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: start FollowerState
datanode_4_1  | 2020-07-11 13:00:44,066 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO impl.LeaderElection: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2: begin an election at term 1 for -1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
datanode_5_1  | 2020-07-11 13:00:43,205 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-07-11 13:00:36,776 [pool-19-thread-1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9: new RaftServerImpl for group-68E1EC73325C:[6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-07-11 13:00:46,803 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3EE7DF2A6792,id=0e925a4a-a3be-400e-ae7d-aecf7064f65c
datanode_4_1  | 2020-07-11 13:00:44,082 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
datanode_5_1  | 2020-07-11 13:00:43,242 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-11 13:00:36,777 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-07-11 13:00:46,822 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792
datanode_4_1  | 2020-07-11 13:00:44,104 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
datanode_5_1  | 2020-07-11 13:00:43,249 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-07-11 13:00:36,794 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-07-11 13:00:47,681 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3EE7DF2A6792 with new leaderId: 6e333534-afe2-4f15-8be5-338f0f6f06b9
datanode_4_1  | 2020-07-11 13:00:44,290 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
datanode_5_1  | 2020-07-11 13:00:43,267 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-07-11 13:00:36,794 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-07-11 13:00:47,698 [grpc-default-executor-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792: change Leader from null to 6e333534-afe2-4f15-8be5-338f0f6f06b9 at term 1 for appendEntries, leader elected after 1871ms
datanode_4_1  | 2020-07-11 13:00:44,293 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_5_1  | 2020-07-11 13:00:43,270 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-11 13:00:43,757 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792
datanode_1_1  | 2020-07-11 13:00:47,731 [grpc-default-executor-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
datanode_5_1  | 2020-07-11 13:00:43,826 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792
datanode_6_1  | 2020-07-11 13:00:36,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-11 13:00:44,308 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_5_1  | 2020-07-11 13:00:43,895 [pool-19-thread-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792: start as a follower, conf=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null
datanode_1_1  | 2020-07-11 13:00:47,739 [grpc-default-executor-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792: inconsistency entries. Reply:6e333534-afe2-4f15-8be5-338f0f6f06b9<-0e925a4a-a3be-400e-ae7d-aecf7064f65c#2:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_6_1  | 2020-07-11 13:00:36,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-11 13:00:44,592 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_5_1  | 2020-07-11 13:00:43,905 [pool-19-thread-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-07-11 13:00:47,830 [grpc-default-executor-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792: set configuration 0: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null at 0
datanode_1_1  | 2020-07-11 13:00:47,862 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-07-11 13:00:44,608 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_5_1  | 2020-07-11 13:00:43,921 [pool-19-thread-1] INFO impl.RoleInfo: e67d091a-1583-4527-8ecf-5d5225cc2732: start FollowerState
datanode_6_1  | 2020-07-11 13:00:36,848 [pool-19-thread-1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C: ConfigurationManager, init=-1: [6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-07-11 13:00:48,084 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-3EE7DF2A6792-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792/current/log_inprogress_0
datanode_4_1  | 2020-07-11 13:00:44,610 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_5_1  | 2020-07-11 13:00:43,986 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3EE7DF2A6792,id=e67d091a-1583-4527-8ecf-5d5225cc2732
datanode_6_1  | 2020-07-11 13:00:36,862 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-11 13:01:05,658 [Command processor thread] INFO impl.RaftServerProxy: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: addNew group-8C2A79EAC89F:[0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858] returns group-8C2A79EAC89F:java.util.concurrent.CompletableFuture@d6dce5[Not completed]
datanode_4_1  | 2020-07-11 13:00:44,960 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO impl.LeaderElection: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2: Election PASSED; received 1 response(s) [778068fc-db62-4104-91e2-4af6f16647b1<-625dea95-7dac-4161-bb51-3704ae488e41#0:OK-t1] and 0 exception(s); 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7:t1, leader=null, voted=778068fc-db62-4104-91e2-4af6f16647b1, raftlog=778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_5_1  | 2020-07-11 13:00:43,989 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792
datanode_6_1  | 2020-07-11 13:00:36,905 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-07-11 13:01:05,661 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: new RaftServerImpl for group-8C2A79EAC89F:[0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-11 13:00:44,973 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: shutdown LeaderElection
scm_1         | 2020-07-11 13:00:30,996 [IPC Server handler 10 on default port 9861] WARN ipc.Server: IPC Server handler 10 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.4:36546: output error
datanode_5_1  | 2020-07-11 13:00:44,289 [grpc-default-executor-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:6e333534-afe2-4f15-8be5-338f0f6f06b9
datanode_6_1  | 2020-07-11 13:00:36,907 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7b1dab79-16bb-42ca-8378-68e1ec73325c does not exist. Creating ...
datanode_1_1  | 2020-07-11 13:01:05,662 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-07-11 13:00:44,974 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1         | 2020-07-11 13:00:30,996 [IPC Server handler 10 on default port 9861] INFO ipc.Server: IPC Server handler 10 on default port 9861 caught an exception
datanode_5_1  | 2020-07-11 13:00:44,334 [grpc-default-executor-1] INFO impl.RoleInfo: e67d091a-1583-4527-8ecf-5d5225cc2732: shutdown FollowerState
datanode_6_1  | 2020-07-11 13:00:36,952 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7b1dab79-16bb-42ca-8378-68e1ec73325c/in_use.lock acquired by nodename 6@d1b8ef127e89
datanode_1_1  | 2020-07-11 13:01:05,662 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-07-11 13:00:44,974 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-935C756C8BF7 with new leaderId: 778068fc-db62-4104-91e2-4af6f16647b1
scm_1         | java.nio.channels.AsynchronousCloseException
datanode_5_1  | 2020-07-11 13:00:44,335 [Thread-23] INFO impl.FollowerState: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 2020-07-11 13:00:36,970 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7b1dab79-16bb-42ca-8378-68e1ec73325c has been successfully formatted.
datanode_1_1  | 2020-07-11 13:01:05,663 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-07-11 13:00:44,976 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7: change Leader from null to 778068fc-db62-4104-91e2-4af6f16647b1 at term 1 for becomeLeader, leader elected after 6106ms
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_5_1  | 2020-07-11 13:00:44,347 [grpc-default-executor-1] INFO impl.RoleInfo: e67d091a-1583-4527-8ecf-5d5225cc2732: start FollowerState
datanode_6_1  | 2020-07-11 13:00:37,015 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-68E1EC73325C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-07-11 13:01:05,663 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-11 13:00:44,980 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
datanode_5_1  | 2020-07-11 13:00:45,142 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3EE7DF2A6792 with new leaderId: 6e333534-afe2-4f15-8be5-338f0f6f06b9
datanode_6_1  | 2020-07-11 13:00:37,025 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-07-11 13:01:05,663 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-11 13:00:44,980 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
datanode_5_1  | 2020-07-11 13:00:45,147 [grpc-default-executor-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792: change Leader from null to 6e333534-afe2-4f15-8be5-338f0f6f06b9 at term 1 for appendEntries, leader elected after 2576ms
datanode_6_1  | 2020-07-11 13:00:37,040 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-07-11 13:01:05,663 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F: ConfigurationManager, init=-1: [0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-11 13:00:44,981 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
datanode_5_1  | 2020-07-11 13:00:45,288 [grpc-default-executor-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792: set configuration 0: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-07-11 13:00:37,102 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-07-11 13:01:05,664 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-11 13:00:44,983 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_5_1  | 2020-07-11 13:00:45,403 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-11 13:00:37,102 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-11 13:01:05,670 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-11 13:00:44,984 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
datanode_5_1  | 2020-07-11 13:00:45,749 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e67d091a-1583-4527-8ecf-5d5225cc2732@group-3EE7DF2A6792-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792/current/log_inprogress_0
datanode_6_1  | 2020-07-11 13:00:37,105 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-11 13:01:05,670 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/55c3f3df-cd99-44a2-8365-8c2a79eac89f does not exist. Creating ...
datanode_4_1  | 2020-07-11 13:00:44,990 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
datanode_5_1  | 2020-07-11 13:01:05,795 [pool-19-thread-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732: new RaftServerImpl for group-0F657835F368:[e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-07-11 13:00:37,140 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C
datanode_1_1  | 2020-07-11 13:01:05,674 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/55c3f3df-cd99-44a2-8365-8c2a79eac89f/in_use.lock acquired by nodename 6@c6927fdffdce
datanode_4_1  | 2020-07-11 13:00:44,993 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
datanode_5_1  | 2020-07-11 13:01:05,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-07-11 13:00:37,339 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-11 13:01:05,680 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/55c3f3df-cd99-44a2-8365-8c2a79eac89f has been successfully formatted.
datanode_4_1  | 2020-07-11 13:00:44,994 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
datanode_5_1  | 2020-07-11 13:01:05,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-07-11 13:00:37,420 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7b1dab79-16bb-42ca-8378-68e1ec73325c
datanode_1_1  | 2020-07-11 13:01:05,681 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-8C2A79EAC89F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-07-11 13:00:45,118 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: start LeaderState
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_5_1  | 2020-07-11 13:01:05,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-07-11 13:00:37,439 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-07-11 13:01:05,681 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-07-11 13:00:45,124 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
datanode_5_1  | 2020-07-11 13:01:05,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-11 13:00:37,444 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-11 13:01:05,681 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-07-11 13:00:45,162 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_6_1  | 2020-07-11 13:00:37,453 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-11 13:01:05,682 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-07-11 13:01:05,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-11 13:00:45,166 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_6_1  | 2020-07-11 13:00:37,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-07-11 13:01:05,682 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-11 13:01:05,796 [pool-19-thread-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368: ConfigurationManager, init=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-11 13:00:45,217 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_6_1  | 2020-07-11 13:00:37,467 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-11 13:01:05,682 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-11 13:01:05,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-11 13:00:45,250 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_6_1  | 2020-07-11 13:00:37,468 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-07-11 13:01:05,682 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F
datanode_5_1  | 2020-07-11 13:01:05,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-11 13:00:45,263 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_6_1  | 2020-07-11 13:00:37,482 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-11 13:00:37,485 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-07-11 13:01:05,683 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-11 13:01:05,683 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/55c3f3df-cd99-44a2-8365-8c2a79eac89f
datanode_4_1  | 2020-07-11 13:00:45,264 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7
datanode_6_1  | 2020-07-11 13:00:37,487 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-07-11 13:01:05,800 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4499f761-518c-41a9-b17e-0f657835f368 does not exist. Creating ...
datanode_1_1  | 2020-07-11 13:01:05,683 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-07-11 13:00:45,395 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1         | 2020-07-11 13:00:30,996 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:43416: output error
datanode_6_1  | 2020-07-11 13:00:37,625 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-07-11 13:01:05,809 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4499f761-518c-41a9-b17e-0f657835f368/in_use.lock acquired by nodename 6@ae22b1cc5a40
datanode_1_1  | 2020-07-11 13:01:05,683 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-11 13:00:45,399 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-11 13:01:05,684 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-11 13:00:37,706 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-11 13:01:05,814 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4499f761-518c-41a9-b17e-0f657835f368 has been successfully formatted.
scm_1         | 2020-07-11 13:00:31,011 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
datanode_4_1  | 2020-07-11 13:00:45,402 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1_1  | 2020-07-11 13:01:05,684 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-11 13:00:37,707 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-11 13:01:05,825 [Command processor thread] INFO impl.RaftServerProxy: e67d091a-1583-4527-8ecf-5d5225cc2732: addNew group-0F657835F368:[e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858] returns group-0F657835F368:java.util.concurrent.CompletableFuture@3f4f6ad6[Not completed]
scm_1         | java.nio.channels.AsynchronousCloseException
datanode_4_1  | 2020-07-11 13:00:45,403 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-07-11 13:01:05,684 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-11 13:01:05,684 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-07-11 13:00:37,746 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-07-11 13:01:05,841 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0F657835F368: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-07-11 13:01:05,841 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-07-11 13:01:05,685 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-07-11 13:00:45,414 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-07-11 13:00:37,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-07-11 13:01:05,841 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_1_1  | 2020-07-11 13:01:05,685 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-07-11 13:00:45,414 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-11 13:00:37,770 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-07-11 13:01:05,841 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
datanode_1_1  | 2020-07-11 13:01:05,686 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-07-11 13:00:45,465 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO impl.RoleInfo: 778068fc-db62-4104-91e2-4af6f16647b1: start LeaderState
datanode_6_1  | 2020-07-11 13:00:37,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-07-11 13:01:05,850 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
datanode_1_1  | 2020-07-11 13:01:05,688 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-07-11 13:00:45,479 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-11 13:00:37,818 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-11 13:01:05,850 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
datanode_1_1  | 2020-07-11 13:01:05,700 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-11 13:00:45,526 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-11 13:00:38,016 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C
datanode_5_1  | 2020-07-11 13:01:05,850 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_1_1  | 2020-07-11 13:01:05,703 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-11 13:00:45,738 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-LeaderElection2] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7: set configuration 0: [625dea95-7dac-4161-bb51-3704ae488e41:10.5.0.5:9858, 778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858, 3a24eea4-be0f-479e-b9a5-49c648d4b7fb:10.5.0.6:9858], old=null at 0
datanode_6_1  | 2020-07-11 13:00:38,059 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C
datanode_5_1  | 2020-07-11 13:01:05,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
datanode_1_1  | 2020-07-11 13:01:05,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-07-11 13:00:45,743 [grpc-default-executor-1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-   LEADER: Withhold vote from candidate 3a24eea4-be0f-479e-b9a5-49c648d4b7fb with term 1. State: leader=778068fc-db62-4104-91e2-4af6f16647b1, term=1, lastRpcElapsed=null
datanode_6_1  | 2020-07-11 13:00:38,073 [pool-19-thread-1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C: start as a follower, conf=-1: [6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null
datanode_5_1  | 2020-07-11 13:01:05,851 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/4499f761-518c-41a9-b17e-0f657835f368
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
datanode_1_1  | 2020-07-11 13:01:05,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-07-11 13:00:45,768 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-LeaderElection1] INFO impl.RaftServerImpl: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0: set configuration 0: [778068fc-db62-4104-91e2-4af6f16647b1:10.5.0.7:9858], old=null at 0
datanode_6_1  | 2020-07-11 13:00:38,119 [pool-19-thread-1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-07-11 13:01:05,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
datanode_1_1  | 2020-07-11 13:01:05,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-07-11 13:00:46,346 [778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 778068fc-db62-4104-91e2-4af6f16647b1@group-B4881F4B13D0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/1bfd57a4-1af7-4204-8a51-b4881f4b13d0/current/log_inprogress_0
datanode_6_1  | 2020-07-11 13:00:38,139 [pool-19-thread-1] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: start FollowerState
datanode_5_1  | 2020-07-11 13:01:05,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
datanode_1_1  | 2020-07-11 13:01:05,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-07-11 13:00:46,350 [778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 778068fc-db62-4104-91e2-4af6f16647b1@group-935C756C8BF7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c0d3e745-7f7a-4b01-abb7-935c756c8bf7/current/log_inprogress_0
datanode_6_1  | 2020-07-11 13:00:38,266 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-68E1EC73325C,id=6e333534-afe2-4f15-8be5-338f0f6f06b9
datanode_5_1  | 2020-07-11 13:01:05,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_1_1  | 2020-07-11 13:01:05,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-07-11 13:00:38,270 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
datanode_1_1  | 2020-07-11 13:01:05,722 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F
datanode_5_1  | 2020-07-11 13:01:05,852 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-11 13:00:38,480 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "7b1dab79-16bb-42ca-8378-68e1ec73325c"
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_5_1  | 2020-07-11 13:01:05,852 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | uuid128 {
datanode_1_1  | 2020-07-11 13:01:05,723 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F
datanode_1_1  | 2020-07-11 13:01:05,724 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F: start as a follower, conf=-1: [0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858], old=null
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_6_1  |   mostSigBits: 8871435377550508746
datanode_5_1  | 2020-07-11 13:01:05,852 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1_1  | 2020-07-11 13:01:05,726 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  |   leastSigBits: -8973306937991810468
datanode_5_1  | 2020-07-11 13:01:05,855 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_1_1  | 2020-07-11 13:01:05,726 [pool-19-thread-1] INFO impl.RoleInfo: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: start FollowerState
datanode_6_1  | }
datanode_6_1  | .
scm_1         | 2020-07-11 13:00:31,012 [IPC Server handler 3 on default port 9861] WARN ipc.Server: IPC Server handler 3 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:60936: output error
datanode_1_1  | 2020-07-11 13:01:05,727 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C2A79EAC89F,id=0e925a4a-a3be-400e-ae7d-aecf7064f65c
datanode_6_1  | 2020-07-11 13:00:38,490 [Command processor thread] INFO impl.RaftServerProxy: 6e333534-afe2-4f15-8be5-338f0f6f06b9: addNew group-3EE7DF2A6792:[e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858] returns group-3EE7DF2A6792:java.util.concurrent.CompletableFuture@72a51a42[Not completed]
datanode_5_1  | 2020-07-11 13:01:05,858 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1         | 2020-07-11 13:00:31,012 [IPC Server handler 3 on default port 9861] INFO ipc.Server: IPC Server handler 3 on default port 9861 caught an exception
datanode_1_1  | 2020-07-11 13:01:05,744 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F
datanode_6_1  | 2020-07-11 13:00:38,503 [pool-19-thread-1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9: new RaftServerImpl for group-3EE7DF2A6792:[e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-07-11 13:01:05,858 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1         | java.nio.channels.AsynchronousCloseException
datanode_1_1  | 2020-07-11 13:01:05,809 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "55c3f3df-cd99-44a2-8365-8c2a79eac89f"
datanode_6_1  | 2020-07-11 13:00:38,512 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-07-11 13:01:05,859 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_1_1  | uuid128 {
datanode_1_1  |   mostSigBits: 6180051256235082914
datanode_5_1  | 2020-07-11 13:01:05,865 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
datanode_1_1  |   leastSigBits: -8978616168031270753
datanode_6_1  | 2020-07-11 13:00:38,522 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-11 13:01:05,865 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
datanode_1_1  | }
datanode_6_1  | 2020-07-11 13:00:38,528 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-07-11 13:01:05,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
datanode_1_1  | .
datanode_6_1  | 2020-07-11 13:00:38,528 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-07-11 13:01:05,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_1_1  | 2020-07-11 13:01:10,809 [Thread-36] INFO impl.FollowerState: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-FollowerState: change to CANDIDATE, lastRpcTime:5082ms, electionTimeout:5065ms
datanode_6_1  | 2020-07-11 13:00:38,528 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-11 13:01:05,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
datanode_1_1  | 2020-07-11 13:01:10,810 [Thread-36] INFO impl.RoleInfo: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: shutdown FollowerState
datanode_6_1  | 2020-07-11 13:00:38,528 [pool-19-thread-1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792: ConfigurationManager, init=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-07-11 13:01:05,932 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
datanode_1_1  | 2020-07-11 13:01:10,810 [Thread-36] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-07-11 13:00:38,529 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-11 13:01:05,932 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
datanode_1_1  | 2020-07-11 13:01:10,814 [Thread-36] INFO impl.RoleInfo: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: start LeaderElection
datanode_6_1  | 2020-07-11 13:00:38,538 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-07-11 13:01:05,938 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
datanode_1_1  | 2020-07-11 13:01:10,830 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO impl.LeaderElection: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1: begin an election at term 1 for -1: [0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858], old=null
datanode_1_1  | 2020-07-11 13:01:10,834 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO impl.RoleInfo: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: shutdown LeaderElection
datanode_5_1  | 2020-07-11 13:01:05,939 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_1_1  | 2020-07-11 13:01:10,834 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-07-11 13:00:38,538 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792 does not exist. Creating ...
datanode_5_1  | 2020-07-11 13:01:05,940 [pool-19-thread-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368: start as a follower, conf=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858], old=null
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
datanode_1_1  | 2020-07-11 13:01:10,834 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8C2A79EAC89F with new leaderId: 0e925a4a-a3be-400e-ae7d-aecf7064f65c
datanode_6_1  | 2020-07-11 13:00:38,549 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792/in_use.lock acquired by nodename 6@d1b8ef127e89
datanode_5_1  | 2020-07-11 13:01:05,943 [pool-19-thread-1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-07-11 13:01:05,944 [pool-19-thread-1] INFO impl.RoleInfo: e67d091a-1583-4527-8ecf-5d5225cc2732: start FollowerState
datanode_6_1  | 2020-07-11 13:00:38,562 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792 has been successfully formatted.
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_1_1  | 2020-07-11 13:01:10,838 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F: change Leader from null to 0e925a4a-a3be-400e-ae7d-aecf7064f65c at term 1 for becomeLeader, leader elected after 5153ms
datanode_5_1  | 2020-07-11 13:01:05,946 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F657835F368,id=e67d091a-1583-4527-8ecf-5d5225cc2732
datanode_6_1  | 2020-07-11 13:00:38,563 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3EE7DF2A6792: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1_1  | 2020-07-11 13:01:10,842 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-07-11 13:01:05,947 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368
datanode_6_1  | 2020-07-11 13:00:38,567 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1_1  | 2020-07-11 13:01:10,843 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-07-11 13:01:05,952 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "4499f761-518c-41a9-b17e-0f657835f368"
datanode_6_1  | 2020-07-11 13:00:38,568 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1_1  | 2020-07-11 13:01:10,845 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F
datanode_5_1  | uuid128 {
datanode_6_1  | 2020-07-11 13:00:38,571 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_1_1  | 2020-07-11 13:01:10,847 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-11 13:01:10,848 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
scm_1         | 2020-07-11 13:00:32,076 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@69f9b561{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-12070125231779787518.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
datanode_5_1  |   mostSigBits: 4943254063367864745
datanode_1_1  | 2020-07-11 13:01:10,856 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-07-11 13:00:38,575 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1         | 2020-07-11 13:00:32,270 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@34009349{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
datanode_5_1  |   leastSigBits: -5657067153447849112
datanode_1_1  | 2020-07-11 13:01:10,856 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-07-11 13:00:38,575 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 2020-07-11 13:00:32,277 [Listener at 0.0.0.0/9860] INFO server.Server: Started @16180ms
datanode_5_1  | }
datanode_1_1  | 2020-07-11 13:01:10,857 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-07-11 13:00:38,575 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792
scm_1         | 2020-07-11 13:00:32,360 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | .
datanode_1_1  | 2020-07-11 13:01:10,865 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO impl.RoleInfo: 0e925a4a-a3be-400e-ae7d-aecf7064f65c: start LeaderState
datanode_6_1  | 2020-07-11 13:00:38,578 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1         | 2020-07-11 13:00:32,360 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-07-11 13:01:10,983 [Thread-38] INFO impl.FollowerState: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-FollowerState: change to CANDIDATE, lastRpcTime:5039ms, electionTimeout:5036ms
datanode_1_1  | 2020-07-11 13:01:10,869 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-11 13:00:38,578 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792
scm_1         | 2020-07-11 13:00:32,371 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
datanode_5_1  | 2020-07-11 13:01:10,984 [Thread-38] INFO impl.RoleInfo: e67d091a-1583-4527-8ecf-5d5225cc2732: shutdown FollowerState
datanode_1_1  | 2020-07-11 13:01:10,871 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/55c3f3df-cd99-44a2-8365-8c2a79eac89f/current/log_inprogress_0
datanode_6_1  | 2020-07-11 13:00:38,579 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
scm_1         | 2020-07-11 13:00:32,522 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@678586f0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-07-11 13:01:10,984 [Thread-38] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-07-11 13:01:10,988 [Thread-38] INFO impl.RoleInfo: e67d091a-1583-4527-8ecf-5d5225cc2732: start LeaderElection
datanode_6_1  | 2020-07-11 13:00:38,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-11 13:01:10,875 [0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F-LeaderElection1] INFO impl.RaftServerImpl: 0e925a4a-a3be-400e-ae7d-aecf7064f65c@group-8C2A79EAC89F: set configuration 0: [0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858], old=null at 0
datanode_6_1  | 2020-07-11 13:00:38,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 2020-07-11 13:00:33,223 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/0e925a4a-a3be-400e-ae7d-aecf7064f65c
datanode_5_1  | 2020-07-11 13:01:10,995 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO impl.LeaderElection: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1: begin an election at term 1 for -1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858], old=null
datanode_6_1  | 2020-07-11 13:00:38,590 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1         | 2020-07-11 13:00:33,223 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0e925a4a-a3be-400e-ae7d-aecf7064f65c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_5_1  | 2020-07-11 13:01:10,997 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO impl.RoleInfo: e67d091a-1583-4527-8ecf-5d5225cc2732: shutdown LeaderElection
datanode_6_1  | 2020-07-11 13:00:38,590 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
scm_1         | 2020-07-11 13:00:33,224 [IPC Server handler 95 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/e67d091a-1583-4527-8ecf-5d5225cc2732
datanode_5_1  | 2020-07-11 13:01:10,997 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-07-11 13:01:10,997 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0F657835F368 with new leaderId: e67d091a-1583-4527-8ecf-5d5225cc2732
datanode_6_1  | 2020-07-11 13:00:38,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1         | 2020-07-11 13:00:33,238 [IPC Server handler 95 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e67d091a-1583-4527-8ecf-5d5225cc2732{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_5_1  | 2020-07-11 13:01:10,997 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368: change Leader from null to e67d091a-1583-4527-8ecf-5d5225cc2732 at term 1 for becomeLeader, leader elected after 5156ms
datanode_6_1  | 2020-07-11 13:00:38,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1         | 2020-07-11 13:00:33,225 [IPC Server handler 97 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/625dea95-7dac-4161-bb51-3704ae488e41
datanode_6_1  | 2020-07-11 13:00:38,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1         | 2020-07-11 13:00:33,244 [IPC Server handler 97 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 625dea95-7dac-4161-bb51-3704ae488e41{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_5_1  | 2020-07-11 13:01:11,002 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-07-11 13:00:38,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1         | 2020-07-11 13:00:33,250 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
datanode_5_1  | 2020-07-11 13:01:11,002 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-07-11 13:00:38,609 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1         | 2020-07-11 13:00:33,283 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
datanode_5_1  | 2020-07-11 13:01:11,009 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368
datanode_6_1  | 2020-07-11 13:00:38,617 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1         | 2020-07-11 13:00:33,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
datanode_5_1  | 2020-07-11 13:01:11,013 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-11 13:00:38,618 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1         | 2020-07-11 13:00:33,285 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_5_1  | 2020-07-11 13:01:11,013 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-07-11 13:00:38,630 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1         | 2020-07-11 13:00:33,410 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_6_1  | 2020-07-11 13:00:38,630 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-11 13:00:38,631 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-07-11 13:01:11,020 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-07-11 13:00:38,632 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1         | 2020-07-11 13:00:33,413 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_5_1  | 2020-07-11 13:01:11,020 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-07-11 13:00:38,632 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1         | 2020-07-11 13:00:33,543 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4499f761-518c-41a9-b17e-0f657835f368 to datanode:e67d091a-1583-4527-8ecf-5d5225cc2732
datanode_5_1  | 2020-07-11 13:01:11,021 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-07-11 13:00:38,632 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792
scm_1         | 2020-07-11 13:00:33,602 [IPC Server handler 14 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/6e333534-afe2-4f15-8be5-338f0f6f06b9
datanode_5_1  | 2020-07-11 13:01:11,030 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO impl.RoleInfo: e67d091a-1583-4527-8ecf-5d5225cc2732: start LeaderState
datanode_6_1  | 2020-07-11 13:00:38,634 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792
scm_1         | 2020-07-11 13:00:33,602 [IPC Server handler 14 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6e333534-afe2-4f15-8be5-338f0f6f06b9{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_5_1  | 2020-07-11 13:01:11,033 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-11 13:00:38,636 [pool-19-thread-1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792: start as a follower, conf=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null
scm_1         | 2020-07-11 13:00:33,602 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_5_1  | 2020-07-11 13:01:11,034 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-LeaderElection1] INFO impl.RaftServerImpl: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368: set configuration 0: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858], old=null at 0
datanode_6_1  | 2020-07-11 13:00:38,643 [pool-19-thread-1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1         | 2020-07-11 13:00:33,602 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
datanode_5_1  | 2020-07-11 13:01:11,035 [e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e67d091a-1583-4527-8ecf-5d5225cc2732@group-0F657835F368-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4499f761-518c-41a9-b17e-0f657835f368/current/log_inprogress_0
datanode_6_1  | 2020-07-11 13:00:38,648 [pool-19-thread-1] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: start FollowerState
scm_1         | 2020-07-11 13:00:33,682 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
datanode_6_1  | 2020-07-11 13:00:38,677 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3EE7DF2A6792,id=6e333534-afe2-4f15-8be5-338f0f6f06b9
scm_1         | 2020-07-11 13:00:33,682 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
datanode_6_1  | 2020-07-11 13:00:38,677 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792
scm_1         | 2020-07-11 13:00:33,764 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 4499f761-518c-41a9-b17e-0f657835f368, Nodes: e67d091a-1583-4527-8ecf-5d5225cc2732{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-11T13:00:33.525811Z]
datanode_6_1  | 2020-07-11 13:00:42,907 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for e67d091a-1583-4527-8ecf-5d5225cc2732{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-11 13:00:33,892 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=55c3f3df-cd99-44a2-8365-8c2a79eac89f to datanode:0e925a4a-a3be-400e-ae7d-aecf7064f65c
datanode_6_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.780114220s. [buffered_nanos=1732304530, remote_addr=/10.5.0.8:9858]
scm_1         | 2020-07-11 13:00:33,893 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 55c3f3df-cd99-44a2-8365-8c2a79eac89f, Nodes: 0e925a4a-a3be-400e-ae7d-aecf7064f65c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-11T13:00:33.892332Z]
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
scm_1         | 2020-07-11 13:00:33,902 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2ad4cb44-feeb-494b-b0df-fe7b82afe6a9 to datanode:625dea95-7dac-4161-bb51-3704ae488e41
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
scm_1         | 2020-07-11 13:00:33,911 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2ad4cb44-feeb-494b-b0df-fe7b82afe6a9, Nodes: 625dea95-7dac-4161-bb51-3704ae488e41{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-11T13:00:33.902917Z]
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
scm_1         | 2020-07-11 13:00:33,918 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7b1dab79-16bb-42ca-8378-68e1ec73325c to datanode:6e333534-afe2-4f15-8be5-338f0f6f06b9
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
scm_1         | 2020-07-11 13:00:33,925 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7b1dab79-16bb-42ca-8378-68e1ec73325c, Nodes: 6e333534-afe2-4f15-8be5-338f0f6f06b9{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-11T13:00:33.918635Z]
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
scm_1         | 2020-07-11 13:00:33,949 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 4 nodes. Healthy nodes 4
datanode_6_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
scm_1         | 2020-07-11 13:00:33,953 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a3f6370e-233d-4d20-9e11-3ee7df2a6792 to datanode:e67d091a-1583-4527-8ecf-5d5225cc2732
datanode_6_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
scm_1         | 2020-07-11 13:00:33,963 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a3f6370e-233d-4d20-9e11-3ee7df2a6792 to datanode:0e925a4a-a3be-400e-ae7d-aecf7064f65c
scm_1         | 2020-07-11 13:00:33,974 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a3f6370e-233d-4d20-9e11-3ee7df2a6792 to datanode:6e333534-afe2-4f15-8be5-338f0f6f06b9
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
scm_1         | 2020-07-11 13:00:33,976 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a3f6370e-233d-4d20-9e11-3ee7df2a6792, Nodes: e67d091a-1583-4527-8ecf-5d5225cc2732{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}0e925a4a-a3be-400e-ae7d-aecf7064f65c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}6e333534-afe2-4f15-8be5-338f0f6f06b9{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-11T13:00:33.953805Z]
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
scm_1         | 2020-07-11 13:00:33,979 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 1
scm_1         | 2020-07-11 13:00:34,325 [IPC Server handler 16 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/3a24eea4-be0f-479e-b9a5-49c648d4b7fb
scm_1         | 2020-07-11 13:00:34,330 [IPC Server handler 16 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3a24eea4-be0f-479e-b9a5-49c648d4b7fb{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_6_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
scm_1         | 2020-07-11 13:00:34,333 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_6_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
scm_1         | 2020-07-11 13:00:34,333 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
scm_1         | 2020-07-11 13:00:34,328 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=be63d3e2-2f7a-45fd-9815-1e47685a59f3 to datanode:3a24eea4-be0f-479e-b9a5-49c648d4b7fb
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
scm_1         | 2020-07-11 13:00:34,351 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: be63d3e2-2f7a-45fd-9815-1e47685a59f3, Nodes: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-11T13:00:34.328207Z]
scm_1         | 2020-07-11 13:00:34,370 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
scm_1         | 2020-07-11 13:00:34,375 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 2
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
scm_1         | 2020-07-11 13:00:34,559 [IPC Server handler 14 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/778068fc-db62-4104-91e2-4af6f16647b1
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
scm_1         | 2020-07-11 13:00:34,561 [IPC Server handler 14 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 778068fc-db62-4104-91e2-4af6f16647b1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
scm_1         | 2020-07-11 13:00:34,560 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=1bfd57a4-1af7-4204-8a51-b4881f4b13d0 to datanode:778068fc-db62-4104-91e2-4af6f16647b1
datanode_6_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
scm_1         | 2020-07-11 13:00:34,562 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 1bfd57a4-1af7-4204-8a51-b4881f4b13d0, Nodes: 778068fc-db62-4104-91e2-4af6f16647b1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-11T13:00:34.560901Z]
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 2020-07-11 13:00:34,562 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
scm_1         | 2020-07-11 13:00:34,563 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-07-11 13:00:34,564 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
datanode_6_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.780114220s. [buffered_nanos=1732304530, remote_addr=/10.5.0.8:9858]
scm_1         | 2020-07-11 13:00:34,564 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c0d3e745-7f7a-4b01-abb7-935c756c8bf7 to datanode:625dea95-7dac-4161-bb51-3704ae488e41
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
scm_1         | 2020-07-11 13:00:34,564 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c0d3e745-7f7a-4b01-abb7-935c756c8bf7 to datanode:778068fc-db62-4104-91e2-4af6f16647b1
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
scm_1         | 2020-07-11 13:00:34,564 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c0d3e745-7f7a-4b01-abb7-935c756c8bf7 to datanode:3a24eea4-be0f-479e-b9a5-49c648d4b7fb
scm_1         | 2020-07-11 13:00:34,565 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c0d3e745-7f7a-4b01-abb7-935c756c8bf7, Nodes: 625dea95-7dac-4161-bb51-3704ae488e41{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}778068fc-db62-4104-91e2-4af6f16647b1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}3a24eea4-be0f-479e-b9a5-49c648d4b7fb{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-11T13:00:34.564613Z]
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
scm_1         | 2020-07-11 13:00:34,568 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_6_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
scm_1         | 2020-07-11 13:00:38,113 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 7b1dab79-16bb-42ca-8378-68e1ec73325c, Nodes: 6e333534-afe2-4f15-8be5-338f0f6f06b9{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6e333534-afe2-4f15-8be5-338f0f6f06b9, CreationTimestamp2020-07-11T13:00:33.918635Z] moved to OPEN state
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
scm_1         | 2020-07-11 13:00:38,135 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_6_1  | 	... 18 more
scm_1         | 2020-07-11 13:00:38,152 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_6_1  | 2020-07-11 13:00:43,292 [Thread-24] INFO impl.FollowerState: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-FollowerState: change to CANDIDATE, lastRpcTime:5152ms, electionTimeout:5116ms
scm_1         | 2020-07-11 13:00:38,744 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: be63d3e2-2f7a-45fd-9815-1e47685a59f3, Nodes: 3a24eea4-be0f-479e-b9a5-49c648d4b7fb{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:3a24eea4-be0f-479e-b9a5-49c648d4b7fb, CreationTimestamp2020-07-11T13:00:34.328207Z] moved to OPEN state
datanode_6_1  | 2020-07-11 13:00:43,299 [Thread-24] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: shutdown FollowerState
scm_1         | 2020-07-11 13:00:38,754 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_6_1  | 2020-07-11 13:00:43,300 [Thread-24] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1         | 2020-07-11 13:00:38,762 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_6_1  | 2020-07-11 13:00:43,306 [Thread-24] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: start LeaderElection
scm_1         | 2020-07-11 13:00:38,767 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 1bfd57a4-1af7-4204-8a51-b4881f4b13d0, Nodes: 778068fc-db62-4104-91e2-4af6f16647b1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:778068fc-db62-4104-91e2-4af6f16647b1, CreationTimestamp2020-07-11T13:00:34.560901Z] moved to OPEN state
datanode_6_1  | 2020-07-11 13:00:43,326 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO impl.LeaderElection: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1: begin an election at term 1 for -1: [6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null
scm_1         | 2020-07-11 13:00:38,772 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_6_1  | 2020-07-11 13:00:43,328 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: shutdown LeaderElection
scm_1         | 2020-07-11 13:00:38,776 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-11 13:00:45,153 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c0d3e745-7f7a-4b01-abb7-935c756c8bf7, Nodes: 625dea95-7dac-4161-bb51-3704ae488e41{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}778068fc-db62-4104-91e2-4af6f16647b1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}3a24eea4-be0f-479e-b9a5-49c648d4b7fb{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:778068fc-db62-4104-91e2-4af6f16647b1, CreationTimestamp2020-07-11T13:00:34.564613Z] moved to OPEN state
datanode_6_1  | 2020-07-11 13:00:43,335 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1         | 2020-07-11 13:00:45,161 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
datanode_6_1  | 2020-07-11 13:00:43,335 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-68E1EC73325C with new leaderId: 6e333534-afe2-4f15-8be5-338f0f6f06b9
scm_1         | 2020-07-11 13:00:45,161 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-07-11 13:00:45,161 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode_6_1  | 2020-07-11 13:00:43,337 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C: change Leader from null to 6e333534-afe2-4f15-8be5-338f0f6f06b9 at term 1 for becomeLeader, leader elected after 6311ms
scm_1         | 2020-07-11 13:00:45,166 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
datanode_6_1  | 2020-07-11 13:00:43,361 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1         | 2020-07-11 13:00:45,204 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_6_1  | 2020-07-11 13:00:43,379 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1         | 2020-07-11 13:00:45,221 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode_6_1  | 2020-07-11 13:00:43,391 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C
scm_1         | 2020-07-11 13:00:45,221 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
datanode_6_1  | 2020-07-11 13:00:43,419 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
scm_1         | 2020-07-11 13:00:46,922 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a3f6370e-233d-4d20-9e11-3ee7df2a6792, Nodes: e67d091a-1583-4527-8ecf-5d5225cc2732{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}0e925a4a-a3be-400e-ae7d-aecf7064f65c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}6e333534-afe2-4f15-8be5-338f0f6f06b9{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:6e333534-afe2-4f15-8be5-338f0f6f06b9, CreationTimestamp2020-07-11T13:00:33.953805Z] moved to OPEN state
datanode_6_1  | 2020-07-11 13:00:43,419 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-07-11 13:00:43,480 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
scm_1         | 2020-07-11 13:01:05,756 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 55c3f3df-cd99-44a2-8365-8c2a79eac89f, Nodes: 0e925a4a-a3be-400e-ae7d-aecf7064f65c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:0e925a4a-a3be-400e-ae7d-aecf7064f65c, CreationTimestamp2020-07-11T13:00:33.892332Z] moved to OPEN state
datanode_6_1  | 2020-07-11 13:00:43,482 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1         | 2020-07-11 13:01:05,937 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 4499f761-518c-41a9-b17e-0f657835f368, Nodes: e67d091a-1583-4527-8ecf-5d5225cc2732{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:e67d091a-1583-4527-8ecf-5d5225cc2732, CreationTimestamp2020-07-11T13:00:33.525811Z] moved to OPEN state
datanode_6_1  | 2020-07-11 13:00:43,489 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1         | 2020-07-11 13:01:06,043 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 2ad4cb44-feeb-494b-b0df-fe7b82afe6a9, Nodes: 625dea95-7dac-4161-bb51-3704ae488e41{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:625dea95-7dac-4161-bb51-3704ae488e41, CreationTimestamp2020-07-11T13:00:33.902917Z] moved to OPEN state
datanode_6_1  | 2020-07-11 13:00:43,588 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: start LeaderState
scm_1         | 2020-07-11 13:01:06,236 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:20,847 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:23,508 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:23,862 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:24,006 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:24,129 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:26,723 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:26,845 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:29,459 [IPC Server handler 98 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:29,575 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:29,754 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:29,844 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:29,952 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:32,560 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:35,155 [IPC Server handler 87 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:35,292 [IPC Server handler 82 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:37,913 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:40,517 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:40,628 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:40,750 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:40,862 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:40,981 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:43,632 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:46,238 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:46,420 [IPC Server handler 97 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:46,580 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:49,188 [IPC Server handler 90 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:49,294 [IPC Server handler 79 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:01:51,872 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:43,730 [Thread-26] INFO impl.FollowerState: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-FollowerState: change to CANDIDATE, lastRpcTime:5081ms, electionTimeout:5040ms
scm_1         | 2020-07-11 13:01:54,458 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:43,731 [Thread-26] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: shutdown FollowerState
scm_1         | 2020-07-11 13:01:54,556 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:43,731 [Thread-26] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1         | 2020-07-11 13:01:57,136 [IPC Server handler 37 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:43,732 [Thread-26] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: start LeaderElection
scm_1         | 2020-07-11 13:01:57,234 [IPC Server handler 82 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:43,760 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-SegmentedRaftLogWorker: Starting segment from index:0
scm_1         | 2020-07-11 13:01:57,322 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:43,768 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO impl.LeaderElection: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2: begin an election at term 1 for -1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null
scm_1         | 2020-07-11 13:01:59,904 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:43,979 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-LeaderElection1] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C: set configuration 0: [6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null at 0
scm_1         | 2020-07-11 13:02:00,000 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,480 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-68E1EC73325C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7b1dab79-16bb-42ca-8378-68e1ec73325c/current/log_inprogress_0
datanode_6_1  | 2020-07-11 13:00:44,655 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO impl.LeaderElection: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2: Election PASSED; received 1 response(s) [6e333534-afe2-4f15-8be5-338f0f6f06b9<-e67d091a-1583-4527-8ecf-5d5225cc2732#0:OK-t1] and 0 exception(s); 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792:t1, leader=null, voted=6e333534-afe2-4f15-8be5-338f0f6f06b9, raftlog=6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null
scm_1         | 2020-07-11 13:02:02,589 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,661 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: shutdown LeaderElection
scm_1         | 2020-07-11 13:02:02,680 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,664 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-07-11 13:00:44,665 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3EE7DF2A6792 with new leaderId: 6e333534-afe2-4f15-8be5-338f0f6f06b9
scm_1         | 2020-07-11 13:02:02,810 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,666 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792: change Leader from null to 6e333534-afe2-4f15-8be5-338f0f6f06b9 at term 1 for becomeLeader, leader elected after 6097ms
scm_1         | 2020-07-11 13:02:05,377 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:05,488 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:05,580 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:08,142 [IPC Server handler 87 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:10,709 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:10,846 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:13,419 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,678 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-07-11 13:00:44,684 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1         | 2020-07-11 13:02:16,032 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,688 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792
scm_1         | 2020-07-11 13:02:18,615 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,689 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
scm_1         | 2020-07-11 13:02:21,196 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,691 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
scm_1         | 2020-07-11 13:02:23,782 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,692 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
scm_1         | 2020-07-11 13:02:26,336 [IPC Server handler 74 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,694 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1         | 2020-07-11 13:02:27,850 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
datanode_6_1  | 2020-07-11 13:00:44,699 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1         | 2020-07-11 13:02:27,851 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-11 13:02:28,927 [IPC Server handler 35 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,717 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_6_1  | 2020-07-11 13:00:44,730 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1         | 2020-07-11 13:02:31,503 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,732 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1         | 2020-07-11 13:02:34,088 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-07-11 13:00:44,764 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_6_1  | 2020-07-11 13:00:44,782 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-07-11 13:00:44,783 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-11 13:00:44,798 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792
datanode_6_1  | 2020-07-11 13:00:44,830 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_6_1  | 2020-07-11 13:00:44,863 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-11 13:00:44,864 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_6_1  | 2020-07-11 13:00:44,864 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_6_1  | 2020-07-11 13:00:44,865 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-07-11 13:00:44,865 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-11 13:00:44,917 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO impl.RoleInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9: start LeaderState
datanode_6_1  | 2020-07-11 13:00:44,922 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-11 13:00:44,938 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a3f6370e-233d-4d20-9e11-3ee7df2a6792/current/log_inprogress_0
datanode_6_1  | 2020-07-11 13:00:44,976 [6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792-LeaderElection2] INFO impl.RaftServerImpl: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792: set configuration 0: [e67d091a-1583-4527-8ecf-5d5225cc2732:10.5.0.8:9858, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:10.5.0.4:9858, 6e333534-afe2-4f15-8be5-338f0f6f06b9:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-07-11 13:00:45,930 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 0e925a4a-a3be-400e-ae7d-aecf7064f65c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_6_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.984942840s. [buffered_nanos=1282530026, remote_addr=/10.5.0.4:9858]
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_6_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_6_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_6_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_6_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
scm_1         | 2020-07-11 13:02:36,669 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
scm_1         | 2020-07-11 13:02:36,828 [IPC Server handler 35 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
scm_1         | 2020-07-11 13:02:36,935 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_6_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-07-11 13:02:39,498 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:39,598 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:42,177 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:42,266 [IPC Server handler 79 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:44,838 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:47,435 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:47,498 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:02:50,080 [IPC Server handler 25 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:03:00,175 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:03:05,254 [IPC Server handler 79 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:03:05,294 [IPC Server handler 69 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:03:15,410 [IPC Server handler 67 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:03:20,469 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:03:30,626 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:03:45,756 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:03:50,909 [IPC Server handler 25 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:04:01,052 [IPC Server handler 32 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:04:16,172 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:04:27,852 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-11 13:04:27,852 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-11 13:04:31,294 [IPC Server handler 69 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:04:46,423 [IPC Server handler 55 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:05:01,533 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:05:16,672 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:05:31,793 [IPC Server handler 35 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:05:39,474 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-11 13:05:45,230 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1         | 2020-07-11 13:05:45,245 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5
scm_1         | 2020-07-11 13:05:45,247 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6
scm_1         | 2020-07-11 13:05:45,245 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 12 milliseconds for processing 10 containers.
scm_1         | 2020-07-11 13:05:45,248 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7
scm_1         | 2020-07-11 13:05:45,248 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8
scm_1         | 2020-07-11 13:05:45,248 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9
scm_1         | 2020-07-11 13:05:45,248 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #10
scm_1         | 2020-07-11 13:05:45,249 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1         | 2020-07-11 13:05:45,249 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
datanode_6_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.984942840s. [buffered_nanos=1282530026, remote_addr=/10.5.0.4:9858]
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_6_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
scm_1         | 2020-07-11 13:05:45,249 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
scm_1         | 2020-07-11 13:05:45,249 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
scm_1         | 2020-07-11 13:05:49,596 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 	... 18 more
datanode_6_1  | 2020-07-11 13:00:45,931 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "a3f6370e-233d-4d20-9e11-3ee7df2a6792"
datanode_6_1  | uuid128 {
datanode_6_1  |   mostSigBits: -6632052867396186848
datanode_6_1  |   leastSigBits: -7056789975510390894
datanode_6_1  | }
datanode_6_1  | .
datanode_6_1  | 2020-07-11 13:00:47,817 [grpc-default-executor-0] INFO impl.FollowerInfo: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c: nextIndex: updateUnconditionally 1 -> 0
datanode_6_1  | 2020-07-11 13:01:47,823 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode_6_1  | 2020-07-11 13:02:06,538 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:1)
datanode_6_1  | 2020-07-11 13:02:06,812 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:2)
datanode_6_1  | 2020-07-11 13:02:08,731 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=13,entriesCount=1,lastEntry=(t:1, i:3)
datanode_6_1  | 2020-07-11 13:02:08,740 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:4)
datanode_6_1  | 2020-07-11 13:02:20,929 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:5)
datanode_6_1  | 2020-07-11 13:02:20,949 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:6)
datanode_6_1  | 2020-07-11 13:02:20,956 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:7)
datanode_6_1  | 2020-07-11 13:02:20,981 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:8)
datanode_6_1  | 2020-07-11 13:02:24,153 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:9)
datanode_6_1  | 2020-07-11 13:02:24,169 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:10)
datanode_6_1  | 2020-07-11 13:02:24,176 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:11)
datanode_6_1  | 2020-07-11 13:02:24,192 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:12)
datanode_6_1  | 2020-07-11 13:02:26,878 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=29,entriesCount=1,lastEntry=(t:1, i:13)
datanode_6_1  | 2020-07-11 13:02:26,895 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:14)
datanode_6_1  | 2020-07-11 13:02:26,896 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:15)
datanode_6_1  | 2020-07-11 13:02:26,917 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:16)
datanode_6_1  | 2020-07-11 13:02:29,982 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=34,entriesCount=1,lastEntry=(t:1, i:17)
datanode_6_1  | 2020-07-11 13:02:29,987 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:18)
datanode_6_1  | 2020-07-11 13:02:30,002 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:19)
datanode_6_1  | 2020-07-11 13:02:30,018 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:20)
datanode_6_1  | 2020-07-11 13:02:32,583 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=39,entriesCount=1,lastEntry=(t:1, i:21)
datanode_6_1  | 2020-07-11 13:02:32,598 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:22)
datanode_6_1  | 2020-07-11 13:02:32,607 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:23)
datanode_6_1  | 2020-07-11 13:02:32,618 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:24)
datanode_6_1  | 2020-07-11 13:02:35,301 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=44,entriesCount=1,lastEntry=(t:1, i:25)
datanode_6_1  | 2020-07-11 13:02:35,329 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:26)
datanode_6_1  | 2020-07-11 13:02:35,367 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:27)
datanode_6_1  | 2020-07-11 13:02:35,386 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:28)
datanode_6_1  | 2020-07-11 13:02:37,939 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=49,entriesCount=1,lastEntry=(t:1, i:29)
datanode_6_1  | 2020-07-11 13:02:37,955 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:30)
datanode_6_1  | 2020-07-11 13:02:37,960 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:31)
datanode_6_1  | 2020-07-11 13:02:37,983 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:32)
datanode_6_1  | 2020-07-11 13:02:41,001 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=54,entriesCount=1,lastEntry=(t:1, i:33)
datanode_6_1  | 2020-07-11 13:02:41,064 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:34)
datanode_6_1  | 2020-07-11 13:02:41,105 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:35)
datanode_6_1  | 2020-07-11 13:02:41,110 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:36)
datanode_6_1  | 2020-07-11 13:02:43,656 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=59,entriesCount=1,lastEntry=(t:1, i:37)
datanode_6_1  | 2020-07-11 13:02:43,675 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:38)
datanode_6_1  | 2020-07-11 13:02:43,698 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:39)
datanode_6_1  | 2020-07-11 13:02:43,709 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:40)
datanode_6_1  | 2020-07-11 13:02:46,598 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=64,entriesCount=1,lastEntry=(t:1, i:41)
datanode_6_1  | 2020-07-11 13:02:46,610 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:42)
datanode_6_1  | 2020-07-11 13:02:46,619 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:43)
datanode_6_1  | 2020-07-11 13:02:46,641 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:44)
datanode_6_1  | 2020-07-11 13:02:49,315 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=69,entriesCount=1,lastEntry=(t:1, i:45)
datanode_6_1  | 2020-07-11 13:02:49,326 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:46)
datanode_6_1  | 2020-07-11 13:02:49,340 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:47)
datanode_6_1  | 2020-07-11 13:02:49,347 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:48)
datanode_6_1  | 2020-07-11 13:02:51,880 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=74,entriesCount=1,lastEntry=(t:1, i:49)
datanode_6_1  | 2020-07-11 13:02:51,901 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:50)
datanode_6_1  | 2020-07-11 13:02:51,921 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:51)
datanode_6_1  | 2020-07-11 13:02:51,931 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:52)
datanode_6_1  | 2020-07-11 13:02:54,577 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:53)
datanode_6_1  | 2020-07-11 13:02:54,577 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:54)
datanode_6_1  | 2020-07-11 13:02:54,599 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:55)
datanode_6_1  | 2020-07-11 13:02:57,347 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:56)
datanode_6_1  | 2020-07-11 13:02:57,349 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:57)
datanode_6_1  | 2020-07-11 13:02:57,367 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:58)
datanode_6_1  | 2020-07-11 13:02:57,383 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:59)
datanode_6_1  | 2020-07-11 13:03:00,038 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=88,entriesCount=1,lastEntry=(t:1, i:60)
datanode_6_1  | 2020-07-11 13:03:00,039 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:61)
datanode_6_1  | 2020-07-11 13:03:00,048 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:62)
datanode_6_1  | 2020-07-11 13:03:00,062 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:63)
datanode_6_1  | 2020-07-11 13:03:02,787 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=93,entriesCount=1,lastEntry=(t:1, i:64)
datanode_6_1  | 2020-07-11 13:03:02,787 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:65)
datanode_6_1  | 2020-07-11 13:03:02,805 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:66)
datanode_6_1  | 2020-07-11 13:03:02,827 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:67)
datanode_6_1  | 2020-07-11 13:03:05,586 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:68)
datanode_6_1  | 2020-07-11 13:03:05,596 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:69)
datanode_6_1  | 2020-07-11 13:03:05,599 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:70)
datanode_6_1  | 2020-07-11 13:03:08,151 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:71)
datanode_6_1  | 2020-07-11 13:03:08,151 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:72)
datanode_6_1  | 2020-07-11 13:03:08,165 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:73)
datanode_6_1  | 2020-07-11 13:03:08,183 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:74)
datanode_6_1  | 2020-07-11 13:03:13,449 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=108,entriesCount=1,lastEntry=(t:1, i:75)
datanode_6_1  | 2020-07-11 13:03:13,461 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:76)
datanode_6_1  | 2020-07-11 13:03:13,513 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:77)
datanode_6_1  | 2020-07-11 13:03:16,053 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:78)
datanode_6_1  | 2020-07-11 13:03:16,065 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:79)
datanode_6_1  | 2020-07-11 13:03:16,081 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:80)
datanode_6_1  | 2020-07-11 13:03:16,088 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=115,entriesCount=1,lastEntry=(t:1, i:81)
datanode_6_1  | 2020-07-11 13:03:18,634 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:82)
datanode_6_1  | 2020-07-11 13:03:18,645 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=118,entriesCount=1,lastEntry=(t:1, i:83)
datanode_6_1  | 2020-07-11 13:03:18,652 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:84)
datanode_6_1  | 2020-07-11 13:03:18,675 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:85)
datanode_6_1  | 2020-07-11 13:03:21,211 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:86)
datanode_6_1  | 2020-07-11 13:03:21,220 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=123,entriesCount=1,lastEntry=(t:1, i:87)
datanode_6_1  | 2020-07-11 13:03:21,241 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:88)
datanode_6_1  | 2020-07-11 13:03:21,253 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:89)
datanode_6_1  | 2020-07-11 13:03:23,786 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:90)
datanode_6_1  | 2020-07-11 13:03:23,786 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=128,entriesCount=1,lastEntry=(t:1, i:91)
datanode_6_1  | 2020-07-11 13:03:23,801 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=129,entriesCount=1,lastEntry=(t:1, i:92)
datanode_6_1  | 2020-07-11 13:03:23,814 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=130,entriesCount=1,lastEntry=(t:1, i:93)
datanode_6_1  | 2020-07-11 13:03:26,354 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:94)
datanode_6_1  | 2020-07-11 13:03:26,368 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:95)
datanode_6_1  | 2020-07-11 13:03:26,384 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:96)
datanode_6_1  | 2020-07-11 13:03:26,402 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:97)
datanode_6_1  | 2020-07-11 13:03:28,939 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:98)
datanode_6_1  | 2020-07-11 13:03:28,945 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=138,entriesCount=1,lastEntry=(t:1, i:99)
datanode_6_1  | 2020-07-11 13:03:28,963 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:100)
datanode_6_1  | 2020-07-11 13:03:28,976 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:101)
datanode_6_1  | 2020-07-11 13:03:31,508 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=142,entriesCount=1,lastEntry=(t:1, i:102)
datanode_6_1  | 2020-07-11 13:03:31,521 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=143,entriesCount=1,lastEntry=(t:1, i:103)
datanode_6_1  | 2020-07-11 13:03:31,542 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:104)
datanode_6_1  | 2020-07-11 13:03:31,559 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:105)
datanode_6_1  | 2020-07-11 13:03:34,113 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:106)
datanode_6_1  | 2020-07-11 13:03:34,121 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=148,entriesCount=1,lastEntry=(t:1, i:107)
datanode_6_1  | 2020-07-11 13:03:34,129 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:108)
datanode_6_1  | 2020-07-11 13:03:34,142 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:109)
datanode_6_1  | 2020-07-11 13:03:36,930 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=152,entriesCount=1,lastEntry=(t:1, i:110)
datanode_6_1  | 2020-07-11 13:03:36,948 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=153,entriesCount=1,lastEntry=(t:1, i:111)
datanode_6_1  | 2020-07-11 13:03:36,956 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:112)
datanode_6_1  | 2020-07-11 13:03:36,978 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:113)
datanode_6_1  | 2020-07-11 13:03:39,605 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=157,entriesCount=1,lastEntry=(t:1, i:114)
datanode_6_1  | 2020-07-11 13:03:39,629 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:115)
datanode_6_1  | 2020-07-11 13:03:39,633 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=159,entriesCount=1,lastEntry=(t:1, i:116)
datanode_6_1  | 2020-07-11 13:03:39,654 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:117)
datanode_6_1  | 2020-07-11 13:03:42,274 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=162,entriesCount=1,lastEntry=(t:1, i:118)
datanode_6_1  | 2020-07-11 13:03:42,288 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:119)
datanode_6_1  | 2020-07-11 13:03:42,304 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=164,entriesCount=1,lastEntry=(t:1, i:120)
datanode_6_1  | 2020-07-11 13:03:42,314 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=165,entriesCount=1,lastEntry=(t:1, i:121)
datanode_6_1  | 2020-07-11 13:03:44,857 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=167,entriesCount=1,lastEntry=(t:1, i:122)
datanode_6_1  | 2020-07-11 13:03:44,868 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:123)
datanode_6_1  | 2020-07-11 13:03:44,882 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=169,entriesCount=1,lastEntry=(t:1, i:124)
datanode_6_1  | 2020-07-11 13:03:44,889 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=170,entriesCount=1,lastEntry=(t:1, i:125)
datanode_6_1  | 2020-07-11 13:03:47,512 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=172,entriesCount=1,lastEntry=(t:1, i:126)
datanode_6_1  | 2020-07-11 13:03:47,524 [java.util.concurrent.ThreadPoolExecutor$Worker@2a4e44c4[State = -1, empty queue]] WARN server.GrpcLogAppender: 6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792->0e925a4a-a3be-400e-ae7d-aecf7064f65c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=173,entriesCount=1,lastEntry=(t:1, i:127)
datanode_6_1  | 2020-07-11 13:05:50,223 [Thread-208] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-EA6C5A1D92EB->6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792, cid=199, seq=0, Watch-ALL_COMMITTED(131), Message:<EMPTY>, reply=RaftClientReply:client-EA6C5A1D92EB->6e333534-afe2-4f15-8be5-338f0f6f06b9@group-3EE7DF2A6792, cid=199, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 199 and log index 131 is not yet replicated to ALL_COMMITTED, logIndex=131, commits[6e333534-afe2-4f15-8be5-338f0f6f06b9:c177, e67d091a-1583-4527-8ecf-5d5225cc2732:c177, 0e925a4a-a3be-400e-ae7d-aecf7064f65c:c127]
