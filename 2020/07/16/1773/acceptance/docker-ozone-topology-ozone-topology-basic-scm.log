Attaching to ozone-topology_om_1, ozone-topology_datanode_1_1, ozone-topology_datanode_6_1, ozone-topology_scm_1, ozone-topology_datanode_3_1, ozone-topology_datanode_2_1, ozone-topology_datanode_5_1, ozone-topology_datanode_4_1
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-07-16 13:00:58,715 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = 7f7b5f3d7e11/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-07-16 13:00:58,758 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-07-16 13:01:00,503 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-07-16 13:01:01,428 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-07-16 13:01:02,891 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-07-16 13:01:02,891 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-07-16 13:01:03,546 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:7f7b5f3d7e11 ip:10.5.0.5
datanode_2_1  | 2020-07-16 13:01:04,475 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-07-16 13:01:04,490 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-07-16 13:01:04,510 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-07-16 13:01:04,597 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-07-16 13:01:05,016 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-07-16 13:01:11,688 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-07-16 13:01:11,994 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-07-16 13:01:13,287 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-07-16 13:01:13,297 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-07-16 13:01:13,304 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-16 13:01:13,307 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-07-16 13:01:13,316 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-07-16 13:01:14,746 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-16 13:01:14,759 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-07-16 13:01:16,409 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-07-16 13:01:16,550 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-07-16 13:01:16,779 [main] INFO util.log: Logging initialized @23728ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-07-16 13:01:17,492 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-07-16 13:01:17,522 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-07-16 13:01:17,561 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-07-16 13:01:17,566 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-07-16 13:01:17,580 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-07-16 13:01:17,580 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-07-16 13:01:17,804 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-07-16 13:01:17,844 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-07-16 13:01:17,860 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-07-16 13:01:18,102 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-07-16 13:01:18,109 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-07-16 13:01:18,111 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2_1  | 2020-07-16 13:01:18,272 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7ea3839e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-07-16 13:01:18,276 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18c820d2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-07-16 13:01:18,986 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@53b7bf01{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13026500047981124331.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-07-16 13:01:19,060 [main] INFO server.AbstractConnector: Started ServerConnector@4dd1548e{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-07-16 13:01:19,061 [main] INFO server.Server: Started @26009ms
datanode_2_1  | 2020-07-16 13:01:19,084 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-07-16 13:01:19,084 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-07-16 13:01:19,088 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-07-16 13:01:19,340 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@31f21a0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-07-16 13:01:20,583 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-07-16 13:01:22,859 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-16 13:01:23,859 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-16 13:01:24,860 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-16 13:01:25,861 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-16 13:01:26,862 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-16 13:01:27,863 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-16 13:01:28,863 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-16 13:01:30,314 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-07-16 13:01:30,319 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-07-16 13:01:30,326 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 2d39f5a5-5993-4301-956d-f519f2994ca2 at port 9858
datanode_2_1  | 2020-07-16 13:01:30,435 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 2d39f5a5-5993-4301-956d-f519f2994ca2: start RPC server
datanode_2_1  | 2020-07-16 13:01:31,075 [Datanode State Machine Thread - 0] INFO server.GrpcService: 2d39f5a5-5993-4301-956d-f519f2994ca2: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-07-16 13:01:34,637 [Command processor thread] INFO impl.RaftServerProxy: 2d39f5a5-5993-4301-956d-f519f2994ca2: addNew group-994262AD379A:[2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858] returns group-994262AD379A:java.util.concurrent.CompletableFuture@58af4ec9[Not completed]
datanode_2_1  | 2020-07-16 13:01:34,769 [pool-19-thread-1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2: new RaftServerImpl for group-994262AD379A:[2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-07-16 13:01:34,777 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-07-16 13:01:34,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-16 13:01:34,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-07-16 13:01:34,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-07-16 13:01:34,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-16 13:01:34,822 [pool-19-thread-1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A: ConfigurationManager, init=-1: [2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-07-16 13:01:34,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-16 13:01:34,843 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-07-16 13:01:34,845 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/928df494-38dd-4453-9ee7-994262ad379a does not exist. Creating ...
datanode_2_1  | 2020-07-16 13:01:34,882 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/928df494-38dd-4453-9ee7-994262ad379a/in_use.lock acquired by nodename 7@7f7b5f3d7e11
datanode_2_1  | 2020-07-16 13:01:34,888 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/928df494-38dd-4453-9ee7-994262ad379a has been successfully formatted.
datanode_2_1  | 2020-07-16 13:01:35,009 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-994262AD379A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-07-16 13:01:35,019 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-07-16 13:01:35,029 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-07-16 13:01:35,055 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-07-16 13:01:35,056 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-16 13:01:35,085 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-16 13:01:35,100 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A
datanode_2_1  | 2020-07-16 13:01:35,171 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-16 13:01:35,186 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/928df494-38dd-4453-9ee7-994262ad379a
datanode_2_1  | 2020-07-16 13:01:35,187 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-07-16 13:01:35,188 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-16 13:01:35,190 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-16 13:01:35,193 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-07-16 13:01:35,194 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-07-16 13:01:35,195 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-07-16 13:01:35,213 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-07-16 13:01:35,226 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-07-16 13:01:35,228 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-07-16 13:01:35,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-07-16 13:01:35,398 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-16 13:01:35,404 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-16 13:01:35,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-07-16 13:01:35,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-07-16 13:01:35,456 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-07-16 13:01:35,460 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-07-16 13:01:35,469 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-07-16 13:01:35,619 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A
datanode_2_1  | 2020-07-16 13:01:35,643 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A
datanode_2_1  | 2020-07-16 13:01:35,647 [pool-19-thread-1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A: start as a follower, conf=-1: [2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-16 13:01:35,660 [pool-19-thread-1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-07-16 13:01:35,663 [pool-19-thread-1] INFO impl.RoleInfo: 2d39f5a5-5993-4301-956d-f519f2994ca2: start FollowerState
datanode_2_1  | 2020-07-16 13:01:35,714 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-994262AD379A,id=2d39f5a5-5993-4301-956d-f519f2994ca2
datanode_2_1  | 2020-07-16 13:01:35,719 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A
datanode_2_1  | 2020-07-16 13:01:35,804 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "928df494-38dd-4453-9ee7-994262ad379a"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: -7886378455009508269
datanode_2_1  |   leastSigBits: -6996454985694365798
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-07-16 13:01:35,805 [Command processor thread] INFO impl.RaftServerProxy: 2d39f5a5-5993-4301-956d-f519f2994ca2: addNew group-D4280D4755F5:[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858] returns group-D4280D4755F5:java.util.concurrent.CompletableFuture@adb1e21[Not completed]
datanode_2_1  | 2020-07-16 13:01:35,839 [pool-19-thread-1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2: new RaftServerImpl for group-D4280D4755F5:[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-07-16 13:01:35,839 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-07-16 13:01:35,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-16 13:01:35,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-07-16 13:01:35,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-07-16 13:01:35,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-16 13:01:35,840 [pool-19-thread-1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5: ConfigurationManager, init=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-07-16 13:01:35,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-16 13:01:35,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-07-16 13:01:35,840 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5 does not exist. Creating ...
datanode_2_1  | 2020-07-16 13:01:35,846 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5/in_use.lock acquired by nodename 7@7f7b5f3d7e11
datanode_2_1  | 2020-07-16 13:01:35,855 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5 has been successfully formatted.
datanode_2_1  | 2020-07-16 13:01:35,856 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-D4280D4755F5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-07-16 13:01:35,856 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-07-16 13:01:35,857 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-07-16 13:01:35,859 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-07-16 13:01:35,866 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-16 13:01:35,866 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-16 13:01:35,867 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5
datanode_2_1  | 2020-07-16 13:01:35,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-16 13:01:35,897 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5
datanode_2_1  | 2020-07-16 13:01:35,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-07-16 13:01:35,907 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-16 13:01:35,909 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-16 13:01:35,909 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-07-16 13:01:35,949 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-07-16 13:01:35,949 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-07-16 13:01:35,951 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-07-16 13:01:35,960 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-07-16 13:01:35,963 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-07-16 13:01:36,032 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-07-16 13:01:36,074 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-16 13:01:36,075 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-16 13:01:36,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-07-16 13:01:36,076 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-07-16 13:01:03,849 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = 573c152f405e/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-07-16 13:01:03,956 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-07-16 13:01:05,874 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-07-16 13:01:06,651 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-07-16 13:01:08,079 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-07-16 13:01:08,079 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-07-16 13:01:08,764 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:573c152f405e ip:10.5.0.6
datanode_3_1  | 2020-07-16 13:01:09,697 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-07-16 13:01:09,707 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-07-16 13:01:09,718 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-07-16 13:01:09,790 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-07-16 13:01:10,145 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-07-16 13:01:17,008 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-07-16 13:01:17,411 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-07-16 13:01:18,667 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-07-16 13:01:18,689 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-07-16 13:01:18,696 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-16 13:01:18,701 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-07-16 13:01:18,708 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-07-16 13:01:20,878 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-16 13:01:20,929 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-07-16 13:01:22,282 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-07-16 13:01:22,376 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-07-16 13:01:22,494 [main] INFO util.log: Logging initialized @26704ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-07-16 13:01:23,015 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-07-16 13:01:23,023 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-07-16 13:01:23,068 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-07-16 13:01:23,072 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-07-16 13:01:23,091 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-07-16 13:01:23,091 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-07-16 13:01:23,191 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-07-16 13:01:23,265 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-07-16 13:01:23,272 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-07-16 13:01:23,500 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-07-16 13:01:23,500 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-07-16 13:01:23,502 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3_1  | 2020-07-16 13:01:23,584 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@23396fc0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-07-16 13:01:23,586 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@41143873{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-07-16 13:01:24,056 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@69a73867{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4801401040923556174.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-07-16 13:01:24,081 [main] INFO server.AbstractConnector: Started ServerConnector@631bc9f4{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-07-16 13:01:24,087 [main] INFO server.Server: Started @28297ms
datanode_3_1  | 2020-07-16 13:01:24,104 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-07-16 13:01:24,105 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-07-16 13:01:24,117 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-07-16 13:01:24,225 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fcacd7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-07-16 13:01:25,014 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-07-16 13:01:27,372 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-16 13:01:28,373 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-16 13:01:29,406 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3_1  | java.net.SocketTimeoutException: Call From 573c152f405e/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:57204 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:57204 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-07-16 13:01:30,005 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-07-16 13:01:30,019 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-07-16 13:01:30,020 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 4f49310f-999a-4016-acc1-42cc4200008f at port 9858
datanode_3_1  | 2020-07-16 13:01:30,251 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 4f49310f-999a-4016-acc1-42cc4200008f: start RPC server
datanode_3_1  | 2020-07-16 13:01:30,745 [Datanode State Machine Thread - 1] INFO server.GrpcService: 4f49310f-999a-4016-acc1-42cc4200008f: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-07-16 13:01:35,313 [Command processor thread] INFO impl.RaftServerProxy: 4f49310f-999a-4016-acc1-42cc4200008f: addNew group-F5735CC90914:[4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858] returns group-F5735CC90914:java.util.concurrent.CompletableFuture@2b0c0049[Not completed]
datanode_3_1  | 2020-07-16 13:01:35,409 [pool-19-thread-1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f: new RaftServerImpl for group-F5735CC90914:[4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-07-16 13:01:35,424 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-07-16 13:01:35,426 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-07-16 13:01:35,426 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-07-16 13:01:35,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-07-16 13:01:35,434 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-16 13:01:35,471 [pool-19-thread-1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914: ConfigurationManager, init=-1: [4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-07-16 13:01:35,486 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-16 13:01:35,494 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-07-16 13:01:35,505 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b0f7a9d8-0f33-40fe-a566-f5735cc90914 does not exist. Creating ...
datanode_3_1  | 2020-07-16 13:01:35,543 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b0f7a9d8-0f33-40fe-a566-f5735cc90914/in_use.lock acquired by nodename 6@573c152f405e
datanode_3_1  | 2020-07-16 13:01:35,551 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b0f7a9d8-0f33-40fe-a566-f5735cc90914 has been successfully formatted.
datanode_3_1  | 2020-07-16 13:01:35,601 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-F5735CC90914: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-07-16 13:01:35,602 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-07-16 13:01:35,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-07-16 13:01:35,644 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-07-16 13:01:35,655 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-16 13:01:35,661 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-16 13:01:35,680 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914
datanode_3_1  | 2020-07-16 13:01:35,758 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-16 13:01:36,076 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-07-16 13:01:36,076 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-07-16 13:01:36,076 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-07-16 13:01:36,079 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5
datanode_2_1  | 2020-07-16 13:01:36,084 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5
datanode_2_1  | 2020-07-16 13:01:36,086 [pool-19-thread-1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5: start as a follower, conf=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null
datanode_2_1  | 2020-07-16 13:01:36,091 [pool-19-thread-1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-07-16 13:01:36,091 [pool-19-thread-1] INFO impl.RoleInfo: 2d39f5a5-5993-4301-956d-f519f2994ca2: start FollowerState
datanode_2_1  | 2020-07-16 13:01:36,119 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D4280D4755F5,id=2d39f5a5-5993-4301-956d-f519f2994ca2
datanode_2_1  | 2020-07-16 13:01:36,119 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5
datanode_2_1  | 2020-07-16 13:01:40,878 [Thread-22] INFO impl.FollowerState: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-FollowerState: change to CANDIDATE, lastRpcTime:5217ms, electionTimeout:5184ms
datanode_2_1  | 2020-07-16 13:01:40,879 [Thread-22] INFO impl.RoleInfo: 2d39f5a5-5993-4301-956d-f519f2994ca2: shutdown FollowerState
datanode_2_1  | 2020-07-16 13:01:40,880 [Thread-22] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-07-16 13:01:40,882 [Thread-22] INFO impl.RoleInfo: 2d39f5a5-5993-4301-956d-f519f2994ca2: start LeaderElection
datanode_2_1  | 2020-07-16 13:01:40,915 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO impl.LeaderElection: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1: begin an election at term 1 for -1: [2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-16 13:01:40,923 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO impl.RoleInfo: 2d39f5a5-5993-4301-956d-f519f2994ca2: shutdown LeaderElection
datanode_2_1  | 2020-07-16 13:01:40,931 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-07-16 13:01:40,936 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-994262AD379A with new leaderId: 2d39f5a5-5993-4301-956d-f519f2994ca2
datanode_2_1  | 2020-07-16 13:01:40,958 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A: change Leader from null to 2d39f5a5-5993-4301-956d-f519f2994ca2 at term 1 for becomeLeader, leader elected after 5923ms
datanode_2_1  | 2020-07-16 13:01:40,985 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
datanode_2_1  | 2020-07-16 13:01:40,985 [grpc-default-executor-0] INFO impl.RoleInfo: 2d39f5a5-5993-4301-956d-f519f2994ca2: shutdown FollowerState
datanode_2_1  | 2020-07-16 13:01:40,986 [Thread-24] INFO impl.FollowerState: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 2020-07-16 13:01:40,986 [grpc-default-executor-0] INFO impl.RoleInfo: 2d39f5a5-5993-4301-956d-f519f2994ca2: start FollowerState
datanode_2_1  | 2020-07-16 13:01:41,033 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-07-16 13:01:41,035 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-07-16 13:01:41,182 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A
datanode_2_1  | 2020-07-16 13:01:41,255 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-16 13:01:41,256 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-07-16 13:01:41,342 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-07-16 13:01:41,346 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-07-16 13:01:41,358 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-07-16 13:01:41,438 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO impl.RoleInfo: 2d39f5a5-5993-4301-956d-f519f2994ca2: start LeaderState
datanode_2_1  | 2020-07-16 13:01:41,517 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-07-16 13:01:41,586 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-LeaderElection1] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A: set configuration 0: [2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-07-16 13:01:41,742 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D4280D4755F5 with new leaderId: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
datanode_2_1  | 2020-07-16 13:01:41,751 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5: change Leader from null to 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c at term 1 for appendEntries, leader elected after 5886ms
datanode_2_1  | 2020-07-16 13:01:41,922 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5: set configuration 0: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null at 0
datanode_2_1  | 2020-07-16 13:01:41,924 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-07-16 13:01:35,814 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b0f7a9d8-0f33-40fe-a566-f5735cc90914
datanode_3_1  | 2020-07-16 13:01:35,818 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-07-16 13:01:35,818 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-16 13:01:35,831 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-16 13:01:35,831 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-07-16 13:01:35,831 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-07-16 13:01:35,832 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-07-16 13:01:35,833 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-07-16 13:01:35,835 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-07-16 13:01:35,835 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-07-16 13:01:36,013 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-07-16 13:01:36,121 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-16 13:01:36,121 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-16 13:01:36,163 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-07-16 13:01:36,178 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-07-16 13:01:36,212 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-07-16 13:01:36,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-07-16 13:01:36,237 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-07-16 13:01:36,547 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914
datanode_3_1  | 2020-07-16 13:01:36,581 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914
datanode_3_1  | 2020-07-16 13:01:36,605 [pool-19-thread-1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914: start as a follower, conf=-1: [4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858], old=null
datanode_3_1  | 2020-07-16 13:01:36,640 [pool-19-thread-1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-07-16 13:01:36,649 [pool-19-thread-1] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: start FollowerState
datanode_3_1  | 2020-07-16 13:01:36,664 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5735CC90914,id=4f49310f-999a-4016-acc1-42cc4200008f
datanode_3_1  | 2020-07-16 13:01:36,666 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914
datanode_3_1  | 2020-07-16 13:01:36,702 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "b0f7a9d8-0f33-40fe-a566-f5735cc90914"
datanode_3_1  | uuid128 {
datanode_3_1  |   mostSigBits: -5694896458353655554
datanode_3_1  |   leastSigBits: -6528260734000232172
datanode_3_1  | }
datanode_3_1  | .
datanode_3_1  | 2020-07-16 13:01:36,708 [Command processor thread] INFO impl.RaftServerProxy: 4f49310f-999a-4016-acc1-42cc4200008f: addNew group-AC9C7A051A6E:[de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858] returns group-AC9C7A051A6E:java.util.concurrent.CompletableFuture@400961bd[Not completed]
datanode_3_1  | 2020-07-16 13:01:36,710 [pool-19-thread-1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f: new RaftServerImpl for group-AC9C7A051A6E:[de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-07-16 13:01:36,715 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-07-16 13:01:36,715 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-07-16 13:01:36,719 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-07-16 13:01:36,719 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-07-16 13:01:36,719 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-16 13:01:36,720 [pool-19-thread-1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E: ConfigurationManager, init=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-07-16 13:01:36,720 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-16 13:01:36,720 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-07-16 13:01:36,721 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e does not exist. Creating ...
datanode_3_1  | 2020-07-16 13:01:36,722 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e/in_use.lock acquired by nodename 6@573c152f405e
datanode_3_1  | 2020-07-16 13:01:36,728 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e has been successfully formatted.
datanode_3_1  | 2020-07-16 13:01:36,728 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-AC9C7A051A6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-07-16 13:01:36,728 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-07-16 13:01:36,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-07-16 13:01:36,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-07-16 13:01:36,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-16 13:01:42,015 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-994262AD379A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/928df494-38dd-4453-9ee7-994262ad379a/current/log_inprogress_0
datanode_2_1  | 2020-07-16 13:01:42,015 [2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2d39f5a5-5993-4301-956d-f519f2994ca2@group-D4280D4755F5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5/current/log_inprogress_0
datanode_2_1  | 2020-07-16 13:01:42,101 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 6377505a-0934-4e3b-8892-495630fc2c1f{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_2_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.966543786s. [buffered_nanos=588124502, remote_addr=/10.5.0.9:9858]
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_2_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_2_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.966543786s. [buffered_nanos=588124502, remote_addr=/10.5.0.9:9858]
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_2_1  | 	... 18 more
datanode_2_1  | 2020-07-16 13:01:42,111 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "169b341c-e67d-4e0d-9cbd-d4280d4755f5"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: 1628952988955266573
datanode_2_1  |   leastSigBits: -7152327364707920395
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-07-16 13:06:46,635 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 154.
datanode_2_1  | 2020-07-16 13:06:46,635 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 154.
datanode_2_1  | 2020-07-16 13:06:46,642 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is closed with bcsId 154.
datanode_2_1  | 2020-07-16 13:06:46,669 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is synced with bcsId 170.
datanode_2_1  | 2020-07-16 13:06:46,670 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is synced with bcsId 170.
datanode_2_1  | 2020-07-16 13:06:46,678 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is closed with bcsId 170.
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-07-16 13:01:04,683 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = ab54e601087f/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_5_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-07-16 13:01:04,751 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5_1  | 2020-07-16 13:01:06,656 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-07-16 13:01:07,667 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-07-16 13:01:08,818 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-07-16 13:01:08,818 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-07-16 13:01:09,654 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:ab54e601087f ip:10.5.0.8
datanode_5_1  | 2020-07-16 13:01:10,577 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-07-16 13:01:10,641 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-07-16 13:01:10,668 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-07-16 13:01:10,717 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-07-16 13:01:11,162 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-07-16 13:01:17,949 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-07-16 13:01:18,375 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-07-16 13:01:19,678 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-07-16 13:01:19,704 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-07-16 13:01:19,744 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-16 13:01:19,747 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-07-16 13:01:19,753 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-07-16 13:01:21,739 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-16 13:01:21,765 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-07-16 13:01:22,850 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-07-16 13:01:22,981 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-07-16 13:01:23,151 [main] INFO util.log: Logging initialized @26126ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-07-16 13:01:23,694 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-07-16 13:01:23,730 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-07-16 13:01:23,769 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-07-16 13:01:23,780 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-07-16 13:01:23,783 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-07-16 13:01:23,783 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-07-16 13:01:23,956 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-07-16 13:01:23,985 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-07-16 13:01:23,991 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-07-16 13:01:24,174 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-07-16 13:01:24,178 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-07-16 13:01:24,187 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_5_1  | 2020-07-16 13:01:24,256 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7956f93a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-07-16 13:01:24,257 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@697a92af{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-07-16 13:01:24,670 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@26101efc{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-9146809162308102013.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-07-16 13:01:24,703 [main] INFO server.AbstractConnector: Started ServerConnector@194911c1{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-07-16 13:01:24,703 [main] INFO server.Server: Started @27678ms
datanode_5_1  | 2020-07-16 13:01:24,713 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-07-16 13:01:24,713 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-07-16 13:01:24,716 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-07-16 13:01:24,782 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ebe1892] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-07-16 13:01:25,583 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-07-16 13:01:28,025 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-07-16 13:01:29,026 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-07-16 13:01:30,196 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-07-16 13:01:30,198 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-07-16 13:00:57,444 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = a68ac153a477/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | 2020-07-16 13:01:30,211 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674 at port 9858
datanode_5_1  | 2020-07-16 13:01:30,346 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: start RPC server
datanode_5_1  | 2020-07-16 13:01:30,924 [Datanode State Machine Thread - 0] INFO server.GrpcService: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-07-16 13:01:36,026 [Command processor thread] INFO impl.RaftServerProxy: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: addNew group-A1E32EC59A07:[3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858] returns group-A1E32EC59A07:java.util.concurrent.CompletableFuture@9f50817[Not completed]
datanode_5_1  | 2020-07-16 13:01:36,180 [pool-19-thread-1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: new RaftServerImpl for group-A1E32EC59A07:[3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-07-16 13:01:36,189 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-07-16 13:01:36,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-16 13:01:36,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-07-16 13:01:36,220 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-07-16 13:01:36,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-16 13:01:36,287 [pool-19-thread-1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07: ConfigurationManager, init=-1: [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-07-16 13:01:36,288 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-16 13:01:36,323 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-07-16 13:01:36,351 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a4d7052a-3090-4d65-b7ef-a1e32ec59a07 does not exist. Creating ...
datanode_5_1  | 2020-07-16 13:01:36,429 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a4d7052a-3090-4d65-b7ef-a1e32ec59a07/in_use.lock acquired by nodename 6@ab54e601087f
datanode_5_1  | 2020-07-16 13:01:36,441 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a4d7052a-3090-4d65-b7ef-a1e32ec59a07 has been successfully formatted.
datanode_5_1  | 2020-07-16 13:01:36,498 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A1E32EC59A07: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-07-16 13:01:36,500 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-07-16 13:01:36,559 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-07-16 13:01:36,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-07-16 13:01:36,649 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-16 13:01:36,654 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-16 13:01:36,703 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07
datanode_5_1  | 2020-07-16 13:01:36,811 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-07-16 13:01:36,863 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a4d7052a-3090-4d65-b7ef-a1e32ec59a07
datanode_5_1  | 2020-07-16 13:01:36,871 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-07-16 13:01:36,873 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-16 13:01:36,884 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-16 13:01:36,890 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-07-16 13:01:36,891 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-07-16 13:01:36,895 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-07-16 13:01:36,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-07-16 13:01:36,915 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-07-16 13:01:36,916 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-07-16 13:01:37,015 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-07-16 13:01:37,053 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-16 13:01:37,059 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-16 13:01:37,078 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-07-16 13:01:37,084 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-07-16 13:01:37,084 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-07-16 13:01:37,088 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-07-16 13:01:37,095 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-16 13:01:37,215 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07
datanode_5_1  | 2020-07-16 13:01:37,274 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07
datanode_5_1  | 2020-07-16 13:01:37,336 [pool-19-thread-1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07: start as a follower, conf=-1: [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-16 13:01:37,340 [pool-19-thread-1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-07-16 13:01:37,356 [pool-19-thread-1] INFO impl.RoleInfo: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: start FollowerState
datanode_5_1  | 2020-07-16 13:01:37,480 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A1E32EC59A07,id=3bdad0fc-b0ab-427d-8e93-13fe3ba6d674
datanode_5_1  | 2020-07-16 13:01:37,481 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07
datanode_5_1  | 2020-07-16 13:01:37,563 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "a4d7052a-3090-4d65-b7ef-a1e32ec59a07"
datanode_5_1  | uuid128 {
datanode_5_1  |   mostSigBits: -6568775852735050395
datanode_5_1  |   leastSigBits: -5192753848220542457
datanode_5_1  | }
datanode_5_1  | .
datanode_5_1  | 2020-07-16 13:01:37,563 [Command processor thread] INFO impl.RaftServerProxy: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: addNew group-AC9C7A051A6E:[de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858] returns group-AC9C7A051A6E:java.util.concurrent.CompletableFuture@876417d[Not completed]
datanode_5_1  | 2020-07-16 13:01:37,574 [pool-19-thread-1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: new RaftServerImpl for group-AC9C7A051A6E:[de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-07-16 13:01:37,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-07-16 13:01:37,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-16 13:01:37,592 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-07-16 13:01:37,593 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-07-16 13:01:37,593 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-16 13:01:37,593 [pool-19-thread-1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E: ConfigurationManager, init=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-07-16 13:01:37,593 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-16 13:01:37,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-07-16 13:01:37,595 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e does not exist. Creating ...
datanode_5_1  | 2020-07-16 13:01:37,599 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e/in_use.lock acquired by nodename 6@ab54e601087f
datanode_5_1  | 2020-07-16 13:01:37,615 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e has been successfully formatted.
datanode_5_1  | 2020-07-16 13:01:37,616 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-AC9C7A051A6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-07-16 13:01:37,616 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-07-16 13:01:37,616 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-07-16 13:01:37,616 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-07-16 13:01:37,616 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-16 13:01:37,628 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-16 13:01:37,630 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E
datanode_5_1  | 2020-07-16 13:01:37,634 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-07-16 13:01:37,634 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e
datanode_5_1  | 2020-07-16 13:01:37,634 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-07-16 13:01:37,635 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-16 13:01:37,639 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-16 13:01:37,640 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-07-16 13:01:37,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-07-16 13:01:37,643 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-07-16 13:01:37,645 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-07-16 13:01:37,645 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-07-16 13:01:37,649 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-07-16 13:01:37,650 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-07-16 13:01:37,657 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-16 13:01:37,657 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-16 13:01:37,671 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-07-16 13:01:37,671 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-07-16 13:01:37,672 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-07-16 13:01:37,672 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-07-16 13:01:37,672 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-16 13:01:37,672 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E
datanode_5_1  | 2020-07-16 13:01:37,673 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E
datanode_5_1  | 2020-07-16 13:01:37,678 [pool-19-thread-1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E: start as a follower, conf=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null
datanode_3_1  | 2020-07-16 13:01:36,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-16 13:01:36,729 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E
datanode_3_1  | 2020-07-16 13:01:36,730 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-07-16 13:01:36,734 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e
datanode_3_1  | 2020-07-16 13:01:36,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-07-16 13:01:36,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-16 13:01:36,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-16 13:01:36,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-07-16 13:01:36,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-07-16 13:01:36,736 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-07-16 13:01:36,736 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-07-16 13:01:36,736 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-07-16 13:01:36,736 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-07-16 13:01:36,738 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-07-16 13:01:36,755 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-16 13:01:36,765 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-16 13:01:36,783 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-07-16 13:01:36,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-07-16 13:01:36,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-07-16 13:01:36,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-07-16 13:01:36,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-07-16 13:01:36,786 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E
datanode_3_1  | 2020-07-16 13:01:36,787 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E
datanode_3_1  | 2020-07-16 13:01:36,792 [pool-19-thread-1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E: start as a follower, conf=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null
datanode_3_1  | 2020-07-16 13:01:36,794 [pool-19-thread-1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-07-16 13:01:36,794 [pool-19-thread-1] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: start FollowerState
datanode_3_1  | 2020-07-16 13:01:36,827 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AC9C7A051A6E,id=4f49310f-999a-4016-acc1-42cc4200008f
datanode_3_1  | 2020-07-16 13:01:36,831 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E
datanode_3_1  | 2020-07-16 13:01:40,872 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for de7eb8b4-4719-42f5-b1f1-5c05eece8d74{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_3_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.878986877s. [buffered_nanos=1447689197, remote_addr=/10.5.0.4:9858]
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_3_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_3_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.878986877s. [buffered_nanos=1447689197, remote_addr=/10.5.0.4:9858]
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_5_1  | 2020-07-16 13:01:37,678 [pool-19-thread-1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-07-16 13:01:37,679 [pool-19-thread-1] INFO impl.RoleInfo: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: start FollowerState
datanode_5_1  | 2020-07-16 13:01:37,685 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AC9C7A051A6E,id=3bdad0fc-b0ab-427d-8e93-13fe3ba6d674
datanode_5_1  | 2020-07-16 13:01:37,686 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E
datanode_5_1  | 2020-07-16 13:01:41,288 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "3126ee1f-b742-47bc-99f8-ac9c7a051a6e"
datanode_5_1  | uuid128 {
datanode_5_1  |   mostSigBits: 3541779976959444924
datanode_5_1  |   leastSigBits: -7351936603620304274
datanode_5_1  | }
datanode_5_1  | .
datanode_5_1  | 2020-07-16 13:01:42,498 [Thread-22] INFO impl.FollowerState: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-FollowerState: change to CANDIDATE, lastRpcTime:5142ms, electionTimeout:5076ms
datanode_5_1  | 2020-07-16 13:01:42,509 [Thread-22] INFO impl.RoleInfo: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: shutdown FollowerState
datanode_5_1  | 2020-07-16 13:01:42,535 [Thread-22] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-07-16 13:01:42,550 [Thread-22] INFO impl.RoleInfo: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: start LeaderElection
datanode_5_1  | 2020-07-16 13:01:42,536 [grpc-default-executor-0] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:4f49310f-999a-4016-acc1-42cc4200008f
datanode_5_1  | 2020-07-16 13:01:42,561 [grpc-default-executor-0] INFO impl.RoleInfo: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: shutdown FollowerState
datanode_5_1  | 2020-07-16 13:01:42,562 [grpc-default-executor-0] INFO impl.RoleInfo: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: start FollowerState
datanode_5_1  | 2020-07-16 13:01:42,562 [Thread-24] INFO impl.FollowerState: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 2020-07-16 13:01:42,607 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO impl.LeaderElection: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1: begin an election at term 1 for -1: [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-16 13:01:42,610 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO impl.RoleInfo: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: shutdown LeaderElection
datanode_5_1  | 2020-07-16 13:01:42,626 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-07-16 13:01:42,626 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A1E32EC59A07 with new leaderId: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674
datanode_5_1  | 2020-07-16 13:01:42,632 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07: change Leader from null to 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674 at term 1 for becomeLeader, leader elected after 6127ms
datanode_5_1  | 2020-07-16 13:01:42,707 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-07-16 13:01:42,707 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-07-16 13:01:42,715 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07
datanode_5_1  | 2020-07-16 13:01:42,732 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-16 13:01:42,733 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-07-16 13:01:42,755 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-07-16 13:01:42,767 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-07-16 13:01:42,778 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-07-16 13:01:42,840 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO impl.RoleInfo: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674: start LeaderState
datanode_5_1  | 2020-07-16 13:01:42,978 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-07-16 13:01:43,105 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-LeaderElection1] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07: set configuration 0: [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-07-16 13:01:43,183 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AC9C7A051A6E with new leaderId: 4f49310f-999a-4016-acc1-42cc4200008f
datanode_5_1  | 2020-07-16 13:01:43,185 [grpc-default-executor-0] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E: change Leader from null to 4f49310f-999a-4016-acc1-42cc4200008f at term 1 for appendEntries, leader elected after 5567ms
datanode_5_1  | 2020-07-16 13:01:43,275 [grpc-default-executor-0] INFO impl.RaftServerImpl: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E: set configuration 0: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-07-16 13:01:43,282 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-07-16 13:01:43,544 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-AC9C7A051A6E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e/current/log_inprogress_0
datanode_5_1  | 2020-07-16 13:01:43,579 [3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674@group-A1E32EC59A07-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a4d7052a-3090-4d65-b7ef-a1e32ec59a07/current/log_inprogress_0
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_3_1  | 	... 18 more
datanode_3_1  | 2020-07-16 13:01:41,641 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "3126ee1f-b742-47bc-99f8-ac9c7a051a6e"
datanode_3_1  | uuid128 {
datanode_3_1  |   mostSigBits: 3541779976959444924
datanode_3_1  |   leastSigBits: -7351936603620304274
datanode_3_1  | }
datanode_3_1  | .
datanode_3_1  | 2020-07-16 13:01:41,831 [Thread-23] INFO impl.FollowerState: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-FollowerState: change to CANDIDATE, lastRpcTime:5186ms, electionTimeout:5180ms
datanode_3_1  | 2020-07-16 13:01:41,843 [Thread-23] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: shutdown FollowerState
datanode_3_1  | 2020-07-16 13:01:41,844 [Thread-23] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-07-16 13:01:41,861 [Thread-23] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: start LeaderElection
datanode_3_1  | 2020-07-16 13:01:41,899 [Thread-25] INFO impl.FollowerState: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-FollowerState: change to CANDIDATE, lastRpcTime:5104ms, electionTimeout:5066ms
datanode_3_1  | 2020-07-16 13:01:41,917 [Thread-25] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: shutdown FollowerState
datanode_3_1  | 2020-07-16 13:01:41,917 [Thread-25] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-07-16 13:01:41,917 [Thread-25] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: start LeaderElection
datanode_3_1  | 2020-07-16 13:01:41,996 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO impl.LeaderElection: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2: begin an election at term 1 for -1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null
datanode_3_1  | 2020-07-16 13:01:42,167 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO impl.LeaderElection: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1: begin an election at term 1 for -1: [4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858], old=null
datanode_3_1  | 2020-07-16 13:01:42,179 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: shutdown LeaderElection
datanode_3_1  | 2020-07-16 13:01:42,310 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-07-16 13:01:42,333 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F5735CC90914 with new leaderId: 4f49310f-999a-4016-acc1-42cc4200008f
datanode_3_1  | 2020-07-16 13:01:42,364 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914: change Leader from null to 4f49310f-999a-4016-acc1-42cc4200008f at term 1 for becomeLeader, leader elected after 6731ms
datanode_3_1  | 2020-07-16 13:01:42,367 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO impl.LeaderElection: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2: Election PASSED; received 1 response(s) [4f49310f-999a-4016-acc1-42cc4200008f<-de7eb8b4-4719-42f5-b1f1-5c05eece8d74#0:OK-t1] and 0 exception(s); 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E:t1, leader=null, voted=4f49310f-999a-4016-acc1-42cc4200008f, raftlog=4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null
datanode_3_1  | 2020-07-16 13:01:42,368 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: shutdown LeaderElection
datanode_3_1  | 2020-07-16 13:01:42,370 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-07-16 13:01:42,371 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AC9C7A051A6E with new leaderId: 4f49310f-999a-4016-acc1-42cc4200008f
datanode_3_1  | 2020-07-16 13:01:42,375 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E: change Leader from null to 4f49310f-999a-4016-acc1-42cc4200008f at term 1 for becomeLeader, leader elected after 5641ms
datanode_3_1  | 2020-07-16 13:01:42,411 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-07-16 13:01:42,412 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-07-16 13:01:42,444 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-07-16 13:01:42,464 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-07-16 13:01:42,471 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914
datanode_3_1  | 2020-07-16 13:01:42,473 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-16 13:01:42,484 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-07-16 13:01:42,436 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E
datanode_3_1  | 2020-07-16 13:01:42,494 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-16 13:01:42,494 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-07-16 13:01:42,545 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-07-16 13:01:42,548 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-07-16 13:01:42,547 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-07-16 13:01:05,205 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = 21aab171bf2f/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-07-16 13:00:57,487 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-07-16 13:00:59,295 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-07-16 13:01:00,141 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-07-16 13:01:01,581 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-07-16 13:01:01,581 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-07-16 13:01:02,305 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:a68ac153a477 ip:10.5.0.7
datanode_4_1  | 2020-07-16 13:01:03,504 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-07-16 13:01:03,531 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-07-16 13:01:03,558 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-07-16 13:01:03,609 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-07-16 13:01:04,027 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-07-16 13:01:11,395 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-07-16 13:01:12,120 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-07-16 13:01:13,285 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-07-16 13:01:13,312 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-07-16 13:01:13,313 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-16 13:01:13,315 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-07-16 13:01:13,317 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-07-16 13:01:14,359 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-16 13:01:14,376 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-07-16 13:01:15,942 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-07-16 13:01:16,083 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-07-16 13:01:16,305 [main] INFO util.log: Logging initialized @23535ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-07-16 13:01:16,955 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-07-16 13:01:16,982 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-07-16 13:01:17,035 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-07-16 13:01:17,062 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-07-16 13:01:17,075 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-07-16 13:01:17,083 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-07-16 13:01:17,342 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-07-16 13:01:17,382 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-07-16 13:01:17,388 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-07-16 13:01:17,761 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-07-16 13:01:17,783 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-07-16 13:01:17,785 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_4_1  | 2020-07-16 13:01:17,846 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16b76858{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-07-16 13:01:17,857 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3d3930fe{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-07-16 13:01:18,582 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@139089a4{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-2871366254907260560.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-07-16 13:01:18,661 [main] INFO server.AbstractConnector: Started ServerConnector@54bb1194{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-07-16 13:01:18,663 [main] INFO server.Server: Started @25893ms
datanode_4_1  | 2020-07-16 13:01:18,679 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-07-16 13:01:18,679 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-07-16 13:01:18,691 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-07-16 13:01:18,824 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ad25b2a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-07-16 13:01:20,260 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-07-16 13:01:22,498 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-16 13:01:23,499 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-16 13:01:24,500 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-16 13:01:25,501 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-16 13:01:26,501 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-16 13:01:27,502 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-16 13:01:42,550 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-07-16 13:01:42,551 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-07-16 13:01:42,558 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-07-16 13:01:42,609 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: start LeaderState
datanode_3_1  | 2020-07-16 13:01:42,642 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-07-16 13:01:42,642 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-16 13:01:42,643 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-07-16 13:01:42,645 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-07-16 13:01:42,667 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-07-16 13:01:42,676 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-16 13:01:42,677 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E
datanode_3_1  | 2020-07-16 13:01:42,785 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-07-16 13:01:42,795 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-16 13:01:42,795 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-07-16 13:01:42,796 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-07-16 13:01:42,796 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-07-16 13:01:42,805 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-16 13:01:42,807 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO impl.RoleInfo: 4f49310f-999a-4016-acc1-42cc4200008f: start LeaderState
datanode_3_1  | 2020-07-16 13:01:42,837 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-07-16 13:01:42,837 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-07-16 13:01:42,924 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-LeaderElection1] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914: set configuration 0: [4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-07-16 13:01:42,956 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-LeaderElection2] INFO impl.RaftServerImpl: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E: set configuration 0: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null at 0
datanode_3_1  | 2020-07-16 13:01:43,368 [4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4f49310f-999a-4016-acc1-42cc4200008f@group-AC9C7A051A6E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e/current/log_inprogress_0
datanode_3_1  | 2020-07-16 13:01:43,383 [4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4f49310f-999a-4016-acc1-42cc4200008f@group-F5735CC90914-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b0f7a9d8-0f33-40fe-a566-f5735cc90914/current/log_inprogress_0
datanode_4_1  | 2020-07-16 13:01:28,503 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-16 13:01:29,526 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From a68ac153a477/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:57336 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_4_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:57336 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_4_1  | 2020-07-16 13:01:30,106 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-07-16 13:01:30,110 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-07-16 13:01:30,120 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c at port 9858
datanode_4_1  | 2020-07-16 13:01:30,327 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: start RPC server
datanode_4_1  | 2020-07-16 13:01:30,901 [Datanode State Machine Thread - 1] INFO server.GrpcService: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-07-16 13:01:34,304 [Command processor thread] INFO impl.RaftServerProxy: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: addNew group-1D861CDB9220:[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858] returns group-1D861CDB9220:java.util.concurrent.CompletableFuture@5b93fd0e[Not completed]
datanode_4_1  | 2020-07-16 13:01:34,427 [pool-19-thread-1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: new RaftServerImpl for group-1D861CDB9220:[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-16 13:01:34,428 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-07-16 13:01:34,430 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-07-16 13:01:34,433 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-07-16 13:01:34,434 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-16 13:01:34,438 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-16 13:01:34,459 [pool-19-thread-1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220: ConfigurationManager, init=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-16 13:01:34,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-16 13:01:34,494 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-16 13:01:34,507 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/61fbd2d9-c788-45d5-b630-1d861cdb9220 does not exist. Creating ...
datanode_4_1  | 2020-07-16 13:01:34,555 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/61fbd2d9-c788-45d5-b630-1d861cdb9220/in_use.lock acquired by nodename 6@a68ac153a477
datanode_4_1  | 2020-07-16 13:01:34,576 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/61fbd2d9-c788-45d5-b630-1d861cdb9220 has been successfully formatted.
datanode_4_1  | 2020-07-16 13:01:34,599 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-1D861CDB9220: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-07-16 13:01:34,631 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-07-16 13:01:34,636 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-07-16 13:01:34,698 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-07-16 13:01:34,702 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-16 13:01:34,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-16 13:01:34,737 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220
datanode_4_1  | 2020-07-16 13:01:34,815 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-07-16 13:01:34,852 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/61fbd2d9-c788-45d5-b630-1d861cdb9220
datanode_4_1  | 2020-07-16 13:01:34,863 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-07-16 13:01:34,863 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-16 13:01:34,864 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-16 13:01:34,865 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-07-16 13:01:34,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-07-16 13:01:34,882 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-07-16 13:01:34,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-07-16 13:01:34,888 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-07-16 13:01:34,890 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-07-16 13:01:35,020 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-07-16 13:01:35,051 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-16 13:01:35,051 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-16 13:01:35,079 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-07-16 13:01:35,107 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-07-16 13:01:35,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-07-16 13:01:35,122 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-07-16 13:01:35,124 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-07-16 13:01:35,198 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220
datanode_4_1  | 2020-07-16 13:01:35,243 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220
datanode_4_1  | 2020-07-16 13:01:35,263 [pool-19-thread-1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220: start as a follower, conf=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858], old=null
datanode_4_1  | 2020-07-16 13:01:35,289 [pool-19-thread-1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-07-16 13:01:35,294 [pool-19-thread-1] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: start FollowerState
datanode_4_1  | 2020-07-16 13:01:35,340 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1D861CDB9220,id=39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
datanode_4_1  | 2020-07-16 13:01:35,341 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220
datanode_4_1  | 2020-07-16 13:01:35,396 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "61fbd2d9-c788-45d5-b630-1d861cdb9220"
datanode_4_1  | uuid128 {
datanode_4_1  |   mostSigBits: 7060468673630717397
datanode_4_1  |   leastSigBits: -5318718698077580768
datanode_4_1  | }
datanode_4_1  | .
datanode_4_1  | 2020-07-16 13:01:35,404 [Command processor thread] INFO impl.RaftServerProxy: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: addNew group-D4280D4755F5:[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858] returns group-D4280D4755F5:java.util.concurrent.CompletableFuture@7490f88[Not completed]
datanode_4_1  | 2020-07-16 13:01:35,420 [pool-19-thread-1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: new RaftServerImpl for group-D4280D4755F5:[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-16 13:01:35,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-07-16 13:01:35,423 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-07-16 13:01:35,424 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-07-16 13:01:35,424 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-16 13:01:35,424 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-16 13:01:35,425 [pool-19-thread-1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5: ConfigurationManager, init=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-16 13:01:35,425 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-16 13:01:35,426 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-16 13:01:35,428 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5 does not exist. Creating ...
datanode_4_1  | 2020-07-16 13:01:35,433 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5/in_use.lock acquired by nodename 6@a68ac153a477
datanode_4_1  | 2020-07-16 13:01:35,444 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5 has been successfully formatted.
datanode_4_1  | 2020-07-16 13:01:35,450 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-D4280D4755F5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-07-16 13:01:35,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-07-16 13:01:35,456 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-07-16 13:01:35,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-07-16 13:01:35,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-16 13:01:35,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-16 13:01:35,460 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5
datanode_4_1  | 2020-07-16 13:01:35,464 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-07-16 13:01:35,467 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5
datanode_4_1  | 2020-07-16 13:01:35,467 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-07-16 13:01:35,467 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-16 13:01:35,550 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-16 13:01:35,551 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-07-16 13:01:35,555 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-07-16 13:01:35,566 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-07-16 13:01:35,566 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-07-16 13:01:35,566 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-07-16 13:01:35,566 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-07-16 13:01:35,575 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-07-16 13:01:35,576 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-16 13:01:35,576 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-16 13:01:35,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-07-16 13:01:35,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-07-16 13:01:35,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-07-16 13:01:35,601 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-07-16 13:01:35,601 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-07-16 13:01:35,601 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5
datanode_4_1  | 2020-07-16 13:01:35,602 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5
datanode_4_1  | 2020-07-16 13:01:35,603 [pool-19-thread-1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5: start as a follower, conf=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null
datanode_4_1  | 2020-07-16 13:01:35,605 [pool-19-thread-1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-07-16 13:01:35,610 [pool-19-thread-1] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: start FollowerState
datanode_4_1  | 2020-07-16 13:01:35,618 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D4280D4755F5,id=39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
datanode_4_1  | 2020-07-16 13:01:35,618 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5
datanode_4_1  | 2020-07-16 13:01:40,435 [Thread-23] INFO impl.FollowerState: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-FollowerState: change to CANDIDATE, lastRpcTime:5140ms, electionTimeout:5113ms
datanode_4_1  | 2020-07-16 13:01:40,436 [Thread-23] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: shutdown FollowerState
datanode_4_1  | 2020-07-16 13:01:40,436 [Thread-23] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-07-16 13:01:40,439 [Thread-23] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: start LeaderElection
datanode_4_1  | 2020-07-16 13:01:40,445 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO impl.LeaderElection: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1: begin an election at term 1 for -1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858], old=null
datanode_4_1  | 2020-07-16 13:01:40,455 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: shutdown LeaderElection
datanode_4_1  | 2020-07-16 13:01:40,456 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-07-16 13:01:40,459 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-1D861CDB9220 with new leaderId: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-07-16 13:01:05,296 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-07-16 13:01:07,163 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-07-16 13:01:08,017 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-07-16 13:01:09,434 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-07-16 13:01:09,434 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-07-16 13:01:10,096 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:21aab171bf2f ip:10.5.0.4
datanode_1_1  | 2020-07-16 13:01:10,952 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-07-16 13:01:10,967 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-07-16 13:01:10,970 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-07-16 13:01:11,010 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-07-16 13:01:11,387 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-07-16 13:01:17,990 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-07-16 13:01:18,612 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-07-16 13:01:19,572 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-07-16 13:01:19,576 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-07-16 13:01:19,580 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-16 13:01:19,582 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-07-16 13:01:19,584 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-07-16 13:01:21,599 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-16 13:01:21,626 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-07-16 13:01:22,851 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-07-16 13:01:22,997 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-07-16 13:01:23,124 [main] INFO util.log: Logging initialized @25604ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-07-16 13:01:23,740 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-07-16 13:01:23,768 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-07-16 13:01:23,775 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-07-16 13:01:23,794 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-07-16 13:01:23,812 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-07-16 13:01:23,819 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-07-16 13:01:23,955 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-07-16 13:01:23,989 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-07-16 13:01:23,990 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-07-16 13:01:24,154 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-07-16 13:01:24,156 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-07-16 13:01:24,157 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1_1  | 2020-07-16 13:01:24,242 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7ea3839e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-07-16 13:01:24,249 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18c820d2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-07-16 13:01:24,635 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@53b7bf01{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-12303134927727205344.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-07-16 13:01:24,657 [main] INFO server.AbstractConnector: Started ServerConnector@4dd1548e{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-07-16 13:01:24,657 [main] INFO server.Server: Started @27137ms
datanode_1_1  | 2020-07-16 13:01:24,673 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-07-16 13:01:24,673 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-07-16 13:01:24,677 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-07-16 13:01:24,893 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@110ea821] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-07-16 13:01:25,730 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-07-16 13:01:28,112 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-16 13:01:29,115 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-16 13:01:30,156 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-07-16 13:01:30,159 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-07-16 13:01:30,165 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis de7eb8b4-4719-42f5-b1f1-5c05eece8d74 at port 9858
datanode_1_1  | 2020-07-16 13:01:30,297 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: start RPC server
datanode_1_1  | 2020-07-16 13:01:30,779 [Datanode State Machine Thread - 0] INFO server.GrpcService: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-07-16 13:01:39,703 [grpc-default-executor-0] INFO impl.RaftServerProxy: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: addNew group-AC9C7A051A6E:[de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858] returns group-AC9C7A051A6E:java.util.concurrent.CompletableFuture@6924727[Not completed]
datanode_1_1  | 2020-07-16 13:01:39,840 [pool-19-thread-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: new RaftServerImpl for group-AC9C7A051A6E:[de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-07-16 13:01:39,844 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-07-16 13:01:39,856 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-07-16 13:01:39,857 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-07-16 13:01:39,860 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-07-16 13:01:39,861 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-07-16 13:01:39,908 [pool-19-thread-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E: ConfigurationManager, init=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-07-16 13:01:39,913 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-16 13:01:39,930 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-07-16 13:01:39,945 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e does not exist. Creating ...
datanode_1_1  | 2020-07-16 13:01:39,975 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e/in_use.lock acquired by nodename 6@21aab171bf2f
datanode_1_1  | 2020-07-16 13:01:39,992 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e has been successfully formatted.
datanode_1_1  | 2020-07-16 13:01:40,063 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-AC9C7A051A6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-07-16 13:01:40,064 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-07-16 13:01:40,066 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-07-16 13:01:40,098 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-07-16 13:01:40,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-16 13:01:40,127 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-16 13:01:40,189 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E
datanode_1_1  | 2020-07-16 13:01:40,465 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-16 13:01:40,547 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e
datanode_1_1  | 2020-07-16 13:01:40,563 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-07-16 13:01:40,568 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-16 13:01:40,570 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-16 13:01:40,579 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-07-16 13:01:40,584 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-16 13:01:40,584 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-07-16 13:01:40,587 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-07-16 13:01:40,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-07-16 13:01:40,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-07-16 13:01:40,713 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-07-16 13:01:40,779 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-16 13:01:40,783 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-16 13:01:40,816 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-07-16 13:01:40,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-07-16 13:01:40,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-07-16 13:01:40,835 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-07-16 13:01:40,842 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-07-16 13:01:41,155 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E
datanode_1_1  | 2020-07-16 13:01:41,194 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E
datanode_1_1  | 2020-07-16 13:01:41,198 [pool-19-thread-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E: start as a follower, conf=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null
datanode_4_1  | 2020-07-16 13:01:40,459 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220: change Leader from null to 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c at term 1 for becomeLeader, leader elected after 5828ms
datanode_4_1  | 2020-07-16 13:01:40,475 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-07-16 13:01:40,490 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-07-16 13:01:40,492 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220
datanode_4_1  | 2020-07-16 13:01:40,523 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-16 13:01:40,548 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-07-16 13:01:40,579 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-07-16 13:01:40,585 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-07-16 13:01:40,586 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-07-16 13:01:40,616 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: start LeaderState
datanode_4_1  | 2020-07-16 13:01:40,621 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "169b341c-e67d-4e0d-9cbd-d4280d4755f5"
datanode_4_1  | uuid128 {
datanode_4_1  |   mostSigBits: 1628952988955266573
datanode_4_1  |   leastSigBits: -7152327364707920395
datanode_4_1  | }
datanode_4_1  | .
datanode_4_1  | 2020-07-16 13:01:40,643 [Thread-25] INFO impl.FollowerState: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-FollowerState: change to CANDIDATE, lastRpcTime:5038ms, electionTimeout:5006ms
datanode_4_1  | 2020-07-16 13:01:40,650 [Thread-25] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: shutdown FollowerState
datanode_4_1  | 2020-07-16 13:01:40,650 [Thread-25] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-07-16 13:01:40,650 [Thread-25] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: start LeaderElection
datanode_4_1  | 2020-07-16 13:01:40,693 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO impl.LeaderElection: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2: begin an election at term 1 for -1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null
datanode_4_1  | 2020-07-16 13:01:40,852 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-07-16 13:01:41,032 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-LeaderElection1] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220: set configuration 0: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-07-16 13:01:41,339 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO impl.LeaderElection: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2: Election PASSED; received 1 response(s) [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c<-2d39f5a5-5993-4301-956d-f519f2994ca2#0:OK-t1] and 0 exception(s); 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5:t1, leader=null, voted=39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c, raftlog=39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null
datanode_4_1  | 2020-07-16 13:01:41,343 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: shutdown LeaderElection
datanode_4_1  | 2020-07-16 13:01:41,351 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-07-16 13:01:41,351 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D4280D4755F5 with new leaderId: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
datanode_4_1  | 2020-07-16 13:01:41,352 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5: change Leader from null to 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c at term 1 for becomeLeader, leader elected after 5900ms
datanode_4_1  | 2020-07-16 13:01:41,352 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-07-16 13:01:41,356 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-07-16 13:01:41,359 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5
datanode_4_1  | 2020-07-16 13:01:41,362 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-16 13:01:41,362 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-07-16 13:01:41,363 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-07-16 13:01:41,368 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-07-16 13:01:41,375 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-07-16 13:01:41,378 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_4_1  | 2020-07-16 13:01:41,386 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-16 13:01:41,398 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4_1  | 2020-07-16 13:01:41,411 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4_1  | 2020-07-16 13:01:41,448 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-07-16 13:01:41,453 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-16 13:01:41,456 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5
datanode_4_1  | 2020-07-16 13:01:41,534 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_4_1  | 2020-07-16 13:01:41,534 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-16 13:01:41,535 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4_1  | 2020-07-16 13:01:41,535 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4_1  | 2020-07-16 13:01:41,535 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-07-16 13:01:41,535 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-16 13:01:41,538 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO impl.RoleInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c: start LeaderState
datanode_4_1  | 2020-07-16 13:01:41,545 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-07-16 13:01:41,646 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-LeaderElection2] INFO impl.RaftServerImpl: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5: set configuration 0: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null at 0
datanode_4_1  | 2020-07-16 13:01:41,761 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5/current/log_inprogress_0
datanode_4_1  | 2020-07-16 13:01:41,814 [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-1D861CDB9220-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/61fbd2d9-c788-45d5-b630-1d861cdb9220/current/log_inprogress_0
datanode_4_1  | 2020-07-16 13:01:44,490 [grpc-default-executor-0] INFO impl.FollowerInfo: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f: nextIndex: updateUnconditionally 1 -> 0
datanode_4_1  | 2020-07-16 13:02:44,491 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode_4_1  | 2020-07-16 13:02:58,214 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:1)
datanode_4_1  | 2020-07-16 13:02:58,303 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:2)
datanode_4_1  | 2020-07-16 13:02:59,825 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:3)
datanode_4_1  | 2020-07-16 13:02:59,828 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:4)
datanode_4_1  | 2020-07-16 13:03:02,369 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:5)
datanode_4_1  | 2020-07-16 13:03:02,382 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:6)
datanode_4_1  | 2020-07-16 13:03:02,433 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:7)
datanode_4_1  | 2020-07-16 13:03:02,448 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:8)
datanode_4_1  | 2020-07-16 13:03:05,193 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:9)
datanode_4_1  | 2020-07-16 13:03:05,207 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:10)
datanode_4_1  | 2020-07-16 13:03:05,212 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:11)
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-07-16 13:01:04,536 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 46f82f0429be/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-07-16 13:01:01,817 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = d1241e819a44/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | 2020-07-16 13:03:05,231 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:12)
datanode_4_1  | 2020-07-16 13:03:07,888 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:13)
datanode_4_1  | 2020-07-16 13:03:07,901 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:14)
datanode_4_1  | 2020-07-16 13:03:07,906 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:15)
datanode_4_1  | 2020-07-16 13:03:07,916 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:16)
datanode_4_1  | 2020-07-16 13:03:13,178 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:17)
datanode_4_1  | 2020-07-16 13:03:13,184 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:18)
datanode_4_1  | 2020-07-16 13:03:13,194 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:19)
datanode_4_1  | 2020-07-16 13:03:13,215 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=33,entriesCount=1,lastEntry=(t:1, i:20)
datanode_4_1  | 2020-07-16 13:03:15,943 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:21)
datanode_4_1  | 2020-07-16 13:03:15,963 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:22)
datanode_4_1  | 2020-07-16 13:03:15,974 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:23)
datanode_4_1  | 2020-07-16 13:03:15,996 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:24)
datanode_4_1  | 2020-07-16 13:03:18,619 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:25)
datanode_4_1  | 2020-07-16 13:03:18,644 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:26)
datanode_4_1  | 2020-07-16 13:03:18,657 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:27)
datanode_4_1  | 2020-07-16 13:03:18,667 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=43,entriesCount=1,lastEntry=(t:1, i:28)
datanode_4_1  | 2020-07-16 13:03:23,767 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:29)
datanode_4_1  | 2020-07-16 13:03:23,782 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:30)
datanode_4_1  | 2020-07-16 13:03:23,802 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=48,entriesCount=1,lastEntry=(t:1, i:31)
datanode_4_1  | 2020-07-16 13:03:23,812 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=49,entriesCount=1,lastEntry=(t:1, i:32)
datanode_4_1  | 2020-07-16 13:03:26,362 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:33)
datanode_4_1  | 2020-07-16 13:03:26,362 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:34)
datanode_1_1  | 2020-07-16 13:01:41,214 [pool-19-thread-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-07-16 13:01:41,232 [pool-19-thread-1] INFO impl.RoleInfo: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: start FollowerState
datanode_1_1  | 2020-07-16 13:01:41,278 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AC9C7A051A6E,id=de7eb8b4-4719-42f5-b1f1-5c05eece8d74
datanode_1_1  | 2020-07-16 13:01:41,279 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E
datanode_1_1  | 2020-07-16 13:01:42,143 [grpc-default-executor-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:4f49310f-999a-4016-acc1-42cc4200008f
datanode_1_1  | 2020-07-16 13:01:42,144 [grpc-default-executor-1] INFO impl.RoleInfo: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: shutdown FollowerState
datanode_1_1  | 2020-07-16 13:01:42,148 [grpc-default-executor-1] INFO impl.RoleInfo: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: start FollowerState
datanode_1_1  | 2020-07-16 13:01:42,148 [Thread-23] INFO impl.FollowerState: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 2020-07-16 13:01:43,052 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AC9C7A051A6E with new leaderId: 4f49310f-999a-4016-acc1-42cc4200008f
datanode_1_1  | 2020-07-16 13:01:43,058 [grpc-default-executor-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E: change Leader from null to 4f49310f-999a-4016-acc1-42cc4200008f at term 1 for appendEntries, leader elected after 2988ms
datanode_1_1  | 2020-07-16 13:01:43,163 [grpc-default-executor-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E: set configuration 0: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858, 4f49310f-999a-4016-acc1-42cc4200008f:10.5.0.6:9858, 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674:10.5.0.8:9858], old=null at 0
datanode_1_1  | 2020-07-16 13:01:43,200 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-07-16 13:01:43,637 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-AC9C7A051A6E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3126ee1f-b742-47bc-99f8-ac9c7a051a6e/current/log_inprogress_0
datanode_1_1  | 2020-07-16 13:02:03,985 [Command processor thread] INFO impl.RaftServerProxy: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: addNew group-0115BDFF853C:[de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858] returns group-0115BDFF853C:java.util.concurrent.CompletableFuture@29736e73[Not completed]
datanode_1_1  | 2020-07-16 13:02:03,988 [pool-19-thread-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: new RaftServerImpl for group-0115BDFF853C:[de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-07-16 13:02:03,988 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-07-16 13:02:03,988 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-07-16 13:02:03,988 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-07-16 13:02:03,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-07-16 13:02:03,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-07-16 13:02:03,989 [pool-19-thread-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C: ConfigurationManager, init=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-07-16 13:02:03,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-16 13:02:03,990 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-07-16 13:02:03,990 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a0b9ca99-9803-40c5-9070-0115bdff853c does not exist. Creating ...
datanode_1_1  | 2020-07-16 13:02:03,991 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a0b9ca99-9803-40c5-9070-0115bdff853c/in_use.lock acquired by nodename 6@21aab171bf2f
datanode_1_1  | 2020-07-16 13:02:03,993 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a0b9ca99-9803-40c5-9070-0115bdff853c has been successfully formatted.
datanode_1_1  | 2020-07-16 13:02:03,993 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0115BDFF853C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-07-16 13:02:03,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-07-16 13:02:03,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-07-16 13:02:03,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-07-16 13:02:03,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-16 13:02:03,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-16 13:02:03,995 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C
datanode_1_1  | 2020-07-16 13:02:03,995 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-16 13:02:03,995 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a0b9ca99-9803-40c5-9070-0115bdff853c
datanode_1_1  | 2020-07-16 13:02:03,996 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-07-16 13:02:03,996 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-16 13:02:03,996 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-16 13:02:03,996 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-07-16 13:02:03,997 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-16 13:02:03,997 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-07-16 13:02:03,997 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-07-16 13:02:03,997 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-07-16 13:02:03,997 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-07-16 13:02:04,000 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-07-16 13:01:04,634 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-07-16 13:01:11,294 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-07-16 13:01:12,123 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-07-16 13:01:12,124 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-07-16 13:01:12,244 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-16 13:01:15,308 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:16,309 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:17,310 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:18,311 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:19,312 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:20,313 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:21,314 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:22,316 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:23,320 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:24,322 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:24,324 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-8d8193db-b762-4253-8ecb-347be1862dac;layoutVersion=0
om_1          | 2020-07-16 13:01:30,448 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 46f82f0429be/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-07-16 13:01:37,513 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 46f82f0429be/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | 2020-07-16 13:02:04,000 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-16 13:02:04,000 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-16 13:02:04,000 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-07-16 13:02:04,000 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-07-16 13:02:04,001 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-07-16 13:02:04,001 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-07-16 13:02:04,001 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-07-16 13:02:04,001 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C
datanode_1_1  | 2020-07-16 13:02:04,002 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C
datanode_1_1  | 2020-07-16 13:02:04,002 [pool-19-thread-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C: start as a follower, conf=-1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858], old=null
datanode_1_1  | 2020-07-16 13:02:04,002 [pool-19-thread-1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-07-16 13:02:04,002 [pool-19-thread-1] INFO impl.RoleInfo: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: start FollowerState
datanode_1_1  | 2020-07-16 13:02:04,003 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0115BDFF853C,id=de7eb8b4-4719-42f5-b1f1-5c05eece8d74
datanode_1_1  | 2020-07-16 13:02:04,003 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C
datanode_1_1  | 2020-07-16 13:02:04,007 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "a0b9ca99-9803-40c5-9070-0115bdff853c"
datanode_1_1  | uuid128 {
datanode_1_1  |   mostSigBits: -6865233395920453435
datanode_1_1  |   leastSigBits: -8038924141962754756
datanode_1_1  | }
datanode_1_1  | .
datanode_1_1  | 2020-07-16 13:02:09,013 [Thread-45] INFO impl.FollowerState: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-FollowerState: change to CANDIDATE, lastRpcTime:5010ms, electionTimeout:5008ms
datanode_1_1  | 2020-07-16 13:02:09,013 [Thread-45] INFO impl.RoleInfo: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: shutdown FollowerState
datanode_1_1  | 2020-07-16 13:02:09,013 [Thread-45] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-07-16 13:02:09,016 [Thread-45] INFO impl.RoleInfo: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: start LeaderElection
datanode_1_1  | 2020-07-16 13:02:09,018 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO impl.LeaderElection: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1: begin an election at term 1 for -1: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858], old=null
datanode_1_1  | 2020-07-16 13:02:09,020 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO impl.RoleInfo: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: shutdown LeaderElection
datanode_1_1  | 2020-07-16 13:02:09,020 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-07-16 13:02:09,020 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0115BDFF853C with new leaderId: de7eb8b4-4719-42f5-b1f1-5c05eece8d74
datanode_1_1  | 2020-07-16 13:02:09,020 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C: change Leader from null to de7eb8b4-4719-42f5-b1f1-5c05eece8d74 at term 1 for becomeLeader, leader elected after 5026ms
datanode_1_1  | 2020-07-16 13:02:09,022 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-07-16 13:02:09,022 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-07-16 13:02:09,025 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C
datanode_1_1  | 2020-07-16 13:02:09,030 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-16 13:02:09,031 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-07-16 13:02:09,036 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-07-16 13:02:09,036 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-07-16 13:02:09,037 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-07-16 13:02:09,053 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO impl.RoleInfo: de7eb8b4-4719-42f5-b1f1-5c05eece8d74: start LeaderState
datanode_1_1  | 2020-07-16 13:02:09,056 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-07-16 13:02:09,057 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a0b9ca99-9803-40c5-9070-0115bdff853c/current/log_inprogress_0
datanode_1_1  | 2020-07-16 13:02:09,059 [de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C-LeaderElection1] INFO impl.RaftServerImpl: de7eb8b4-4719-42f5-b1f1-5c05eece8d74@group-0115BDFF853C: set configuration 0: [de7eb8b4-4719-42f5-b1f1-5c05eece8d74:10.5.0.4:9858], old=null at 0
datanode_4_1  | 2020-07-16 13:03:26,382 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=53,entriesCount=1,lastEntry=(t:1, i:35)
datanode_4_1  | 2020-07-16 13:03:29,024 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:36)
datanode_4_1  | 2020-07-16 13:03:29,024 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:37)
datanode_4_1  | 2020-07-16 13:03:29,044 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:38)
datanode_4_1  | 2020-07-16 13:03:29,053 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=58,entriesCount=1,lastEntry=(t:1, i:39)
datanode_4_1  | 2020-07-16 13:03:31,602 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:40)
datanode_4_1  | 2020-07-16 13:03:31,608 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:41)
datanode_4_1  | 2020-07-16 13:03:31,624 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:42)
datanode_4_1  | 2020-07-16 13:03:31,634 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=63,entriesCount=1,lastEntry=(t:1, i:43)
datanode_4_1  | 2020-07-16 13:03:34,193 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:44)
datanode_4_1  | 2020-07-16 13:03:34,207 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:45)
datanode_4_1  | 2020-07-16 13:03:34,207 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:46)
datanode_4_1  | 2020-07-16 13:03:34,222 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=68,entriesCount=1,lastEntry=(t:1, i:47)
datanode_4_1  | 2020-07-16 13:03:36,750 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:48)
datanode_4_1  | 2020-07-16 13:03:36,761 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:49)
datanode_4_1  | 2020-07-16 13:03:36,777 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:50)
datanode_4_1  | 2020-07-16 13:03:36,785 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=73,entriesCount=1,lastEntry=(t:1, i:51)
datanode_4_1  | 2020-07-16 13:03:42,059 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:52)
datanode_4_1  | 2020-07-16 13:03:42,070 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:53)
datanode_4_1  | 2020-07-16 13:03:42,112 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=78,entriesCount=1,lastEntry=(t:1, i:54)
datanode_4_1  | 2020-07-16 13:03:44,652 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:55)
datanode_4_1  | 2020-07-16 13:03:44,662 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:56)
datanode_4_1  | 2020-07-16 13:03:44,678 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=82,entriesCount=1,lastEntry=(t:1, i:57)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-07-16 13:01:37,548 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-07-16 13:01:41,815 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-07-16 13:01:42,202 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-07-16 13:01:42,202 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-07-16 13:01:42,610 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-16 13:01:42,711 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-16 13:01:45,859 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-16 13:01:46,644 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-07-16 13:01:46,665 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-07-16 13:01:46,890 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-07-16 13:01:46,975 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-07-16 13:01:46,976 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1          | 2020-07-16 13:01:47,051 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
om_1          | 2020-07-16 13:01:47,090 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-07-16 13:01:47,097 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-07-16 13:01:47,281 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-07-16 13:01:47,281 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1          | 2020-07-16 13:01:47,327 [Listener at om/9862] INFO util.log: Logging initialized @16095ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-07-16 13:01:47,510 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-07-16 13:01:47,519 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-07-16 13:01:01,917 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-07-16 13:01:03,559 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-07-16 13:01:04,380 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-07-16 13:01:05,759 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-07-16 13:01:05,759 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-07-16 13:01:06,422 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d1241e819a44 ip:10.5.0.9
datanode_6_1  | 2020-07-16 13:01:07,341 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-07-16 13:01:07,387 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-07-16 13:01:07,398 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-07-16 13:01:07,474 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-07-16 13:01:07,884 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-07-16 13:01:15,638 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-07-16 13:01:16,335 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-07-16 13:01:17,460 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-07-16 13:01:17,470 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-07-16 13:01:17,476 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-16 13:01:17,477 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-07-16 13:01:17,506 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-07-16 13:01:18,655 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-16 13:01:18,670 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-07-16 13:01:20,518 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-07-16 13:01:20,624 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 2020-07-16 13:01:20,783 [main] INFO util.log: Logging initialized @26600ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-07-16 13:01:21,405 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-07-16 13:01:21,418 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-07-16 13:01:21,458 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-07-16 13:01:21,469 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_6_1  | 2020-07-16 13:01:21,470 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 2020-07-16 13:01:21,470 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 2020-07-16 13:01:21,672 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-07-16 13:01:21,713 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-07-16 13:01:21,714 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-07-16 13:01:22,056 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-07-16 13:01:22,062 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-07-16 13:01:22,064 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_6_1  | 2020-07-16 13:01:22,145 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@473847fb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-07-16 13:01:22,152 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@74707df8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-07-16 13:01:22,632 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@359e27d2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-11504217747106643032.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-07-16 13:01:22,721 [main] INFO server.AbstractConnector: Started ServerConnector@60816371{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-07-16 13:01:22,722 [main] INFO server.Server: Started @28539ms
datanode_6_1  | 2020-07-16 13:01:22,731 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-07-16 13:01:22,731 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-07-16 13:01:22,738 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-07-16 13:01:22,919 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@693aca59] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-07-16 13:01:23,888 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-07-16 13:01:26,308 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-16 13:01:27,309 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-16 13:01:28,310 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-16 13:01:47,534 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-07-16 13:01:47,542 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1          | 2020-07-16 13:01:47,546 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-07-16 13:01:47,546 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-07-16 13:01:47,595 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-07-16 13:01:47,601 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-07-16 13:01:47,602 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-07-16 13:01:47,638 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-07-16 13:01:47,639 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-07-16 13:01:47,641 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1          | 2020-07-16 13:01:47,655 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3063be68{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-07-16 13:01:47,657 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56b704ea{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-07-16 13:01:47,822 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@335896bd{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-14642083521849779712.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-07-16 13:01:47,838 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@3bda1f0{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-07-16 13:01:47,839 [Listener at om/9862] INFO server.Server: Started @16606ms
om_1          | 2020-07-16 13:01:47,846 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-07-16 13:01:47,847 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-07-16 13:01:47,850 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-07-16 13:01:47,864 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7d47b021] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2020-07-16 13:01:53,189 [IPC Server handler 1 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-80565 for user:hadoop
om_1          | 2020-07-16 13:01:53,217 [IPC Server handler 75 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-66832 for user:hadoop
om_1          | 2020-07-16 13:01:53,244 [IPC Server handler 0 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-20150 for user:hadoop
om_1          | 2020-07-16 13:01:53,253 [IPC Server handler 3 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-70171 for user:hadoop
om_1          | 2020-07-16 13:01:53,272 [IPC Server handler 5 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-96147 for user:hadoop
datanode_4_1  | 2020-07-16 13:03:44,686 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:58)
datanode_4_1  | 2020-07-16 13:03:47,241 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:59)
datanode_4_1  | 2020-07-16 13:03:47,241 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:60)
datanode_4_1  | 2020-07-16 13:03:47,245 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=87,entriesCount=1,lastEntry=(t:1, i:61)
datanode_4_1  | 2020-07-16 13:03:49,774 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:62)
datanode_4_1  | 2020-07-16 13:03:49,786 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:63)
datanode_4_1  | 2020-07-16 13:03:49,793 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:64)
datanode_4_1  | 2020-07-16 13:03:49,806 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=92,entriesCount=1,lastEntry=(t:1, i:65)
datanode_4_1  | 2020-07-16 13:03:52,338 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:66)
datanode_4_1  | 2020-07-16 13:03:52,350 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:67)
datanode_4_1  | 2020-07-16 13:03:52,359 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:68)
datanode_4_1  | 2020-07-16 13:03:55,008 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:69)
datanode_4_1  | 2020-07-16 13:03:55,029 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:70)
datanode_4_1  | 2020-07-16 13:03:55,029 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:71)
datanode_4_1  | 2020-07-16 13:03:57,593 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:72)
datanode_4_1  | 2020-07-16 13:03:57,606 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:73)
datanode_4_1  | 2020-07-16 13:03:57,612 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:74)
datanode_4_1  | 2020-07-16 13:03:57,622 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:75)
datanode_4_1  | 2020-07-16 13:04:00,397 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=107,entriesCount=1,lastEntry=(t:1, i:76)
datanode_4_1  | 2020-07-16 13:04:00,412 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=108,entriesCount=1,lastEntry=(t:1, i:77)
datanode_4_1  | 2020-07-16 13:04:00,413 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:78)
datanode_4_1  | 2020-07-16 13:04:03,471 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:79)
datanode_4_1  | 2020-07-16 13:04:03,481 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:80)
datanode_6_1  | 2020-07-16 13:01:29,334 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_6_1  | java.net.SocketTimeoutException: Call From d1241e819a44/10.5.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:54910 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_6_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_6_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_6_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:54910 remote=scm/10.5.0.71:9861]
datanode_6_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_6_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_6_1  | 2020-07-16 13:01:30,197 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-07-16 13:01:30,206 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-07-16 13:01:30,218 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 6377505a-0934-4e3b-8892-495630fc2c1f at port 9858
datanode_6_1  | 2020-07-16 13:01:30,314 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 6377505a-0934-4e3b-8892-495630fc2c1f: start RPC server
datanode_6_1  | 2020-07-16 13:01:30,900 [Datanode State Machine Thread - 1] INFO server.GrpcService: 6377505a-0934-4e3b-8892-495630fc2c1f: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-07-16 13:01:40,160 [grpc-default-executor-0] INFO impl.RaftServerProxy: 6377505a-0934-4e3b-8892-495630fc2c1f: addNew group-D4280D4755F5:[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858] returns group-D4280D4755F5:java.util.concurrent.CompletableFuture@3b4b152d[Not completed]
datanode_6_1  | 2020-07-16 13:01:40,441 [pool-19-thread-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f: new RaftServerImpl for group-D4280D4755F5:[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-07-16 13:01:40,526 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-07-16 13:01:40,576 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-07-16 13:01:40,576 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-07-16 13:01:40,576 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-16 13:01:40,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-16 13:01:40,677 [pool-19-thread-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5: ConfigurationManager, init=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-07-16 13:01:40,679 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-16 13:01:40,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-07-16 13:01:40,713 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5 does not exist. Creating ...
datanode_6_1  | 2020-07-16 13:01:40,761 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5/in_use.lock acquired by nodename 6@d1241e819a44
datanode_6_1  | 2020-07-16 13:01:40,844 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5 has been successfully formatted.
datanode_6_1  | 2020-07-16 13:01:41,119 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-D4280D4755F5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-07-16 13:01:41,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-07-16 13:01:41,313 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-07-16 13:04:03,487 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:81)
datanode_4_1  | 2020-07-16 13:04:03,498 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:82)
datanode_4_1  | 2020-07-16 13:04:06,197 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=116,entriesCount=1,lastEntry=(t:1, i:83)
datanode_4_1  | 2020-07-16 13:04:06,205 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:84)
datanode_4_1  | 2020-07-16 13:04:06,220 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=118,entriesCount=1,lastEntry=(t:1, i:85)
datanode_4_1  | 2020-07-16 13:04:06,245 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:86)
datanode_4_1  | 2020-07-16 13:04:08,770 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=121,entriesCount=1,lastEntry=(t:1, i:87)
datanode_4_1  | 2020-07-16 13:04:08,778 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:88)
datanode_4_1  | 2020-07-16 13:04:08,792 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=123,entriesCount=1,lastEntry=(t:1, i:89)
datanode_4_1  | 2020-07-16 13:04:08,800 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:90)
datanode_4_1  | 2020-07-16 13:04:11,338 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=126,entriesCount=1,lastEntry=(t:1, i:91)
datanode_4_1  | 2020-07-16 13:04:11,346 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:92)
datanode_4_1  | 2020-07-16 13:04:11,363 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=128,entriesCount=1,lastEntry=(t:1, i:93)
datanode_4_1  | 2020-07-16 13:04:11,378 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=129,entriesCount=1,lastEntry=(t:1, i:94)
datanode_4_1  | 2020-07-16 13:04:14,060 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=131,entriesCount=1,lastEntry=(t:1, i:95)
datanode_4_1  | 2020-07-16 13:04:14,073 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:96)
datanode_4_1  | 2020-07-16 13:04:14,128 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:97)
datanode_4_1  | 2020-07-16 13:04:16,729 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:98)
datanode_4_1  | 2020-07-16 13:04:16,730 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=136,entriesCount=1,lastEntry=(t:1, i:99)
datanode_4_1  | 2020-07-16 13:04:16,753 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:100)
datanode_4_1  | 2020-07-16 13:04:16,761 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=138,entriesCount=1,lastEntry=(t:1, i:101)
datanode_4_1  | 2020-07-16 13:04:22,062 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=141,entriesCount=1,lastEntry=(t:1, i:102)
datanode_4_1  | 2020-07-16 13:04:22,068 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=142,entriesCount=1,lastEntry=(t:1, i:103)
datanode_6_1  | 2020-07-16 13:01:41,326 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-07-16 13:01:41,326 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-16 13:01:41,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-16 13:01:41,534 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5
datanode_6_1  | 2020-07-16 13:01:41,703 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-07-16 13:01:41,759 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5
datanode_6_1  | 2020-07-16 13:01:41,763 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-07-16 13:01:41,764 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-16 13:01:41,781 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-16 13:01:41,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-16 13:01:41,807 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-07-16 13:01:41,808 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-07-16 13:01:41,809 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-16 13:01:41,819 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-07-16 13:01:41,820 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-07-16 13:01:42,072 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-07-16 13:01:42,147 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-16 13:01:42,159 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-16 13:01:42,199 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-07-16 13:01:42,220 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-16 13:01:42,221 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-07-16 13:01:42,225 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-07-16 13:01:42,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-07-16 13:01:42,604 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5
datanode_6_1  | 2020-07-16 13:01:42,631 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5
datanode_6_1  | 2020-07-16 13:01:42,696 [pool-19-thread-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5: start as a follower, conf=-1: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null
datanode_6_1  | 2020-07-16 13:01:42,709 [pool-19-thread-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-07-16 13:01:42,726 [pool-19-thread-1] INFO impl.RoleInfo: 6377505a-0934-4e3b-8892-495630fc2c1f: start FollowerState
datanode_6_1  | 2020-07-16 13:01:42,732 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 6377505a-0934-4e3b-8892-495630fc2c1f: Failed requestVote 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c->6377505a-0934-4e3b-8892-495630fc2c1f#0: org.apache.ratis.protocol.ServerNotReadyException: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5 is not in [RUNNING]: current state is STARTING
datanode_6_1  | 2020-07-16 13:01:42,807 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D4280D4755F5,id=6377505a-0934-4e3b-8892-495630fc2c1f
datanode_6_1  | 2020-07-16 13:01:42,836 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5
datanode_6_1  | 2020-07-16 13:01:44,435 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D4280D4755F5 with new leaderId: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
datanode_6_1  | 2020-07-16 13:01:44,436 [grpc-default-executor-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5: change Leader from null to 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c at term 1 for appendEntries, leader elected after 3314ms
datanode_6_1  | 2020-07-16 13:01:44,438 [grpc-default-executor-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_6_1  | 2020-07-16 13:01:44,449 [grpc-default-executor-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5: inconsistency entries. Reply:39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c<-6377505a-0934-4e3b-8892-495630fc2c1f#2:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_6_1  | 2020-07-16 13:01:44,543 [grpc-default-executor-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5: set configuration 0: [39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:10.5.0.7:9858, 2d39f5a5-5993-4301-956d-f519f2994ca2:10.5.0.5:9858, 6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-07-16 13:01:44,560 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-16 13:01:44,724 [6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6377505a-0934-4e3b-8892-495630fc2c1f@group-D4280D4755F5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/169b341c-e67d-4e0d-9cbd-d4280d4755f5/current/log_inprogress_0
datanode_6_1  | 2020-07-16 13:02:04,139 [pool-19-thread-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f: new RaftServerImpl for group-E054F39F9C62:[6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-07-16 13:02:04,139 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-07-16 13:02:04,139 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-07-16 13:02:04,139 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-07-16 13:01:10,199 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = d869b4d313f1/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | 2020-07-16 13:04:22,075 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=143,entriesCount=1,lastEntry=(t:1, i:104)
datanode_4_1  | 2020-07-16 13:04:22,098 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:105)
datanode_4_1  | 2020-07-16 13:04:27,181 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:106)
datanode_4_1  | 2020-07-16 13:04:27,199 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=148,entriesCount=1,lastEntry=(t:1, i:107)
datanode_4_1  | 2020-07-16 13:04:27,224 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:108)
datanode_4_1  | 2020-07-16 13:04:27,235 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:109)
datanode_4_1  | 2020-07-16 13:04:30,434 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=152,entriesCount=1,lastEntry=(t:1, i:110)
datanode_4_1  | 2020-07-16 13:04:30,438 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=153,entriesCount=1,lastEntry=(t:1, i:111)
datanode_4_1  | 2020-07-16 13:04:30,443 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:112)
datanode_4_1  | 2020-07-16 13:04:30,451 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:113)
datanode_4_1  | 2020-07-16 13:04:33,292 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=157,entriesCount=1,lastEntry=(t:1, i:114)
datanode_4_1  | 2020-07-16 13:04:33,302 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:115)
datanode_4_1  | 2020-07-16 13:04:33,317 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=159,entriesCount=1,lastEntry=(t:1, i:116)
datanode_4_1  | 2020-07-16 13:04:33,322 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:117)
datanode_4_1  | 2020-07-16 13:04:38,483 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:118)
datanode_4_1  | 2020-07-16 13:04:38,494 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=164,entriesCount=1,lastEntry=(t:1, i:119)
datanode_4_1  | 2020-07-16 13:04:38,505 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=165,entriesCount=1,lastEntry=(t:1, i:120)
datanode_4_1  | 2020-07-16 13:04:38,524 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=166,entriesCount=1,lastEntry=(t:1, i:121)
datanode_4_1  | 2020-07-16 13:04:41,320 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:122)
datanode_4_1  | 2020-07-16 13:04:41,329 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=169,entriesCount=1,lastEntry=(t:1, i:123)
datanode_4_1  | 2020-07-16 13:04:41,337 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=170,entriesCount=1,lastEntry=(t:1, i:124)
datanode_4_1  | 2020-07-16 13:04:41,342 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=171,entriesCount=1,lastEntry=(t:1, i:125)
datanode_6_1  | 2020-07-16 13:02:04,140 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-16 13:02:04,140 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-16 13:02:04,140 [pool-19-thread-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62: ConfigurationManager, init=-1: [6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-07-16 13:02:04,140 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-16 13:02:04,141 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-07-16 13:02:04,141 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2271bf5c-25f3-49af-8629-e054f39f9c62 does not exist. Creating ...
datanode_6_1  | 2020-07-16 13:02:04,141 [Command processor thread] INFO impl.RaftServerProxy: 6377505a-0934-4e3b-8892-495630fc2c1f: addNew group-E054F39F9C62:[6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858] returns group-E054F39F9C62:java.util.concurrent.CompletableFuture@8835652[Not completed]
datanode_6_1  | 2020-07-16 13:02:04,142 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2271bf5c-25f3-49af-8629-e054f39f9c62/in_use.lock acquired by nodename 6@d1241e819a44
datanode_6_1  | 2020-07-16 13:02:04,145 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2271bf5c-25f3-49af-8629-e054f39f9c62 has been successfully formatted.
datanode_6_1  | 2020-07-16 13:02:04,145 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-E054F39F9C62: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-07-16 13:02:04,145 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-07-16 13:02:04,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-07-16 13:02:04,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-07-16 13:02:04,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-16 13:02:04,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-16 13:02:04,146 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62
datanode_6_1  | 2020-07-16 13:02:04,147 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-07-16 13:02:04,147 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2271bf5c-25f3-49af-8629-e054f39f9c62
datanode_6_1  | 2020-07-16 13:02:04,147 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-07-16 13:02:04,148 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-16 13:02:04,148 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-16 13:02:04,148 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-16 13:02:04,150 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-07-16 13:02:04,150 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-07-16 13:02:04,150 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-16 13:02:04,150 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-07-16 13:02:04,150 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-07-16 13:02:04,153 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-07-16 13:02:04,154 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-16 13:02:04,154 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-16 13:02:04,154 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-07-16 13:02:04,155 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-16 13:02:04,155 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-07-16 13:02:04,155 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-07-16 13:02:04,156 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-07-16 13:02:04,156 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62
datanode_6_1  | 2020-07-16 13:02:04,156 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62
datanode_6_1  | 2020-07-16 13:02:04,158 [pool-19-thread-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62: start as a follower, conf=-1: [6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null
datanode_6_1  | 2020-07-16 13:02:04,159 [pool-19-thread-1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-07-16 13:02:04,159 [pool-19-thread-1] INFO impl.RoleInfo: 6377505a-0934-4e3b-8892-495630fc2c1f: start FollowerState
datanode_6_1  | 2020-07-16 13:02:04,161 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E054F39F9C62,id=6377505a-0934-4e3b-8892-495630fc2c1f
datanode_6_1  | 2020-07-16 13:02:04,161 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62
datanode_6_1  | 2020-07-16 13:02:04,165 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "2271bf5c-25f3-49af-8629-e054f39f9c62"
datanode_6_1  | uuid128 {
datanode_6_1  |   mostSigBits: 2481975272152451503
datanode_6_1  |   leastSigBits: -8779239343112872862
datanode_6_1  | }
datanode_6_1  | .
datanode_6_1  | 2020-07-16 13:02:09,332 [Thread-44] INFO impl.FollowerState: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-FollowerState: change to CANDIDATE, lastRpcTime:5172ms, electionTimeout:5170ms
datanode_6_1  | 2020-07-16 13:02:09,333 [Thread-44] INFO impl.RoleInfo: 6377505a-0934-4e3b-8892-495630fc2c1f: shutdown FollowerState
datanode_6_1  | 2020-07-16 13:02:09,333 [Thread-44] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-07-16 13:02:09,335 [Thread-44] INFO impl.RoleInfo: 6377505a-0934-4e3b-8892-495630fc2c1f: start LeaderElection
datanode_6_1  | 2020-07-16 13:02:09,339 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO impl.LeaderElection: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1: begin an election at term 1 for -1: [6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null
datanode_6_1  | 2020-07-16 13:02:09,341 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO impl.RoleInfo: 6377505a-0934-4e3b-8892-495630fc2c1f: shutdown LeaderElection
datanode_6_1  | 2020-07-16 13:02:09,342 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-07-16 13:02:09,342 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E054F39F9C62 with new leaderId: 6377505a-0934-4e3b-8892-495630fc2c1f
datanode_6_1  | 2020-07-16 13:02:09,343 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62: change Leader from null to 6377505a-0934-4e3b-8892-495630fc2c1f at term 1 for becomeLeader, leader elected after 5196ms
datanode_6_1  | 2020-07-16 13:02:09,352 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-07-16 13:02:09,353 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-07-16 13:02:09,355 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62
datanode_6_1  | 2020-07-16 13:02:09,357 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-16 13:02:09,357 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-07-16 13:02:09,364 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-07-16 13:02:09,364 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-07-16 13:02:09,364 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-07-16 13:02:09,370 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO impl.RoleInfo: 6377505a-0934-4e3b-8892-495630fc2c1f: start LeaderState
datanode_6_1  | 2020-07-16 13:02:09,373 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-16 13:02:09,375 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2271bf5c-25f3-49af-8629-e054f39f9c62/current/log_inprogress_0
datanode_6_1  | 2020-07-16 13:02:09,384 [6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62-LeaderElection1] INFO impl.RaftServerImpl: 6377505a-0934-4e3b-8892-495630fc2c1f@group-E054F39F9C62: set configuration 0: [6377505a-0934-4e3b-8892-495630fc2c1f:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-07-16 13:06:45,102 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #6 does not exist in datanode. Container close failed.
datanode_6_1  | 2020-07-16 13:06:45,102 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #8 does not exist in datanode. Container close failed.
datanode_4_1  | 2020-07-16 13:04:44,110 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=173,entriesCount=1,lastEntry=(t:1, i:126)
datanode_4_1  | 2020-07-16 13:04:44,116 [java.util.concurrent.ThreadPoolExecutor$Worker@577d2a15[State = -1, empty queue]] WARN server.GrpcLogAppender: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5->6377505a-0934-4e3b-8892-495630fc2c1f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=174,entriesCount=1,lastEntry=(t:1, i:127)
datanode_4_1  | 2020-07-16 13:06:44,777 [Thread-203] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-591CCEABD33A->39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5, cid=265, seq=0, Watch-ALL_COMMITTED(128), Message:<EMPTY>, reply=RaftClientReply:client-591CCEABD33A->39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c@group-D4280D4755F5, cid=265, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 265 and log index 128 is not yet replicated to ALL_COMMITTED, logIndex=128, commits[39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c:c172, 2d39f5a5-5993-4301-956d-f519f2994ca2:c172, 6377505a-0934-4e3b-8892-495630fc2c1f:c127]
datanode_4_1  | 2020-07-16 13:06:46,618 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 154.
datanode_4_1  | 2020-07-16 13:06:46,618 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 154.
datanode_4_1  | 2020-07-16 13:06:46,626 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is closed with bcsId 154.
datanode_4_1  | 2020-07-16 13:06:46,664 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is synced with bcsId 170.
datanode_4_1  | 2020-07-16 13:06:46,665 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is synced with bcsId 170.
datanode_4_1  | 2020-07-16 13:06:46,671 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is closed with bcsId 170.
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-07-16 13:01:10,325 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-07-16 13:01:11,800 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-16 13:01:12,365 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-8d8193db-b762-4253-8ecb-347be1862dac;layoutVersion=0
scm_1         | 2020-07-16 13:01:12,515 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at d869b4d313f1/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-07-16 13:01:26,145 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = d869b4d313f1/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/de027855798bf3b891b8d3c00dc8e59531f98781 ; compiled by 'runner' on 2020-07-16T12:35Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-07-16 13:01:26,155 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-07-16 13:01:26,370 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-16 13:01:26,602 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-16 13:01:26,733 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@37cd92d6
scm_1         | 2020-07-16 13:01:26,734 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-07-16 13:01:27,024 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-07-16 13:01:27,247 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-07-16 13:01:27,326 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-07-16 13:01:27,494 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-07-16 13:01:27,505 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-07-16 13:01:27,573 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1         | 2020-07-16 13:01:28,231 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-16 13:01:28,258 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-07-16 13:01:28,301 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-16 13:01:28,303 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-07-16 13:01:28,326 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-16 13:01:28,327 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-07-16 13:01:28,380 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-07-16 13:01:28,382 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1         | 2020-07-16 13:01:28,416 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @13848ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-07-16 13:01:28,532 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-07-16 13:01:28,545 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-07-16 13:01:28,552 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-07-16 13:01:28,553 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1         | 2020-07-16 13:01:28,554 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2020-07-16 13:01:28,554 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2020-07-16 13:01:28,585 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-07-16 13:01:28,606 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-07-16 13:01:28,763 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-07-16 13:01:28,847 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-07-16 13:01:28,847 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-07-16 13:01:29,157 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-07-16 13:01:29,167 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-07-16 13:01:29,168 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-07-16 13:01:29,243 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-07-16 13:01:29,252 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-07-16 13:01:29,253 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-07-16 13:01:29,253 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-07-16 13:01:29,293 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-07-16 13:01:29,299 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1         | 2020-07-16 13:01:29,301 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-07-16 13:01:29,303 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1         | 2020-07-16 13:01:29,392 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-07-16 13:01:29,402 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1         | 2020-07-16 13:01:29,540 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-07-16 13:01:29,540 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-07-16 13:01:29,542 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1         | 2020-07-16 13:01:29,573 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5384ce66{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2020-07-16 13:01:29,573 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b4969ea{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2020-07-16 13:01:29,800 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:57336: output error
scm_1         | 2020-07-16 13:01:29,804 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:57204: output error
scm_1         | 2020-07-16 13:01:29,805 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:54910: output error
scm_1         | 2020-07-16 13:01:29,930 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-16 13:01:29,931 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-16 13:01:29,931 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-16 13:01:30,507 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1f26b992{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-16500311364789761524.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1         | 2020-07-16 13:01:30,604 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4245bf68{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1         | 2020-07-16 13:01:30,614 [Listener at 0.0.0.0/9860] INFO server.Server: Started @16046ms
scm_1         | 2020-07-16 13:01:30,657 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2020-07-16 13:01:30,660 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2020-07-16 13:01:30,675 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1         | 2020-07-16 13:01:30,754 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3bab95ca] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2020-07-16 13:01:31,412 [IPC Server handler 58 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/6377505a-0934-4e3b-8892-495630fc2c1f
scm_1         | 2020-07-16 13:01:31,475 [IPC Server handler 58 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6377505a-0934-4e3b-8892-495630fc2c1f{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-16 13:01:31,595 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:31,600 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/de7eb8b4-4719-42f5-b1f1-5c05eece8d74
scm_1         | 2020-07-16 13:01:31,682 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : de7eb8b4-4719-42f5-b1f1-5c05eece8d74{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-16 13:01:31,683 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:31,524 [IPC Server handler 53 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
scm_1         | 2020-07-16 13:01:31,683 [IPC Server handler 53 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-16 13:01:31,684 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:31,683 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
scm_1         | 2020-07-16 13:01:31,728 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
scm_1         | 2020-07-16 13:01:31,728 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
scm_1         | 2020-07-16 13:01:31,786 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2271bf5c-25f3-49af-8629-e054f39f9c62 to datanode:6377505a-0934-4e3b-8892-495630fc2c1f
scm_1         | 2020-07-16 13:01:31,899 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/2d39f5a5-5993-4301-956d-f519f2994ca2
scm_1         | 2020-07-16 13:01:31,909 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2d39f5a5-5993-4301-956d-f519f2994ca2{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-16 13:01:31,910 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:31,913 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
scm_1         | 2020-07-16 13:01:31,951 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2271bf5c-25f3-49af-8629-e054f39f9c62, Nodes: 6377505a-0934-4e3b-8892-495630fc2c1f{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T13:01:31.768986Z]
scm_1         | 2020-07-16 13:01:31,963 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:31,963 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1         | 2020-07-16 13:01:31,973 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=61fbd2d9-c788-45d5-b630-1d861cdb9220 to datanode:39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
scm_1         | 2020-07-16 13:01:31,977 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 61fbd2d9-c788-45d5-b630-1d861cdb9220, Nodes: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T13:01:31.973589Z]
scm_1         | 2020-07-16 13:01:31,977 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=928df494-38dd-4453-9ee7-994262ad379a to datanode:2d39f5a5-5993-4301-956d-f519f2994ca2
scm_1         | 2020-07-16 13:01:31,986 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 928df494-38dd-4453-9ee7-994262ad379a, Nodes: 2d39f5a5-5993-4301-956d-f519f2994ca2{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T13:01:31.977804Z]
scm_1         | 2020-07-16 13:01:31,987 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a0b9ca99-9803-40c5-9070-0115bdff853c to datanode:de7eb8b4-4719-42f5-b1f1-5c05eece8d74
scm_1         | 2020-07-16 13:01:31,992 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a0b9ca99-9803-40c5-9070-0115bdff853c, Nodes: de7eb8b4-4719-42f5-b1f1-5c05eece8d74{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T13:01:31.987190Z]
scm_1         | 2020-07-16 13:01:31,993 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 4 nodes. Healthy nodes 4
scm_1         | 2020-07-16 13:01:32,016 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=169b341c-e67d-4e0d-9cbd-d4280d4755f5 to datanode:39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c
scm_1         | 2020-07-16 13:01:32,021 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=169b341c-e67d-4e0d-9cbd-d4280d4755f5 to datanode:2d39f5a5-5993-4301-956d-f519f2994ca2
scm_1         | 2020-07-16 13:01:32,021 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=169b341c-e67d-4e0d-9cbd-d4280d4755f5 to datanode:6377505a-0934-4e3b-8892-495630fc2c1f
scm_1         | 2020-07-16 13:01:32,022 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 169b341c-e67d-4e0d-9cbd-d4280d4755f5, Nodes: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}2d39f5a5-5993-4301-956d-f519f2994ca2{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}6377505a-0934-4e3b-8892-495630fc2c1f{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T13:01:32.016619Z]
scm_1         | 2020-07-16 13:01:32,023 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 1
scm_1         | 2020-07-16 13:01:32,438 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/4f49310f-999a-4016-acc1-42cc4200008f
scm_1         | 2020-07-16 13:01:32,458 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4f49310f-999a-4016-acc1-42cc4200008f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-16 13:01:32,458 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b0f7a9d8-0f33-40fe-a566-f5735cc90914 to datanode:4f49310f-999a-4016-acc1-42cc4200008f
scm_1         | 2020-07-16 13:01:32,478 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:32,479 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:32,492 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b0f7a9d8-0f33-40fe-a566-f5735cc90914, Nodes: 4f49310f-999a-4016-acc1-42cc4200008f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T13:01:32.458902Z]
scm_1         | 2020-07-16 13:01:32,493 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
scm_1         | 2020-07-16 13:01:32,493 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 2
scm_1         | 2020-07-16 13:01:33,167 [IPC Server handler 10 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/3bdad0fc-b0ab-427d-8e93-13fe3ba6d674
scm_1         | 2020-07-16 13:01:33,168 [IPC Server handler 10 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-16 13:01:33,180 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:33,180 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:33,169 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a4d7052a-3090-4d65-b7ef-a1e32ec59a07 to datanode:3bdad0fc-b0ab-427d-8e93-13fe3ba6d674
scm_1         | 2020-07-16 13:01:33,181 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a4d7052a-3090-4d65-b7ef-a1e32ec59a07, Nodes: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T13:01:33.169705Z]
scm_1         | 2020-07-16 13:01:33,231 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-16 13:01:33,244 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3126ee1f-b742-47bc-99f8-ac9c7a051a6e to datanode:de7eb8b4-4719-42f5-b1f1-5c05eece8d74
scm_1         | 2020-07-16 13:01:33,257 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3126ee1f-b742-47bc-99f8-ac9c7a051a6e to datanode:3bdad0fc-b0ab-427d-8e93-13fe3ba6d674
scm_1         | 2020-07-16 13:01:33,257 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3126ee1f-b742-47bc-99f8-ac9c7a051a6e to datanode:4f49310f-999a-4016-acc1-42cc4200008f
scm_1         | 2020-07-16 13:01:33,258 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3126ee1f-b742-47bc-99f8-ac9c7a051a6e, Nodes: de7eb8b4-4719-42f5-b1f1-5c05eece8d74{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}3bdad0fc-b0ab-427d-8e93-13fe3ba6d674{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}4f49310f-999a-4016-acc1-42cc4200008f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T13:01:33.244413Z]
scm_1         | 2020-07-16 13:01:33,260 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-16 13:01:35,294 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 61fbd2d9-c788-45d5-b630-1d861cdb9220, Nodes: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c, CreationTimestamp2020-07-16T13:01:31.973589Z] moved to OPEN state
scm_1         | 2020-07-16 13:01:35,298 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-16 13:01:35,299 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-16 13:01:35,675 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 928df494-38dd-4453-9ee7-994262ad379a, Nodes: 2d39f5a5-5993-4301-956d-f519f2994ca2{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:2d39f5a5-5993-4301-956d-f519f2994ca2, CreationTimestamp2020-07-16T13:01:31.977804Z] moved to OPEN state
scm_1         | 2020-07-16 13:01:35,676 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-16 13:01:35,676 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-16 13:01:36,625 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b0f7a9d8-0f33-40fe-a566-f5735cc90914, Nodes: 4f49310f-999a-4016-acc1-42cc4200008f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:4f49310f-999a-4016-acc1-42cc4200008f, CreationTimestamp2020-07-16T13:01:32.458902Z] moved to OPEN state
scm_1         | 2020-07-16 13:01:36,625 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-16 13:01:36,625 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-16 13:01:37,433 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a4d7052a-3090-4d65-b7ef-a1e32ec59a07, Nodes: 3bdad0fc-b0ab-427d-8e93-13fe3ba6d674{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:3bdad0fc-b0ab-427d-8e93-13fe3ba6d674, CreationTimestamp2020-07-16T13:01:33.169705Z] moved to OPEN state
scm_1         | 2020-07-16 13:01:37,434 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-16 13:01:37,434 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-16 13:01:42,484 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 3126ee1f-b742-47bc-99f8-ac9c7a051a6e, Nodes: de7eb8b4-4719-42f5-b1f1-5c05eece8d74{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}3bdad0fc-b0ab-427d-8e93-13fe3ba6d674{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}4f49310f-999a-4016-acc1-42cc4200008f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:4f49310f-999a-4016-acc1-42cc4200008f, CreationTimestamp2020-07-16T13:01:33.244413Z] moved to OPEN state
scm_1         | 2020-07-16 13:01:42,505 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-16 13:01:42,509 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1         | 2020-07-16 13:01:42,510 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-07-16 13:01:42,517 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1         | 2020-07-16 13:01:42,519 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1         | 2020-07-16 13:01:42,843 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 169b341c-e67d-4e0d-9cbd-d4280d4755f5, Nodes: 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}2d39f5a5-5993-4301-956d-f519f2994ca2{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}6377505a-0934-4e3b-8892-495630fc2c1f{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c, CreationTimestamp2020-07-16T13:01:32.016619Z] moved to OPEN state
scm_1         | 2020-07-16 13:01:57,950 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:01:59,045 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:02,364 [IPC Server handler 71 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:03,996 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a0b9ca99-9803-40c5-9070-0115bdff853c, Nodes: de7eb8b4-4719-42f5-b1f1-5c05eece8d74{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:de7eb8b4-4719-42f5-b1f1-5c05eece8d74, CreationTimestamp2020-07-16T13:01:31.987190Z] moved to OPEN state
scm_1         | 2020-07-16 13:02:04,149 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 2271bf5c-25f3-49af-8629-e054f39f9c62, Nodes: 6377505a-0934-4e3b-8892-495630fc2c1f{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6377505a-0934-4e3b-8892-495630fc2c1f, CreationTimestamp2020-07-16T13:01:31.768986Z] moved to OPEN state
scm_1         | 2020-07-16 13:02:05,013 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:05,087 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:05,183 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:07,757 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:07,861 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:10,439 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:13,059 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:13,168 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:15,769 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:15,859 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:15,940 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:18,519 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:18,608 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:21,192 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:23,750 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:26,337 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:28,920 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:28,998 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:31,579 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:34,151 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:36,740 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:39,310 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:39,447 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:42,039 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:44,638 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:47,215 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:49,764 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:52,337 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:54,888 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:55,003 [IPC Server handler 61 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:02:57,573 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:00,142 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:00,229 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:00,294 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:00,370 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:02,932 [IPC Server handler 61 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:03,024 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:03,097 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:03,179 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:03,273 [IPC Server handler 60 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:03,355 [IPC Server handler 32 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:03,462 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:06,015 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:06,098 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:06,186 [IPC Server handler 60 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:08,758 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:11,324 [IPC Server handler 55 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:13,896 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:13,980 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:14,051 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:16,651 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:16,713 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:19,280 [IPC Server handler 55 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:21,837 [IPC Server handler 61 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:21,915 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:21,981 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:22,047 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:24,614 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:27,177 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:27,587 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-16 13:03:27,587 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-16 13:03:29,751 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:29,894 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:29,995 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:30,062 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:30,142 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:30,243 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:30,359 [IPC Server handler 44 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:30,428 [IPC Server handler 95 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:32,968 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:33,033 [IPC Server handler 60 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:33,115 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:33,164 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:33,223 [IPC Server handler 65 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:33,285 [IPC Server handler 54 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:35,848 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:38,394 [IPC Server handler 78 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:38,464 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:41,047 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:41,153 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:41,232 [IPC Server handler 54 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:41,303 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:43,863 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:43,935 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:44,013 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:44,096 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:54,211 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:03:59,306 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:04:09,415 [IPC Server handler 97 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:04:14,489 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:04:24,646 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:04:29,741 [IPC Server handler 61 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:04:39,813 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:04:44,905 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:04:54,999 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:05:10,113 [IPC Server handler 65 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:05:25,186 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:05:27,588 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-16 13:05:27,589 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-16 13:05:40,274 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:05:45,429 [IPC Server handler 96 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:05:45,499 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:05:55,632 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:06:10,709 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:06:15,833 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:06:25,913 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:06:41,024 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:06:42,537 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1         | 2020-07-16 13:06:42,554 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 15 milliseconds for processing 9 containers.
scm_1         | 2020-07-16 13:06:42,558 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6
scm_1         | 2020-07-16 13:06:42,560 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8
scm_1         | 2020-07-16 13:06:46,111 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:06:46,141 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:06:46,640 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #6 to CLOSED state, datanode 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-07-16 13:06:46,673 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #8 to CLOSED state, datanode 39f666a6-6a03-47b5-b8ea-eb3ef9dfc27c{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-07-16 13:06:48,721 [IPC Server handler 61 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-16 13:06:48,773 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
