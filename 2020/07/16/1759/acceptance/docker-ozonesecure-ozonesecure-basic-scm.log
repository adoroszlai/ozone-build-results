Attaching to ozonesecure_recon_1, ozonesecure_om_1, ozonesecure_scm_1, ozonesecure_kms_1, ozonesecure_datanode_2, ozonesecure_datanode_1, ozonesecure_kdc_1, ozonesecure_s3g_1, ozonesecure_datanode_3
datanode_1  | Sleeping for 5 seconds
datanode_1  | Setting up kerberos!!
datanode_1  | KDC ISSUER_SERVER => kdc:8081
datanode_1  | Sleeping for 5 seconds
datanode_1  | Got 200, KDC service ready!!
datanode_1  | Download dn/27eb3e7e62d5@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_1  | --2020-07-16 02:04:07--  http://kdc:8081/keytab/27eb3e7e62d5/dn
datanode_1  | Resolving kdc (kdc)... 172.26.0.7
datanode_1  | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 158 [application/octet-stream]
datanode_1  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_1  | 
datanode_1  |      0K                                                       100% 19.6M=0s
datanode_1  | 
datanode_1  | 2020-07-16 02:04:07 (19.6 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 07/16/20 02:04:07 dn/27eb3e7e62d5@EXAMPLE.COM
datanode_1  |    2 07/16/20 02:04:07 dn/27eb3e7e62d5@EXAMPLE.COM
datanode_1  | Download HTTP/27eb3e7e62d5@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_1  | --2020-07-16 02:04:07--  http://kdc:8081/keytab/27eb3e7e62d5/HTTP
datanode_1  | Resolving kdc (kdc)... 172.26.0.7
datanode_1  | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
datanode_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 07/16/20 02:04:07 HTTP/27eb3e7e62d5@EXAMPLE.COM
datanode_1  |    2 07/16/20 02:04:07 HTTP/27eb3e7e62d5@EXAMPLE.COM
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 162 [application/octet-stream]
datanode_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_1  | 
datanode_1  |      0K                                                       100% 23.4M=0s
datanode_1  | 
datanode_1  | 2020-07-16 02:04:07 (23.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_1  | 
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-07-16 02:04:16,293 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 27eb3e7e62d5/172.26.0.4
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
datanode_1  | STARTUP_MSG:   java = 11.0.6
datanode_1  | ************************************************************/
datanode_1  | 2020-07-16 02:04:16,461 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-07-16 02:04:18,947 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-07-16 02:04:20,160 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-07-16 02:04:21,898 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-07-16 02:04:21,899 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-07-16 02:04:22,761 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:27eb3e7e62d5 ip:172.26.0.4
datanode_1  | 2020-07-16 02:04:27,198 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_1  | WARNING: An illegal reflective access operation has occurred
datanode_1  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
datanode_1  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_1  | WARNING: All illegal access operations will be denied in a future release
datanode_2  | Sleeping for 5 seconds
datanode_2  | Setting up kerberos!!
datanode_2  | KDC ISSUER_SERVER => kdc:8081
datanode_2  | Sleeping for 5 seconds
datanode_2  | Got 200, KDC service ready!!
datanode_2  | Download dn/6b746e10bfd4@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | --2020-07-16 02:04:06--  http://kdc:8081/keytab/6b746e10bfd4/dn
datanode_2  | Resolving kdc (kdc)... 172.26.0.7
datanode_2  | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 158 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 24.3M=0s
datanode_2  | 
datanode_2  | 2020-07-16 02:04:06 (24.3 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 07/16/20 02:04:06 dn/6b746e10bfd4@EXAMPLE.COM
datanode_2  |    2 07/16/20 02:04:06 dn/6b746e10bfd4@EXAMPLE.COM
datanode_2  | Download HTTP/6b746e10bfd4@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_2  | --2020-07-16 02:04:06--  http://kdc:8081/keytab/6b746e10bfd4/HTTP
datanode_2  | Resolving kdc (kdc)... 172.26.0.7
datanode_2  | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 162 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 23.4M=0s
datanode_2  | 
datanode_2  | 2020-07-16 02:04:06 (23.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 07/16/20 02:04:06 HTTP/6b746e10bfd4@EXAMPLE.COM
datanode_2  |    2 07/16/20 02:04:06 HTTP/6b746e10bfd4@EXAMPLE.COM
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-07-16 02:04:10,318 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 6b746e10bfd4/172.26.0.2
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
datanode_2  | STARTUP_MSG:   java = 11.0.6
datanode_2  | ************************************************************/
datanode_2  | 2020-07-16 02:04:10,602 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-07-16 02:04:13,430 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-07-16 02:04:14,932 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-07-16 02:04:16,415 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-07-16 02:04:16,420 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-07-16 02:04:17,273 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:6b746e10bfd4 ip:172.26.0.2
datanode_2  | 2020-07-16 02:04:21,433 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_2  | WARNING: An illegal reflective access operation has occurred
datanode_2  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
datanode_2  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_2  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2020-07-16 02:04:23,077 [main] INFO security.UserGroupInformation: Login successful for user dn/6b746e10bfd4@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_2  | 2020-07-16 02:04:23,097 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_2  | 2020-07-16 02:04:23,098 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_1  | 2020-07-16 02:04:28,887 [main] INFO security.UserGroupInformation: Login successful for user dn/27eb3e7e62d5@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_1  | 2020-07-16 02:04:28,891 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_1  | 2020-07-16 02:04:28,891 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_1  | 2020-07-16 02:04:28,892 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_1  | 2020-07-16 02:04:28,903 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_1  | 2020-07-16 02:04:28,938 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_1  | 2020-07-16 02:04:33,771 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_1  | 2020-07-16 02:04:33,866 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.26.0.4,host:27eb3e7e62d5
datanode_1  | 2020-07-16 02:04:33,883 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_1  | 2020-07-16 02:04:33,897 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@27eb3e7e62d5
datanode_1  | 2020-07-16 02:04:37,256 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:38,257 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:39,260 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:40,262 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:41,263 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:42,265 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:43,277 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:44,279 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:45,280 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:46,282 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:47,283 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:48,284 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:49,286 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:50,287 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:51,288 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 02:04:56,647 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_1  | 2020-07-16 02:04:57,149 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-07-16 02:04:57,181 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-07-16 02:04:57,217 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-07-16 02:04:57,294 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-07-16 02:04:57,541 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-07-16 02:05:01,989 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-07-16 02:05:02,441 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-07-16 02:05:02,772 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-07-16 02:05:02,777 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-07-16 02:05:02,780 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-16 02:05:02,785 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-07-16 02:05:02,790 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-07-16 02:05:03,642 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-16 02:05:05,027 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-07-16 02:05:05,029 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_1  | 2020-07-16 02:05:05,030 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_1  | 2020-07-16 02:05:05,226 [main] INFO util.log: Logging initialized @57248ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-07-16 02:05:05,853 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-07-16 02:05:05,900 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-07-16 02:05:05,903 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_1  | 2020-07-16 02:05:05,910 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | 2020-07-16 02:05:05,910 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | 2020-07-16 02:05:05,924 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_1  | 2020-07-16 02:05:06,111 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-07-16 02:05:06,118 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1  | 2020-07-16 02:05:06,278 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-07-16 02:05:06,278 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-07-16 02:05:06,283 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2020-07-16 02:05:06,398 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/27eb3e7e62d5@EXAMPLE.COM
datanode_1  | 2020-07-16 02:05:06,407 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1aca6dc3{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-07-16 02:05:06,418 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@35995029{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-07-16 02:05:07,129 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/27eb3e7e62d5@EXAMPLE.COM
datanode_1  | 2020-07-16 02:05:07,217 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2b561f51{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-12477864419905452952.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-07-16 02:05:07,247 [main] INFO server.AbstractConnector: Started ServerConnector@1983a4e4{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-07-16 02:05:07,249 [main] INFO server.Server: Started @59281ms
datanode_1  | 2020-07-16 02:05:07,271 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-07-16 02:05:07,271 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-07-16 02:05:07,279 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-07-16 02:05:07,476 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@742106b5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-07-16 02:05:07,757 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.26.0.10:9891
datanode_1  | 2020-07-16 02:05:10,690 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From 27eb3e7e62d5/172.26.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.26.0.4:35119 remote=scm/172.26.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Issuer is listening on : 8081krb5kdc: starting...
kdc_1       | kadmind: starting...
kdc_1       | Jul 16 01:56:59 fed1af093bf9 kadmin.local[1](info): No dictionary file specified, continuing without one.
kdc_1       | Jul 16 01:57:00 b883563bdf0e kadmin.local[1](info): No dictionary file specified, continuing without one.
kdc_1       | Jul 16 02:04:00 kdc kadmind[14](info): No dictionary file specified, continuing without one.
kdc_1       | Jul 16 02:04:00 kdc kadmind[14](info): setting up network...
kdc_1       | kadmind: setsockopt(9,IPV6_V6ONLY,1) worked
kdc_1       | kadmind: setsockopt(11,IPV6_V6ONLY,1) worked
kdc_1       | kadmind: setsockopt(13,IPV6_V6ONLY,1) worked
kdc_1       | Jul 16 02:04:00 kdc kadmind[14](info): set up 6 sockets
kdc_1       | Jul 16 02:04:00 kdc kadmind[14](info): Seeding random number generator
kdc_1       | Jul 16 02:04:00 kdc kadmind[14](info): starting
kdc_1       | otp: Loaded
kdc_1       | Jul 16 02:03:56 kdc krb5kdc[9](info): setting up network...
kdc_1       | krb5kdc: setsockopt(9,IPV6_V6ONLY,1) worked
kdc_1       | krb5kdc: setsockopt(11,IPV6_V6ONLY,1) worked
kdc_1       | Jul 16 02:03:56 kdc krb5kdc[9](info): set up 4 sockets
kdc_1       | Jul 16 02:03:56 kdc krb5kdc[9](info): commencing operation
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "test/test@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/6b746e10bfd4@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/6b746e10bfd4@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/6b746e10bfd4@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.6b746e10bfd4.keytab.
kdc_1       | Entry for principal dn/6b746e10bfd4@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.6b746e10bfd4.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/6b746e10bfd4@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/6b746e10bfd4@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/6b746e10bfd4@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.6b746e10bfd4.keytab.
kdc_1       | Entry for principal HTTP/6b746e10bfd4@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.6b746e10bfd4.keytab.
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_create_principal, dn/6b746e10bfd4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, dn/6b746e10bfd4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_get_principal, dn/6b746e10bfd4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_create_principal, HTTP/6b746e10bfd4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, HTTP/6b746e10bfd4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](Notice): Request: kadm5_get_principal, HTTP/6b746e10bfd4@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:06 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_2  | 2020-07-16 02:04:23,098 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_2  | 2020-07-16 02:04:23,099 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_2  | 2020-07-16 02:04:23,136 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_2  | 2020-07-16 02:04:28,406 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_2  | 2020-07-16 02:04:28,543 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.26.0.2,host:6b746e10bfd4
datanode_2  | 2020-07-16 02:04:28,575 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_2  | 2020-07-16 02:04:28,608 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@6b746e10bfd4
datanode_2  | 2020-07-16 02:04:32,706 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:33,707 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:34,709 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:35,713 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:36,715 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:37,716 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:38,718 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:39,719 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:40,720 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:41,722 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:42,724 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:43,725 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 11 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:44,726 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 12 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:45,729 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 13 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:46,730 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 14 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:47,734 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 15 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:48,735 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 16 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:49,737 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 17 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:50,738 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 18 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:51,740 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 19 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 02:04:57,834 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_2  | 2020-07-16 02:04:58,713 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-07-16 02:04:58,759 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-07-16 02:04:58,763 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-07-16 02:04:58,854 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-07-16 02:04:59,131 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-07-16 02:05:03,367 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-07-16 02:05:03,932 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-07-16 02:05:04,606 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-07-16 02:05:04,607 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-07-16 02:05:04,608 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-16 02:05:04,628 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-07-16 02:05:04,629 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-07-16 02:05:05,704 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-16 02:05:06,714 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-07-16 02:05:06,719 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_2  | 2020-07-16 02:05:06,720 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_2  | 2020-07-16 02:05:06,859 [main] INFO util.log: Logging initialized @60224ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-07-16 02:05:07,513 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-07-16 02:05:07,586 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-07-16 02:05:07,596 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_2  | 2020-07-16 02:05:07,613 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_2  | 2020-07-16 02:05:07,615 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2020-07-16 02:05:07,618 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_2  | 2020-07-16 02:05:07,844 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-07-16 02:05:07,846 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2  | 2020-07-16 02:05:08,043 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-07-16 02:05:08,061 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-07-16 02:05:08,063 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2  | 2020-07-16 02:05:08,183 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/6b746e10bfd4@EXAMPLE.COM
datanode_2  | 2020-07-16 02:05:08,194 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2674ca88{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-07-16 02:05:08,227 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@310f8a05{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-07-16 02:05:08,668 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/6b746e10bfd4@EXAMPLE.COM
datanode_2  | 2020-07-16 02:05:08,739 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@c0521e5{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-9623524480061145136.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-07-16 02:05:08,789 [main] INFO server.AbstractConnector: Started ServerConnector@e4bb10b{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-07-16 02:05:08,798 [main] INFO server.Server: Started @62163ms
datanode_2  | 2020-07-16 02:05:08,822 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-07-16 02:05:08,822 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.26.0.4:35119 remote=scm/172.26.0.5:9861]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:290)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)
datanode_1  | 	at java.base/java.io.DataInputStream.read(DataInputStream.java:149)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1  | 2020-07-16 02:05:11,773 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-07-16 02:05:11,795 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-07-16 02:05:11,803 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c1f0c1f5-4f44-4e41-a2d3-123376104d0a at port 9858
datanode_1  | 2020-07-16 02:05:12,090 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: start RPC server
datanode_1  | 2020-07-16 02:05:12,438 [Datanode State Machine Thread - 1] INFO server.GrpcService: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-07-16 02:05:20,737 [grpc-default-executor-1] INFO impl.RaftServerProxy: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: addNew group-82DBE919E7AD:[875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858] returns group-82DBE919E7AD:java.util.concurrent.CompletableFuture@1117710c[Not completed]
datanode_1  | 2020-07-16 02:05:20,883 [pool-20-thread-1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: new RaftServerImpl for group-82DBE919E7AD:[875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-07-16 02:05:20,902 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-07-16 02:05:20,902 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-07-16 02:05:20,952 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-07-16 02:05:20,953 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-07-16 02:05:20,961 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-07-16 02:05:21,001 [pool-20-thread-1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD: ConfigurationManager, init=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-07-16 02:05:21,001 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-16 02:05:21,016 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-07-16 02:05:21,018 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad does not exist. Creating ...
datanode_1  | 2020-07-16 02:05:21,055 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad/in_use.lock acquired by nodename 6@27eb3e7e62d5
datanode_1  | 2020-07-16 02:05:21,061 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad has been successfully formatted.
datanode_1  | 2020-07-16 02:05:21,271 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-82DBE919E7AD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-07-16 02:05:21,272 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-07-16 02:05:21,321 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-07-16 02:05:21,361 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-07-16 02:05:21,363 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-16 02:05:21,370 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-16 02:05:21,448 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD
datanode_1  | 2020-07-16 02:05:21,581 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-07-16 02:05:21,623 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad
datanode_1  | 2020-07-16 02:05:21,633 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-07-16 02:05:21,639 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-07-16 02:05:21,645 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-16 02:05:21,653 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-07-16 02:05:21,655 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-07-16 02:05:21,663 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-07-16 02:05:21,666 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-07-16 02:05:21,678 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-07-16 02:05:21,679 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-07-16 02:05:21,828 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-07-16 02:05:21,882 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-16 02:05:21,883 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-16 02:05:21,948 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-07-16 02:05:21,967 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-07-16 02:05:21,969 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-07-16 02:05:21,976 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-07-16 02:05:21,979 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-07-16 02:05:22,262 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD
datanode_1  | 2020-07-16 02:05:22,286 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD
datanode_1  | 2020-07-16 02:05:22,427 [pool-20-thread-1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD: start as a follower, conf=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null
datanode_1  | 2020-07-16 02:05:22,428 [pool-20-thread-1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-07-16 02:05:22,442 [pool-20-thread-1] INFO impl.RoleInfo: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: start FollowerState
datanode_1  | 2020-07-16 02:05:22,472 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: Failed requestVote 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0->c1f0c1f5-4f44-4e41-a2d3-123376104d0a#0: org.apache.ratis.protocol.ServerNotReadyException: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD is not in [RUNNING]: current state is STARTING
datanode_1  | 2020-07-16 02:05:22,570 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82DBE919E7AD,id=c1f0c1f5-4f44-4e41-a2d3-123376104d0a
datanode_1  | 2020-07-16 02:05:22,572 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD
datanode_1  | 2020-07-16 02:05:24,744 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-82DBE919E7AD with new leaderId: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
datanode_1  | 2020-07-16 02:05:24,745 [grpc-default-executor-0] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD: change Leader from null to 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0 at term 1 for appendEntries, leader elected after 3472ms
datanode_1  | 2020-07-16 02:05:24,749 [grpc-default-executor-0] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_1  | 2020-07-16 02:05:24,765 [grpc-default-executor-0] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD: inconsistency entries. Reply:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0<-c1f0c1f5-4f44-4e41-a2d3-123376104d0a#2:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_1  | 2020-07-16 02:05:24,788 [grpc-default-executor-0] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD: set configuration 0: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null at 0
datanode_1  | 2020-07-16 02:05:24,802 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-07-16 02:05:24,946 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-82DBE919E7AD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad/current/log_inprogress_0
datanode_1  | 2020-07-16 02:05:44,447 [Command processor thread] INFO impl.RaftServerProxy: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: addNew group-6008C7A79D63:[c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858] returns group-6008C7A79D63:java.util.concurrent.CompletableFuture@55514bbf[Not completed]
datanode_1  | 2020-07-16 02:05:44,449 [pool-20-thread-1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: new RaftServerImpl for group-6008C7A79D63:[c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-07-16 02:05:44,454 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-07-16 02:05:44,455 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-07-16 02:05:44,458 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-07-16 02:05:44,458 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865046, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
datanode_1  | 2020-07-16 02:05:44,459 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-07-16 02:05:44,459 [pool-20-thread-1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63: ConfigurationManager, init=-1: [c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-07-16 02:05:44,459 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-16 02:05:44,460 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-07-16 02:05:44,460 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3b55a46e-bbed-4c85-b75d-6008c7a79d63 does not exist. Creating ...
datanode_1  | 2020-07-16 02:05:44,463 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3b55a46e-bbed-4c85-b75d-6008c7a79d63/in_use.lock acquired by nodename 6@27eb3e7e62d5
datanode_1  | 2020-07-16 02:05:44,466 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3b55a46e-bbed-4c85-b75d-6008c7a79d63 has been successfully formatted.
datanode_1  | 2020-07-16 02:05:44,466 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-6008C7A79D63: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-07-16 02:05:44,466 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-07-16 02:05:44,466 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-07-16 02:05:44,467 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-07-16 02:05:44,467 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-16 02:05:44,467 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-16 02:05:44,467 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63
datanode_1  | 2020-07-16 02:05:44,469 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-07-16 02:05:44,469 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3b55a46e-bbed-4c85-b75d-6008c7a79d63
datanode_1  | 2020-07-16 02:05:44,469 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-07-16 02:05:44,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-07-16 02:05:44,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-16 02:05:44,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-07-16 02:05:44,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-07-16 02:05:44,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-07-16 02:05:44,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-07-16 02:05:44,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-07-16 02:05:44,470 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-07-16 02:05:44,515 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-07-16 02:05:44,517 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-16 02:05:44,518 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-16 02:05:44,543 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-07-16 02:05:44,543 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-07-16 02:05:44,543 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-07-16 02:05:44,543 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-07-16 02:05:44,544 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-07-16 02:05:44,544 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63
datanode_1  | 2020-07-16 02:05:44,544 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63
datanode_1  | 2020-07-16 02:05:44,545 [pool-20-thread-1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63: start as a follower, conf=-1: [c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858], old=null
datanode_1  | 2020-07-16 02:05:44,545 [pool-20-thread-1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-07-16 02:05:44,545 [pool-20-thread-1] INFO impl.RoleInfo: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: start FollowerState
datanode_1  | 2020-07-16 02:05:44,560 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6008C7A79D63,id=c1f0c1f5-4f44-4e41-a2d3-123376104d0a
datanode_1  | 2020-07-16 02:05:44,560 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63
datanode_1  | 2020-07-16 02:05:44,580 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "3b55a46e-bbed-4c85-b75d-6008c7a79d63"
datanode_1  | uuid128 {
datanode_1  |   mostSigBits: 4275504216764402821
datanode_1  |   leastSigBits: -5233921601108992669
datanode_1  | }
datanode_1  | .
datanode_1  | 2020-07-16 02:05:45,479 [ChunkWriter-3-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:3734990031298.
datanode_1  | 2020-07-16 02:05:49,620 [Thread-39] INFO impl.FollowerState: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-FollowerState: change to CANDIDATE, lastRpcTime:5074ms, electionTimeout:5055ms
datanode_1  | 2020-07-16 02:05:49,620 [Thread-39] INFO impl.RoleInfo: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: shutdown FollowerState
datanode_1  | 2020-07-16 02:05:49,624 [Thread-39] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-07-16 02:05:49,641 [Thread-39] INFO impl.RoleInfo: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: start LeaderElection
datanode_1  | 2020-07-16 02:05:49,655 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO impl.LeaderElection: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1: begin an election at term 1 for -1: [c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858], old=null
datanode_1  | 2020-07-16 02:05:49,658 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO impl.RoleInfo: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: shutdown LeaderElection
datanode_1  | 2020-07-16 02:05:49,660 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-07-16 02:05:49,660 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6008C7A79D63 with new leaderId: c1f0c1f5-4f44-4e41-a2d3-123376104d0a
datanode_1  | 2020-07-16 02:05:49,666 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63: change Leader from null to c1f0c1f5-4f44-4e41-a2d3-123376104d0a at term 1 for becomeLeader, leader elected after 5193ms
datanode_1  | 2020-07-16 02:05:49,708 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-07-16 02:05:49,709 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-07-16 02:05:49,714 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63
datanode_1  | 2020-07-16 02:05:49,797 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-07-16 02:05:49,797 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-07-16 02:05:49,818 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-07-16 02:05:49,827 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-07-16 02:05:49,828 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-07-16 02:05:49,845 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO impl.RoleInfo: c1f0c1f5-4f44-4e41-a2d3-123376104d0a: start LeaderState
datanode_1  | 2020-07-16 02:05:49,851 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-07-16 02:05:49,855 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3b55a46e-bbed-4c85-b75d-6008c7a79d63/current/log_inprogress_0
datanode_1  | 2020-07-16 02:05:49,864 [c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63-LeaderElection1] INFO impl.RaftServerImpl: c1f0c1f5-4f44-4e41-a2d3-123376104d0a@group-6008C7A79D63: set configuration 0: [c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858], old=null at 0
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865046, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865046, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865046, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865046, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865046, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/27eb3e7e62d5@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/27eb3e7e62d5@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/27eb3e7e62d5@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.27eb3e7e62d5.keytab.
kdc_1       | Entry for principal dn/27eb3e7e62d5@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.27eb3e7e62d5.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/27eb3e7e62d5@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/27eb3e7e62d5@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/27eb3e7e62d5@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.27eb3e7e62d5.keytab.
kdc_1       | Entry for principal HTTP/27eb3e7e62d5@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.27eb3e7e62d5.keytab.
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_create_principal, dn/27eb3e7e62d5@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, dn/27eb3e7e62d5@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_get_principal, dn/27eb3e7e62d5@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kms_1       | Sleeping for 5 seconds
kms_1       | Setting up kerberos!!
kms_1       | KDC ISSUER_SERVER => kdc:8081
kms_1       | /opt/starter.sh: line 66: SLEEP_SECONDS: command not found
kms_1       | Sleeping for  seconds
kms_1       | Got 200, KDC service ready!!
kms_1       | # Licensed to the Apache Software Foundation (ASF) under one or more
kms_1       | # contributor license agreements.  See the NOTICE file distributed with
kms_1       | # this work for additional information regarding copyright ownership.
kms_1       | # The ASF licenses this file to You under the Apache License, Version 2.0
kms_1       | # (the "License"); you may not use this file except in compliance with
kms_1       | # the License.  You may obtain a copy of the License at
kms_1       | #
kms_1       | #     http://www.apache.org/licenses/LICENSE-2.0
kms_1       | #
kms_1       | # Unless required by applicable law or agreed to in writing, software
kms_1       | # distributed under the License is distributed on an "AS IS" BASIS,
kms_1       | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
kms_1       | # See the License for the specific language governing permissions and
kms_1       | # limitations under the License.
kms_1       | 
kms_1       | [logging]
kms_1       |  default = FILE:/var/log/krb5libs.log
kms_1       |  kdc = FILE:/var/log/krb5kdc.log
kms_1       |  admin_server = FILE:/var/log/kadmind.log
kms_1       | 
kms_1       | [libdefaults]
kms_1       |  dns_canonicalize_hostname = false
kms_1       |  dns_lookup_realm = false
kms_1       |  ticket_lifetime = 24h
kms_1       |  renew_lifetime = 7d
kms_1       |  forwardable = true
kms_1       |  rdns = false
kms_1       |  default_realm = EXAMPLE.COM
kms_1       | 
kms_1       | [realms]
kms_1       |  EXAMPLE.COM = {
kms_1       |   kdc = kdc
kms_1       |   admin_server = kdc
kms_1       |  }
kms_1       | 
kms_1       | [domain_realm]
kms_1       |  .example.com = EXAMPLE.COM
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
kms_1       | WARNING: /opt/hadoop/logs does not exist. Creating.
kms_1       | Jul 16, 2020 2:04:26 AM com.sun.jersey.api.core.PackagesResourceConfig init
kms_1       | INFO: Scanning for root resource and provider classes in the packages:
kms_1       |   org.apache.hadoop.crypto.key.kms.server
kms_1       | Jul 16, 2020 2:04:26 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
kms_1       | INFO: Root resource classes found:
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMS
kms_1       | Jul 16, 2020 2:04:26 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
kms_1       | INFO: Provider classes found:
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
kms_1       | Jul 16, 2020 2:04:27 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
kms_1       | INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
datanode_1  | 2020-07-16 02:07:23,574 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 130 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 130 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:10:56,034 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 183 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 183 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_create_principal, HTTP/27eb3e7e62d5@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, HTTP/27eb3e7e62d5@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](Notice): Request: kadm5_get_principal, HTTP/27eb3e7e62d5@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:07 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865047, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865047, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865047, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865047, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for om/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "om/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_create_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:11:26,397 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 195 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 195 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:11:30,901 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 192 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 192 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:11:46,509 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 200 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 200 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_2  | 2020-07-16 02:05:08,829 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-07-16 02:05:08,892 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d73e573] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-07-16 02:05:09,000 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.26.0.10:9891
datanode_2  | 2020-07-16 02:05:11,404 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-07-16 02:05:11,408 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-07-16 02:05:11,408 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 875ee6ea-3105-488d-9849-16ec805378c3 at port 9858
datanode_2  | 2020-07-16 02:05:11,540 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 875ee6ea-3105-488d-9849-16ec805378c3: start RPC server
datanode_2  | 2020-07-16 02:05:11,821 [Datanode State Machine Thread - 0] INFO server.GrpcService: 875ee6ea-3105-488d-9849-16ec805378c3: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-07-16 02:05:16,040 [Command processor thread] INFO impl.RaftServerProxy: 875ee6ea-3105-488d-9849-16ec805378c3: addNew group-EBC71622A859:[875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858] returns group-EBC71622A859:java.util.concurrent.CompletableFuture@9b50c88[Not completed]
datanode_2  | 2020-07-16 02:05:16,131 [pool-20-thread-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3: new RaftServerImpl for group-EBC71622A859:[875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-16 02:05:16,144 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-07-16 02:05:16,149 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-07-16 02:05:16,149 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-16 02:05:16,150 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-07-16 02:05:16,150 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-16 02:05:16,177 [pool-20-thread-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859: ConfigurationManager, init=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-07-16 02:05:16,187 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-16 02:05:16,194 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-07-16 02:05:16,202 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d57ae6f0-8d25-40f6-9cce-ebc71622a859 does not exist. Creating ...
datanode_2  | 2020-07-16 02:05:16,215 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d57ae6f0-8d25-40f6-9cce-ebc71622a859/in_use.lock acquired by nodename 7@6b746e10bfd4
datanode_2  | 2020-07-16 02:05:16,226 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d57ae6f0-8d25-40f6-9cce-ebc71622a859 has been successfully formatted.
datanode_2  | 2020-07-16 02:05:16,261 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-EBC71622A859: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-07-16 02:05:16,274 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-07-16 02:05:16,288 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-07-16 02:05:16,298 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-07-16 02:05:16,314 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-16 02:05:16,317 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-16 02:05:16,366 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859
datanode_2  | 2020-07-16 02:05:16,499 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-07-16 02:05:16,555 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d57ae6f0-8d25-40f6-9cce-ebc71622a859
datanode_2  | 2020-07-16 02:05:16,557 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-07-16 02:05:16,597 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-07-16 02:05:16,607 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-16 02:05:16,608 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-07-16 02:05:16,616 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-07-16 02:05:16,618 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-07-16 02:05:16,623 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-07-16 02:05:16,628 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-07-16 02:05:16,651 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-07-16 02:05:16,788 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-07-16 02:05:16,952 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-16 02:05:16,953 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-16 02:05:16,992 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-07-16 02:05:17,008 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-07-16 02:05:17,026 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-07-16 02:05:17,027 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-07-16 02:05:17,053 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-07-16 02:05:17,332 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859
datanode_2  | 2020-07-16 02:05:17,335 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_create_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_create_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_create_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | WARNING: no policy specified for recon/recon@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "recon/recon@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal recon/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/recon.recon.keytab.
kdc_1       | Entry for principal recon/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/recon.recon.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/recon@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/recon@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "scm/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:12:07,589 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 192 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 192 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:12:51,878 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 219 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 219 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:13:57,542 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 239 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 239 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:14:07,732 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 243 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 243 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | Sleeping for 5 seconds
datanode_3  | Setting up kerberos!!
datanode_3  | KDC ISSUER_SERVER => kdc:8081
datanode_3  | Sleeping for 5 seconds
datanode_3  | Got 200, KDC service ready!!
datanode_3  | Download dn/16c542ca05b0@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_3  | --2020-07-16 02:04:09--  http://kdc:8081/keytab/16c542ca05b0/dn
datanode_3  | Resolving kdc (kdc)... 172.26.0.7
datanode_3  | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 158 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_3  | 
datanode_3  |      0K                                                       100% 5.66M=0s
datanode_3  | 
datanode_3  | 2020-07-16 02:04:09 (5.66 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 07/16/20 02:04:09 dn/16c542ca05b0@EXAMPLE.COM
datanode_3  |    2 07/16/20 02:04:09 dn/16c542ca05b0@EXAMPLE.COM
datanode_3  | Download HTTP/16c542ca05b0@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_3  | --2020-07-16 02:04:10--  http://kdc:8081/keytab/16c542ca05b0/HTTP
datanode_3  | Resolving kdc (kdc)... 172.26.0.7
datanode_3  | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 162 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_3  | 
datanode_3  |      0K                                                       100% 21.5M=0s
datanode_3  | 
datanode_3  | 2020-07-16 02:04:10 (21.5 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 07/16/20 02:04:10 HTTP/16c542ca05b0@EXAMPLE.COM
datanode_3  |    2 07/16/20 02:04:10 HTTP/16c542ca05b0@EXAMPLE.COM
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-07-16 02:04:21,729 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 16c542ca05b0/172.26.0.9
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
datanode_3  | STARTUP_MSG:   java = 11.0.6
datanode_3  | ************************************************************/
datanode_3  | 2020-07-16 02:04:21,871 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-07-16 02:04:24,256 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-07-16 02:04:25,455 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-07-16 02:04:27,212 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-07-16 02:04:27,212 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-07-16 02:04:28,114 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:16c542ca05b0 ip:172.26.0.9
datanode_3  | 2020-07-16 02:04:31,633 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_3  | WARNING: An illegal reflective access operation has occurred
datanode_3  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
datanode_3  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_3  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3  | WARNING: All illegal access operations will be denied in a future release
datanode_3  | 2020-07-16 02:04:33,236 [main] INFO security.UserGroupInformation: Login successful for user dn/16c542ca05b0@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865048, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865049, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:14:22,872 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 247 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 247 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:14:58,153 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 255 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 255 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_3  | 2020-07-16 02:04:33,236 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_3  | 2020-07-16 02:04:33,237 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_3  | 2020-07-16 02:04:33,237 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_3  | 2020-07-16 02:04:33,237 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_3  | 2020-07-16 02:04:33,240 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_3  | 2020-07-16 02:04:39,139 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_3  | 2020-07-16 02:04:39,250 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.26.0.9,host:16c542ca05b0
datanode_3  | 2020-07-16 02:04:39,250 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_3  | 2020-07-16 02:04:39,258 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@16c542ca05b0
datanode_3  | 2020-07-16 02:04:41,494 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:42,496 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:43,497 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:44,499 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:45,501 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:46,502 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:47,505 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:48,506 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:49,508 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:50,510 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:51,511 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9961. Already tried 10 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 02:04:57,322 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_3  | 2020-07-16 02:04:57,868 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-07-16 02:04:57,882 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-07-16 02:04:57,885 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-07-16 02:04:57,974 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-07-16 02:04:58,265 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-07-16 02:05:02,206 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-07-16 02:05:02,490 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-07-16 02:05:02,845 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-07-16 02:05:02,848 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-07-16 02:05:02,856 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-16 02:05:02,858 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-07-16 02:05:02,860 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-07-16 02:05:04,361 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-16 02:05:05,440 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-07-16 02:05:05,441 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 2020-07-16 02:05:05,441 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_3  | 2020-07-16 02:05:05,594 [main] INFO util.log: Logging initialized @54188ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-07-16 02:05:06,228 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-07-16 02:05:06,274 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-07-16 02:05:06,281 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3  | 2020-07-16 02:05:06,295 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 2020-07-16 02:05:06,296 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2020-07-16 02:05:06,303 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_3  | 2020-07-16 02:05:06,513 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-07-16 02:05:06,516 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3  | 2020-07-16 02:05:06,707 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-07-16 02:05:06,708 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-07-16 02:05:06,720 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 2020-07-16 02:05:06,793 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/16c542ca05b0@EXAMPLE.COM
datanode_3  | 2020-07-16 02:05:06,811 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@683fac7e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-07-16 02:05:06,817 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@bc4a9b0{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-07-16 02:05:07,503 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/16c542ca05b0@EXAMPLE.COM
datanode_3  | 2020-07-16 02:05:07,619 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@75345e47{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5419861650548478934.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-07-16 02:05:07,707 [main] INFO server.AbstractConnector: Started ServerConnector@6afaf27{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-07-16 02:05:07,710 [main] INFO server.Server: Started @56305ms
datanode_3  | 2020-07-16 02:05:07,727 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-07-16 02:05:07,727 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-07-16 02:05:07,747 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-07-16 02:05:07,947 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4c802ed4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-07-16 02:05:08,373 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.26.0.10:9891
datanode_3  | 2020-07-16 02:05:10,964 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-07-16 02:05:10,974 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-07-16 02:05:10,978 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0 at port 9858
datanode_3  | 2020-07-16 02:05:11,048 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: start RPC server
datanode_3  | 2020-07-16 02:05:11,370 [Datanode State Machine Thread - 0] INFO server.GrpcService: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-07-16 02:05:14,988 [Command processor thread] INFO impl.RaftServerProxy: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: addNew group-8E92E435FEA5:[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858] returns group-8E92E435FEA5:java.util.concurrent.CompletableFuture@7e122035[Not completed]
datanode_3  | 2020-07-16 02:05:15,110 [pool-20-thread-1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: new RaftServerImpl for group-8E92E435FEA5:[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-16 02:05:17,381 [pool-20-thread-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859: start as a follower, conf=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858], old=null
datanode_2  | 2020-07-16 02:05:17,383 [pool-20-thread-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-07-16 02:05:17,414 [pool-20-thread-1] INFO impl.RoleInfo: 875ee6ea-3105-488d-9849-16ec805378c3: start FollowerState
datanode_2  | 2020-07-16 02:05:17,605 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EBC71622A859,id=875ee6ea-3105-488d-9849-16ec805378c3
datanode_2  | 2020-07-16 02:05:17,607 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859
datanode_2  | 2020-07-16 02:05:17,698 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "d57ae6f0-8d25-40f6-9cce-ebc71622a859"
datanode_2  | uuid128 {
datanode_2  |   mostSigBits: -3063882675637632778
datanode_2  |   leastSigBits: -7147516318288009127
datanode_2  | }
datanode_2  | .
datanode_2  | 2020-07-16 02:05:17,704 [Command processor thread] INFO impl.RaftServerProxy: 875ee6ea-3105-488d-9849-16ec805378c3: addNew group-82DBE919E7AD:[875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858] returns group-82DBE919E7AD:java.util.concurrent.CompletableFuture@6220b34f[Not completed]
datanode_2  | 2020-07-16 02:05:17,707 [pool-20-thread-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3: new RaftServerImpl for group-82DBE919E7AD:[875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-16 02:05:17,735 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-07-16 02:05:17,735 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-07-16 02:05:17,735 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-16 02:05:17,736 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-07-16 02:05:17,736 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-16 02:05:17,736 [pool-20-thread-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD: ConfigurationManager, init=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-07-16 02:05:17,737 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-16 02:05:17,737 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-07-16 02:05:17,739 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad does not exist. Creating ...
datanode_2  | 2020-07-16 02:05:17,744 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad/in_use.lock acquired by nodename 7@6b746e10bfd4
datanode_2  | 2020-07-16 02:05:17,759 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad has been successfully formatted.
datanode_2  | 2020-07-16 02:05:17,760 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-82DBE919E7AD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-07-16 02:05:17,761 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-07-16 02:05:17,761 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-07-16 02:05:17,765 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-07-16 02:05:17,765 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-16 02:05:17,765 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-16 02:05:17,766 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD
datanode_2  | 2020-07-16 02:05:17,766 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-07-16 02:05:17,779 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad
datanode_2  | 2020-07-16 02:05:17,780 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-07-16 02:05:17,780 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-07-16 02:05:17,780 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-16 02:05:17,781 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-07-16 02:05:17,781 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-07-16 02:05:17,782 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-07-16 02:05:17,782 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-07-16 02:05:17,785 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-07-16 02:05:17,785 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-07-16 02:05:17,786 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-07-16 02:05:17,793 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-16 02:05:17,799 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-16 02:05:17,800 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-07-16 02:05:17,800 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-07-16 02:05:17,801 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-07-16 02:05:17,801 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-07-16 02:05:17,801 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865049, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865049, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865049, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865049, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_create_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](Notice): Request: kadm5_get_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:08 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_create_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_get_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_create_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_get_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_create_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_get_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](info): closing down fd 18
kdc_1       | WARNING: no policy specified for dn/16c542ca05b0@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/16c542ca05b0@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/16c542ca05b0@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.16c542ca05b0.keytab.
kdc_1       | Entry for principal dn/16c542ca05b0@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.16c542ca05b0.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/16c542ca05b0@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/16c542ca05b0@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/16c542ca05b0@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.16c542ca05b0.keytab.
kdc_1       | Entry for principal HTTP/16c542ca05b0@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.16c542ca05b0.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/scm@EXAMPLE.COM; defaulting to no policy
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:15:06,773 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 259 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 259 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:15:28,459 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 270 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 270 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:15:31,892 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 267 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 267 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
recon_1     | Sleeping for 5 seconds
recon_1     | Setting up kerberos!!
recon_1     | KDC ISSUER_SERVER => kdc:8081
recon_1     | Sleeping for 5 seconds
recon_1     | Got 200, KDC service ready!!
recon_1     | Download recon/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/recon.keytab
recon_1     | --2020-07-16 02:04:08--  http://kdc:8081/keytab/recon/recon
recon_1     | Resolving kdc (kdc)... 172.26.0.7
recon_1     | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 150 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/recon.keytab'
recon_1     | 
recon_1     |      0K                                                       100%  986K=0s
recon_1     | 
recon_1     | 2020-07-16 02:04:08 (986 KB/s) - '/etc/security/keytabs/recon.keytab' saved [150/150]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/recon.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 07/16/20 02:04:08 recon/recon@EXAMPLE.COM
recon_1     |    2 07/16/20 02:04:08 recon/recon@EXAMPLE.COM
recon_1     | Download HTTP/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
recon_1     | --2020-07-16 02:04:08--  http://kdc:8081/keytab/recon/HTTP
recon_1     | Resolving kdc (kdc)... 172.26.0.7
recon_1     | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 148 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/HTTP.keytab'
recon_1     | 
recon_1     |      0K                                                       100% 23.1M=0s
recon_1     | 
recon_1     | 2020-07-16 02:04:09 (23.1 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [148/148]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 07/16/20 02:04:09 HTTP/recon@EXAMPLE.COM
recon_1     |    2 07/16/20 02:04:09 HTTP/recon@EXAMPLE.COM
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2020-07-16 02:04:18,344 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1     | /************************************************************
recon_1     | STARTUP_MSG: Starting ReconServer
recon_1     | STARTUP_MSG:   host = recon/172.26.0.10
recon_1     | STARTUP_MSG:   args = []
recon_1     | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | 2020-07-16 02:05:15,134 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-07-16 02:05:15,136 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-07-16 02:05:15,136 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-16 02:05:17,802 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD
datanode_2  | 2020-07-16 02:05:17,802 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD
datanode_2  | 2020-07-16 02:05:17,808 [pool-20-thread-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD: start as a follower, conf=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null
datanode_2  | 2020-07-16 02:05:17,829 [pool-20-thread-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-07-16 02:05:17,835 [pool-20-thread-1] INFO impl.RoleInfo: 875ee6ea-3105-488d-9849-16ec805378c3: start FollowerState
datanode_2  | 2020-07-16 02:05:17,859 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82DBE919E7AD,id=875ee6ea-3105-488d-9849-16ec805378c3
datanode_2  | 2020-07-16 02:05:17,865 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD
datanode_2  | 2020-07-16 02:05:21,850 [grpc-default-executor-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
datanode_2  | 2020-07-16 02:05:21,850 [grpc-default-executor-1] INFO impl.RoleInfo: 875ee6ea-3105-488d-9849-16ec805378c3: shutdown FollowerState
datanode_2  | 2020-07-16 02:05:21,851 [Thread-26] INFO impl.FollowerState: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-07-16 02:05:21,851 [grpc-default-executor-1] INFO impl.RoleInfo: 875ee6ea-3105-488d-9849-16ec805378c3: start FollowerState
datanode_2  | 2020-07-16 02:05:22,182 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-82DBE919E7AD with new leaderId: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
datanode_2  | 2020-07-16 02:05:22,196 [grpc-default-executor-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD: change Leader from null to 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0 at term 1 for appendEntries, leader elected after 4421ms
datanode_2  | 2020-07-16 02:05:22,309 [grpc-default-executor-1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD: set configuration 0: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null at 0
datanode_2  | 2020-07-16 02:05:22,528 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-07-16 02:05:22,603 [Thread-24] INFO impl.FollowerState: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-FollowerState: change to CANDIDATE, lastRpcTime:5190ms, electionTimeout:5111ms
datanode_2  | 2020-07-16 02:05:22,641 [Thread-24] INFO impl.RoleInfo: 875ee6ea-3105-488d-9849-16ec805378c3: shutdown FollowerState
datanode_2  | 2020-07-16 02:05:22,641 [Thread-24] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-07-16 02:05:22,643 [Thread-24] INFO impl.RoleInfo: 875ee6ea-3105-488d-9849-16ec805378c3: start LeaderElection
datanode_2  | 2020-07-16 02:05:22,672 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO impl.LeaderElection: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1: begin an election at term 1 for -1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858], old=null
datanode_2  | 2020-07-16 02:05:22,674 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO impl.RoleInfo: 875ee6ea-3105-488d-9849-16ec805378c3: shutdown LeaderElection
datanode_2  | 2020-07-16 02:05:22,714 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-07-16 02:05:22,714 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-EBC71622A859 with new leaderId: 875ee6ea-3105-488d-9849-16ec805378c3
datanode_2  | 2020-07-16 02:05:22,718 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859: change Leader from null to 875ee6ea-3105-488d-9849-16ec805378c3 at term 1 for becomeLeader, leader elected after 6452ms
datanode_2  | 2020-07-16 02:05:22,772 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-07-16 02:05:22,780 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-07-16 02:05:22,793 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859
datanode_2  | 2020-07-16 02:05:22,805 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-07-16 02:05:22,826 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-07-16 02:05:22,857 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "153b2045-8688-49df-8258-82dbe919e7ad"
datanode_2  | uuid128 {
datanode_2  |   mostSigBits: 1529851981404326367
datanode_2  |   leastSigBits: -9054343169808144467
datanode_2  | }
datanode_2  | .
datanode_2  | 2020-07-16 02:05:22,882 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-07-16 02:05:22,883 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-07-16 02:05:22,885 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-07-16 02:05:22,919 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO impl.RoleInfo: 875ee6ea-3105-488d-9849-16ec805378c3: start LeaderState
datanode_2  | 2020-07-16 02:05:22,938 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-07-16 02:05:22,960 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-LeaderElection1] INFO impl.RaftServerImpl: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859: set configuration 0: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858], old=null at 0
datanode_2  | 2020-07-16 02:05:23,076 [875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 875ee6ea-3105-488d-9849-16ec805378c3@group-EBC71622A859-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d57ae6f0-8d25-40f6-9cce-ebc71622a859/current/log_inprogress_0
datanode_2  | 2020-07-16 02:05:23,091 [875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 875ee6ea-3105-488d-9849-16ec805378c3@group-82DBE919E7AD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad/current/log_inprogress_0
datanode_2  | 2020-07-16 02:05:45,476 [ChunkWriter-9-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:3734990031298.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:15:38,636 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 274 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 274 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:16:03,218 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 279 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 279 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:17:29,641 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 314 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 314 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-reconcodegen-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.27.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:06Z
recon_1     | STARTUP_MSG:   java = 11.0.6
recon_1     | ************************************************************/
recon_1     | 2020-07-16 02:04:18,580 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 2020-07-16 02:04:25,147 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1     | 2020-07-16 02:04:28,962 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2020-07-16 02:04:29,928 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
recon_1     | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2020-07-16 02:04:31,886 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file /etc/security/keytabs/recon.keytab
recon_1     | 2020-07-16 02:04:31,906 [main] INFO recon.ReconServer: Recon login successful.
recon_1     | 2020-07-16 02:04:33,813 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2020-07-16 02:04:40,794 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2020-07-16 02:04:41,961 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2020-07-16 02:04:42,022 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2020-07-16 02:04:42,044 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1     | 2020-07-16 02:04:44,583 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2020-07-16 02:04:44,584 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 2020-07-16 02:05:15,137 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-07-16 02:05:15,138 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-07-16 02:05:15,167 [pool-20-thread-1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5: ConfigurationManager, init=-1: [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-07-16 02:05:15,175 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-16 02:05:15,194 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-07-16 02:05:15,209 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/64ff4463-865e-4a7e-b1b3-8e92e435fea5 does not exist. Creating ...
datanode_3  | 2020-07-16 02:05:15,242 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/64ff4463-865e-4a7e-b1b3-8e92e435fea5/in_use.lock acquired by nodename 7@16c542ca05b0
datanode_3  | 2020-07-16 02:05:15,256 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/64ff4463-865e-4a7e-b1b3-8e92e435fea5 has been successfully formatted.
datanode_3  | 2020-07-16 02:05:15,274 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-8E92E435FEA5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-07-16 02:05:15,274 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-07-16 02:05:15,288 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-07-16 02:05:15,318 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-07-16 02:05:15,318 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-16 02:05:15,331 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-16 02:05:15,365 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5
datanode_3  | 2020-07-16 02:05:15,446 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-07-16 02:05:15,462 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/64ff4463-865e-4a7e-b1b3-8e92e435fea5
datanode_3  | 2020-07-16 02:05:15,462 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-07-16 02:05:15,463 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-07-16 02:05:15,472 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-16 02:05:15,472 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-07-16 02:05:15,473 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-07-16 02:05:15,473 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-07-16 02:05:15,475 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-07-16 02:05:15,485 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-07-16 02:05:15,492 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-07-16 02:05:15,589 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-07-16 02:05:15,615 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-16 02:05:15,623 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-16 02:05:15,639 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-07-16 02:05:15,668 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-07-16 02:05:15,669 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-07-16 02:05:15,670 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-07-16 02:05:15,684 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-07-16 02:05:15,846 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5
datanode_3  | 2020-07-16 02:05:15,866 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5
datanode_3  | 2020-07-16 02:05:15,908 [pool-20-thread-1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5: start as a follower, conf=-1: [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null
datanode_3  | 2020-07-16 02:05:15,913 [pool-20-thread-1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-07-16 02:05:15,933 [pool-20-thread-1] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: start FollowerState
datanode_3  | 2020-07-16 02:05:15,964 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E92E435FEA5,id=1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
datanode_3  | 2020-07-16 02:05:15,965 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5
datanode_3  | 2020-07-16 02:05:16,042 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "64ff4463-865e-4a7e-b1b3-8e92e435fea5"
datanode_3  | uuid128 {
datanode_3  |   mostSigBits: 7277610717100788350
datanode_3  |   leastSigBits: -5642009146619986267
datanode_3  | }
datanode_3  | .
datanode_3  | 2020-07-16 02:05:16,043 [Command processor thread] INFO impl.RaftServerProxy: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: addNew group-82DBE919E7AD:[875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858] returns group-82DBE919E7AD:java.util.concurrent.CompletableFuture@2f16d1bd[Not completed]
datanode_3  | 2020-07-16 02:05:16,060 [pool-20-thread-1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: new RaftServerImpl for group-82DBE919E7AD:[875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858] with ContainerStateMachine:uninitialized
recon_1     | 2020-07-16 02:04:44,584 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1     | 2020-07-16 02:04:44,607 [main] INFO util.log: Logging initialized @34925ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2020-07-16 02:04:44,787 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2020-07-16 02:04:44,799 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2020-07-16 02:04:44,805 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1     | 2020-07-16 02:04:44,805 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1     | 2020-07-16 02:04:44,805 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 2020-07-16 02:04:44,811 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1     | 2020-07-16 02:04:45,023 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2020-07-16 02:04:45,528 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2020-07-16 02:04:46,698 [main] INFO Configuration.deprecation: No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1     | 2020-07-16 02:04:47,058 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-07-16 02:04:47,450 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-07-16 02:04:47,527 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@159a32a4
recon_1     | 2020-07-16 02:04:47,529 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2020-07-16 02:04:47,782 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-07-16 02:04:47,949 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2020-07-16 02:04:47,967 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-07-16 02:04:48,008 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1     | 2020-07-16 02:04:48,014 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1     | 2020-07-16 02:04:48,084 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2020-07-16 02:04:48,142 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2020-07-16 02:04:48,297 [Listener at 0.0.0.0/9891] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1     | 2020-07-16 02:04:48,401 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2020-07-16 02:04:48,408 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1     | 2020-07-16 02:04:48,661 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2020-07-16 02:04:48,740 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2020-07-16 02:04:48,740 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2020-07-16 02:04:49,202 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2020-07-16 02:04:49,209 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
recon_1     | 2020-07-16 02:04:49,328 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2020-07-16 02:04:49,333 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2020-07-16 02:04:49,335 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1     | 2020-07-16 02:04:49,400 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1     | 2020-07-16 02:04:49,425 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@76b305e1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2020-07-16 02:04:49,426 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@b1d19ff{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2020-07-16 02:04:50,486 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1     | 2020-07-16 02:04:52,775 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@750afe12{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_6_0-SNAPSHOT_jar-_-any-1163137648262464771.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2020-07-16 02:04:52,794 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@58182b96{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
recon_1     | 2020-07-16 02:04:52,803 [Listener at 0.0.0.0/9891] INFO server.Server: Started @43122ms
recon_1     | 2020-07-16 02:04:52,812 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2020-07-16 02:04:52,812 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2020-07-16 02:04:52,818 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2020-07-16 02:04:52,818 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2020-07-16 02:04:52,836 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1     | 2020-07-16 02:04:52,867 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2020-07-16 02:04:52,868 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2020-07-16 02:04:52,868 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-07-16 02:04:52,869 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2020-07-16 02:04:52,874 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2020-07-16 02:04:54,081 [Listener at 0.0.0.0/9891] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9860. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:17:34,033 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 311 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 311 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-07-16 02:18:06,804 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 327 .Container 1 bcsId is 125. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 327 .Container 1 bcsId is 125.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-07-16 02:05:16,061 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-07-16 02:05:16,061 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-07-16 02:05:16,062 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-07-16 02:05:16,063 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-07-16 02:05:16,064 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-07-16 02:05:16,065 [pool-20-thread-1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD: ConfigurationManager, init=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-07-16 02:05:16,065 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-16 02:05:16,066 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-07-16 02:05:16,070 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad does not exist. Creating ...
datanode_3  | 2020-07-16 02:05:16,075 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad/in_use.lock acquired by nodename 7@16c542ca05b0
datanode_3  | 2020-07-16 02:05:16,080 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad has been successfully formatted.
datanode_3  | 2020-07-16 02:05:16,083 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-82DBE919E7AD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-07-16 02:05:16,084 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-07-16 02:05:16,084 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-07-16 02:05:16,084 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-07-16 02:05:16,084 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-16 02:05:16,084 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-16 02:05:16,085 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD
datanode_3  | 2020-07-16 02:05:16,085 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-07-16 02:05:16,087 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad
datanode_3  | 2020-07-16 02:05:16,087 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-07-16 02:05:16,088 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-07-16 02:05:16,093 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-16 02:05:16,093 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-07-16 02:05:16,094 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-07-16 02:05:16,098 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-07-16 02:05:16,099 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-07-16 02:05:16,099 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-07-16 02:05:16,099 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-07-16 02:05:16,111 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-07-16 02:05:16,112 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-16 02:05:16,112 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-16 02:05:16,119 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-07-16 02:05:16,120 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-07-16 02:05:16,120 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-07-16 02:05:16,120 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-07-16 02:05:16,120 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-07-16 02:05:16,120 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD
datanode_3  | 2020-07-16 02:05:16,121 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD
datanode_3  | 2020-07-16 02:05:16,128 [pool-20-thread-1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD: start as a follower, conf=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null
datanode_3  | 2020-07-16 02:05:16,128 [pool-20-thread-1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-07-16 02:05:16,128 [pool-20-thread-1] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: start FollowerState
datanode_3  | 2020-07-16 02:05:16,151 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82DBE919E7AD,id=1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
datanode_3  | 2020-07-16 02:05:16,151 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD
datanode_3  | 2020-07-16 02:05:20,974 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "153b2045-8688-49df-8258-82dbe919e7ad"
datanode_3  | uuid128 {
datanode_3  |   mostSigBits: 1529851981404326367
datanode_3  |   leastSigBits: -9054343169808144467
datanode_3  | }
datanode_3  | .
datanode_3  | 2020-07-16 02:05:21,107 [Thread-24] INFO impl.FollowerState: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-FollowerState: change to CANDIDATE, lastRpcTime:5174ms, electionTimeout:5135ms
datanode_3  | 2020-07-16 02:05:21,108 [Thread-24] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: shutdown FollowerState
kdc_1       | Principal "testuser/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser2/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser2/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865049, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865049, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865050, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865050, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865050, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865050, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865050, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865050, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865050, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jul 16 02:04:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1594865050, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_create_principal, dn/16c542ca05b0@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, dn/16c542ca05b0@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](Notice): Request: kadm5_get_principal, dn/16c542ca05b0@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:09 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | 2020-07-16 02:05:21,109 [Thread-24] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-07-16 02:05:21,112 [Thread-24] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: start LeaderElection
datanode_3  | 2020-07-16 02:05:21,145 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO impl.LeaderElection: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1: begin an election at term 1 for -1: [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null
datanode_3  | 2020-07-16 02:05:21,147 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: shutdown LeaderElection
datanode_3  | 2020-07-16 02:05:21,148 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-07-16 02:05:21,149 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8E92E435FEA5 with new leaderId: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
datanode_3  | 2020-07-16 02:05:21,165 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5: change Leader from null to 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0 at term 1 for becomeLeader, leader elected after 5874ms
datanode_3  | 2020-07-16 02:05:21,187 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-07-16 02:05:21,187 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-07-16 02:05:21,190 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5
datanode_3  | 2020-07-16 02:05:21,206 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-07-16 02:05:21,222 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-07-16 02:05:21,239 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-07-16 02:05:21,242 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-07-16 02:05:21,256 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-07-16 02:05:21,274 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: start LeaderState
datanode_3  | 2020-07-16 02:05:21,335 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-07-16 02:05:21,350 [Thread-26] INFO impl.FollowerState: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-FollowerState: change to CANDIDATE, lastRpcTime:5222ms, electionTimeout:5181ms
datanode_3  | 2020-07-16 02:05:21,358 [Thread-26] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: shutdown FollowerState
datanode_3  | 2020-07-16 02:05:21,361 [Thread-26] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-07-16 02:05:21,362 [Thread-26] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: start LeaderElection
datanode_3  | 2020-07-16 02:05:21,448 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-LeaderElection1] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5: set configuration 0: [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null at 0
datanode_3  | 2020-07-16 02:05:21,683 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-8E92E435FEA5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/64ff4463-865e-4a7e-b1b3-8e92e435fea5/current/log_inprogress_0
datanode_3  | 2020-07-16 02:05:21,683 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO impl.LeaderElection: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2: begin an election at term 1 for -1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null
datanode_3  | 2020-07-16 02:05:21,904 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO impl.LeaderElection: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2: Election PASSED; received 1 response(s) [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0<-875ee6ea-3105-488d-9849-16ec805378c3#0:OK-t1] and 0 exception(s); 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD:t1, leader=null, voted=1ec8a11d-967c-4d6b-b9a9-dc794cb618e0, raftlog=1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null
datanode_3  | 2020-07-16 02:05:21,904 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: shutdown LeaderElection
datanode_3  | 2020-07-16 02:05:21,904 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-07-16 02:05:21,904 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-82DBE919E7AD with new leaderId: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
datanode_3  | 2020-07-16 02:05:21,905 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD: change Leader from null to 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0 at term 1 for becomeLeader, leader elected after 5820ms
datanode_3  | 2020-07-16 02:05:21,905 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-07-16 02:05:21,905 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-07-16 02:05:21,905 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD
datanode_3  | 2020-07-16 02:05:21,906 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-07-16 02:05:21,913 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-07-16 02:05:21,915 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-07-16 02:05:21,920 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-07-16 02:05:21,922 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-07-16 02:05:21,924 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-07-16 02:05:21,926 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-16 02:05:21,928 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-07-16 02:05:21,950 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-07-16 02:05:21,962 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-07-16 02:05:21,962 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-07-16 02:05:21,963 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD
datanode_3  | 2020-07-16 02:05:21,992 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-07-16 02:05:21,995 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-16 02:05:21,996 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-07-16 02:05:21,996 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-07-16 02:05:21,996 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-07-16 02:05:21,996 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-07-16 02:05:22,012 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO impl.RoleInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0: start LeaderState
datanode_3  | 2020-07-16 02:05:22,017 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-07-16 02:05:22,022 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/153b2045-8688-49df-8258-82dbe919e7ad/current/log_inprogress_0
datanode_3  | 2020-07-16 02:05:22,051 [1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD-LeaderElection2] INFO impl.RaftServerImpl: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD: set configuration 0: [875ee6ea-3105-488d-9849-16ec805378c3:172.26.0.2:9858, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:172.26.0.4:9858, 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:172.26.0.9:9858], old=null at 0
datanode_3  | 2020-07-16 02:05:24,773 [grpc-default-executor-0] INFO impl.FollowerInfo: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a: nextIndex: updateUnconditionally 1 -> 0
datanode_3  | 2020-07-16 02:05:44,961 [ChunkWriter-7-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:3734990031298.
datanode_3  | 2020-07-16 02:06:24,774 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode_3  | 2020-07-16 02:06:44,800 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:1)
datanode_3  | 2020-07-16 02:06:44,901 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:2)
datanode_3  | 2020-07-16 02:06:46,819 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=13,entriesCount=1,lastEntry=(t:1, i:3)
datanode_3  | 2020-07-16 02:06:46,859 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:4)
datanode_3  | 2020-07-16 02:06:49,605 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:5)
recon_1     | 2020-07-16 02:04:58,163 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2020-07-16 02:04:58,179 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-07-16 02:04:58,184 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2020-07-16 02:04:58,210 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2020-07-16 02:04:58,246 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2020-07-16 02:04:59,092 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2020-07-16 02:04:59,103 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2020-07-16 02:04:59,144 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1     | 2020-07-16 02:04:59,146 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1     | 2020-07-16 02:04:59,159 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-07-16 02:04:59,192 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 54 milliseconds.
recon_1     | 2020-07-16 02:04:59,523 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 371 milliseconds to process 0 existing database records.
recon_1     | 2020-07-16 02:04:59,612 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 89 milliseconds for processing 0 containers.
recon_1     | 2020-07-16 02:05:09,655 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:05:09,686 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:05:10,164 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:05:10,198 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:05:11,150 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:05:11,192 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:05:11,628 [IPC Server handler 44 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/c1f0c1f5-4f44-4e41-a2d3-123376104d0a
recon_1     | 2020-07-16 02:05:11,630 [IPC Server handler 44 on default port 9891] INFO node.SCMNodeManager: Registered Data node : c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727587558692}
recon_1     | 2020-07-16 02:05:11,758 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node c1f0c1f5-4f44-4e41-a2d3-123376104d0a to Node DB.
recon_1     | 2020-07-16 02:05:12,134 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
recon_1     | 2020-07-16 02:05:12,138 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727771908603}
recon_1     | 2020-07-16 02:05:12,141 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0 to Node DB.
recon_1     | 2020-07-16 02:05:12,871 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:05:12,872 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2020-07-16 02:05:12,917 [pool-13-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to obtain Ozone Manager DB Snapshot. 
recon_1     | java.net.ConnectException: Error while authenticating with endpoint: http://om:9874/dbCheckpoint
recon_1     | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1     | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1     | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1     | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1     | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:216)
recon_1     | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:348)
recon_1     | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1     | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:229)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:282)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:517)
recon_1     | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:498)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:281)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:313)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:411)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:217)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | Caused by: java.net.ConnectException: Connection refused (Connection refused)
recon_1     | 	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method)
recon_1     | 	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399)
recon_1     | 	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242)
datanode_3  | 2020-07-16 02:06:49,659 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:6)
datanode_3  | 2020-07-16 02:06:49,690 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=18,entriesCount=1,lastEntry=(t:1, i:7)
datanode_3  | 2020-07-16 02:06:49,760 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:8)
datanode_3  | 2020-07-16 02:06:52,371 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:9)
datanode_3  | 2020-07-16 02:06:52,390 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:10)
datanode_3  | 2020-07-16 02:06:52,404 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=23,entriesCount=1,lastEntry=(t:1, i:11)
datanode_3  | 2020-07-16 02:06:55,045 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:12)
datanode_3  | 2020-07-16 02:06:55,048 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:13)
datanode_3  | 2020-07-16 02:06:55,059 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:14)
datanode_3  | 2020-07-16 02:06:55,073 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=28,entriesCount=1,lastEntry=(t:1, i:15)
datanode_3  | 2020-07-16 02:06:57,642 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:16)
datanode_3  | 2020-07-16 02:06:57,657 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:17)
datanode_3  | 2020-07-16 02:06:57,722 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:18)
datanode_3  | 2020-07-16 02:06:57,724 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=33,entriesCount=1,lastEntry=(t:1, i:19)
datanode_3  | 2020-07-16 02:07:00,304 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:20)
datanode_3  | 2020-07-16 02:07:00,307 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:21)
datanode_3  | 2020-07-16 02:07:00,339 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:22)
datanode_3  | 2020-07-16 02:07:02,936 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=39,entriesCount=1,lastEntry=(t:1, i:23)
datanode_3  | 2020-07-16 02:07:02,945 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:24)
datanode_3  | 2020-07-16 02:07:02,954 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:25)
datanode_3  | 2020-07-16 02:07:02,954 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:26)
datanode_3  | 2020-07-16 02:07:05,547 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=44,entriesCount=1,lastEntry=(t:1, i:27)
datanode_3  | 2020-07-16 02:07:05,547 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:28)
datanode_3  | 2020-07-16 02:07:05,573 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:29)
datanode_3  | 2020-07-16 02:07:05,585 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:30)
datanode_3  | 2020-07-16 02:07:08,165 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=49,entriesCount=1,lastEntry=(t:1, i:31)
datanode_3  | 2020-07-16 02:07:08,185 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:32)
datanode_3  | 2020-07-16 02:07:08,202 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:33)
datanode_3  | 2020-07-16 02:07:08,202 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:34)
datanode_3  | 2020-07-16 02:07:10,826 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=54,entriesCount=1,lastEntry=(t:1, i:35)
datanode_3  | 2020-07-16 02:07:10,842 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:36)
datanode_3  | 2020-07-16 02:07:10,844 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:37)
datanode_3  | 2020-07-16 02:07:10,856 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:38)
datanode_3  | 2020-07-16 02:07:13,437 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=59,entriesCount=1,lastEntry=(t:1, i:39)
datanode_3  | 2020-07-16 02:07:13,468 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:40)
datanode_3  | 2020-07-16 02:07:13,492 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:41)
datanode_3  | 2020-07-16 02:07:13,501 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:42)
datanode_3  | 2020-07-16 02:07:16,064 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=64,entriesCount=1,lastEntry=(t:1, i:43)
datanode_3  | 2020-07-16 02:07:16,076 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:44)
datanode_3  | 2020-07-16 02:07:16,110 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:45)
datanode_3  | 2020-07-16 02:07:16,117 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:46)
datanode_3  | 2020-07-16 02:07:18,663 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=69,entriesCount=1,lastEntry=(t:1, i:47)
datanode_3  | 2020-07-16 02:07:18,683 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:48)
datanode_3  | 2020-07-16 02:07:18,708 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:49)
datanode_3  | 2020-07-16 02:07:18,721 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:50)
datanode_3  | 2020-07-16 02:07:21,282 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=74,entriesCount=1,lastEntry=(t:1, i:51)
datanode_3  | 2020-07-16 02:07:21,293 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:52)
datanode_3  | 2020-07-16 02:07:21,304 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:53)
datanode_3  | 2020-07-16 02:07:21,332 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:54)
datanode_3  | 2020-07-16 02:07:23,890 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:55)
datanode_3  | 2020-07-16 02:07:23,896 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:56)
datanode_3  | 2020-07-16 02:07:23,913 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:57)
datanode_3  | 2020-07-16 02:07:23,924 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=82,entriesCount=1,lastEntry=(t:1, i:58)
datanode_3  | 2020-07-16 02:07:26,501 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:59)
datanode_3  | 2020-07-16 02:07:26,510 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:60)
datanode_3  | 2020-07-16 02:07:26,529 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:61)
datanode_3  | 2020-07-16 02:07:26,539 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=87,entriesCount=1,lastEntry=(t:1, i:62)
datanode_3  | 2020-07-16 02:07:29,113 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:63)
datanode_3  | 2020-07-16 02:07:29,131 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:64)
datanode_3  | 2020-07-16 02:07:29,147 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:65)
datanode_3  | 2020-07-16 02:07:29,162 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=92,entriesCount=1,lastEntry=(t:1, i:66)
datanode_3  | 2020-07-16 02:07:31,733 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:67)
datanode_3  | 2020-07-16 02:07:31,750 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:68)
datanode_3  | 2020-07-16 02:07:31,767 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:69)
datanode_3  | 2020-07-16 02:07:31,774 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=97,entriesCount=1,lastEntry=(t:1, i:70)
datanode_3  | 2020-07-16 02:07:34,337 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:71)
datanode_3  | 2020-07-16 02:07:34,353 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:72)
datanode_3  | 2020-07-16 02:07:34,366 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:73)
datanode_3  | 2020-07-16 02:07:34,390 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:74)
datanode_3  | 2020-07-16 02:07:36,964 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:75)
datanode_3  | 2020-07-16 02:07:36,982 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:76)
datanode_3  | 2020-07-16 02:07:36,992 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=106,entriesCount=1,lastEntry=(t:1, i:77)
datanode_3  | 2020-07-16 02:07:37,016 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=107,entriesCount=1,lastEntry=(t:1, i:78)
datanode_3  | 2020-07-16 02:07:39,573 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:79)
datanode_3  | 2020-07-16 02:07:39,588 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:80)
datanode_3  | 2020-07-16 02:07:39,600 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:81)
datanode_3  | 2020-07-16 02:07:39,624 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:82)
datanode_3  | 2020-07-16 02:07:42,192 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:83)
datanode_3  | 2020-07-16 02:07:42,202 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=115,entriesCount=1,lastEntry=(t:1, i:84)
datanode_3  | 2020-07-16 02:07:42,203 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=116,entriesCount=1,lastEntry=(t:1, i:85)
datanode_3  | 2020-07-16 02:07:42,231 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:86)
datanode_3  | 2020-07-16 02:07:44,799 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:87)
datanode_3  | 2020-07-16 02:07:44,812 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:88)
datanode_3  | 2020-07-16 02:07:44,828 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=121,entriesCount=1,lastEntry=(t:1, i:89)
datanode_3  | 2020-07-16 02:07:44,844 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:90)
datanode_3  | 2020-07-16 02:07:47,401 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:91)
datanode_3  | 2020-07-16 02:07:47,412 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:92)
datanode_3  | 2020-07-16 02:07:47,420 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=126,entriesCount=1,lastEntry=(t:1, i:93)
datanode_3  | 2020-07-16 02:07:49,973 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=128,entriesCount=1,lastEntry=(t:1, i:94)
datanode_3  | 2020-07-16 02:07:49,978 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=129,entriesCount=1,lastEntry=(t:1, i:95)
datanode_3  | 2020-07-16 02:07:49,993 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=130,entriesCount=1,lastEntry=(t:1, i:96)
datanode_3  | 2020-07-16 02:07:49,999 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=131,entriesCount=1,lastEntry=(t:1, i:97)
datanode_3  | 2020-07-16 02:07:52,587 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:98)
datanode_3  | 2020-07-16 02:07:52,595 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:99)
s3g_1       | Sleeping for 5 seconds
s3g_1       | Setting up kerberos!!
s3g_1       | KDC ISSUER_SERVER => kdc:8081
s3g_1       | Sleeping for 5 seconds
s3g_1       | Got 200, KDC service ready!!
s3g_1       | Download s3g/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
s3g_1       | --2020-07-16 02:04:08--  http://kdc:8081/keytab/s3g/s3g
s3g_1       | Resolving kdc (kdc)... 172.26.0.7
s3g_1       | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 142 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 22.6M=0s
s3g_1       | 
s3g_1       | 2020-07-16 02:04:08 (22.6 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 07/16/20 02:04:08 s3g/s3g@EXAMPLE.COM
s3g_1       |    2 07/16/20 02:04:08 s3g/s3g@EXAMPLE.COM
s3g_1       | Download HTTP/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
s3g_1       | --2020-07-16 02:04:08--  http://kdc:8081/keytab/s3g/HTTP
s3g_1       | Resolving kdc (kdc)... 172.26.0.7
s3g_1       | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 144 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 4.98M=0s
s3g_1       | 
s3g_1       | 2020-07-16 02:04:08 (4.98 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 07/16/20 02:04:08 HTTP/s3g@EXAMPLE.COM
s3g_1       |    2 07/16/20 02:04:08 HTTP/s3g@EXAMPLE.COM
s3g_1       | Download testuser/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
s3g_1       | --2020-07-16 02:04:08--  http://kdc:8081/keytab/s3g/testuser
s3g_1       | Resolving kdc (kdc)... 172.26.0.7
s3g_1       | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 152 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 17.9M=0s
s3g_1       | 
s3g_1       | 2020-07-16 02:04:08 (17.9 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 07/16/20 02:04:08 testuser/s3g@EXAMPLE.COM
s3g_1       |    2 07/16/20 02:04:08 testuser/s3g@EXAMPLE.COM
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | 2020-07-16 02:04:21,941 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2020-07-16 02:04:21,998 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1       | 2020-07-16 02:04:22,007 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1       | 2020-07-16 02:04:22,624 [main] INFO util.log: Logging initialized @13209ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-07-16 02:04:23,949 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-07-16 02:04:24,013 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | Sleeping for 5 seconds
om_1        | Setting up kerberos!!
om_1        | KDC ISSUER_SERVER => kdc:8081
om_1        | Sleeping for 5 seconds
om_1        | Got 200, KDC service ready!!
om_1        | Download om/om@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om_1        | --2020-07-16 02:04:08--  http://kdc:8081/keytab/om/om
om_1        | Resolving kdc (kdc)... 172.26.0.7
om_1        | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 138 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/om.keytab'
om_1        | 
om_1        |      0K                                                       100% 16.5M=0s
om_1        | 
om_1        | 2020-07-16 02:04:08 (16.5 MB/s) - '/etc/security/keytabs/om.keytab' saved [138/138]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 07/16/20 02:04:08 om/om@EXAMPLE.COM
om_1        |    2 07/16/20 02:04:08 om/om@EXAMPLE.COM
om_1        | Download HTTP/om@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om_1        | --2020-07-16 02:04:08--  http://kdc:8081/keytab/om/HTTP
om_1        | Resolving kdc (kdc)... 172.26.0.7
om_1        | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 142 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        | 
om_1        |      0K                                                       100% 16.7M=0s
om_1        | 
om_1        | 2020-07-16 02:04:09 (16.7 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [142/142]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 07/16/20 02:04:09 HTTP/om@EXAMPLE.COM
om_1        |    2 07/16/20 02:04:09 HTTP/om@EXAMPLE.COM
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-07-16 02:04:20,788 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.26.0.3
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | 2020-07-16 02:07:52,596 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:100)
datanode_3  | 2020-07-16 02:07:52,608 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=136,entriesCount=1,lastEntry=(t:1, i:101)
datanode_3  | 2020-07-16 02:07:55,166 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=138,entriesCount=1,lastEntry=(t:1, i:102)
datanode_3  | 2020-07-16 02:07:55,179 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:103)
datanode_3  | 2020-07-16 02:07:55,182 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:104)
datanode_3  | 2020-07-16 02:07:55,198 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=141,entriesCount=1,lastEntry=(t:1, i:105)
datanode_3  | 2020-07-16 02:07:57,751 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=143,entriesCount=1,lastEntry=(t:1, i:106)
datanode_3  | 2020-07-16 02:07:57,751 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:107)
datanode_3  | 2020-07-16 02:07:57,764 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:108)
datanode_3  | 2020-07-16 02:07:57,809 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=146,entriesCount=1,lastEntry=(t:1, i:109)
datanode_3  | 2020-07-16 02:08:00,371 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=148,entriesCount=1,lastEntry=(t:1, i:110)
datanode_3  | 2020-07-16 02:08:00,401 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:111)
datanode_3  | 2020-07-16 02:08:00,401 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:112)
datanode_3  | 2020-07-16 02:08:00,423 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=151,entriesCount=1,lastEntry=(t:1, i:113)
datanode_3  | 2020-07-16 02:08:02,984 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=153,entriesCount=1,lastEntry=(t:1, i:114)
datanode_3  | 2020-07-16 02:08:02,989 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:115)
datanode_3  | 2020-07-16 02:08:03,006 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:116)
datanode_3  | 2020-07-16 02:08:05,576 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=157,entriesCount=1,lastEntry=(t:1, i:117)
datanode_3  | 2020-07-16 02:08:05,595 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:118)
datanode_3  | 2020-07-16 02:08:05,595 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=159,entriesCount=1,lastEntry=(t:1, i:119)
datanode_3  | 2020-07-16 02:08:08,160 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=161,entriesCount=1,lastEntry=(t:1, i:120)
datanode_3  | 2020-07-16 02:08:08,177 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=162,entriesCount=1,lastEntry=(t:1, i:121)
datanode_3  | 2020-07-16 02:08:08,183 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:122)
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_create_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_get_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_create_principal, HTTP/16c542ca05b0@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, HTTP/16c542ca05b0@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_get_principal, HTTP/16c542ca05b0@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_create_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_get_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_create_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_randkey_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](Notice): Request: kadm5_get_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jul 16 02:04:10 kdc kadmind[14](info): closing down fd 18
kdc_1       | Jul 16 02:04:13 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865053, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:04:22 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.26.0.2: ISSUE: authtime 1594865062, etypes {rep=18 tkt=18 ses=18}, dn/6b746e10bfd4@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:04:28 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.26.0.4: ISSUE: authtime 1594865068, etypes {rep=18 tkt=18 ses=18}, dn/27eb3e7e62d5@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:04:31 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.26.0.10: ISSUE: authtime 1594865071, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:04:31 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.26.0.3: ISSUE: authtime 1594865071, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:04:32 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.26.0.9: ISSUE: authtime 1594865072, etypes {rep=18 tkt=18 ses=18}, dn/16c542ca05b0@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:04:46 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.26.0.5: ISSUE: authtime 1594865086, etypes {rep=18 tkt=18 ses=18}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:04:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.10: ISSUE: authtime 1594865071, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:04:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.3: ISSUE: authtime 1594865071, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:04:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1594865068, etypes {rep=18 tkt=18 ses=18}, dn/27eb3e7e62d5@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:04:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.2: ISSUE: authtime 1594865062, etypes {rep=18 tkt=18 ses=18}, dn/6b746e10bfd4@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:04:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.9: ISSUE: authtime 1594865072, etypes {rep=18 tkt=18 ses=18}, dn/16c542ca05b0@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:04:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865053, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:05:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865105, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:05:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1594865068, etypes {rep=18 tkt=18 ses=18}, dn/27eb3e7e62d5@EXAMPLE.COM for recon/recon@EXAMPLE.COM
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:06Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-07-16 02:04:20,927 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-07-16 02:04:28,973 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-07-16 02:04:29,569 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.26.0.3:9862
om_1        | 2020-07-16 02:04:29,583 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | WARNING: An illegal reflective access operation has occurred
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | WARNING: All illegal access operations will be denied in a future release
om_1        | 2020-07-16 02:04:31,999 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om_1        | 2020-07-16 02:04:32,011 [main] INFO om.OzoneManager: Ozone Manager login successful.
om_1        | 2020-07-16 02:04:32,119 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-16 02:04:34,439 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:35,451 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:36,453 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:37,454 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:38,457 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:39,536 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:40,548 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:41,550 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:42,551 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:43,552 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:43,555 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1        | 2020-07-16 02:04:49,559 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:50,561 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:51,562 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:52,563 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224)
recon_1     | 	at java.base/java.net.Socket.connect(Socket.java:609)
recon_1     | 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177)
recon_1     | 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474)
recon_1     | 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569)
recon_1     | 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242)
recon_1     | 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341)
recon_1     | 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362)
recon_1     | 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1248)
recon_1     | 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1187)
recon_1     | 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1081)
recon_1     | 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1015)
recon_1     | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:189)
recon_1     | 	... 19 more
recon_1     | 2020-07-16 02:05:12,955 [pool-13-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Null snapshot location got from OM.
recon_1     | 2020-07-16 02:05:13,057 [IPC Server handler 99 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/875ee6ea-3105-488d-9849-16ec805378c3
recon_1     | 2020-07-16 02:05:13,057 [IPC Server handler 99 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727931076021}
recon_1     | 2020-07-16 02:05:13,058 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 875ee6ea-3105-488d-9849-16ec805378c3 to Node DB.
recon_1     | 2020-07-16 02:05:15,757 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=64ff4463-865e-4a7e-b1b3-8e92e435fea5. Trying to get from SCM.
recon_1     | 2020-07-16 02:05:15,870 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 64ff4463-865e-4a7e-b1b3-8e92e435fea5, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0, CreationTimestamp2020-07-16T02:05:12.577Z] to Recon pipeline metadata.
recon_1     | 2020-07-16 02:05:15,910 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 64ff4463-865e-4a7e-b1b3-8e92e435fea5, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0, CreationTimestamp2020-07-16T02:05:12.577Z]
recon_1     | 2020-07-16 02:05:16,097 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=153b2045-8688-49df-8258-82dbe919e7ad. Trying to get from SCM.
recon_1     | 2020-07-16 02:05:16,108 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 153b2045-8688-49df-8258-82dbe919e7ad, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T02:05:13.479Z] to Recon pipeline metadata.
recon_1     | 2020-07-16 02:05:16,110 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 153b2045-8688-49df-8258-82dbe919e7ad, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T02:05:13.479Z]
recon_1     | 2020-07-16 02:05:16,115 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=153b2045-8688-49df-8258-82dbe919e7ad reported by 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727771908603}
recon_1     | 2020-07-16 02:05:17,500 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d57ae6f0-8d25-40f6-9cce-ebc71622a859. Trying to get from SCM.
recon_1     | 2020-07-16 02:05:17,505 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d57ae6f0-8d25-40f6-9cce-ebc71622a859, Nodes: 875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:875ee6ea-3105-488d-9849-16ec805378c3, CreationTimestamp2020-07-16T02:05:13.080Z] to Recon pipeline metadata.
recon_1     | 2020-07-16 02:05:17,506 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d57ae6f0-8d25-40f6-9cce-ebc71622a859, Nodes: 875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:875ee6ea-3105-488d-9849-16ec805378c3, CreationTimestamp2020-07-16T02:05:13.080Z]
recon_1     | 2020-07-16 02:05:17,784 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=153b2045-8688-49df-8258-82dbe919e7ad reported by 875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727931076021}
recon_1     | 2020-07-16 02:05:21,166 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=153b2045-8688-49df-8258-82dbe919e7ad reported by 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727771908603}
recon_1     | 2020-07-16 02:05:21,917 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=153b2045-8688-49df-8258-82dbe919e7ad reported by 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727771908603}
recon_1     | 2020-07-16 02:05:22,059 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=153b2045-8688-49df-8258-82dbe919e7ad reported by c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727587558692}
recon_1     | 2020-07-16 02:05:22,059 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 153b2045-8688-49df-8258-82dbe919e7ad, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0, CreationTimestamp2020-07-16T02:05:13.479Z] moved to OPEN state
recon_1     | 2020-07-16 02:05:44,496 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:05:44,516 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:05:44,517 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=3b55a46e-bbed-4c85-b75d-6008c7a79d63. Trying to get from SCM.
recon_1     | 2020-07-16 02:05:44,592 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 3b55a46e-bbed-4c85-b75d-6008c7a79d63, Nodes: c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:c1f0c1f5-4f44-4e41-a2d3-123376104d0a, CreationTimestamp2020-07-16T02:05:13.466Z] to Recon pipeline metadata.
recon_1     | 2020-07-16 02:05:44,593 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3b55a46e-bbed-4c85-b75d-6008c7a79d63, Nodes: c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:c1f0c1f5-4f44-4e41-a2d3-123376104d0a, CreationTimestamp2020-07-16T02:05:13.466Z]
recon_1     | 2020-07-16 02:05:45,853 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:05:45,939 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:05:46,004 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure_datanode_3.ozonesecure_default.
recon_1     | 2020-07-16 02:05:46,276 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1     | 2020-07-16 02:05:46,571 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:05:46,618 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:06:12,956 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:06:12,956 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2020-07-16 02:06:13,267 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1594865172956
recon_1     | 2020-07-16 02:06:13,330 [pool-13-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1594865172956.
recon_1     | 2020-07-16 02:06:13,424 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2020-07-16 02:06:13,481 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2020-07-16 02:06:13,539 [pool-14-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1594865173482
recon_1     | 2020-07-16 02:06:13,540 [pool-14-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1594865071952.
recon_1     | 2020-07-16 02:06:13,694 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2020-07-16 02:06:13,695 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.212 seconds to process 9 keys.
recon_1     | 2020-07-16 02:06:13,771 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:06:15,806 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:06:15,823 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:06:16,463 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:06:16,488 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:06:19,704 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:06:19,714 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:06:45,824 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:06:45,830 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:06:46,452 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:06:46,457 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:06:49,689 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:06:49,702 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:07:13,776 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:07:13,778 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 2020-07-16 02:04:24,023 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1       | 2020-07-16 02:04:24,035 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1       | 2020-07-16 02:04:24,035 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1       | 2020-07-16 02:04:24,054 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1       | 2020-07-16 02:04:24,872 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = s3g/172.26.0.8
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:06Z
s3g_1       | STARTUP_MSG:   java = 11.0.6
s3g_1       | ************************************************************/
s3g_1       | 2020-07-16 02:04:24,980 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2020-07-16 02:04:25,429 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-07-16 02:04:25,496 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-07-16 02:04:25,534 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g_1       | 2020-07-16 02:04:25,959 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2020-07-16 02:04:25,959 [main] INFO server.session: No SessionScavenger set, using defaults
scm_1       | Sleeping for 5 seconds
scm_1       | Setting up kerberos!!
scm_1       | KDC ISSUER_SERVER => kdc:8081
scm_1       | Sleeping for 5 seconds
scm_1       | Got 200, KDC service ready!!
scm_1       | Download scm/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
scm_1       | --2020-07-16 02:04:09--  http://kdc:8081/keytab/scm/scm
scm_1       | Resolving kdc (kdc)... 172.26.0.7
scm_1       | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 142 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/scm.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 20.2M=0s
scm_1       | 
scm_1       | 2020-07-16 02:04:09 (20.2 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 07/16/20 02:04:09 scm/scm@EXAMPLE.COM
scm_1       |    2 07/16/20 02:04:09 scm/scm@EXAMPLE.COM
scm_1       | Download HTTP/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1       | --2020-07-16 02:04:09--  http://kdc:8081/keytab/scm/HTTP
scm_1       | Resolving kdc (kdc)... 172.26.0.7
scm_1       | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 144 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 20.8M=0s
scm_1       | 
scm_1       | 2020-07-16 02:04:10 (20.8 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 07/16/20 02:04:10 HTTP/scm@EXAMPLE.COM
scm_1       |    2 07/16/20 02:04:10 HTTP/scm@EXAMPLE.COM
scm_1       | Download testuser/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
scm_1       | --2020-07-16 02:04:10--  http://kdc:8081/keytab/scm/testuser
scm_1       | Resolving kdc (kdc)... 172.26.0.7
scm_1       | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 152 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 1.98M=0s
scm_1       | 
scm_1       | 2020-07-16 02:04:10 (1.98 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 07/16/20 02:04:10 testuser/scm@EXAMPLE.COM
scm_1       |    2 07/16/20 02:04:10 testuser/scm@EXAMPLE.COM
scm_1       | --2020-07-16 02:04:10--  http://kdc:8081/keytab/scm/testuser2
scm_1       | Download testuser2/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       | Resolving kdc (kdc)... 172.26.0.7
scm_1       | Connecting to kdc (kdc)|172.26.0.7|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 154 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 24.1M=0s
scm_1       | 
scm_1       | 2020-07-16 02:04:10 (24.1 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 07/16/20 02:04:10 testuser2/scm@EXAMPLE.COM
scm_1       |    2 07/16/20 02:04:10 testuser2/scm@EXAMPLE.COM
datanode_3  | 2020-07-16 02:08:08,213 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=164,entriesCount=1,lastEntry=(t:1, i:123)
datanode_3  | 2020-07-16 02:08:10,769 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=166,entriesCount=1,lastEntry=(t:1, i:124)
datanode_3  | 2020-07-16 02:08:10,777 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=167,entriesCount=1,lastEntry=(t:1, i:125)
datanode_3  | 2020-07-16 02:08:10,788 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:126)
datanode_3  | 2020-07-16 02:08:10,812 [java.util.concurrent.ThreadPoolExecutor$Worker@f5dc3d6[State = -1, empty queue]] WARN server.GrpcLogAppender: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD->c1f0c1f5-4f44-4e41-a2d3-123376104d0a-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=169,entriesCount=1,lastEntry=(t:1, i:127)
datanode_3  | 2020-07-16 02:10:13,462 [Thread-209] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-C87DCD1CC6A7->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=102, seq=0, Watch-ALL_COMMITTED(130), Message:<EMPTY>, reply=RaftClientReply:client-C87DCD1CC6A7->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=102, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 102 and log index 130 is not yet replicated to ALL_COMMITTED, logIndex=130, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c173, 875ee6ea-3105-488d-9849-16ec805378c3:c173, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:10:29,460 [Thread-216] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-EB1FAD85EC72->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=107, seq=0, Watch-ALL_COMMITTED(133), Message:<EMPTY>, reply=RaftClientReply:client-EB1FAD85EC72->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=107, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 107 and log index 133 is not yet replicated to ALL_COMMITTED, logIndex=133, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c177, 875ee6ea-3105-488d-9849-16ec805378c3:c177, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:10:44,461 [Thread-221] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-0C9C478B2C7E->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=112, seq=0, Watch-ALL_COMMITTED(137), Message:<EMPTY>, reply=RaftClientReply:client-0C9C478B2C7E->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=112, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 112 and log index 137 is not yet replicated to ALL_COMMITTED, logIndex=137, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c181, 875ee6ea-3105-488d-9849-16ec805378c3:c181, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:10:59,460 [Thread-228] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-9C651434B11A->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=117, seq=0, Watch-ALL_COMMITTED(141), Message:<EMPTY>, reply=RaftClientReply:client-9C651434B11A->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=117, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 117 and log index 141 is not yet replicated to ALL_COMMITTED, logIndex=141, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c185, 875ee6ea-3105-488d-9849-16ec805378c3:c185, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:11:14,460 [Thread-237] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-CE55D6E5B5E3->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=122, seq=0, Watch-ALL_COMMITTED(145), Message:<EMPTY>, reply=RaftClientReply:client-CE55D6E5B5E3->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=122, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 122 and log index 145 is not yet replicated to ALL_COMMITTED, logIndex=145, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c193, 875ee6ea-3105-488d-9849-16ec805378c3:c193, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:11:29,460 [Thread-245] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-78A639364505->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=127, seq=0, Watch-ALL_COMMITTED(149), Message:<EMPTY>, reply=RaftClientReply:client-78A639364505->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=127, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 127 and log index 149 is not yet replicated to ALL_COMMITTED, logIndex=149, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c197, 875ee6ea-3105-488d-9849-16ec805378c3:c197, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:11:45,460 [Thread-253] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-C320B63EBC9C->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=132, seq=0, Watch-ALL_COMMITTED(152), Message:<EMPTY>, reply=RaftClientReply:client-C320B63EBC9C->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=132, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 132 and log index 152 is not yet replicated to ALL_COMMITTED, logIndex=152, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c205, 875ee6ea-3105-488d-9849-16ec805378c3:c205, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:12:00,460 [Thread-261] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-F08F79A5D4A6->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=137, seq=0, Watch-ALL_COMMITTED(156), Message:<EMPTY>, reply=RaftClientReply:client-F08F79A5D4A6->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=137, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 137 and log index 156 is not yet replicated to ALL_COMMITTED, logIndex=156, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c209, 875ee6ea-3105-488d-9849-16ec805378c3:c209, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:12:15,460 [Thread-270] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-698EBA1BF15B->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=142, seq=0, Watch-ALL_COMMITTED(160), Message:<EMPTY>, reply=RaftClientReply:client-698EBA1BF15B->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=142, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 142 and log index 160 is not yet replicated to ALL_COMMITTED, logIndex=160, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c217, 875ee6ea-3105-488d-9849-16ec805378c3:c217, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
s3g_1       | 2020-07-16 02:04:25,985 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1       | 2020-07-16 02:04:26,368 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1       | 2020-07-16 02:04:26,685 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3d9f6567{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2020-07-16 02:04:26,696 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5066d65f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1       | 2020-07-16 02:04:40,661 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1       | Jul 16, 2020 2:04:43 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2020-07-16 02:04:43,981 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@21f9c6ea{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-2690471615844463964.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2020-07-16 02:04:44,013 [main] INFO server.AbstractConnector: Started ServerConnector@11981797{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1       | 2020-07-16 02:04:44,014 [main] INFO server.Server: Started @34621ms
s3g_1       | 2020-07-16 02:04:44,026 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-07-16 02:04:32,096 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = scm/172.26.0.5
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
kdc_1       | Jul 16 02:05:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.9: ISSUE: authtime 1594865072, etypes {rep=18 tkt=18 ses=18}, dn/16c542ca05b0@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Jul 16 02:05:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.2: ISSUE: authtime 1594865062, etypes {rep=18 tkt=18 ses=18}, dn/6b746e10bfd4@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Jul 16 02:05:14 kdc krb5kdc[9](info): AS_REQ (2 etypes {18 17}) 172.26.0.3: ISSUE: authtime 1594865114, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:05:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.3: ISSUE: authtime 1594865114, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:05:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865105, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:05:26 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865126, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:05:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865135, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:05:35 kdc krb5kdc[9](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865135, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
kdc_1       | Jul 16 02:05:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865135, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:05:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865135, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:06:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.10: ISSUE: authtime 1594865071, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
kdc_1       | Jul 16 02:07:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.10: ISSUE: authtime 1594865071, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:10:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:10:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:10:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:10:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:10:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:10:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:10:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:10:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:11:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:11:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:11:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:11:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:11:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:11:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:11:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865435, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:35 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:12:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:12:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 2020-07-16 02:12:30,460 [Thread-278] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-C750BAC5E67A->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=147, seq=0, Watch-ALL_COMMITTED(164), Message:<EMPTY>, reply=RaftClientReply:client-C750BAC5E67A->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=147, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 147 and log index 164 is not yet replicated to ALL_COMMITTED, logIndex=164, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c221, 875ee6ea-3105-488d-9849-16ec805378c3:c221, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:12:45,460 [Thread-279] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-24F8EEAD6BE9->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=152, seq=0, Watch-ALL_COMMITTED(168), Message:<EMPTY>, reply=RaftClientReply:client-24F8EEAD6BE9->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=152, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 152 and log index 168 is not yet replicated to ALL_COMMITTED, logIndex=168, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c221, 875ee6ea-3105-488d-9849-16ec805378c3:c221, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:13:01,460 [Thread-285] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-6140C5B6E611->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=157, seq=0, Watch-ALL_COMMITTED(172), Message:<EMPTY>, reply=RaftClientReply:client-6140C5B6E611->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=157, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 157 and log index 172 is not yet replicated to ALL_COMMITTED, logIndex=172, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c225, 875ee6ea-3105-488d-9849-16ec805378c3:c225, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:13:16,460 [Thread-293] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-54E2C418C2A4->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=162, seq=0, Watch-ALL_COMMITTED(176), Message:<EMPTY>, reply=RaftClientReply:client-54E2C418C2A4->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=162, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 162 and log index 176 is not yet replicated to ALL_COMMITTED, logIndex=176, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c229, 875ee6ea-3105-488d-9849-16ec805378c3:c229, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:13:31,460 [Thread-298] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-AD8FDB03E399->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=167, seq=0, Watch-ALL_COMMITTED(180), Message:<EMPTY>, reply=RaftClientReply:client-AD8FDB03E399->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=167, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 167 and log index 180 is not yet replicated to ALL_COMMITTED, logIndex=180, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c233, 875ee6ea-3105-488d-9849-16ec805378c3:c233, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:13:46,460 [Thread-309] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-49808DF30BF6->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=172, seq=0, Watch-ALL_COMMITTED(183), Message:<EMPTY>, reply=RaftClientReply:client-49808DF30BF6->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=172, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 172 and log index 183 is not yet replicated to ALL_COMMITTED, logIndex=183, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c241, 875ee6ea-3105-488d-9849-16ec805378c3:c241, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:14:01,460 [Thread-314] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-EEE2A0AA9045->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=177, seq=0, Watch-ALL_COMMITTED(187), Message:<EMPTY>, reply=RaftClientReply:client-EEE2A0AA9045->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=177, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 177 and log index 187 is not yet replicated to ALL_COMMITTED, logIndex=187, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c245, 875ee6ea-3105-488d-9849-16ec805378c3:c245, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:14:11,460 [Thread-316] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-1E10B5E7AD36->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, seq=0, Watch-ALL_COMMITTED(192), Message:<EMPTY>, reply=RaftClientReply:client-1E10B5E7AD36->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 192 is not yet replicated to ALL_COMMITTED, logIndex=192, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c245, 875ee6ea-3105-488d-9849-16ec805378c3:c245, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:14:16,462 [Thread-322] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-93DABD7A91DA->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=182, seq=0, Watch-ALL_COMMITTED(195), Message:<EMPTY>, reply=RaftClientReply:client-93DABD7A91DA->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=182, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 182 and log index 195 is not yet replicated to ALL_COMMITTED, logIndex=195, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c249, 875ee6ea-3105-488d-9849-16ec805378c3:c249, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:14:31,462 [Thread-327] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-CDAC8E5D90D4->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=187, seq=0, Watch-ALL_COMMITTED(200), Message:<EMPTY>, reply=RaftClientReply:client-CDAC8E5D90D4->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=187, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 187 and log index 200 is not yet replicated to ALL_COMMITTED, logIndex=200, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c253, 875ee6ea-3105-488d-9849-16ec805378c3:c253, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:14:36,460 [Thread-328] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-F70AC52A10D7->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, seq=0, Watch-ALL_COMMITTED(204), Message:<EMPTY>, reply=RaftClientReply:client-F70AC52A10D7->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 204 is not yet replicated to ALL_COMMITTED, logIndex=204, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c253, 875ee6ea-3105-488d-9849-16ec805378c3:c253, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:14:47,460 [Thread-338] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-09C43089BB37->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=192, seq=0, Watch-ALL_COMMITTED(207), Message:<EMPTY>, reply=RaftClientReply:client-09C43089BB37->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=192, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 192 and log index 207 is not yet replicated to ALL_COMMITTED, logIndex=207, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c260, 875ee6ea-3105-488d-9849-16ec805378c3:c259, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:15:02,460 [Thread-344] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-CEAF512A71FF->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=197, seq=0, Watch-ALL_COMMITTED(211), Message:<EMPTY>, reply=RaftClientReply:client-CEAF512A71FF->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=197, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 197 and log index 211 is not yet replicated to ALL_COMMITTED, logIndex=211, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c264, 875ee6ea-3105-488d-9849-16ec805378c3:c264, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
recon_1     | 2020-07-16 02:07:14,150 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 48
recon_1     | 2020-07-16 02:07:14,251 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 24 OM DB update event(s).
recon_1     | 2020-07-16 02:07:14,477 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:07:15,810 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:07:15,816 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:07:16,458 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:07:16,463 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:07:19,691 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:07:19,698 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:07:45,804 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:07:45,821 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:07:46,457 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:07:46,464 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:07:49,692 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:07:49,712 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:08:14,482 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:08:14,483 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:08:14,514 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8
recon_1     | 2020-07-16 02:08:14,521 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2020-07-16 02:08:14,556 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:08:15,803 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:08:15,808 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:08:16,454 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:08:16,470 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:08:19,687 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:08:19,699 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:08:45,815 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:08:45,831 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:08:46,440 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:08:46,446 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:08:49,703 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:08:49,716 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:09:14,568 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:09:14,568 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:09:14,617 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8
recon_1     | 2020-07-16 02:09:14,637 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2020-07-16 02:09:14,691 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:09:15,823 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:09:15,839 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:09:16,477 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:09:16,482 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:09:19,687 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:09:19,701 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:09:45,810 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:09:45,815 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:09:46,441 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:09:46,454 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:09:49,688 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:09:49,693 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:09:59,627 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1     | 2020-07-16 02:09:59,631 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 1 containers.
recon_1     | 2020-07-16 02:10:14,712 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:10:14,712 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:10:14,742 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8
recon_1     | 2020-07-16 02:10:14,747 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2020-07-16 02:10:14,761 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:10:15,813 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:10:15,819 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:10:16,444 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:10:16,449 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:10:19,679 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:10:19,691 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:10:45,809 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:10:45,820 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:10:46,447 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:10:46,462 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:10:49,740 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:10:49,756 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-07-16 02:04:32,397 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-07-16 02:04:33,602 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-07-16 02:04:34,192 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-c3c8f73b-2a11-4ca7-9b47-f72253e929a8;layoutVersion=0
scm_1       | 2020-07-16 02:04:34,451 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.26.0.5
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-07-16 02:04:45,256 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = scm/172.26.0.5
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-07-16 02:04:45,312 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-07-16 02:04:45,894 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | WARNING: An illegal reflective access operation has occurred
scm_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
scm_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
scm_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
scm_1       | WARNING: All illegal access operations will be denied in a future release
scm_1       | 2020-07-16 02:04:47,102 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm_1       | 2020-07-16 02:04:47,102 [main] INFO server.StorageContainerManager: SCM login successful.
scm_1       | 2020-07-16 02:04:47,441 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-07-16 02:04:51,041 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-16 02:04:51,142 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm_1       | 2020-07-16 02:04:51,588 [Listener at 0.0.0.0/9961] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@4bd51d3e
om_1        | 2020-07-16 02:04:53,564 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.5:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 02:04:56,031 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om_1        | 2020-07-16 02:04:57,647 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om_1        | 2020-07-16 02:04:57,671 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om_1        | 2020-07-16 02:04:57,673 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om_1        | 2020-07-16 02:05:01,896 [main] INFO om.OzoneManager: Init response: GETCERT
om_1        | 2020-07-16 02:05:02,129 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.26.0.3,host:om
om_1        | 2020-07-16 02:05:02,131 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om_1        | 2020-07-16 02:05:02,156 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-07-16 02:05:02,157 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.26.0.3:9862
om_1        | 2020-07-16 02:05:02,160 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-07-16 02:05:02,166 [main] INFO om.OzoneManager: Creating csr for OM->dns:om,ip:172.26.0.3,scmId:1dab16e7-34af-4a3f-97fc-4b8b21b266ab,clusterId:CID-c3c8f73b-2a11-4ca7-9b47-f72253e929a8,subject:root@om
om_1        | 2020-07-16 02:05:02,890 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om_1        | value: 9862
om_1        | ]
om_1        | 2020-07-16 02:05:03,824 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-c3c8f73b-2a11-4ca7-9b47-f72253e929a8;layoutVersion=0
om_1        | 2020-07-16 02:05:04,059 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.26.0.3
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-07-16 02:05:10,635 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.26.0.3
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
recon_1     | 2020-07-16 02:11:14,765 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:11:14,765 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:11:14,785 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 12
recon_1     | 2020-07-16 02:11:14,796 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2020-07-16 02:11:14,815 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:11:15,798 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:11:15,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:11:16,446 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:11:16,449 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:11:19,684 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:11:19,690 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:11:45,799 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:11:45,802 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:11:46,445 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:11:46,455 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:11:49,685 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:11:49,697 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:12:14,819 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
kdc_1       | Jul 16 02:12:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865555, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:13:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865584, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:30 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:13:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:56 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:13:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865610, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:14:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:14:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:15:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:15:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:15:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:15:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:15:38 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:15:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 2020-07-16 02:15:08,460 [Thread-346] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-8885203B43F1->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, seq=0, Watch-ALL_COMMITTED(216), Message:<EMPTY>, reply=RaftClientReply:client-8885203B43F1->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 216 is not yet replicated to ALL_COMMITTED, logIndex=216, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c264, 875ee6ea-3105-488d-9849-16ec805378c3:c264, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:15:17,460 [Thread-355] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-C2972A48C68E->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=202, seq=0, Watch-ALL_COMMITTED(219), Message:<EMPTY>, reply=RaftClientReply:client-C2972A48C68E->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=202, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 202 and log index 219 is not yet replicated to ALL_COMMITTED, logIndex=219, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c272, 875ee6ea-3105-488d-9849-16ec805378c3:c272, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:15:57,460 [Thread-372] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-75FF27AB7593->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=207, seq=0, Watch-ALL_COMMITTED(223), Message:<EMPTY>, reply=RaftClientReply:client-75FF27AB7593->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=207, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 207 and log index 223 is not yet replicated to ALL_COMMITTED, logIndex=223, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c284, 875ee6ea-3105-488d-9849-16ec805378c3:c284, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:16:12,460 [Thread-377] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-9816C7617A63->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=212, seq=0, Watch-ALL_COMMITTED(227), Message:<EMPTY>, reply=RaftClientReply:client-9816C7617A63->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=212, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 212 and log index 227 is not yet replicated to ALL_COMMITTED, logIndex=227, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c288, 875ee6ea-3105-488d-9849-16ec805378c3:c288, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:16:27,460 [Thread-384] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-CB2D448CD5B6->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=217, seq=0, Watch-ALL_COMMITTED(232), Message:<EMPTY>, reply=RaftClientReply:client-CB2D448CD5B6->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=217, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 217 and log index 232 is not yet replicated to ALL_COMMITTED, logIndex=232, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c292, 875ee6ea-3105-488d-9849-16ec805378c3:c292, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:16:35,460 [Thread-388] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-2CE13DC22EDE->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, seq=0, Watch-ALL_COMMITTED(236), Message:<EMPTY>, reply=RaftClientReply:client-2CE13DC22EDE->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 236 is not yet replicated to ALL_COMMITTED, logIndex=236, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c296, 875ee6ea-3105-488d-9849-16ec805378c3:c296, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:16:42,460 [Thread-390] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-7108089BDF71->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=222, seq=0, Watch-ALL_COMMITTED(239), Message:<EMPTY>, reply=RaftClientReply:client-7108089BDF71->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=222, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 222 and log index 239 is not yet replicated to ALL_COMMITTED, logIndex=239, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c296, 875ee6ea-3105-488d-9849-16ec805378c3:c296, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:16:58,460 [Thread-400] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-207D87C810B8->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=227, seq=0, Watch-ALL_COMMITTED(243), Message:<EMPTY>, reply=RaftClientReply:client-207D87C810B8->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=227, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 227 and log index 243 is not yet replicated to ALL_COMMITTED, logIndex=243, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c304, 875ee6ea-3105-488d-9849-16ec805378c3:c304, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:17:13,460 [Thread-406] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-1B789EA2878E->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=232, seq=0, Watch-ALL_COMMITTED(247), Message:<EMPTY>, reply=RaftClientReply:client-1B789EA2878E->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=232, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 232 and log index 247 is not yet replicated to ALL_COMMITTED, logIndex=247, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c308, 875ee6ea-3105-488d-9849-16ec805378c3:c308, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:17:28,460 [Thread-417] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-D86BE7D01CB1->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=237, seq=0, Watch-ALL_COMMITTED(251), Message:<EMPTY>, reply=RaftClientReply:client-D86BE7D01CB1->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=237, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 237 and log index 251 is not yet replicated to ALL_COMMITTED, logIndex=251, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c316, 875ee6ea-3105-488d-9849-16ec805378c3:c316, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:17:43,460 [Thread-422] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-FBE941AC52C3->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=242, seq=0, Watch-ALL_COMMITTED(255), Message:<EMPTY>, reply=RaftClientReply:client-FBE941AC52C3->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=242, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 242 and log index 255 is not yet replicated to ALL_COMMITTED, logIndex=255, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c320, 875ee6ea-3105-488d-9849-16ec805378c3:c320, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:17:47,460 [Thread-431] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-B60EDDBB374E->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, seq=0, Watch-ALL_COMMITTED(259), Message:<EMPTY>, reply=RaftClientReply:client-B60EDDBB374E->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 259 is not yet replicated to ALL_COMMITTED, logIndex=259, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c328, 875ee6ea-3105-488d-9849-16ec805378c3:c327, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:17:58,460 [Thread-434] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-12FC355AE4D7->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=247, seq=0, Watch-ALL_COMMITTED(262), Message:<EMPTY>, reply=RaftClientReply:client-12FC355AE4D7->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=247, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 247 and log index 262 is not yet replicated to ALL_COMMITTED, logIndex=262, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c328, 875ee6ea-3105-488d-9849-16ec805378c3:c328, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:18:12,460 [Thread-439] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5F1E18AF05BF->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, seq=0, Watch-ALL_COMMITTED(267), Message:<EMPTY>, reply=RaftClientReply:client-5F1E18AF05BF->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 267 is not yet replicated to ALL_COMMITTED, logIndex=267, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c332, 875ee6ea-3105-488d-9849-16ec805378c3:c332, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
datanode_3  | 2020-07-16 02:18:13,460 [Thread-440] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-0F68B519830C->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=252, seq=0, Watch-ALL_COMMITTED(270), Message:<EMPTY>, reply=RaftClientReply:client-0F68B519830C->1ec8a11d-967c-4d6b-b9a9-dc794cb618e0@group-82DBE919E7AD, cid=252, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 252 and log index 270 is not yet replicated to ALL_COMMITTED, logIndex=270, commits[1ec8a11d-967c-4d6b-b9a9-dc794cb618e0:c332, 875ee6ea-3105-488d-9849-16ec805378c3:c332, c1f0c1f5-4f44-4e41-a2d3-123376104d0a:c127]
scm_1       | 2020-07-16 02:04:51,589 [Listener at 0.0.0.0/9961] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-07-16 02:04:51,892 [Listener at 0.0.0.0/9961] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-07-16 02:04:52,285 [Listener at 0.0.0.0/9961] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-07-16 02:04:52,409 [Listener at 0.0.0.0/9961] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-07-16 02:04:52,752 [Listener at 0.0.0.0/9961] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-07-16 02:04:52,757 [Listener at 0.0.0.0/9961] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-07-16 02:04:52,878 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-07-16 02:04:53,444 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-16 02:04:53,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-07-16 02:04:53,501 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-16 02:04:53,512 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-07-16 02:04:53,582 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-16 02:04:53,583 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-07-16 02:04:53,700 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-07-16 02:04:53,700 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm_1       | 2020-07-16 02:04:53,702 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm_1       | 2020-07-16 02:04:53,732 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @17312ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-07-16 02:04:53,868 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-07-16 02:04:53,876 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-07-16 02:04:53,878 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm_1       | 2020-07-16 02:04:53,878 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1       | 2020-07-16 02:04:53,879 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1       | 2020-07-16 02:04:53,882 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm_1       | 2020-07-16 02:04:53,941 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-07-16 02:04:54,025 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-07-16 02:04:54,087 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-07-16 02:04:54,087 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-07-16 02:04:54,346 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-07-16 02:04:54,347 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-16 02:04:54,350 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-07-16 02:04:54,446 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-07-16 02:04:54,457 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-07-16 02:04:54,458 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-16 02:04:54,472 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-07-16 02:04:54,581 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-07-16 02:04:54,585 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-07-16 02:04:54,601 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-16 02:04:54,603 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-07-16 02:04:54,722 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm_1       | 2020-07-16 02:04:54,732 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-16 02:04:54,732 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm_1       | 2020-07-16 02:04:54,734 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-07-16 02:04:54,778 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1       | 2020-07-16 02:04:55,134 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-07-16 02:04:55,134 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-07-16 02:04:55,136 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1       | 2020-07-16 02:04:55,181 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:04:55,209 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:04:55,214 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:04:55,238 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:04:55,253 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1       | 2020-07-16 02:04:55,276 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:04:55,278 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f6c4ae{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-07-16 02:04:55,287 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:04:55,284 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:04:55,283 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:04:55,293 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2c56eba5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-07-16 02:04:55,301 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:04:55,331 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:04:55,538 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:04:55,583 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:04:55,694 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1       | 2020-07-16 02:04:55,732 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@390a07a0{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-10626021789376288566.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-07-16 02:04:55,758 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 16c542ca05b0, UUID: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
scm_1       | 2020-07-16 02:04:55,763 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 27eb3e7e62d5, UUID: c1f0c1f5-4f44-4e41-a2d3-123376104d0a
scm_1       | 2020-07-16 02:04:55,800 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@6ac9b66b{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-07-16 02:04:55,800 [Listener at 0.0.0.0/9860] INFO server.Server: Started @19379ms
scm_1       | 2020-07-16 02:04:55,805 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-07-16 02:04:55,805 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-07-16 02:04:55,819 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-07-16 02:04:55,839 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e79c25] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-07-16 02:04:56,175 [IPC Server handler 0 on default port 9961] ERROR authority.DefaultCAServer: Certificate storage failed, retrying one more time.
scm_1       | org.apache.hadoop.hdds.security.exception.SCMSecurityException: Conflicting certificate ID
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMCertStore.storeValidCertificate(SCMCertStore.java:60)
scm_1       | 	at org.apache.hadoop.hdds.security.x509.certificate.authority.DefaultCAServer.signAndStoreCertificate(DefaultCAServer.java:256)
scm_1       | 	at org.apache.hadoop.hdds.security.x509.certificate.authority.DefaultCAServer.requestCertificate(DefaultCAServer.java:229)
scm_1       | 	at org.apache.hadoop.hdds.security.x509.certificate.authority.DefaultCAServer.requestCertificate(DefaultCAServer.java:266)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMSecurityProtocolServer.getDataNodeCertificate(SCMSecurityProtocolServer.java:116)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.getDataNodeCertificate(SCMSecurityProtocolServerSideTranslatorPB.java:125)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.processRequest(SCMSecurityProtocolServerSideTranslatorPB.java:102)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:68)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:6374)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-07-16 02:04:56,282 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 6b746e10bfd4, UUID: 875ee6ea-3105-488d-9849-16ec805378c3
scm_1       | 2020-07-16 02:04:58,261 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:04:58,325 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:05:03,400 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:03,418 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:05:03,423 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: 9a4e40d3-2b32-4503-b202-4793c731c06e
scm_1       | 2020-07-16 02:05:09,640 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:09,669 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:06Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-07-16 02:05:10,721 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-07-16 02:05:13,874 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-07-16 02:05:14,032 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.26.0.3:9862
om_1        | 2020-07-16 02:05:14,032 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-07-16 02:05:14,142 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | WARNING: An illegal reflective access operation has occurred
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | WARNING: All illegal access operations will be denied in a future release
om_1        | 2020-07-16 02:05:14,772 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om_1        | 2020-07-16 02:05:14,774 [main] INFO om.OzoneManager: Ozone Manager login successful.
om_1        | 2020-07-16 02:05:14,775 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-16 02:05:19,049 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om_1        | 2020-07-16 02:05:19,430 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
om_1        | 2020-07-16 02:05:19,454 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/3734990031298.crt.
om_1        | 2020-07-16 02:05:19,730 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-16 02:05:20,950 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om_1        | 2020-07-16 02:05:20,983 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om_1        | 2020-07-16 02:05:20,983 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om_1        | 2020-07-16 02:05:21,340 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-07-16 02:05:21,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-07-16 02:05:22,525 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-07-16 02:05:22,844 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-07-16 02:05:22,844 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-07-16 02:05:23,052 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.26.0.3:9862
om_1        | 2020-07-16 02:05:23,059 [Listener at om/9862] INFO om.OzoneManager: Reading keypair and certificate from file system.
om_1        | 2020-07-16 02:05:23,121 [Listener at om/9862] INFO om.OzoneManager: Starting OM block token secret manager
om_1        | 2020-07-16 02:05:23,123 [Listener at om/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om_1        | 2020-07-16 02:05:23,126 [Listener at om/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om_1        | 2020-07-16 02:05:23,135 [Listener at om/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om_1        | 2020-07-16 02:05:23,164 [Thread[Thread-10,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om_1        | 2020-07-16 02:05:23,291 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-07-16 02:05:23,300 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-07-16 02:05:23,822 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-07-16 02:05:23,823 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om_1        | 2020-07-16 02:05:23,823 [Listener at om/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om_1        | 2020-07-16 02:05:23,871 [Listener at om/9862] INFO util.log: Logging initialized @19047ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-07-16 02:05:24,197 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-07-16 02:05:24,218 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-07-16 02:05:24,224 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om_1        | 2020-07-16 02:05:24,225 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1        | 2020-07-16 02:05:24,225 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om_1        | 2020-07-16 02:05:24,228 [Listener at om/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om_1        | 2020-07-16 02:05:24,303 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2020-07-16 02:05:24,306 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1        | 2020-07-16 02:05:24,392 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-07-16 02:05:24,392 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2020-07-16 02:05:24,397 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1        | 2020-07-16 02:05:24,448 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2020-07-16 02:05:24,457 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@f287a4e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-07-16 02:05:24,459 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@73c09a98{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2020-07-16 02:05:24,711 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2020-07-16 02:05:24,739 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6003eb60{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-404881687807070977.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-07-16 02:05:24,845 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@3450bd13{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-07-16 02:05:24,846 [Listener at om/9862] INFO server.Server: Started @20022ms
om_1        | 2020-07-16 02:05:24,849 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-07-16 02:05:24,849 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-07-16 02:05:24,855 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-07-16 02:05:24,887 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@160e45c8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2020-07-16 02:05:39,439 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:05:39,464 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:05:41,431 [IPC Server handler 1 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-47734 for user:testuser/scm@EXAMPLE.COM
recon_1     | 2020-07-16 02:12:14,819 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:12:14,837 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 13
recon_1     | 2020-07-16 02:12:14,845 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 7 OM DB update event(s).
recon_1     | 2020-07-16 02:12:14,866 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:12:15,800 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:12:15,810 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:12:16,440 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:12:16,452 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:12:19,684 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:12:19,690 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:12:45,801 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:12:45,807 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:12:46,454 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:12:46,461 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:12:49,688 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:12:49,692 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:13:14,870 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:13:14,870 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:13:14,889 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 12
recon_1     | 2020-07-16 02:13:14,904 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2020-07-16 02:13:14,923 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:13:15,812 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:13:15,830 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:13:16,441 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:13:16,454 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:13:19,680 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:13:19,695 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:13:45,800 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:13:45,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:13:46,438 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:13:46,458 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:13:49,689 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:13:49,698 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:14:14,926 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:14:14,926 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:14:14,941 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 17
recon_1     | 2020-07-16 02:14:14,975 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 6 OM DB update event(s).
recon_1     | 2020-07-16 02:14:15,008 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:14:15,794 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:14:15,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:14:16,436 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:14:16,442 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:14:19,690 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:10,281 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:10,320 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:05:10,754 [IPC Server handler 35 on default port 9861] WARN ipc.Server: IPC Server handler 35 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.26.0.4:35119: output error
scm_1       | 2020-07-16 02:05:10,755 [IPC Server handler 35 on default port 9861] INFO ipc.Server: IPC Server handler 35 on default port 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-07-16 02:05:11,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:11,148 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:05:11,588 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:11,668 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:05:12,288 [IPC Server handler 32 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
scm_1       | 2020-07-16 02:05:12,329 [IPC Server handler 32 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727771908603}
scm_1       | 2020-07-16 02:05:12,436 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 02:05:12,464 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2020-07-16 02:05:12,624 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=64ff4463-865e-4a7e-b1b3-8e92e435fea5 to datanode:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
scm_1       | 2020-07-16 02:05:12,728 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 64ff4463-865e-4a7e-b1b3-8e92e435fea5, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T02:05:12.577392Z]
scm_1       | 2020-07-16 02:05:12,746 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
scm_1       | 2020-07-16 02:05:13,065 [IPC Server handler 32 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/875ee6ea-3105-488d-9849-16ec805378c3
scm_1       | 2020-07-16 02:05:13,065 [IPC Server handler 32 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727931076021}
scm_1       | 2020-07-16 02:05:13,073 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 02:05:13,079 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-07-16 02:05:13,080 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d57ae6f0-8d25-40f6-9cce-ebc71622a859 to datanode:875ee6ea-3105-488d-9849-16ec805378c3
scm_1       | 2020-07-16 02:05:13,080 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d57ae6f0-8d25-40f6-9cce-ebc71622a859, Nodes: 875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T02:05:13.080067Z]
scm_1       | 2020-07-16 02:05:13,081 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1       | 2020-07-16 02:05:13,454 [IPC Server handler 30 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/c1f0c1f5-4f44-4e41-a2d3-123376104d0a
scm_1       | 2020-07-16 02:05:13,464 [IPC Server handler 30 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 3727587558692}
scm_1       | 2020-07-16 02:05:13,464 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 02:05:13,466 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3b55a46e-bbed-4c85-b75d-6008c7a79d63 to datanode:c1f0c1f5-4f44-4e41-a2d3-123376104d0a
scm_1       | 2020-07-16 02:05:13,469 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3b55a46e-bbed-4c85-b75d-6008c7a79d63, Nodes: c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T02:05:13.466560Z]
scm_1       | 2020-07-16 02:05:13,466 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1       | 2020-07-16 02:05:13,470 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 02:05:13,470 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-07-16 02:05:13,472 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-16 02:05:13,479 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=153b2045-8688-49df-8258-82dbe919e7ad to datanode:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0
scm_1       | 2020-07-16 02:05:13,482 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=153b2045-8688-49df-8258-82dbe919e7ad to datanode:875ee6ea-3105-488d-9849-16ec805378c3
scm_1       | 2020-07-16 02:05:13,482 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=153b2045-8688-49df-8258-82dbe919e7ad to datanode:c1f0c1f5-4f44-4e41-a2d3-123376104d0a
scm_1       | 2020-07-16 02:05:13,483 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 153b2045-8688-49df-8258-82dbe919e7ad, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T02:05:13.479286Z]
scm_1       | 2020-07-16 02:05:13,486 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-16 02:05:15,775 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 64ff4463-865e-4a7e-b1b3-8e92e435fea5, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0, CreationTimestamp2020-07-16T02:05:12.577392Z] moved to OPEN state
scm_1       | 2020-07-16 02:05:15,828 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-07-16 02:05:15,841 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:15,846 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-07-16 02:05:15,854 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:05:16,865 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:16,939 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:05:17,426 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d57ae6f0-8d25-40f6-9cce-ebc71622a859, Nodes: 875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:875ee6ea-3105-488d-9849-16ec805378c3, CreationTimestamp2020-07-16T02:05:13.080067Z] moved to OPEN state
scm_1       | 2020-07-16 02:05:17,430 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-07-16 02:05:17,433 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-07-16 02:05:21,586 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:21,684 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:05:22,118 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 153b2045-8688-49df-8258-82dbe919e7ad, Nodes: 1ec8a11d-967c-4d6b-b9a9-dc794cb618e0{ip: 172.26.0.9, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}875ee6ea-3105-488d-9849-16ec805378c3{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:1ec8a11d-967c-4d6b-b9a9-dc794cb618e0, CreationTimestamp2020-07-16T02:05:13.479286Z] moved to OPEN state
scm_1       | 2020-07-16 02:05:22,119 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-07-16 02:05:22,119 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2020-07-16 02:05:22,163 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 02:05:22,163 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-07-16 02:05:22,163 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2020-07-16 02:05:22,800 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:22,862 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:05:42,102 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:42,108 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:05:44,503 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:44,549 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:05:44,561 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 3b55a46e-bbed-4c85-b75d-6008c7a79d63, Nodes: c1f0c1f5-4f44-4e41-a2d3-123376104d0a{ip: 172.26.0.4, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:c1f0c1f5-4f44-4e41-a2d3-123376104d0a, CreationTimestamp2020-07-16T02:05:13.466560Z] moved to OPEN state
scm_1       | 2020-07-16 02:05:44,562 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:44,583 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:05:45,029 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:45,054 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:05:45,531 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:45,548 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:05:45,575 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:45,612 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-07-16 02:05:45,858 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:45,974 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
kdc_1       | Jul 16 02:16:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865652, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jul 16 02:16:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:16:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:17:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:17:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:17:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:17:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:17:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:17:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:18:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:18:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jul 16 02:18:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.5: ISSUE: authtime 1594865772, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2020-07-16 02:05:46,587 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:46,615 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:05:49,769 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:05:49,790 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:06:15,807 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:06:15,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:06:16,487 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:06:16,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:06:19,696 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:06:19,707 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:06:45,806 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:06:45,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:06:46,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:06:46,445 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:06:49,712 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:06:49,716 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:06:52,880 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-16 02:06:52,880 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-16 02:07:15,819 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:15,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:07:16,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:16,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:07:19,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:19,693 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:07:23,510 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:23,511 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:23,517 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:07:23,522 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:07:38,707 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:38,709 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:07:38,761 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:38,764 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:07:45,803 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:45,819 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:07:46,440 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:46,446 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:07:49,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:49,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:07:53,923 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:53,925 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:07:53,934 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:07:53,936 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:08:09,080 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:09,083 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:09,091 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:08:09,094 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:08:15,810 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:15,814 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:08:16,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:16,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:08:19,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:19,694 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:08:24,245 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:24,252 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:08:24,268 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:24,277 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:08:39,423 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:39,424 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:39,437 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:08:39,438 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:08:45,811 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:45,821 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:08:46,437 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:14:19,695 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:14:45,802 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:14:45,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:14:46,431 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:14:46,442 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:14:49,675 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:14:49,681 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:14:59,633 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2020-07-16 02:14:59,635 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 1 containers.
recon_1     | 2020-07-16 02:14:59,653 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2020-07-16 02:14:59,654 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 31 milliseconds.
recon_1     | 2020-07-16 02:15:15,011 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:15:15,012 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:15:15,038 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 14
recon_1     | 2020-07-16 02:15:15,043 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 5 OM DB update event(s).
recon_1     | 2020-07-16 02:15:15,062 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:15:15,802 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:15:15,813 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:15:16,447 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:15:16,453 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:15:19,681 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:15:19,689 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:15:45,803 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:15:45,812 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:15:46,440 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:15:46,446 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:15:49,688 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:15:49,695 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:16:15,065 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:16:15,065 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:16:15,083 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 13
recon_1     | 2020-07-16 02:16:15,098 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 8 OM DB update event(s).
recon_1     | 2020-07-16 02:16:15,128 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:16:15,800 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:16:15,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:16:16,432 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:16:16,440 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:16:19,690 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:16:19,699 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:16:45,819 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:16:45,821 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:16:46,435 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:16:46,446 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:16:49,688 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:16:49,696 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:17:15,137 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:17:15,137 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:17:15,158 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 15
recon_1     | 2020-07-16 02:17:15,169 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 5 OM DB update event(s).
recon_1     | 2020-07-16 02:17:15,181 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:17:15,803 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:17:15,808 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:17:16,440 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:17:16,449 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:17:19,681 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:17:19,695 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:17:45,796 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:17:45,802 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:17:46,433 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:17:46,455 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:17:49,685 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:17:49,693 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:18:15,185 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-16 02:18:15,185 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-16 02:18:15,222 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 13
recon_1     | 2020-07-16 02:18:15,233 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 8 OM DB update event(s).
recon_1     | 2020-07-16 02:18:15,253 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-16 02:18:15,820 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:18:15,831 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:18:16,438 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:18:16,449 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-07-16 02:18:19,694 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-07-16 02:18:19,698 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2020-07-16 02:08:46,448 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:08:49,697 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:49,708 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:08:52,881 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-16 02:08:52,881 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-16 02:08:54,674 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:54,675 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:08:54,693 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:08:54,720 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:09:09,876 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:09,878 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:09,892 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:09:09,895 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:09:15,814 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:15,831 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:09:16,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:16,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:09:19,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:19,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:09:25,061 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:25,063 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:25,081 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:09:25,101 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:09:40,226 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:40,228 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:40,229 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:09:40,240 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:09:45,796 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:45,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:09:46,437 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:46,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:09:49,687 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:49,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:09:55,367 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:55,373 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:09:55,380 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:09:55,389 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:10:10,512 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:10,516 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:10:10,520 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:10,539 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:10:15,802 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:15,810 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:10:16,442 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:16,460 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:10:19,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:19,698 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:10:22,174 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2020-07-16 02:10:22,183 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 6 milliseconds for processing 1 containers.
scm_1       | 2020-07-16 02:10:25,662 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:25,663 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:25,669 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:10:25,680 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:10:40,822 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:40,824 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:10:40,828 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:40,831 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:10:45,824 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:45,832 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:10:46,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:46,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:10:49,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:49,755 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:10:52,882 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-16 02:10:52,883 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-16 02:10:56,005 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:56,012 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:10:56,112 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:10:56,115 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:11:09,185 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:09,186 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:11:11,228 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:11,241 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:11:15,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:15,809 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:11:16,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:16,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:11:19,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:19,695 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:11:26,345 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:26,347 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:26,360 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:11:26,368 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:11:41,484 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:41,489 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:11:45,803 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:45,808 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:11:46,444 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:46,451 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:11:49,681 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:49,692 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:11:54,773 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:54,776 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2020-07-16 02:05:41,479 [IPC Server handler 50 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-02567 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-07-16 02:05:41,494 [IPC Server handler 57 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-45569 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-07-16 02:05:41,504 [IPC Server handler 59 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-92341 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-07-16 02:05:41,513 [IPC Server handler 60 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-00459 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-07-16 02:06:13,130 [qtp726690425-136] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om_1        | 2020-07-16 02:06:13,151 [qtp726690425-136] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1594865173131 in 19 milliseconds
om_1        | 2020-07-16 02:06:13,195 [qtp726690425-136] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 42 milliseconds
om_1        | 2020-07-16 02:06:13,196 [qtp726690425-136] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1594865173131
om_1        | 2020-07-16 02:07:13,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:07:13,843 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:07:23,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:07:23,482 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:07:38,687 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:07:38,691 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:07:53,882 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:07:53,892 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:08:09,048 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:08:09,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:08:14,497 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:08:14,512 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:08:24,220 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:08:24,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:08:39,389 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:08:39,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:08:54,621 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:08:54,629 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:09:09,836 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:09:09,840 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:09:14,589 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:09:14,612 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:09:25,016 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:09:25,033 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:09:40,193 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:09:40,199 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:09:55,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:09:55,341 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:10,488 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:10,494 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:14,738 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:14,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:25,629 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:25,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:38,268 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:38,284 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:40,790 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:40,796 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:41,745 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:41,760 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:42,357 [IPC Server handler 58 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:88025-rpcwoport for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-07-16 02:10:44,965 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:44,976 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:48,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:48,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:51,790 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:51,805 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:55,298 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:55,316 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:55,972 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:56,650 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:11:56,656 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:12:15,803 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:15,808 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:12:16,441 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:16,454 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:12:19,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:19,700 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:12:23,759 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:23,767 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:12:23,822 [IPC Server handler 88 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2020-07-16 02:12:23,824 [IPC Server handler 88 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104521105047617588 bcsId: 0
scm_1       | 2020-07-16 02:12:27,029 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:27,037 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:12:40,016 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:40,020 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:12:45,809 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:45,821 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:12:46,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:46,450 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:12:49,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:49,709 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:12:51,851 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:51,853 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:12:51,856 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:12:51,860 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:12:52,884 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-16 02:12:52,886 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-16 02:13:07,027 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:07,029 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:13:07,030 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:07,047 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:13:15,831 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:15,847 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:13:16,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:16,469 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:13:19,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:19,735 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:13:22,187 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:22,189 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:13:22,199 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:22,212 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:13:23,907 [IPC Server handler 17 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2020-07-16 02:13:23,907 [IPC Server handler 17 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104521107137167415 bcsId: 0
scm_1       | 2020-07-16 02:13:37,394 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:37,396 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:13:45,803 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:45,806 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:13:46,436 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:46,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:13:49,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:49,685 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:13:52,502 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:52,505 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:13:52,517 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:13:52,520 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:14:07,699 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:07,710 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:14:07,714 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:07,717 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:14:15,814 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:15,827 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:14:16,447 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:16,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:14:19,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:19,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:14:22,833 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:22,841 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:14:22,842 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:22,849 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:14:37,994 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:37,995 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:38,000 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:14:38,003 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:14:45,814 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:45,834 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:14:46,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:46,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:14:49,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:49,699 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:14:52,886 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-16 02:14:52,887 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-16 02:14:53,133 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:53,140 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:14:59,635 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:14:59,650 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:15:05,528 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:05,530 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:15:08,299 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:08,315 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:15:15,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:15,807 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:15:16,440 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:16,442 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:15:19,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:19,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:15:22,183 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2020-07-16 02:15:23,424 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:23,427 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:15:23,432 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:23,443 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2020-07-16 02:10:55,980 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:10:58,599 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:10:58,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:01,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:01,752 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:05,474 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:05,488 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:08,649 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:08,665 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:11,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:11,208 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:14,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:14,782 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:20,860 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:20,867 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:26,316 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:26,322 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:29,105 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:29,118 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:33,994 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:34,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:41,451 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:41,452 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:46,163 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:46,167 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:54,230 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:54,245 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:56,626 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:56,631 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:11:59,168 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:11:59,179 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:02,676 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:02,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:05,753 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:05,766 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:11,768 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:11,776 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:14,829 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:14,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:18,049 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:18,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:26,430 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:26,444 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:31,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:31,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:34,516 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:34,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:38,881 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:38,918 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:40,507 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:40,543 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:41,401 [IPC Server handler 70 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:88025-rpcwoport2 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-07-16 02:12:44,500 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:44,512 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:47,715 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:47,761 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:51,007 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:51,023 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:51,811 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:51,817 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:54,374 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:54,388 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:12:57,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:12:57,521 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:00,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:00,929 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:04,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:04,060 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:06,999 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:38,617 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:38,623 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:15:45,802 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:45,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:15:46,433 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:46,439 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:15:49,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:49,683 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:15:53,747 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:53,755 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:15:53,757 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:15:53,760 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:16:08,924 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:08,929 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:16:15,812 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:15,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:16:16,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:16,454 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:16:19,693 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:19,735 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:16:23,920 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:23,930 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:16:23,931 [IPC Server handler 17 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-07-16 02:16:23,931 [IPC Server handler 17 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104521121254342728 bcsId: 0
scm_1       | 2020-07-16 02:16:23,932 [IPC Server handler 17 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104521119195791429 bcsId: 0
scm_1       | 2020-07-16 02:16:24,115 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:24,118 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:16:39,252 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:39,263 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:16:39,279 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:39,295 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:16:45,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:45,812 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:16:46,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:46,449 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:16:49,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:49,698 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:16:52,888 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-16 02:16:52,888 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
om_1        | 2020-07-16 02:13:07,009 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:07,397 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:07,409 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:10,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:10,480 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:13,615 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:13,636 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:14,092 [IPC Server handler 44 on default port 9862] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /88025-rpcwoport2/bb1 failed, because acl already exist
om_1        | 2020-07-16 02:13:14,879 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:14,881 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:16,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:16,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:20,158 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:20,172 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:22,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:22,168 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:23,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:23,116 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:26,286 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:26,301 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:29,507 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:29,525 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:32,781 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:32,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:37,353 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:37,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:45,013 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:45,019 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:52,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:52,487 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:52,950 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:52,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:56,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:56,372 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:13:59,393 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:13:59,401 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:02,669 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:02,690 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:05,574 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:05,583 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:07,666 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:07,682 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:08,778 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:08,792 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:11,821 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:11,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:14,934 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:14,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:15,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:54,372 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:16:54,379 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:17:07,369 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:07,375 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:17:09,461 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:09,467 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:17:15,803 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:15,805 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:17:16,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:16,441 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:17:19,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:19,694 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:17:24,591 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:24,593 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:17:24,596 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:24,608 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:17:39,762 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:39,769 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:17:45,815 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:45,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:17:46,442 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:46,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:17:49,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:49,695 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:17:54,914 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:54,914 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:17:54,920 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:17:54,923 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:18:05,574 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:18:05,577 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-07-16 02:18:10,060 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:18:10,069 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-07-16 02:18:15,808 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:18:15,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/16c542ca05b0@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:18:16,440 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:18:16,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/6b746e10bfd4@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-07-16 02:18:19,693 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-07-16 02:18:19,699 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/27eb3e7e62d5@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2020-07-16 02:14:15,409 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:18,528 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:18,539 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:19,014 [IPC Server handler 40 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:88025-rpcwport for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-07-16 02:14:21,654 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:21,678 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:22,811 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:22,818 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:25,048 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:25,061 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:28,266 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:28,274 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:31,474 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:31,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:34,775 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:34,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:37,830 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:37,842 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:37,965 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:37,973 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:41,216 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:41,233 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:44,698 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:44,716 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:53,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:53,111 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:14:56,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:14:56,913 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:04,993 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:05,004 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:08,234 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:08,244 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:09,819 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:09,836 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:15,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:15,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:21,980 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:21,983 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:23,402 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:23,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:30,142 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:30,156 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:34,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:34,918 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:38,120 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:38,131 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:38,578 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:38,593 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:41,181 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:41,196 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:53,487 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:53,496 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:15:53,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:15:53,722 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:01,384 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:01,403 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:06,143 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:06,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:08,867 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:08,871 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:09,197 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:09,208 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:12,295 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:12,306 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:15,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:15,081 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:16,773 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:16,784 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:19,868 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:19,882 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:20,421 [IPC Server handler 71 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:88025-rpcwoscheme for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-07-16 02:16:23,240 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:23,257 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:24,077 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:24,081 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:26,624 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:26,638 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:29,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:29,972 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:33,341 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:33,362 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:36,630 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:36,646 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:39,217 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:39,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:39,661 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:39,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:43,033 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:43,045 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:46,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:46,384 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:54,343 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:54,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:16:58,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:16:58,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:06,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:06,784 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:09,442 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:09,447 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:11,751 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:11,760 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:15,151 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:15,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:24,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:24,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:24,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:24,573 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:32,193 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:32,208 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:37,489 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:37,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:39,723 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:39,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:41,024 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:41,038 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:44,146 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:44,159 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:54,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:54,888 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:17:56,711 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:17:56,725 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:18:04,961 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:18:04,974 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:18:10,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:18:10,038 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:18:10,142 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:18:10,156 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:18:13,391 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:18:13,405 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-07-16 02:18:15,192 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-07-16 02:18:15,214 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
