Attaching to ozone-csi_datanode_3, ozone-csi_datanode_1, ozone-csi_datanode_2, ozone-csi_csi_1, ozone-csi_scm_1, ozone-csi_om_1
csi_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
csi_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
csi_1       | 2020-07-16 01:16:03,716 [main] INFO csi.CsiServer: STARTUP_MSG: 
csi_1       | /************************************************************
csi_1       | STARTUP_MSG: Starting CsiServer
csi_1       | STARTUP_MSG:   host = 065ca05bdb80/172.18.0.4
csi_1       | STARTUP_MSG:   args = []
csi_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
csi_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-1.17.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.18.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.29.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.29.0.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.19.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.29.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.29.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.29.0.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.29.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.29.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-epoll-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-util-3.11.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/protobuf-java-3.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-csi-0.6.0-SNAPSHOT.jar
csi_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:06Z
csi_1       | STARTUP_MSG:   java = 11.0.6
csi_1       | ************************************************************/
csi_1       | 2020-07-16 01:16:03,862 [main] INFO csi.CsiServer: registered UNIX signal handlers for [TERM, HUP, INT]
csi_1       | 2020-07-16 01:16:12,641 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:13,642 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:14,643 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:15,644 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:16,645 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:17,646 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:18,647 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:19,647 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:20,648 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:21,649 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:24,653 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:25,654 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:26,655 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:27,656 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:28,657 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:29,658 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:30,659 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:31,666 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:32,666 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:33,667 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:33,668 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 065ca05bdb80/172.18.0.4 to om:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy16.submitRequest over nodeId=null,nodeAddress=om:9862 after 1 failover attempts. Trying to failover after sleeping for 4000ms.
csi_1       | 2020-07-16 01:16:38,675 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:39,685 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:40,685 [main] INFO ipc.Client: Retrying connect to server: om/172.18.0.3:9862. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
csi_1       | 2020-07-16 01:16:43,400 [epollEventLoopGroup-2-1] WARN bootstrap.ServerBootstrap: Unknown channel option 'SO_KEEPALIVE' for channel '[id: 0x5cd2deff]'
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-07-16 01:16:05,507 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 03fdcd2a638f/172.18.0.7
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
datanode_1  | STARTUP_MSG:   java = 11.0.6
datanode_1  | ************************************************************/
datanode_1  | 2020-07-16 01:16:05,586 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-07-16 01:16:06,956 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-07-16 01:16:07,805 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-07-16 01:16:08,584 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-07-16 01:16:08,586 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-07-16 01:16:09,259 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:03fdcd2a638f ip:172.18.0.7
datanode_1  | 2020-07-16 01:16:09,874 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-07-16 01:16:09,899 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-07-16 01:16:09,902 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-07-16 01:16:09,964 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-07-16 01:16:10,188 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-07-16 01:16:14,903 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-07-16 01:16:15,167 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-07-16 01:16:15,757 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-07-16 01:16:15,758 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-07-16 01:16:15,764 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-16 01:16:15,764 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-07-16 01:16:15,765 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-07-16 01:16:16,852 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-16 01:16:17,802 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-07-16 01:16:17,867 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1  | 2020-07-16 01:16:18,092 [main] INFO util.log: Logging initialized @17956ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-07-16 01:16:18,459 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-07-16 01:16:18,484 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-07-16 01:16:18,503 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-07-16 01:16:18,507 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2020-07-16 01:16:18,507 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2020-07-16 01:16:18,516 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2020-07-16 01:16:18,676 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-07-16 01:16:18,681 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1  | 2020-07-16 01:16:18,910 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-07-16 01:16:18,911 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-07-16 01:16:18,913 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2020-07-16 01:16:18,939 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@65753724{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-07-16 01:16:18,944 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6dece1f9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-07-16 01:16:19,337 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@a4df251{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-945113659472032748.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-07-16 01:16:19,395 [main] INFO server.AbstractConnector: Started ServerConnector@42cc420b{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-07-16 01:16:19,395 [main] INFO server.Server: Started @19259ms
datanode_1  | 2020-07-16 01:16:19,409 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-07-16 01:16:19,410 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-07-16 01:16:19,416 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-07-16 01:16:19,538 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d81bf84] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-07-16 01:16:20,226 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-07-16 01:16:22,916 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 01:16:23,917 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 01:16:24,918 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-07-16 01:16:25,962 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From 03fdcd2a638f/172.18.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:51102 remote=scm/172.18.0.2:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-07-16 01:16:07,800 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 9f275dc6ad8b/172.18.0.5
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
datanode_2  | STARTUP_MSG:   java = 11.0.6
datanode_2  | ************************************************************/
datanode_2  | 2020-07-16 01:16:07,842 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-07-16 01:16:09,209 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-07-16 01:16:09,767 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-07-16 01:16:10,696 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-07-16 01:16:10,696 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-07-16 01:16:11,099 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:9f275dc6ad8b ip:172.18.0.5
datanode_2  | 2020-07-16 01:16:11,896 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-07-16 01:16:11,923 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-07-16 01:16:11,945 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-07-16 01:16:12,003 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-07-16 01:16:12,293 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-07-16 01:16:16,759 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-07-16 01:16:17,006 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-07-16 01:16:17,648 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-07-16 01:16:17,654 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-07-16 01:16:17,654 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-16 01:16:17,657 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-07-16 01:16:17,667 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-07-16 01:16:18,749 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-16 01:16:19,617 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-07-16 01:16:19,723 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2  | 2020-07-16 01:16:19,821 [main] INFO util.log: Logging initialized @18069ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-07-16 01:16:20,280 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-07-16 01:16:20,293 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-07-16 01:16:20,324 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-07-16 01:16:20,327 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-07-16 01:16:20,336 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-07-16 01:16:20,337 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-07-16 01:16:20,482 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-07-16 01:16:20,488 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2  | 2020-07-16 01:16:20,666 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-07-16 01:16:20,666 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-07-16 01:16:20,674 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-07-16 01:16:20,749 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@502c2278{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-07-16 01:16:20,750 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ecdc2b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-07-16 01:16:21,176 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7f2c995b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-11623765314742089580.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-07-16 01:16:21,210 [main] INFO server.AbstractConnector: Started ServerConnector@3739f3c9{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-07-16 01:16:21,210 [main] INFO server.Server: Started @19458ms
datanode_2  | 2020-07-16 01:16:21,231 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-07-16 01:16:21,231 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-07-16 01:16:21,239 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-07-16 01:16:21,292 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@48a44fa0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-07-16 01:16:21,954 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-07-16 01:16:24,395 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 01:16:25,395 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-16 01:16:26,273 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-07-16 01:16:26,275 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-07-16 01:16:26,276 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 0e780947-836a-40f7-b526-7e9d072ab28b at port 9858
datanode_2  | 2020-07-16 01:16:26,358 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 0e780947-836a-40f7-b526-7e9d072ab28b: start RPC server
datanode_2  | 2020-07-16 01:16:26,584 [Datanode State Machine Thread - 0] INFO server.GrpcService: 0e780947-836a-40f7-b526-7e9d072ab28b: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-07-16 01:16:30,432 [Command processor thread] INFO impl.RaftServerProxy: 0e780947-836a-40f7-b526-7e9d072ab28b: addNew group-CE13C617EA4B:[0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858] returns group-CE13C617EA4B:java.util.concurrent.CompletableFuture@6954dcaa[Not completed]
datanode_2  | 2020-07-16 01:16:30,586 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b: new RaftServerImpl for group-CE13C617EA4B:[0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-16 01:16:30,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-07-16 01:16:30,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-07-16 01:16:30,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-16 01:16:30,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-07-16 01:16:30,609 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-16 01:16:30,638 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B: ConfigurationManager, init=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-07-16 01:16:30,638 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-16 01:16:30,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-07-16 01:16:30,656 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4376d0d9-62c8-4e70-9be5-ce13c617ea4b does not exist. Creating ...
datanode_2  | 2020-07-16 01:16:30,678 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4376d0d9-62c8-4e70-9be5-ce13c617ea4b/in_use.lock acquired by nodename 6@9f275dc6ad8b
datanode_2  | 2020-07-16 01:16:30,688 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4376d0d9-62c8-4e70-9be5-ce13c617ea4b has been successfully formatted.
datanode_2  | 2020-07-16 01:16:30,705 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-CE13C617EA4B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-07-16 01:16:30,720 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-07-16 01:16:30,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-07-16 01:16:30,751 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-07-16 01:16:30,759 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-16 01:16:30,793 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-16 01:16:30,849 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B
datanode_2  | 2020-07-16 01:16:30,937 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-07-16 01:16:30,965 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/4376d0d9-62c8-4e70-9be5-ce13c617ea4b
datanode_2  | 2020-07-16 01:16:30,966 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-07-16 01:16:30,967 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-07-16 01:16:30,971 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-16 01:16:30,997 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-07-16 01:16:30,998 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-07-16 01:16:30,998 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:51102 remote=scm/172.18.0.2:9861]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1  | 2020-07-16 01:16:26,226 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-07-16 01:16:26,227 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-07-16 01:16:26,227 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c6fe274f-723d-46da-a19a-f99aea9a1072 at port 9858
datanode_1  | 2020-07-16 01:16:26,271 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: c6fe274f-723d-46da-a19a-f99aea9a1072: start RPC server
datanode_1  | 2020-07-16 01:16:26,488 [Datanode State Machine Thread - 1] INFO server.GrpcService: c6fe274f-723d-46da-a19a-f99aea9a1072: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-07-16 01:16:30,856 [Command processor thread] INFO impl.RaftServerProxy: c6fe274f-723d-46da-a19a-f99aea9a1072: addNew group-BF79CD5C1F00:[c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858] returns group-BF79CD5C1F00:java.util.concurrent.CompletableFuture@1f81e682[Not completed]
datanode_1  | 2020-07-16 01:16:30,918 [pool-19-thread-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072: new RaftServerImpl for group-BF79CD5C1F00:[c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-07-16 01:16:30,927 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-07-16 01:16:30,928 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-07-16 01:16:30,935 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-07-16 01:16:30,936 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-07-16 01:16:30,937 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-07-16 01:16:30,965 [pool-19-thread-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00: ConfigurationManager, init=-1: [c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-07-16 01:16:30,966 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-16 01:16:30,971 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-07-16 01:16:30,992 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/80f04674-9024-4200-9a06-bf79cd5c1f00 does not exist. Creating ...
datanode_1  | 2020-07-16 01:16:31,013 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/80f04674-9024-4200-9a06-bf79cd5c1f00/in_use.lock acquired by nodename 6@03fdcd2a638f
datanode_1  | 2020-07-16 01:16:31,028 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/80f04674-9024-4200-9a06-bf79cd5c1f00 has been successfully formatted.
datanode_1  | 2020-07-16 01:16:31,072 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-BF79CD5C1F00: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-07-16 01:16:31,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-07-16 01:16:31,081 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-07-16 01:16:31,109 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-07-16 01:16:31,116 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-16 01:16:31,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-16 01:16:31,147 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-07-16 01:16:08,080 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = 37e4640a39e3/172.18.0.3
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:06Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-07-16 01:16:08,133 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-07-16 01:16:12,690 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-07-16 01:16:13,199 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.3:9862
om_1        | 2020-07-16 01:16:13,200 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-07-16 01:16:13,284 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-16 01:16:15,594 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:16,595 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:17,596 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:18,596 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:19,597 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:20,598 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:21,600 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:22,601 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:23,601 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:24,602 [main] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-07-16 01:16:24,606 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-4a0924ed-f6d5-4640-a71f-c59f8a141c3c;layoutVersion=0
om_1        | 2020-07-16 01:16:30,289 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at 37e4640a39e3/172.18.0.3
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-07-16 01:16:35,089 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = 37e4640a39e3/172.18.0.3
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | 2020-07-16 01:16:31,001 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-07-16 01:16:31,002 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-07-16 01:16:31,005 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-07-16 01:16:31,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-07-16 01:16:31,128 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-16 01:16:31,128 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-16 01:16:31,145 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-07-16 01:16:31,157 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-07-16 01:16:31,157 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-07-16 01:16:31,168 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-07-16 01:16:31,191 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-07-16 01:16:31,309 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B
datanode_2  | 2020-07-16 01:16:31,330 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B
datanode_2  | 2020-07-16 01:16:31,347 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B: start as a follower, conf=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858], old=null
datanode_2  | 2020-07-16 01:16:31,364 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-07-16 01:16:31,368 [pool-19-thread-1] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: start FollowerState
datanode_2  | 2020-07-16 01:16:31,404 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE13C617EA4B,id=0e780947-836a-40f7-b526-7e9d072ab28b
datanode_2  | 2020-07-16 01:16:31,406 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B
datanode_2  | 2020-07-16 01:16:31,504 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "4376d0d9-62c8-4e70-9be5-ce13c617ea4b"
datanode_2  | uuid128 {
datanode_1  | 2020-07-16 01:16:31,220 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-07-16 01:16:31,262 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/80f04674-9024-4200-9a06-bf79cd5c1f00
datanode_1  | 2020-07-16 01:16:31,275 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-07-16 01:16:31,275 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-07-16 01:16:31,276 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-16 01:16:31,295 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-07-16 01:16:31,296 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-07-16 01:16:31,297 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-07-16 01:16:31,298 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-07-16 01:16:31,299 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-07-16 01:16:31,300 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-07-16 01:16:31,406 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-07-16 01:16:31,441 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-16 01:16:31,441 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-16 01:16:31,463 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-07-16 01:16:31,472 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-07-16 01:16:31,475 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-07-16 01:16:31,477 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-07-16 01:16:31,487 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-07-16 01:16:31,582 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00
datanode_1  | 2020-07-16 01:16:31,610 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00
datanode_1  | 2020-07-16 01:16:31,620 [pool-19-thread-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00: start as a follower, conf=-1: [c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_1  | 2020-07-16 01:16:31,621 [pool-19-thread-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-07-16 01:16:31,638 [pool-19-thread-1] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: start FollowerState
datanode_1  | 2020-07-16 01:16:31,661 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF79CD5C1F00,id=c6fe274f-723d-46da-a19a-f99aea9a1072
datanode_1  | 2020-07-16 01:16:31,668 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00
datanode_1  | 2020-07-16 01:16:31,745 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "80f04674-9024-4200-9a06-bf79cd5c1f00"
datanode_1  | uuid128 {
datanode_1  |   mostSigBits: -9155740575995772416
datanode_1  |   leastSigBits: -7347975212151070976
datanode_1  | }
datanode_1  | .
datanode_1  | 2020-07-16 01:16:31,753 [Command processor thread] INFO impl.RaftServerProxy: c6fe274f-723d-46da-a19a-f99aea9a1072: addNew group-235B557A5446:[0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858] returns group-235B557A5446:java.util.concurrent.CompletableFuture@56734f2d[Not completed]
datanode_1  | 2020-07-16 01:16:31,780 [pool-19-thread-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072: new RaftServerImpl for group-235B557A5446:[0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-07-16 01:16:31,789 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-07-16 01:16:31,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-07-16 01:16:31,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-07-16 01:16:31,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-07-16 01:16:31,791 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-07-16 01:16:31,791 [pool-19-thread-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446: ConfigurationManager, init=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-07-16 01:16:31,791 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-07-16 01:16:31,792 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-07-16 01:16:31,792 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446 does not exist. Creating ...
datanode_1  | 2020-07-16 01:16:31,800 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446/in_use.lock acquired by nodename 6@03fdcd2a638f
datanode_1  | 2020-07-16 01:16:31,804 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446 has been successfully formatted.
datanode_1  | 2020-07-16 01:16:31,805 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-235B557A5446: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-07-16 01:16:31,819 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-07-16 01:16:31,820 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-07-16 01:16:31,820 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-07-16 01:16:31,820 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:06Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-07-16 01:16:35,109 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-07-16 01:16:36,988 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-07-16 01:16:37,349 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.18.0.3:9862
om_1        | 2020-07-16 01:16:37,349 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-07-16 01:16:37,415 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-16 01:16:37,516 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-16 01:16:39,693 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-07-16 01:16:40,242 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-07-16 01:16:40,258 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-07-16 01:16:40,492 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-07-16 01:16:40,598 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-07-16 01:16:40,599 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-07-16 01:16:40,677 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.18.0.3:9862
om_1        | 2020-07-16 01:16:40,780 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-07-16 01:16:40,783 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-07-16 01:16:41,207 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-07-16 01:16:41,208 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1        | 2020-07-16 01:16:41,279 [Listener at om/9862] INFO util.log: Logging initialized @10540ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-07-16 01:16:41,491 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-07-16 01:16:41,494 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-07-16 01:16:41,500 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-07-16 01:16:41,502 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1        | 2020-07-16 01:16:41,502 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2020-07-16 01:16:41,502 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2020-07-16 01:16:41,540 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2020-07-16 01:16:41,541 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1        | 2020-07-16 01:16:41,641 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-07-16 01:16:41,641 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2020-07-16 01:16:41,644 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1        | 2020-07-16 01:16:41,698 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7e94de5f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-07-16 01:16:41,699 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@22ff11ef{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2020-07-16 01:16:41,890 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5d68be4f{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-16228490180422190142.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-07-16 01:16:41,919 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@6f17dd06{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-07-16 01:16:41,919 [Listener at om/9862] INFO server.Server: Started @11180ms
om_1        | 2020-07-16 01:16:41,925 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-07-16 01:16:41,925 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-07-16 01:16:41,930 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-07-16 01:16:41,943 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e1ad7de] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-07-16 01:16:31,820 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-16 01:16:31,821 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446
datanode_1  | 2020-07-16 01:16:31,821 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-07-16 01:16:31,821 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446
datanode_1  | 2020-07-16 01:16:31,821 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-07-16 01:16:31,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-07-16 01:16:31,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-07-16 01:16:31,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-07-16 01:16:31,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-07-16 01:16:31,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-07-16 01:16:31,823 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-07-16 01:16:31,823 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-07-16 01:16:31,823 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-07-16 01:16:31,829 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-07-16 01:16:31,843 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-16 01:16:31,844 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-16 01:16:31,863 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-07-16 01:16:31,871 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-07-16 01:16:31,872 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-07-16 01:16:31,872 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-07-16 01:16:31,873 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-07-16 01:16:31,873 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446
datanode_1  | 2020-07-16 01:16:31,874 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446
datanode_1  | 2020-07-16 01:16:31,890 [pool-19-thread-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446: start as a follower, conf=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_1  | 2020-07-16 01:16:31,890 [pool-19-thread-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-07-16 01:16:31,890 [pool-19-thread-1] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: start FollowerState
datanode_1  | 2020-07-16 01:16:31,898 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-235B557A5446,id=c6fe274f-723d-46da-a19a-f99aea9a1072
datanode_1  | 2020-07-16 01:16:31,899 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446
datanode_1  | 2020-07-16 01:16:34,188 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "9a76e84a-d63a-4be2-9104-235b557a5446"
datanode_1  | uuid128 {
datanode_1  |   mostSigBits: -7316405136497423390
datanode_1  |   leastSigBits: -7997228163120081850
datanode_1  | }
datanode_1  | .
datanode_1  | 2020-07-16 01:16:36,786 [Thread-23] INFO impl.FollowerState: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-FollowerState: change to CANDIDATE, lastRpcTime:5148ms, electionTimeout:5119ms
datanode_1  | 2020-07-16 01:16:36,788 [Thread-23] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: shutdown FollowerState
datanode_1  | 2020-07-16 01:16:36,789 [Thread-23] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-07-16 01:16:36,791 [Thread-23] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: start LeaderElection
datanode_1  | 2020-07-16 01:16:36,811 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO impl.LeaderElection: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1: begin an election at term 1 for -1: [c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_1  | 2020-07-16 01:16:36,812 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: shutdown LeaderElection
datanode_1  | 2020-07-16 01:16:36,812 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-07-16 01:16:36,834 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BF79CD5C1F00 with new leaderId: c6fe274f-723d-46da-a19a-f99aea9a1072
datanode_1  | 2020-07-16 01:16:36,834 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00: change Leader from null to c6fe274f-723d-46da-a19a-f99aea9a1072 at term 1 for becomeLeader, leader elected after 5761ms
datanode_1  | 2020-07-16 01:16:36,846 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-07-16 01:16:36,846 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-07-16 01:16:36,852 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00
datanode_1  | 2020-07-16 01:16:36,854 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  |   mostSigBits: 4861302479876804208
datanode_2  |   leastSigBits: -7213132643840824757
datanode_2  | }
datanode_2  | .
datanode_2  | 2020-07-16 01:16:31,509 [Command processor thread] INFO impl.RaftServerProxy: 0e780947-836a-40f7-b526-7e9d072ab28b: addNew group-235B557A5446:[0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858] returns group-235B557A5446:java.util.concurrent.CompletableFuture@558d3ae6[Not completed]
datanode_2  | 2020-07-16 01:16:31,512 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b: new RaftServerImpl for group-235B557A5446:[0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-16 01:16:31,518 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-07-16 01:16:31,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-07-16 01:16:31,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-16 01:16:31,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-07-16 01:16:31,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-16 01:16:31,525 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446: ConfigurationManager, init=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-07-16 01:16:31,525 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-16 01:16:31,527 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-07-16 01:16:31,528 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446 does not exist. Creating ...
datanode_2  | 2020-07-16 01:16:31,530 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446/in_use.lock acquired by nodename 6@9f275dc6ad8b
datanode_2  | 2020-07-16 01:16:31,536 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446 has been successfully formatted.
datanode_2  | 2020-07-16 01:16:31,536 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-235B557A5446: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-07-16 01:16:31,542 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-07-16 01:16:31,544 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-07-16 01:16:31,547 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-07-16 01:16:31,547 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-16 01:16:31,548 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-16 01:16:31,548 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446
datanode_2  | 2020-07-16 01:16:31,552 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-07-16 01:16:31,552 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446
datanode_2  | 2020-07-16 01:16:31,552 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-07-16 01:16:31,552 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-07-16 01:16:31,553 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-16 01:16:31,553 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-07-16 01:16:31,564 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-07-16 01:16:31,568 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-07-16 01:16:31,568 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-07-16 01:16:31,571 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-07-16 01:16:31,572 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-07-16 01:16:31,575 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-07-16 01:16:31,579 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-16 01:16:31,582 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-16 01:16:31,583 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-07-16 01:16:31,584 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-07-16 01:16:31,584 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-07-16 01:16:31,584 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-07-16 01:16:31,584 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-07-16 01:16:31,585 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446
datanode_2  | 2020-07-16 01:16:31,585 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446
datanode_2  | 2020-07-16 01:16:31,597 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446: start as a follower, conf=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_2  | 2020-07-16 01:16:31,604 [pool-19-thread-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-07-16 01:16:31,604 [pool-19-thread-1] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: start FollowerState
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-07-16 01:16:06,195 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 1412b4a8f975/172.18.0.6
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | 2020-07-16 01:16:31,605 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-235B557A5446,id=0e780947-836a-40f7-b526-7e9d072ab28b
datanode_2  | 2020-07-16 01:16:31,605 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446
datanode_2  | 2020-07-16 01:16:34,528 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "9a76e84a-d63a-4be2-9104-235b557a5446"
datanode_2  | uuid128 {
datanode_2  |   mostSigBits: -7316405136497423390
datanode_2  |   leastSigBits: -7997228163120081850
datanode_2  | }
datanode_2  | .
datanode_2  | 2020-07-16 01:16:36,468 [Thread-22] INFO impl.FollowerState: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-FollowerState: change to CANDIDATE, lastRpcTime:5099ms, electionTimeout:5063ms
datanode_2  | 2020-07-16 01:16:36,470 [Thread-22] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: shutdown FollowerState
datanode_2  | 2020-07-16 01:16:36,470 [Thread-22] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-07-16 01:16:36,472 [Thread-22] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: start LeaderElection
datanode_2  | 2020-07-16 01:16:36,501 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO impl.LeaderElection: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1: begin an election at term 1 for -1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858], old=null
datanode_2  | 2020-07-16 01:16:36,502 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: shutdown LeaderElection
datanode_2  | 2020-07-16 01:16:36,502 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-07-16 01:16:36,506 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CE13C617EA4B with new leaderId: 0e780947-836a-40f7-b526-7e9d072ab28b
datanode_2  | 2020-07-16 01:16:36,507 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B: change Leader from null to 0e780947-836a-40f7-b526-7e9d072ab28b at term 1 for becomeLeader, leader elected after 5800ms
datanode_2  | 2020-07-16 01:16:36,516 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-07-16 01:16:36,516 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-07-16 01:16:36,518 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B
datanode_2  | 2020-07-16 01:16:36,533 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-07-16 01:16:36,535 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-07-16 01:16:36,555 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-07-16 01:16:36,555 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-07-16 01:16:36,564 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-07-16 01:16:36,596 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: start LeaderState
datanode_2  | 2020-07-16 01:16:36,656 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-07-16 01:16:36,696 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-LeaderElection1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B: set configuration 0: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858], old=null at 0
datanode_2  | 2020-07-16 01:16:36,719 [Thread-24] INFO impl.FollowerState: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-FollowerState: change to CANDIDATE, lastRpcTime:5114ms, electionTimeout:5113ms
datanode_2  | 2020-07-16 01:16:36,719 [Thread-24] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: shutdown FollowerState
datanode_2  | 2020-07-16 01:16:36,719 [Thread-24] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-07-16 01:16:36,720 [Thread-24] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: start LeaderElection
datanode_2  | 2020-07-16 01:16:36,790 [0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-LeaderElection2] INFO impl.LeaderElection: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-LeaderElection2: begin an election at term 1 for -1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_2  | 2020-07-16 01:16:37,195 [0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0e780947-836a-40f7-b526-7e9d072ab28b@group-CE13C617EA4B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4376d0d9-62c8-4e70-9be5-ce13c617ea4b/current/log_inprogress_0
datanode_2  | 2020-07-16 01:16:37,577 [grpc-default-executor-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
datanode_2  | 2020-07-16 01:16:37,577 [grpc-default-executor-1] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: shutdown LeaderElection
datanode_2  | 2020-07-16 01:16:37,577 [grpc-default-executor-1] INFO impl.RoleInfo: 0e780947-836a-40f7-b526-7e9d072ab28b: start FollowerState
datanode_2  | 2020-07-16 01:16:37,577 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-235B557A5446 with new leaderId: c6fe274f-723d-46da-a19a-f99aea9a1072
datanode_2  | 2020-07-16 01:16:37,577 [grpc-default-executor-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446: change Leader from null to c6fe274f-723d-46da-a19a-f99aea9a1072 at term 1 for appendEntries, leader elected after 6035ms
datanode_2  | 2020-07-16 01:16:37,602 [0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-LeaderElection2] INFO impl.LeaderElection: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-LeaderElection2: Election REJECTED; received 2 response(s) [0e780947-836a-40f7-b526-7e9d072ab28b<-4377bb4e-f732-42f4-8e4f-04d6e89d4e86#0:FAIL-t1, 0e780947-836a-40f7-b526-7e9d072ab28b<-c6fe274f-723d-46da-a19a-f99aea9a1072#0:FAIL-t1] and 0 exception(s); 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446:t1, leader=c6fe274f-723d-46da-a19a-f99aea9a1072, voted=0e780947-836a-40f7-b526-7e9d072ab28b, raftlog=0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_2  | 2020-07-16 01:16:37,642 [grpc-default-executor-1] INFO impl.RaftServerImpl: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446: set configuration 0: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null at 0
datanode_2  | 2020-07-16 01:16:37,644 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-07-16 01:16:37,657 [0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 0e780947-836a-40f7-b526-7e9d072ab28b@group-235B557A5446-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446/current/log_inprogress_0
datanode_1  | 2020-07-16 01:16:36,855 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-07-16 01:16:36,927 [Thread-25] INFO impl.FollowerState: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-FollowerState: change to CANDIDATE, lastRpcTime:5036ms, electionTimeout:5014ms
datanode_1  | 2020-07-16 01:16:36,928 [Thread-25] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: shutdown FollowerState
datanode_1  | 2020-07-16 01:16:36,928 [Thread-25] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-07-16 01:16:36,928 [Thread-25] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: start LeaderElection
datanode_1  | 2020-07-16 01:16:36,940 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-07-16 01:16:36,966 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-07-16 01:16:36,972 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO impl.LeaderElection: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2: begin an election at term 1 for -1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_1  | 2020-07-16 01:16:36,986 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-07-16 01:16:37,061 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: start LeaderState
datanode_1  | 2020-07-16 01:16:37,172 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO impl.LeaderElection: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2: Election PASSED; received 1 response(s) [c6fe274f-723d-46da-a19a-f99aea9a1072<-4377bb4e-f732-42f4-8e4f-04d6e89d4e86#0:OK-t1] and 0 exception(s); c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446:t1, leader=null, voted=c6fe274f-723d-46da-a19a-f99aea9a1072, raftlog=c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_1  | 2020-07-16 01:16:37,175 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: shutdown LeaderElection
datanode_1  | 2020-07-16 01:16:37,176 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-07-16 01:16:37,183 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-235B557A5446 with new leaderId: c6fe274f-723d-46da-a19a-f99aea9a1072
datanode_1  | 2020-07-16 01:16:37,184 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446: change Leader from null to c6fe274f-723d-46da-a19a-f99aea9a1072 at term 1 for becomeLeader, leader elected after 5378ms
datanode_1  | 2020-07-16 01:16:37,184 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-07-16 01:16:37,184 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-07-16 01:16:37,184 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446
datanode_1  | 2020-07-16 01:16:37,185 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-07-16 01:16:37,191 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-07-16 01:16:37,199 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-07-16 01:16:37,201 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-07-16 01:16:37,201 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-07-16 01:16:37,228 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2020-07-16 01:16:37,241 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-16 01:16:37,249 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-07-16 01:16:37,276 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2020-07-16 01:16:37,293 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2020-07-16 01:16:37,373 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-07-16 01:16:37,373 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-07-16 01:16:37,379 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446
datanode_1  | 2020-07-16 01:16:37,380 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-LeaderElection1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00: set configuration 0: [c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null at 0
datanode_1  | 2020-07-16 01:16:37,400 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2020-07-16 01:16:37,401 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-07-16 01:16:37,401 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
datanode_3  | STARTUP_MSG:   java = 11.0.6
datanode_3  | ************************************************************/
datanode_3  | 2020-07-16 01:16:06,261 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-07-16 01:16:07,726 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-07-16 01:16:08,381 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-07-16 01:16:09,327 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-07-16 01:16:09,328 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-07-16 01:16:09,856 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:1412b4a8f975 ip:172.18.0.6
datanode_3  | 2020-07-16 01:16:10,655 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-07-16 01:16:10,678 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-07-16 01:16:10,685 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-07-16 01:16:10,725 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-07-16 01:16:10,994 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-07-16 01:16:15,459 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-07-16 01:16:15,685 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-07-16 01:16:16,110 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-07-16 01:16:16,141 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-07-16 01:16:16,158 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-16 01:16:16,168 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-07-16 01:16:16,168 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-07-16 01:16:17,077 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-16 01:16:17,962 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-07-16 01:16:18,068 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2020-07-16 01:16:18,184 [main] INFO util.log: Logging initialized @17913ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-07-16 01:16:18,575 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-07-16 01:16:18,580 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-07-16 01:16:18,613 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-07-16 01:16:18,621 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-07-16 01:16:18,623 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-07-16 01:16:18,623 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-07-16 01:16:18,777 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-07-16 01:16:18,780 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3  | 2020-07-16 01:16:18,832 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-07-16 01:16:18,832 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-07-16 01:16:18,833 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 2020-07-16 01:16:18,865 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4948daec{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-07-16 01:16:18,866 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5c573229{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-07-16 01:16:19,281 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1aeff8ca{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-8877782818251277360.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-07-16 01:16:19,423 [main] INFO server.AbstractConnector: Started ServerConnector@285bf5ac{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-07-16 01:16:19,426 [main] INFO server.Server: Started @19155ms
datanode_3  | 2020-07-16 01:16:19,452 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-07-16 01:16:19,452 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-07-16 01:16:19,464 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-07-16 01:16:19,605 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73eefd7d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-07-16 01:16:20,366 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-07-16 01:16:22,879 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 01:16:23,880 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 01:16:24,881 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.18.0.2:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-07-16 01:16:25,902 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-07-16 01:16:14,596 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = fc4517d8c8b3/172.18.0.2
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | java.net.SocketTimeoutException: Call From 1412b4a8f975/172.18.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:42122 remote=scm/172.18.0.2:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:42122 remote=scm/172.18.0.2:9861]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3  | 2020-07-16 01:16:26,295 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-07-16 01:16:26,297 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-07-16 01:16:26,300 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 4377bb4e-f732-42f4-8e4f-04d6e89d4e86 at port 9858
datanode_3  | 2020-07-16 01:16:26,329 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: start RPC server
datanode_3  | 2020-07-16 01:16:26,536 [Datanode State Machine Thread - 1] INFO server.GrpcService: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-07-16 01:16:31,001 [Command processor thread] INFO impl.RaftServerProxy: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: addNew group-1CEC9013BE77:[4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858] returns group-1CEC9013BE77:java.util.concurrent.CompletableFuture@488c429a[Not completed]
datanode_3  | 2020-07-16 01:16:31,132 [pool-19-thread-1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: new RaftServerImpl for group-1CEC9013BE77:[4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-07-16 01:16:31,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-07-16 01:16:31,154 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-07-16 01:16:31,155 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-07-16 01:16:31,156 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-07-16 01:16:31,159 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-07-16 01:16:31,194 [pool-19-thread-1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77: ConfigurationManager, init=-1: [4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-07-16 01:16:31,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-16 01:16:31,237 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-07-16 01:16:31,250 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9bd16abb-c7b1-40e9-bcab-1cec9013be77 does not exist. Creating ...
datanode_3  | 2020-07-16 01:16:31,274 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9bd16abb-c7b1-40e9-bcab-1cec9013be77/in_use.lock acquired by nodename 6@1412b4a8f975
datanode_3  | 2020-07-16 01:16:31,292 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9bd16abb-c7b1-40e9-bcab-1cec9013be77 has been successfully formatted.
datanode_3  | 2020-07-16 01:16:31,348 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-1CEC9013BE77: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-07-16 01:16:31,349 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-07-16 01:16:31,366 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-07-16 01:16:31,427 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-07-16 01:16:31,428 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-16 01:16:31,430 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-16 01:16:31,457 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-07-16 01:16:14,691 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-07-16 01:16:15,321 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-07-16 01:16:15,526 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-4a0924ed-f6d5-4640-a71f-c59f8a141c3c;layoutVersion=0
scm_1       | 2020-07-16 01:16:15,567 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at fc4517d8c8b3/172.18.0.2
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-07-16 01:16:22,891 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = fc4517d8c8b3/172.18.0.2
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | 2020-07-16 01:16:37,401 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2020-07-16 01:16:37,403 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-07-16 01:16:37,403 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-07-16 01:16:37,405 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO impl.RoleInfo: c6fe274f-723d-46da-a19a-f99aea9a1072: start LeaderState
datanode_1  | 2020-07-16 01:16:37,409 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-07-16 01:16:37,463 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-LeaderElection2] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446: set configuration 0: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null at 0
datanode_1  | 2020-07-16 01:16:37,496 [grpc-default-executor-1] INFO impl.RaftServerImpl: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-   LEADER: Withhold vote from candidate 0e780947-836a-40f7-b526-7e9d072ab28b with term 1. State: leader=c6fe274f-723d-46da-a19a-f99aea9a1072, term=1, lastRpcElapsed=null
datanode_1  | 2020-07-16 01:16:37,723 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c6fe274f-723d-46da-a19a-f99aea9a1072@group-235B557A5446-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446/current/log_inprogress_0
datanode_1  | 2020-07-16 01:16:37,737 [c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c6fe274f-723d-46da-a19a-f99aea9a1072@group-BF79CD5C1F00-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/80f04674-9024-4200-9a06-bf79cd5c1f00/current/log_inprogress_0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/22d03f657a1680875a2e022b45e94c87e080188b ; compiled by 'runner' on 2020-07-16T01:05Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-07-16 01:16:22,900 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-07-16 01:16:22,982 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-07-16 01:16:23,215 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-07-16 01:16:23,493 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@70925b45
scm_1       | 2020-07-16 01:16:23,497 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-07-16 01:16:23,641 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-07-16 01:16:23,792 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-07-16 01:16:23,848 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-07-16 01:16:23,932 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 0
scm_1       | 2020-07-16 01:16:23,934 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-07-16 01:16:23,999 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-07-16 01:16:24,560 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-16 01:16:24,585 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-07-16 01:16:24,623 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-16 01:16:24,628 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-07-16 01:16:24,645 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-07-16 01:16:24,646 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-07-16 01:16:24,670 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-07-16 01:16:24,671 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1       | 2020-07-16 01:16:24,696 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @7962ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-07-16 01:16:24,778 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-07-16 01:16:24,791 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-07-16 01:16:24,796 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-07-16 01:16:24,798 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2020-07-16 01:16:24,798 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2020-07-16 01:16:24,798 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1       | 2020-07-16 01:16:24,833 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-07-16 01:16:24,972 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-07-16 01:16:25,032 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-07-16 01:16:25,033 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-07-16 01:16:25,285 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-07-16 01:16:25,287 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-16 01:16:25,300 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-07-16 01:16:25,343 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-07-16 01:16:25,344 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-07-16 01:16:25,347 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-16 01:16:25,352 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-07-16 01:16:25,376 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-07-16 01:16:25,376 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-07-16 01:16:25,377 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-07-16 01:16:25,378 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-07-16 01:16:25,454 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-07-16 01:16:25,455 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1       | 2020-07-16 01:16:25,617 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-07-16 01:16:25,617 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-07-16 01:16:25,639 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2020-07-16 01:16:25,651 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@40bd0f8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-07-16 01:16:25,652 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@49c1e294{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-07-16 01:16:25,771 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@75ed7512{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-4576563459861020923.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-07-16 01:16:25,793 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@73a845cb{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-07-16 01:16:25,793 [Listener at 0.0.0.0/9860] INFO server.Server: Started @9060ms
scm_1       | 2020-07-16 01:16:25,828 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-07-16 01:16:25,828 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-07-16 01:16:25,839 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-07-16 01:16:25,923 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b936b04] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-07-16 01:16:26,013 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.7:51102: output error
scm_1       | 2020-07-16 01:16:26,027 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.18.0.6:42122: output error
scm_1       | 2020-07-16 01:16:26,091 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-07-16 01:16:26,092 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-07-16 01:16:27,405 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/0e780947-836a-40f7-b526-7e9d072ab28b
scm_1       | 2020-07-16 01:16:27,416 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 0e780947-836a-40f7-b526-7e9d072ab28b{ip: 172.18.0.5, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-16 01:16:27,437 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 01:16:27,443 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
scm_1       | 2020-07-16 01:16:27,460 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 01:16:27,460 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-07-16 01:16:27,503 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4376d0d9-62c8-4e70-9be5-ce13c617ea4b to datanode:0e780947-836a-40f7-b526-7e9d072ab28b
scm_1       | 2020-07-16 01:16:27,563 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 4376d0d9-62c8-4e70-9be5-ce13c617ea4b, Nodes: 0e780947-836a-40f7-b526-7e9d072ab28b{ip: 172.18.0.5, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T01:16:27.495704Z]
scm_1       | 2020-07-16 01:16:27,569 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
scm_1       | 2020-07-16 01:16:27,570 [RatisPipelineUtilsThread] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
scm_1       | 2020-07-16 01:16:27,570 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
scm_1       | 2020-07-16 01:16:27,834 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/c6fe274f-723d-46da-a19a-f99aea9a1072
scm_1       | 2020-07-16 01:16:27,835 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c6fe274f-723d-46da-a19a-f99aea9a1072{ip: 172.18.0.7, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-16 01:16:27,835 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/4377bb4e-f732-42f4-8e4f-04d6e89d4e86
scm_1       | 2020-07-16 01:16:27,836 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4377bb4e-f732-42f4-8e4f-04d6e89d4e86{ip: 172.18.0.6, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-16 01:16:27,836 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 01:16:27,837 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 01:16:27,837 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 01:16:27,837 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 01:16:27,838 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=80f04674-9024-4200-9a06-bf79cd5c1f00 to datanode:c6fe274f-723d-46da-a19a-f99aea9a1072
scm_1       | 2020-07-16 01:16:27,850 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 80f04674-9024-4200-9a06-bf79cd5c1f00, Nodes: c6fe274f-723d-46da-a19a-f99aea9a1072{ip: 172.18.0.7, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T01:16:27.838460Z]
scm_1       | 2020-07-16 01:16:27,851 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9bd16abb-c7b1-40e9-bcab-1cec9013be77 to datanode:4377bb4e-f732-42f4-8e4f-04d6e89d4e86
scm_1       | 2020-07-16 01:16:27,851 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 9bd16abb-c7b1-40e9-bcab-1cec9013be77, Nodes: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86{ip: 172.18.0.6, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T01:16:27.851352Z]
scm_1       | 2020-07-16 01:16:27,852 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-16 01:16:27,868 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9a76e84a-d63a-4be2-9104-235b557a5446 to datanode:0e780947-836a-40f7-b526-7e9d072ab28b
scm_1       | 2020-07-16 01:16:27,868 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9a76e84a-d63a-4be2-9104-235b557a5446 to datanode:4377bb4e-f732-42f4-8e4f-04d6e89d4e86
scm_1       | 2020-07-16 01:16:27,869 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9a76e84a-d63a-4be2-9104-235b557a5446 to datanode:c6fe274f-723d-46da-a19a-f99aea9a1072
scm_1       | 2020-07-16 01:16:27,869 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 9a76e84a-d63a-4be2-9104-235b557a5446, Nodes: 0e780947-836a-40f7-b526-7e9d072ab28b{ip: 172.18.0.5, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}4377bb4e-f732-42f4-8e4f-04d6e89d4e86{ip: 172.18.0.6, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}c6fe274f-723d-46da-a19a-f99aea9a1072{ip: 172.18.0.7, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-16T01:16:27.868267Z]
scm_1       | 2020-07-16 01:16:27,870 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-16 01:16:31,474 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 4376d0d9-62c8-4e70-9be5-ce13c617ea4b, Nodes: 0e780947-836a-40f7-b526-7e9d072ab28b{ip: 172.18.0.5, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:0e780947-836a-40f7-b526-7e9d072ab28b, CreationTimestamp2020-07-16T01:16:27.495704Z] moved to OPEN state
scm_1       | 2020-07-16 01:16:31,497 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-07-16 01:16:31,524 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-07-16 01:16:31,530 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-07-16 01:16:31,531 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2020-07-16 01:16:31,641 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 80f04674-9024-4200-9a06-bf79cd5c1f00, Nodes: c6fe274f-723d-46da-a19a-f99aea9a1072{ip: 172.18.0.7, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:c6fe274f-723d-46da-a19a-f99aea9a1072, CreationTimestamp2020-07-16T01:16:27.838460Z] moved to OPEN state
scm_1       | 2020-07-16 01:16:32,043 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 9bd16abb-c7b1-40e9-bcab-1cec9013be77, Nodes: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86{ip: 172.18.0.6, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:4377bb4e-f732-42f4-8e4f-04d6e89d4e86, CreationTimestamp2020-07-16T01:16:27.851352Z] moved to OPEN state
scm_1       | 2020-07-16 01:16:37,226 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 9a76e84a-d63a-4be2-9104-235b557a5446, Nodes: 0e780947-836a-40f7-b526-7e9d072ab28b{ip: 172.18.0.5, host: ozone-csi_datanode_2.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}4377bb4e-f732-42f4-8e4f-04d6e89d4e86{ip: 172.18.0.6, host: ozone-csi_datanode_3.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}c6fe274f-723d-46da-a19a-f99aea9a1072{ip: 172.18.0.7, host: ozone-csi_datanode_1.ozone-csi_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:c6fe274f-723d-46da-a19a-f99aea9a1072, CreationTimestamp2020-07-16T01:16:27.868267Z] moved to OPEN state
datanode_3  | 2020-07-16 01:16:31,546 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-07-16 01:16:31,578 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9bd16abb-c7b1-40e9-bcab-1cec9013be77
datanode_3  | 2020-07-16 01:16:31,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-07-16 01:16:31,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-07-16 01:16:31,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-16 01:16:31,610 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-07-16 01:16:31,611 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-07-16 01:16:31,611 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-07-16 01:16:31,612 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-07-16 01:16:31,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-07-16 01:16:31,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-07-16 01:16:31,683 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-07-16 01:16:31,698 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-16 01:16:31,719 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-16 01:16:31,752 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-07-16 01:16:31,765 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-07-16 01:16:31,770 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-07-16 01:16:31,771 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-07-16 01:16:31,775 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-07-16 01:16:31,927 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77
datanode_3  | 2020-07-16 01:16:31,957 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77
datanode_3  | 2020-07-16 01:16:31,964 [pool-19-thread-1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77: start as a follower, conf=-1: [4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858], old=null
datanode_3  | 2020-07-16 01:16:31,984 [pool-19-thread-1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-07-16 01:16:31,993 [pool-19-thread-1] INFO impl.RoleInfo: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: start FollowerState
datanode_3  | 2020-07-16 01:16:32,022 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1CEC9013BE77,id=4377bb4e-f732-42f4-8e4f-04d6e89d4e86
datanode_3  | 2020-07-16 01:16:32,034 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77
datanode_3  | 2020-07-16 01:16:32,116 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "9bd16abb-c7b1-40e9-bcab-1cec9013be77"
datanode_3  | uuid128 {
datanode_3  |   mostSigBits: -7218871372956483351
datanode_3  |   leastSigBits: -4851752371206504841
datanode_3  | }
datanode_3  | .
datanode_3  | 2020-07-16 01:16:32,123 [Command processor thread] INFO impl.RaftServerProxy: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: addNew group-235B557A5446:[0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858] returns group-235B557A5446:java.util.concurrent.CompletableFuture@4b8b100a[Not completed]
datanode_3  | 2020-07-16 01:16:32,154 [pool-19-thread-1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: new RaftServerImpl for group-235B557A5446:[0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-07-16 01:16:32,156 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-07-16 01:16:32,172 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-07-16 01:16:32,172 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-07-16 01:16:32,172 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-07-16 01:16:32,172 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-07-16 01:16:32,172 [pool-19-thread-1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446: ConfigurationManager, init=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-07-16 01:16:32,173 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-16 01:16:32,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-07-16 01:16:32,179 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446 does not exist. Creating ...
datanode_3  | 2020-07-16 01:16:32,180 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446/in_use.lock acquired by nodename 6@1412b4a8f975
datanode_3  | 2020-07-16 01:16:32,184 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446 has been successfully formatted.
datanode_3  | 2020-07-16 01:16:32,184 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-235B557A5446: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-07-16 01:16:32,188 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-07-16 01:16:32,196 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-07-16 01:16:32,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-07-16 01:16:32,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-16 01:16:32,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-16 01:16:32,217 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446
datanode_3  | 2020-07-16 01:16:32,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-07-16 01:16:32,218 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446
datanode_3  | 2020-07-16 01:16:32,225 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-07-16 01:16:32,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-07-16 01:16:32,231 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-16 01:16:32,233 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-07-16 01:16:32,241 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-07-16 01:16:32,241 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-07-16 01:16:32,259 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-07-16 01:16:32,259 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-07-16 01:16:32,259 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-07-16 01:16:32,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-07-16 01:16:32,271 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-16 01:16:32,271 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-16 01:16:32,286 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-07-16 01:16:32,286 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-07-16 01:16:32,286 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-07-16 01:16:32,286 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-07-16 01:16:32,287 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-07-16 01:16:32,287 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446
datanode_3  | 2020-07-16 01:16:32,287 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446
datanode_3  | 2020-07-16 01:16:32,289 [pool-19-thread-1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446: start as a follower, conf=-1: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null
datanode_3  | 2020-07-16 01:16:32,301 [pool-19-thread-1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-07-16 01:16:32,301 [pool-19-thread-1] INFO impl.RoleInfo: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: start FollowerState
datanode_3  | 2020-07-16 01:16:32,309 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-235B557A5446,id=4377bb4e-f732-42f4-8e4f-04d6e89d4e86
datanode_3  | 2020-07-16 01:16:32,311 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446
datanode_3  | 2020-07-16 01:16:34,511 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "9a76e84a-d63a-4be2-9104-235b557a5446"
datanode_3  | uuid128 {
datanode_3  |   mostSigBits: -7316405136497423390
datanode_3  |   leastSigBits: -7997228163120081850
datanode_3  | }
datanode_3  | .
datanode_3  | 2020-07-16 01:16:37,101 [grpc-default-executor-0] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:c6fe274f-723d-46da-a19a-f99aea9a1072
datanode_3  | 2020-07-16 01:16:37,103 [grpc-default-executor-0] INFO impl.RoleInfo: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: shutdown FollowerState
datanode_3  | 2020-07-16 01:16:37,104 [Thread-25] INFO impl.FollowerState: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2020-07-16 01:16:37,104 [grpc-default-executor-0] INFO impl.RoleInfo: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: start FollowerState
datanode_3  | 2020-07-16 01:16:37,130 [Thread-23] INFO impl.FollowerState: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-FollowerState: change to CANDIDATE, lastRpcTime:5137ms, electionTimeout:5108ms
datanode_3  | 2020-07-16 01:16:37,132 [Thread-23] INFO impl.RoleInfo: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: shutdown FollowerState
datanode_3  | 2020-07-16 01:16:37,132 [Thread-23] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-07-16 01:16:37,134 [Thread-23] INFO impl.RoleInfo: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: start LeaderElection
datanode_3  | 2020-07-16 01:16:37,156 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO impl.LeaderElection: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1: begin an election at term 1 for -1: [4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858], old=null
datanode_3  | 2020-07-16 01:16:37,157 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO impl.RoleInfo: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: shutdown LeaderElection
datanode_3  | 2020-07-16 01:16:37,161 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-07-16 01:16:37,164 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-1CEC9013BE77 with new leaderId: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86
datanode_3  | 2020-07-16 01:16:37,168 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77: change Leader from null to 4377bb4e-f732-42f4-8e4f-04d6e89d4e86 at term 1 for becomeLeader, leader elected after 5816ms
datanode_3  | 2020-07-16 01:16:37,198 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-07-16 01:16:37,199 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-07-16 01:16:37,209 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77
datanode_3  | 2020-07-16 01:16:37,247 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-07-16 01:16:37,252 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-07-16 01:16:37,264 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-07-16 01:16:37,267 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-07-16 01:16:37,269 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-07-16 01:16:37,338 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO impl.RoleInfo: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86: start LeaderState
datanode_3  | 2020-07-16 01:16:37,383 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-07-16 01:16:37,408 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-LeaderElection1] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77: set configuration 0: [4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858], old=null at 0
datanode_3  | 2020-07-16 01:16:37,543 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-235B557A5446 with new leaderId: c6fe274f-723d-46da-a19a-f99aea9a1072
datanode_3  | 2020-07-16 01:16:37,547 [grpc-default-executor-0] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446: change Leader from null to c6fe274f-723d-46da-a19a-f99aea9a1072 at term 1 for appendEntries, leader elected after 5358ms
datanode_3  | 2020-07-16 01:16:37,576 [grpc-default-executor-0] INFO impl.RaftServerImpl: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446: set configuration 0: [0e780947-836a-40f7-b526-7e9d072ab28b:172.18.0.5:9858, 4377bb4e-f732-42f4-8e4f-04d6e89d4e86:172.18.0.6:9858, c6fe274f-723d-46da-a19a-f99aea9a1072:172.18.0.7:9858], old=null at 0
datanode_3  | 2020-07-16 01:16:37,582 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-07-16 01:16:37,785 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-235B557A5446-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9a76e84a-d63a-4be2-9104-235b557a5446/current/log_inprogress_0
datanode_3  | 2020-07-16 01:16:37,789 [4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4377bb4e-f732-42f4-8e4f-04d6e89d4e86@group-1CEC9013BE77-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9bd16abb-c7b1-40e9-bcab-1cec9013be77/current/log_inprogress_0
