Attaching to ozone_om_1, ozone_datanode_2, ozone_scm_1, ozone_datanode_1, ozone_s3g_1, ozone_datanode_3, ozone_recon_1
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-07-27 01:14:58,071 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 591eba6d0ede/172.23.0.4
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:48Z
datanode_2  | STARTUP_MSG:   java = 11.0.7
datanode_2  | ************************************************************/
datanode_2  | 2020-07-27 01:14:58,151 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-07-27 01:14:59,620 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-07-27 01:15:00,380 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-07-27 01:15:01,216 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-07-27 01:15:01,220 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-07-27 01:15:01,681 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:591eba6d0ede ip:172.23.0.4
datanode_2  | 2020-07-27 01:15:02,586 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-07-27 01:15:02,616 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-07-27 01:15:02,619 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-07-27 01:15:02,719 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-07-27 01:15:03,077 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-07-27 01:15:03,422 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_2  | 2020-07-27 01:15:03,431 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2  | 2020-07-27 01:15:03,431 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_2  | 2020-07-27 01:15:08,718 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-07-27 01:15:09,047 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-07-27 01:15:09,844 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-07-27 01:15:09,854 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-07-27 01:15:09,854 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-27 01:15:09,855 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-07-27 01:15:09,876 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-07-27 01:15:10,893 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-27 01:15:10,919 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-07-27 01:15:11,826 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-07-27 01:15:11,957 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2  | 2020-07-27 01:15:12,142 [main] INFO util.log: Logging initialized @20139ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-07-27 01:15:12,807 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-07-27 01:15:12,827 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-07-27 01:15:12,878 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-07-27 01:15:12,882 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-07-27 01:15:12,895 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-07-27 01:15:12,895 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-07-27 01:15:13,178 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-07-27 01:15:13,188 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_2  | 2020-07-27 01:15:13,421 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-07-27 01:15:13,436 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-07-27 01:15:13,449 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-07-27 01:15:13,557 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5aa6da2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-07-27 01:15:13,577 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2f60cbf2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-07-27 01:15:14,255 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4809c771{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13454326370353362648.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-07-27 01:15:14,326 [main] INFO server.AbstractConnector: Started ServerConnector@3dda8a2e{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-07-27 01:15:14,326 [main] INFO server.Server: Started @22324ms
datanode_2  | 2020-07-27 01:15:14,340 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-07-27 01:15:14,340 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-07-27 01:15:14,349 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-07-27 01:15:14,442 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e2c32d0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-07-27 01:15:15,336 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.23.0.3:9891
datanode_2  | 2020-07-27 01:15:15,728 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-07-27 01:15:17,773 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-27 01:15:18,775 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-27 01:15:19,776 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-27 01:15:20,576 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 2 seconds.
datanode_2  | 2020-07-27 01:15:20,778 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-27 01:15:21,800 [Datanode State Machine Task Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From 591eba6d0ede/172.23.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.4:34738 remote=scm/172.23.0.7:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.4:34738 remote=scm/172.23.0.7:9861]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2  | 2020-07-27 01:15:40,579 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 22 seconds.
datanode_2  | 2020-07-27 01:16:00,580 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 42 seconds.
datanode_2  | 2020-07-27 01:16:16,773 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: recon/172.23.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
datanode_2  | 2020-07-27 01:16:16,842 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-07-27 01:16:16,844 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-07-27 01:16:16,846 [Datanode State Machine Task Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis fd0af4ce-9605-4cba-bb56-a16d05501772 at port 9858
datanode_2  | 2020-07-27 01:16:16,872 [Datanode State Machine Task Thread - 0] INFO impl.RaftServerProxy: fd0af4ce-9605-4cba-bb56-a16d05501772: start RPC server
datanode_2  | 2020-07-27 01:16:16,930 [Datanode State Machine Task Thread - 0] INFO server.GrpcService: fd0af4ce-9605-4cba-bb56-a16d05501772: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-07-27 01:16:21,653 [Command processor thread] INFO impl.RaftServerProxy: fd0af4ce-9605-4cba-bb56-a16d05501772: addNew group-021E176A3503:[fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858] returns group-021E176A3503:java.util.concurrent.CompletableFuture@7d4a6683[Not completed]
datanode_2  | 2020-07-27 01:16:21,725 [pool-19-thread-1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772: new RaftServerImpl for group-021E176A3503:[fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-27 01:16:21,726 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-07-27 01:16:21,727 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-07-27 01:16:21,728 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-27 01:16:21,737 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-07-27 01:16:21,739 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-27 01:16:21,745 [pool-19-thread-1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503: ConfigurationManager, init=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-07-27 01:16:21,745 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-27 01:16:21,754 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-07-27 01:16:21,773 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/57140d50-7eca-41c1-bb5e-021e176a3503 does not exist. Creating ...
datanode_2  | 2020-07-27 01:16:21,803 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/57140d50-7eca-41c1-bb5e-021e176a3503/in_use.lock acquired by nodename 6@591eba6d0ede
datanode_2  | 2020-07-27 01:16:21,809 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/57140d50-7eca-41c1-bb5e-021e176a3503 has been successfully formatted.
datanode_2  | 2020-07-27 01:16:21,826 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-021E176A3503: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-07-27 01:16:21,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2020-07-27 01:16:21,855 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-07-27 01:16:21,889 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-07-27 01:16:21,892 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503
datanode_2  | 2020-07-27 01:16:21,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-27 01:16:21,929 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-27 01:16:21,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-07-27 01:16:21,971 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/57140d50-7eca-41c1-bb5e-021e176a3503
datanode_2  | 2020-07-27 01:16:21,973 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-07-27 01:16:21,975 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-07-27 01:16:21,976 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-27 01:16:21,978 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-07-27 01:16:21,980 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-07-27 01:16:21,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-07-27 01:16:21,983 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-07-27 01:16:21,986 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-07-27 01:16:21,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-07-27 01:16:22,018 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-07-27 01:16:22,034 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-27 01:16:22,038 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-27 01:16:22,047 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-07-27 01:16:22,049 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-07-27 01:16:22,059 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-07-27 01:16:22,060 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-07-27 01:16:22,065 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-07-27 01:16:22,141 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503
datanode_2  | 2020-07-27 01:16:22,152 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503
datanode_2  | 2020-07-27 01:16:22,172 [pool-19-thread-1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503: start as a follower, conf=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858], old=null
datanode_2  | 2020-07-27 01:16:22,173 [pool-19-thread-1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-07-27 01:16:22,185 [pool-19-thread-1] INFO impl.RoleInfo: fd0af4ce-9605-4cba-bb56-a16d05501772: start FollowerState
datanode_2  | 2020-07-27 01:16:22,201 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-021E176A3503,id=fd0af4ce-9605-4cba-bb56-a16d05501772
datanode_2  | 2020-07-27 01:16:22,202 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503
datanode_2  | 2020-07-27 01:16:22,319 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "57140d50-7eca-41c1-bb5e-021e176a3503"
datanode_2  | uuid128 {
datanode_2  |   mostSigBits: 6274654820209672641
datanode_2  |   leastSigBits: -4945513012541115133
datanode_2  | }
datanode_2  | .
datanode_2  | 2020-07-27 01:16:22,320 [Command processor thread] INFO impl.RaftServerProxy: fd0af4ce-9605-4cba-bb56-a16d05501772: addNew group-911A6C7098D3:[fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858] returns group-911A6C7098D3:java.util.concurrent.CompletableFuture@2a54fffb[Not completed]
datanode_2  | 2020-07-27 01:16:22,346 [pool-19-thread-1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772: new RaftServerImpl for group-911A6C7098D3:[fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-07-27 01:16:22,347 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-07-27 01:16:22,347 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-07-27 01:16:22,347 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-07-27 01:16:22,347 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-07-27 01:16:22,348 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-07-27 01:16:22,348 [pool-19-thread-1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3: ConfigurationManager, init=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-07-27 01:16:22,348 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-07-27 01:16:22,354 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-07-27 01:16:22,354 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3 does not exist. Creating ...
datanode_2  | 2020-07-27 01:16:22,363 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3/in_use.lock acquired by nodename 6@591eba6d0ede
datanode_2  | 2020-07-27 01:16:22,368 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3 has been successfully formatted.
datanode_2  | 2020-07-27 01:16:22,369 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-911A6C7098D3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-07-27 01:16:22,369 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2020-07-27 01:16:22,370 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-07-27 01:16:22,376 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-07-27 01:16:22,377 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3
datanode_2  | 2020-07-27 01:16:22,377 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-07-27 01:16:22,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-27 01:16:22,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-07-27 01:16:22,380 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3
datanode_2  | 2020-07-27 01:16:22,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-07-27 01:16:22,381 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-07-27 01:16:22,382 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-07-27 01:16:22,383 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-07-27 01:16:22,383 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-07-27 01:16:22,385 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-07-27 01:16:22,388 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-07-27 01:16:22,388 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-07-27 01:16:22,389 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-07-27 01:16:22,390 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-07-27 01:16:22,407 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-27 01:16:22,408 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-07-27 01:16:22,410 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-07-27 01:16:22,411 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-07-27 01:16:22,411 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-07-27 01:16:22,411 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-07-27 01:16:22,411 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-07-27 01:14:58,410 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 3b515c2c2a2d/172.23.0.2
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:48Z
datanode_3  | STARTUP_MSG:   java = 11.0.7
datanode_3  | ************************************************************/
datanode_3  | 2020-07-27 01:14:58,474 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-07-27 01:15:00,002 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-07-27 01:15:00,641 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-07-27 01:15:01,787 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-07-27 01:15:01,787 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-07-27 01:15:02,335 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:3b515c2c2a2d ip:172.23.0.2
datanode_3  | 2020-07-27 01:15:03,244 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-07-27 01:15:03,277 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-07-27 01:15:03,310 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-07-27 01:15:03,349 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-07-27 01:15:03,615 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-07-27 01:15:03,944 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_3  | 2020-07-27 01:15:03,945 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3  | 2020-07-27 01:15:03,948 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_3  | 2020-07-27 01:15:09,269 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-07-27 01:15:09,644 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-07-27 01:15:10,362 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-07-27 01:15:10,382 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-07-27 01:15:10,383 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-07-27 01:15:10,384 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-07-27 01:15:10,386 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-07-27 01:15:11,359 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-07-27 01:15:11,366 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-07-27 01:15:12,308 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-07-27 01:15:12,418 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2020-07-27 01:15:12,575 [main] INFO util.log: Logging initialized @20485ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-07-27 01:15:13,091 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-07-27 01:15:13,109 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-07-27 01:15:13,134 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-07-27 01:15:13,147 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-07-27 01:15:13,147 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-07-27 01:15:13,147 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-07-27 01:15:13,353 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-07-27 01:15:13,362 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_3  | 2020-07-27 01:15:13,612 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-07-27 01:15:13,612 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2020-07-27 01:14:59,598 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2020-07-27 01:14:59,620 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1       | 2020-07-27 01:14:59,977 [main] INFO util.log: Logging initialized @7830ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-07-27 01:15:00,650 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-07-27 01:15:00,785 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-07-27 01:15:00,813 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2020-07-27 01:15:00,823 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1       | 2020-07-27 01:15:00,823 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2020-07-27 01:15:00,828 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1       | 2020-07-27 01:15:01,192 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = a6ff2e38ab34/172.23.0.6
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:49Z
s3g_1       | STARTUP_MSG:   java = 11.0.7
s3g_1       | ************************************************************/
s3g_1       | 2020-07-27 01:15:01,238 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2020-07-27 01:15:01,468 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-07-27 01:15:01,506 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-07-27 01:15:01,518 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
s3g_1       | 2020-07-27 01:15:01,739 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2020-07-27 01:15:01,739 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2020-07-27 01:15:01,758 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2020-07-27 01:15:01,883 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2ceb80a1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2020-07-27 01:15:01,912 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@d3957fe{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Jul 27, 2020 1:15:17 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
datanode_3  | 2020-07-27 01:15:13,614 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 2020-07-27 01:15:13,682 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5aa6da2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-07-27 01:15:13,697 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2f60cbf2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-07-27 01:15:14,316 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4809c771{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16748679727914150462.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-07-27 01:15:14,398 [main] INFO server.AbstractConnector: Started ServerConnector@3dda8a2e{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-07-27 01:15:14,399 [main] INFO server.Server: Started @22308ms
datanode_3  | 2020-07-27 01:15:14,414 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-07-27 01:15:14,414 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-07-27 01:15:14,420 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2020-07-27 01:14:54,612 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1     | /************************************************************
recon_1     | STARTUP_MSG: Starting ReconServer
recon_1     | STARTUP_MSG:   host = c90aef7d290c/172.23.0.3
recon_1     | STARTUP_MSG:   args = []
recon_1     | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-reconcodegen-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.27.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:49Z
recon_1     | STARTUP_MSG:   java = 11.0.7
recon_1     | ************************************************************/
recon_1     | 2020-07-27 01:14:54,690 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 2020-07-27 01:14:58,826 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1     | 2020-07-27 01:15:00,974 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2020-07-27 01:15:02,636 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2020-07-27 01:15:08,702 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1     | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2020-07-27 01:15:10,515 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2020-07-27 01:15:10,732 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2020-07-27 01:15:10,801 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1     | 2020-07-27 01:15:15,757 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2020-07-27 01:15:15,861 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1     | 2020-07-27 01:15:15,913 [main] INFO util.log: Logging initialized @25915ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2020-07-27 01:15:16,185 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1     | 2020-07-27 01:15:16,215 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2020-07-27 01:15:16,222 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2020-07-27 01:15:16,239 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1     | 2020-07-27 01:15:16,239 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1     | 2020-07-27 01:15:16,240 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1     | 2020-07-27 01:15:16,623 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2020-07-27 01:15:17,398 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2020-07-27 01:15:17,444 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1     | 2020-07-27 01:15:17,445 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
recon_1     | 2020-07-27 01:15:18,421 [main] INFO Configuration.deprecation: No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1     | 2020-07-27 01:15:18,730 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-07-27 01:15:19,032 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-07-27 01:15:19,075 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@54d116d5
recon_1     | 2020-07-27 01:15:19,080 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2020-07-27 01:15:19,178 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2020-07-27 01:14:56,813 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = d9b4dd9bc409/172.23.0.5
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:48Z
datanode_1  | STARTUP_MSG:   java = 11.0.7
datanode_1  | ************************************************************/
datanode_1  | 2020-07-27 01:14:56,889 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-07-27 01:14:58,329 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-07-27 01:14:59,033 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-07-27 01:15:00,200 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-07-27 01:15:00,201 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-07-27 01:15:00,635 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d9b4dd9bc409 ip:172.23.0.5
datanode_1  | 2020-07-27 01:15:01,636 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-07-27 01:15:01,644 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-07-27 01:15:01,666 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-07-27 01:15:01,744 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-07-27 01:15:02,078 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-07-27 01:15:02,472 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_3  | 2020-07-27 01:15:14,725 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@44fd8156] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-07-27 01:15:15,407 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.23.0.3:9891
datanode_3  | 2020-07-27 01:15:15,684 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | 2020-07-27 01:15:02,473 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
recon_1     | 2020-07-27 01:15:19,318 [main] INFO node.SCMNodeManager: Entering startup safe mode.
datanode_3  | 2020-07-27 01:15:18,095 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | 2020-07-27 01:15:17,372 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3bbb8c16{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-13782327220322319696.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
datanode_2  | 2020-07-27 01:16:22,411 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-07-27 01:15:02,473 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
recon_1     | 2020-07-27 01:15:19,334 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | 2020-07-27 01:15:19,096 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | 2020-07-27 01:15:17,409 [main] INFO server.AbstractConnector: Started ServerConnector@395b56bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
datanode_2  | 2020-07-27 01:16:22,412 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3
om_1        | 2020-07-27 01:14:59,712 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_1  | 2020-07-27 01:15:07,539 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
recon_1     | 2020-07-27 01:15:19,383 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-07-27 01:15:20,096 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
s3g_1       | 2020-07-27 01:15:17,409 [main] INFO server.Server: Started @25286ms
datanode_2  | 2020-07-27 01:16:22,412 [pool-19-thread-1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3: start as a follower, conf=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null
om_1        | /************************************************************
datanode_1  | 2020-07-27 01:15:07,776 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
recon_1     | 2020-07-27 01:15:19,390 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-07-27 01:14:57,735 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_3  | 2020-07-27 01:15:20,852 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 2 seconds.
s3g_1       | 2020-07-27 01:15:17,414 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
datanode_2  | 2020-07-27 01:16:22,417 [pool-19-thread-1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | STARTUP_MSG: Starting OzoneManager
datanode_1  | 2020-07-27 01:15:08,525 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
recon_1     | 2020-07-27 01:15:19,445 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | /************************************************************
datanode_3  | 2020-07-27 01:15:21,129 [Datanode State Machine Task Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
s3g_1       | 2020-07-27 01:37:33,342 [qtp1939022383-19] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-07-27 01:16:22,417 [pool-19-thread-1] INFO impl.RoleInfo: fd0af4ce-9605-4cba-bb56-a16d05501772: start FollowerState
om_1        | STARTUP_MSG:   host = 3c06f7bff04c/172.23.0.8
datanode_1  | 2020-07-27 01:15:08,529 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
recon_1     | 2020-07-27 01:15:19,490 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_3  | java.net.SocketTimeoutException: Call From 3b515c2c2a2d/172.23.0.2 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.2:50830 remote=scm/172.23.0.7:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
s3g_1       | 2020-07-27 01:37:33,372 [qtp1939022383-19] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-07-27 01:16:22,422 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-911A6C7098D3,id=fd0af4ce-9605-4cba-bb56-a16d05501772
om_1        | STARTUP_MSG:   args = [--init]
datanode_1  | 2020-07-27 01:15:08,537 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2020-07-27 01:15:19,581 [Listener at 0.0.0.0/9891] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | STARTUP_MSG:   host = 18032619ea46/172.23.0.7
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 2020-07-27 01:37:33,372 [qtp1939022383-19] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
datanode_2  | 2020-07-27 01:16:22,422 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | 2020-07-27 01:15:08,541 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
recon_1     | 2020-07-27 01:15:19,650 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
scm_1       | STARTUP_MSG:   args = [--init]
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 2020-07-27 01:37:33,376 [qtp1939022383-19] WARN impl.MetricsSystemImpl: Sink prometheus already exists!
datanode_2  | 2020-07-27 01:16:23,897 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "69ab0f71-979b-4f32-abe3-911a6c7098d3"
datanode_1  | 2020-07-27 01:15:08,549 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
recon_1     | 2020-07-27 01:15:19,650 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 2020-07-27 01:37:41,228 [qtp1939022383-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-18676, with Versioning false and Storage Type set to DISK and Encryption set to false 
datanode_2  | uuid128 {
datanode_1  | 2020-07-27 01:15:09,923 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:49Z
recon_1     | 2020-07-27 01:15:19,760 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
s3g_1       | 2020-07-27 01:37:41,243 [qtp1939022383-17] INFO endpoint.BucketEndpoint: Location is /bucket-18676
datanode_2  |   mostSigBits: 7614196575549214514
datanode_1  | 2020-07-27 01:15:09,945 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | STARTUP_MSG:   java = 11.0.7
recon_1     | 2020-07-27 01:15:19,828 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:48Z
s3g_1       | 2020-07-27 01:37:41,695 [qtp1939022383-21] INFO rpc.RpcClient: Creating Bucket: s3v/link, with Versioning false and Storage Type set to DISK and Encryption set to false 
datanode_2  |   leastSigBits: -6060841130836059949
datanode_1  | 2020-07-27 01:15:11,195 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
om_1        | ************************************************************/
recon_1     | 2020-07-27 01:15:19,829 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
scm_1       | STARTUP_MSG:   java = 11.0.7
s3g_1       | 2020-07-27 01:37:41,708 [qtp1939022383-21] INFO endpoint.BucketEndpoint: Location is /link
datanode_2  | }
datanode_1  | 2020-07-27 01:15:11,270 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1        | 2020-07-27 01:14:59,757 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | 2020-07-27 01:15:20,107 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
scm_1       | ************************************************************/
s3g_1       | 2020-07-27 01:37:42,147 [qtp1939022383-17] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
datanode_2  | .
datanode_1  | 2020-07-27 01:15:11,397 [main] INFO util.log: Logging initialized @21095ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-07-27 01:15:04,788 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1     | 2020-07-27 01:15:20,109 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
scm_1       | 2020-07-27 01:14:57,803 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
datanode_2  | 2020-07-27 01:16:26,647 [grpc-default-executor-0] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:d827362c-8092-4b3a-8ed7-ce1b50249841
datanode_1  | 2020-07-27 01:15:12,101 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-07-27 01:15:05,555 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.23.0.8:9862
recon_1     | 2020-07-27 01:15:20,194 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
scm_1       | 2020-07-27 01:14:58,602 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:478)
datanode_2  | 2020-07-27 01:16:26,648 [grpc-default-executor-0] INFO impl.RoleInfo: fd0af4ce-9605-4cba-bb56-a16d05501772: shutdown FollowerState
datanode_1  | 2020-07-27 01:15:12,133 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
om_1        | 2020-07-27 01:15:05,557 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
recon_1     | 2020-07-27 01:15:20,203 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
scm_1       | 2020-07-27 01:14:58,930 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-208cd4c4-ef70-4ef5-98f1-7157da6bbaf2;layoutVersion=0
datanode_2  | 2020-07-27 01:16:26,649 [Thread-26] INFO impl.FollowerState: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-07-27 01:15:12,186 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:426)
om_1        | 2020-07-27 01:15:05,652 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-07-27 01:15:20,204 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
scm_1       | 2020-07-27 01:14:59,011 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_2  | 2020-07-27 01:16:26,649 [grpc-default-executor-0] INFO impl.RoleInfo: fd0af4ce-9605-4cba-bb56-a16d05501772: start FollowerState
datanode_1  | 2020-07-27 01:15:12,198 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:417)
om_1        | 2020-07-27 01:15:08,583 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:20,245 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3cd46491{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
scm_1       | /************************************************************
datanode_2  | 2020-07-27 01:16:26,792 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-911A6C7098D3 with new leaderId: d827362c-8092-4b3a-8ed7-ce1b50249841
datanode_1  | 2020-07-27 01:15:12,204 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:266)
om_1        | 2020-07-27 01:15:09,584 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:20,252 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@774f2992{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at 18032619ea46/172.23.0.7
datanode_2  | 2020-07-27 01:16:26,792 [grpc-default-executor-0] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3: change Leader from null to d827362c-8092-4b3a-8ed7-ce1b50249841 at term 1 for appendEntries, leader elected after 4422ms
datanode_1  | 2020-07-27 01:15:12,204 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1       | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
om_1        | 2020-07-27 01:15:10,586 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:22,573 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3b6f7ab3{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_6_0-SNAPSHOT_jar-_-any-12648612032839687724.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/recon}
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
scm_1       | ************************************************************/
datanode_1  | 2020-07-27 01:15:12,400 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-07-27 01:16:26,820 [grpc-default-executor-0] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3: set configuration 0: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null at 0
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:96)
om_1        | 2020-07-27 01:15:11,587 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:22,583 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@eded048{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | 2020-07-27 01:15:12,422 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_2  | 2020-07-27 01:16:26,850 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:205)
om_1        | 2020-07-27 01:15:12,587 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:22,583 [Listener at 0.0.0.0/9891] INFO server.Server: Started @32585ms
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-07-27 01:15:12,661 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-07-27 01:16:27,182 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fd0af4ce-9605-4cba-bb56-a16d05501772@group-911A6C7098D3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3/current/log_inprogress_0
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2020-07-27 01:15:13,588 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:22,586 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 2020-07-27 01:15:12,601 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode_1  | 2020-07-27 01:15:12,661 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-07-27 01:16:27,402 [Thread-24] INFO impl.FollowerState: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-FollowerState: change to CANDIDATE, lastRpcTime:5217ms, electionTimeout:5186ms
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 2020-07-27 01:15:14,589 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:22,586 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | /************************************************************
datanode_1  | 2020-07-27 01:15:12,662 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-07-27 01:16:27,403 [Thread-24] INFO impl.RoleInfo: fd0af4ce-9605-4cba-bb56-a16d05501772: shutdown FollowerState
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 2020-07-27 01:15:15,590 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:22,593 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_1  | 2020-07-27 01:15:12,701 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ccdacf5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-07-27 01:16:27,403 [Thread-24] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 2020-07-27 01:15:16,591 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:22,593 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | STARTUP_MSG:   host = 18032619ea46/172.23.0.7
datanode_1  | 2020-07-27 01:15:12,706 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f26b992{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-07-27 01:16:27,405 [Thread-24] INFO impl.RoleInfo: fd0af4ce-9605-4cba-bb56-a16d05501772: start LeaderElection
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
om_1        | 2020-07-27 01:15:17,592 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-07-27 01:15:22,624 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | STARTUP_MSG:   args = []
datanode_1  | 2020-07-27 01:15:13,318 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7e1d8d41{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-2882913137303697413.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-07-27 01:16:27,409 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO impl.LeaderElection: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1: begin an election at term 1 for -1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858], old=null
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
om_1        | 2020-07-27 01:15:17,594 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
recon_1     | 2020-07-27 01:15:22,641 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | 2020-07-27 01:15:13,377 [main] INFO server.AbstractConnector: Started ServerConnector@698f4aa{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-07-27 01:16:27,410 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO impl.RoleInfo: fd0af4ce-9605-4cba-bb56-a16d05501772: shutdown LeaderElection
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-208cd4c4-ef70-4ef5-98f1-7157da6bbaf2;layoutVersion=0
recon_1     | 2020-07-27 01:15:22,644 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.2:50830 remote=scm/172.23.0.7:9861]
datanode_1  | 2020-07-27 01:15:13,388 [main] INFO server.Server: Started @23086ms
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
datanode_2  | 2020-07-27 01:16:27,411 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om_1        | 2020-07-27 01:15:23,035 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
recon_1     | 2020-07-27 01:15:22,645 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 2020-07-27 01:15:13,408 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:48Z
datanode_2  | 2020-07-27 01:16:27,411 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-021E176A3503 with new leaderId: fd0af4ce-9605-4cba-bb56-a16d05501772
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
om_1        | /************************************************************
recon_1     | 2020-07-27 01:15:22,645 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 2020-07-27 01:15:13,408 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | STARTUP_MSG:   java = 11.0.7
datanode_2  | 2020-07-27 01:16:27,412 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503: change Leader from null to fd0af4ce-9605-4cba-bb56-a16d05501772 at term 1 for becomeLeader, leader elected after 5575ms
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at 3c06f7bff04c/172.23.0.8
recon_1     | 2020-07-27 01:15:22,653 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 2020-07-27 01:15:13,424 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
scm_1       | ************************************************************/
datanode_2  | 2020-07-27 01:16:27,413 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
om_1        | ************************************************************/
recon_1     | 2020-07-27 01:15:23,455 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 2020-07-27 01:15:13,558 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22b2a649] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-07-27 01:15:12,711 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-07-27 01:16:27,413 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
recon_1     | 2020-07-27 01:15:23,455 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 2020-07-27 01:15:14,328 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.23.0.3:9891
scm_1       | 2020-07-27 01:15:14,189 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2020-07-27 01:16:27,420 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2020-07-27 01:15:23,455 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 2020-07-27 01:15:14,698 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
scm_1       | 2020-07-27 01:15:16,071 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2020-07-27 01:16:27,426 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 2020-07-27 01:15:24,758 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
recon_1     | 2020-07-27 01:15:23,482 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 2020-07-27 01:15:17,012 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2020-07-27 01:15:17,317 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@70925b45
datanode_2  | 2020-07-27 01:16:27,427 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | /************************************************************
recon_1     | 2020-07-27 01:15:23,506 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 2020-07-27 01:15:18,013 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
scm_1       | 2020-07-27 01:15:17,329 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_2  | 2020-07-27 01:16:27,431 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | STARTUP_MSG: Starting OzoneManager
recon_1     | 2020-07-27 01:15:23,705 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
scm_1       | 2020-07-27 01:15:18,009 [main] INFO node.SCMNodeManager: Entering startup safe mode.
datanode_1  | 2020-07-27 01:15:19,014 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-27 01:16:27,431 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | STARTUP_MSG:   host = 3c06f7bff04c/172.23.0.8
recon_1     | 2020-07-27 01:15:23,752 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
scm_1       | 2020-07-27 01:15:18,330 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
datanode_1  | 2020-07-27 01:15:19,762 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 2 seconds.
datanode_2  | 2020-07-27 01:16:27,432 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | STARTUP_MSG:   args = []
recon_1     | 2020-07-27 01:15:23,790 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
scm_1       | 2020-07-27 01:15:18,448 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
datanode_1  | 2020-07-27 01:15:20,016 [Datanode State Machine Task Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.23.0.7:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-07-27 01:16:27,440 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO impl.RoleInfo: fd0af4ce-9605-4cba-bb56-a16d05501772: start LeaderState
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
recon_1     | 2020-07-27 01:15:23,792 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 12 milliseconds.
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
scm_1       | 2020-07-27 01:15:18,702 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
datanode_1  | 2020-07-27 01:15:21,037 [Datanode State Machine Task Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2  | 2020-07-27 01:16:27,444 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
recon_1     | 2020-07-27 01:15:23,819 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
scm_1       | 2020-07-27 01:15:18,708 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
datanode_1  | java.net.SocketTimeoutException: Call From d9b4dd9bc409/172.23.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.5:44782 remote=scm/172.23.0.7:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 2020-07-27 01:16:27,448 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-LeaderElection1] INFO impl.RaftServerImpl: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503: set configuration 0: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858], old=null at 0
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/093f5560c645c745e331e9e5ee3c47ff75015783 ; compiled by 'runner' on 2020-07-27T00:49Z
recon_1     | 2020-07-27 01:15:23,888 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
datanode_3  | 2020-07-27 01:15:40,853 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 22 seconds.
scm_1       | 2020-07-27 01:15:18,802 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 2020-07-27 01:16:27,449 [fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fd0af4ce-9605-4cba-bb56-a16d05501772@group-021E176A3503-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/57140d50-7eca-41c1-bb5e-021e176a3503/current/log_inprogress_0
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | STARTUP_MSG:   java = 11.0.7
recon_1     | 2020-07-27 01:15:24,029 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 101 milliseconds to process 0 existing database records.
datanode_3  | 2020-07-27 01:16:00,856 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 42 seconds.
scm_1       | 2020-07-27 01:15:19,860 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | ************************************************************/
recon_1     | 2020-07-27 01:15:24,050 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 15 milliseconds for processing 0 containers.
datanode_3  | 2020-07-27 01:16:17,095 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: recon/172.23.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
scm_1       | 2020-07-27 01:15:19,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2020-07-27 01:15:24,766 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
recon_1     | 2020-07-27 01:16:17,888 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/d827362c-8092-4b3a-8ed7-ce1b50249841
datanode_3  | 2020-07-27 01:16:17,208 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
scm_1       | 2020-07-27 01:15:19,977 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om_1        | 2020-07-27 01:15:25,412 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
recon_1     | 2020-07-27 01:16:17,915 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-07-27 01:16:17,210 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
scm_1       | 2020-07-27 01:15:19,984 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
om_1        | 2020-07-27 01:15:25,447 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.23.0.8:9862
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
recon_1     | 2020-07-27 01:16:18,015 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node d827362c-8092-4b3a-8ed7-ce1b50249841 to Node DB.
recon_1     | 2020-07-27 01:16:18,599 [IPC Server handler 30 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/fd0af4ce-9605-4cba-bb56-a16d05501772
scm_1       | 2020-07-27 01:15:20,043 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
om_1        | 2020-07-27 01:15:25,447 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
recon_1     | 2020-07-27 01:16:18,599 [IPC Server handler 30 on default port 9891] INFO node.SCMNodeManager: Registered Data node : fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-07-27 01:16:17,210 [Datanode State Machine Task Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 049cb58c-d205-4f90-a803-ee8758f93325 at port 9858
scm_1       | 2020-07-27 01:15:20,056 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
om_1        | 2020-07-27 01:15:25,487 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
recon_1     | 2020-07-27 01:16:18,600 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node fd0af4ce-9605-4cba-bb56-a16d05501772 to Node DB.
datanode_3  | 2020-07-27 01:16:17,257 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerProxy: 049cb58c-d205-4f90-a803-ee8758f93325: start RPC server
scm_1       | 2020-07-27 01:15:20,117 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
om_1        | 2020-07-27 01:15:25,498 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
recon_1     | 2020-07-27 01:16:18,875 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/049cb58c-d205-4f90-a803-ee8758f93325
datanode_3  | 2020-07-27 01:16:17,320 [Datanode State Machine Task Thread - 1] INFO server.GrpcService: 049cb58c-d205-4f90-a803-ee8758f93325: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
scm_1       | 2020-07-27 01:15:20,117 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
om_1        | 2020-07-27 01:15:26,815 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
datanode_3  | 2020-07-27 01:16:21,921 [Command processor thread] INFO impl.RaftServerProxy: 049cb58c-d205-4f90-a803-ee8758f93325: addNew group-DC986645F542:[049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858] returns group-DC986645F542:java.util.concurrent.CompletableFuture@29377150[Not completed]
recon_1     | 2020-07-27 01:16:18,875 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-27 01:15:20,171 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @19905ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
om_1        | 2020-07-27 01:15:26,994 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
datanode_3  | 2020-07-27 01:16:22,028 [pool-19-thread-1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325: new RaftServerImpl for group-DC986645F542:[049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858] with ContainerStateMachine:uninitialized
recon_1     | 2020-07-27 01:16:18,876 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 049cb58c-d205-4f90-a803-ee8758f93325 to Node DB.
scm_1       | 2020-07-27 01:15:20,419 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
om_1        | 2020-07-27 01:15:26,995 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
datanode_3  | 2020-07-27 01:16:22,048 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
recon_1     | 2020-07-27 01:16:20,997 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=173f92fc-7f52-4aed-8ff4-19d4c7579cb9. Trying to get from SCM.
scm_1       | 2020-07-27 01:15:20,455 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
datanode_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
om_1        | 2020-07-27 01:15:27,382 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
datanode_3  | 2020-07-27 01:16:22,057 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1     | 2020-07-27 01:16:21,148 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 173f92fc-7f52-4aed-8ff4-19d4c7579cb9, Nodes: d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:d827362c-8092-4b3a-8ed7-ce1b50249841, CreationTimestamp2020-07-27T01:16:18.134Z] to Recon pipeline metadata.
scm_1       | 2020-07-27 01:15:20,467 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
om_1        | 2020-07-27 01:15:27,445 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
datanode_3  | 2020-07-27 01:16:22,057 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
recon_1     | 2020-07-27 01:16:21,189 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 173f92fc-7f52-4aed-8ff4-19d4c7579cb9, Nodes: d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:d827362c-8092-4b3a-8ed7-ce1b50249841, CreationTimestamp2020-07-27T01:16:18.134Z]
scm_1       | 2020-07-27 01:15:20,471 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
om_1        | 2020-07-27 01:15:27,460 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
datanode_3  | 2020-07-27 01:16:22,057 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
recon_1     | 2020-07-27 01:16:21,454 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3. Trying to get from SCM.
scm_1       | 2020-07-27 01:15:20,476 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
om_1        | 2020-07-27 01:15:27,664 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
datanode_3  | 2020-07-27 01:16:22,059 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1     | 2020-07-27 01:16:21,461 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 69ab0f71-979b-4f32-abe3-911a6c7098d3, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-27T01:16:18.898Z] to Recon pipeline metadata.
scm_1       | 2020-07-27 01:15:20,476 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
om_1        | 2020-07-27 01:15:27,800 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
datanode_3  | 2020-07-27 01:16:22,075 [pool-19-thread-1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542: ConfigurationManager, init=-1: [049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null, confs=<EMPTY_MAP>
recon_1     | 2020-07-27 01:16:21,462 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 69ab0f71-979b-4f32-abe3-911a6c7098d3, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-27T01:16:18.898Z]
scm_1       | 2020-07-27 01:15:20,580 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        | 2020-07-27 01:15:27,800 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
datanode_3  | 2020-07-27 01:16:22,077 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
recon_1     | 2020-07-27 01:16:21,462 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3 reported by d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-27 01:15:20,841 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om_1        | 2020-07-27 01:15:27,850 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.23.0.8:9862
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode_3  | 2020-07-27 01:16:22,102 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
recon_1     | 2020-07-27 01:16:21,852 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=57140d50-7eca-41c1-bb5e-021e176a3503. Trying to get from SCM.
scm_1       | 2020-07-27 01:15:20,948 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        | 2020-07-27 01:15:27,886 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
datanode_3  | 2020-07-27 01:16:22,103 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/70909638-f70e-424a-bc36-dc986645f542 does not exist. Creating ...
recon_1     | 2020-07-27 01:16:21,855 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 57140d50-7eca-41c1-bb5e-021e176a3503, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-27T01:16:18.607Z] to Recon pipeline metadata.
scm_1       | 2020-07-27 01:15:20,948 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 2020-07-27 01:15:27,887 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
datanode_3  | 2020-07-27 01:16:22,124 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/70909638-f70e-424a-bc36-dc986645f542/in_use.lock acquired by nodename 7@3b515c2c2a2d
recon_1     | 2020-07-27 01:16:21,856 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 57140d50-7eca-41c1-bb5e-021e176a3503, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-27T01:16:18.607Z]
recon_1     | 2020-07-27 01:16:21,856 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline ONE PipelineID=57140d50-7eca-41c1-bb5e-021e176a3503 reported by fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 2020-07-27 01:15:28,192 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
recon_1     | 2020-07-27 01:16:21,856 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 57140d50-7eca-41c1-bb5e-021e176a3503, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:fd0af4ce-9605-4cba-bb56-a16d05501772, CreationTimestamp2020-07-27T01:16:18.607Z] moved to OPEN state
scm_1       | 2020-07-27 01:15:21,418 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
datanode_3  | 2020-07-27 01:16:22,127 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/70909638-f70e-424a-bc36-dc986645f542 has been successfully formatted.
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2020-07-27 01:15:28,192 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
recon_1     | 2020-07-27 01:16:22,144 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=70909638-f70e-424a-bc36-dc986645f542. Trying to get from SCM.
scm_1       | 2020-07-27 01:15:21,424 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2020-07-27 01:16:22,138 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-DC986645F542: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.5:44782 remote=scm/172.23.0.7:9861]
om_1        | 2020-07-27 01:15:28,246 [Listener at om/9862] INFO util.log: Logging initialized @4975ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
recon_1     | 2020-07-27 01:16:22,158 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 70909638-f70e-424a-bc36-dc986645f542, Nodes: 049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:049cb58c-d205-4f90-a803-ee8758f93325, CreationTimestamp2020-07-27T01:16:18.886Z] to Recon pipeline metadata.
scm_1       | 2020-07-27 01:15:21,524 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
datanode_3  | 2020-07-27 01:16:22,139 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
om_1        | 2020-07-27 01:15:28,434 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
recon_1     | 2020-07-27 01:16:22,158 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 70909638-f70e-424a-bc36-dc986645f542, Nodes: 049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:049cb58c-d205-4f90-a803-ee8758f93325, CreationTimestamp2020-07-27T01:16:18.886Z]
scm_1       | 2020-07-27 01:15:21,626 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_3  | 2020-07-27 01:16:22,141 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
om_1        | 2020-07-27 01:15:28,437 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
recon_1     | 2020-07-27 01:16:22,375 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3 reported by fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-07-27 01:15:21,627 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
datanode_3  | 2020-07-27 01:16:22,171 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
om_1        | 2020-07-27 01:15:28,442 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
scm_1       | 2020-07-27 01:15:21,781 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
datanode_3  | 2020-07-27 01:16:22,190 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
recon_1     | 2020-07-27 01:16:22,609 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3 reported by 049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 2020-07-27 01:15:28,446 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
scm_1       | 2020-07-27 01:15:21,799 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
datanode_3  | 2020-07-27 01:16:22,218 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
recon_1     | 2020-07-27 01:16:22,653 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 2020-07-27 01:15:28,446 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2020-07-27 01:15:21,816 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
datanode_3  | 2020-07-27 01:16:22,225 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1     | 2020-07-27 01:16:22,654 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
om_1        | 2020-07-27 01:15:28,446 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2020-07-27 01:15:28,500 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
datanode_3  | 2020-07-27 01:16:22,256 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
recon_1     | 2020-07-27 01:16:23,083 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1595812582654
om_1        | 2020-07-27 01:15:28,506 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
scm_1       | 2020-07-27 01:15:21,818 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2020-07-27 01:16:22,286 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/70909638-f70e-424a-bc36-dc986645f542
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
recon_1     | 2020-07-27 01:16:23,113 [pool-11-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1        | 2020-07-27 01:15:28,568 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-07-27 01:15:21,821 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2020-07-27 01:16:22,286 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
recon_1     | 2020-07-27 01:16:23,115 [pool-11-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1        | 2020-07-27 01:15:28,569 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-07-27 01:15:21,821 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
datanode_3  | 2020-07-27 01:16:22,291 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
om_1        | 2020-07-27 01:15:28,571 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
recon_1     | 2020-07-27 01:16:23,355 [pool-11-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1595812582654.
scm_1       | 2020-07-27 01:15:21,869 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
datanode_3  | 2020-07-27 01:16:22,293 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-27 01:16:22,293 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
om_1        | 2020-07-27 01:15:28,589 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@74a03bd5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2020-07-27 01:16:23,397 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
datanode_3  | 2020-07-27 01:16:22,294 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
scm_1       | 2020-07-27 01:15:21,870 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 2020-07-27 01:15:28,590 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@342dc040{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2020-07-27 01:16:23,400 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
datanode_3  | 2020-07-27 01:16:22,296 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
scm_1       | 2020-07-27 01:15:21,992 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
om_1        | 2020-07-27 01:15:28,767 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7a522157{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-11655410199911756457.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
recon_1     | 2020-07-27 01:16:23,443 [pool-12-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1595812583401
datanode_3  | 2020-07-27 01:16:22,305 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
scm_1       | 2020-07-27 01:15:21,992 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
om_1        | 2020-07-27 01:15:28,782 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@17477bbb{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
recon_1     | 2020-07-27 01:16:23,444 [pool-12-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1595812501319.
datanode_3  | 2020-07-27 01:16:22,306 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-07-27 01:15:39,762 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 22 seconds.
scm_1       | 2020-07-27 01:15:21,993 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
om_1        | 2020-07-27 01:15:28,783 [Listener at om/9862] INFO server.Server: Started @5512ms
recon_1     | 2020-07-27 01:16:23,660 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
datanode_3  | 2020-07-27 01:16:22,306 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-07-27 01:15:59,763 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 42 seconds.
scm_1       | 2020-07-27 01:15:22,033 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@49c1e294{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
om_1        | 2020-07-27 01:15:28,792 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2020-07-27 01:16:23,662 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.259 seconds to process 0 keys.
datanode_3  | 2020-07-27 01:16:22,326 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-07-27 01:16:16,012 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: recon/172.23.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
scm_1       | 2020-07-27 01:15:22,033 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@d8835af{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
om_1        | 2020-07-27 01:15:28,792 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2020-07-27 01:16:23,663 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
datanode_3  | 2020-07-27 01:16:22,334 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-27 01:16:16,280 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
scm_1       | 2020-07-27 01:15:22,473 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5f45bc8e{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-10739589556794407034.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
om_1        | 2020-07-27 01:15:28,798 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
recon_1     | 2020-07-27 01:16:26,495 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3 reported by d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-07-27 01:16:22,339 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-07-27 01:16:16,281 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
scm_1       | 2020-07-27 01:15:22,517 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7911cc15{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
om_1        | 2020-07-27 01:15:28,812 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22b3b5d0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
recon_1     | 2020-07-27 01:16:26,677 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3 reported by d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-07-27 01:16:22,344 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-07-27 01:16:16,283 [Datanode State Machine Task Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d827362c-8092-4b3a-8ed7-ce1b50249841 at port 9858
scm_1       | 2020-07-27 01:15:22,518 [Listener at 0.0.0.0/9860] INFO server.Server: Started @22253ms
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
om_1        | 2020-07-27 01:16:22,889 [qtp1676857380-135] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
recon_1     | 2020-07-27 01:16:26,677 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 69ab0f71-979b-4f32-abe3-911a6c7098d3, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:d827362c-8092-4b3a-8ed7-ce1b50249841, CreationTimestamp2020-07-27T01:16:18.898Z] moved to OPEN state
datanode_3  | 2020-07-27 01:16:22,349 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-07-27 01:16:16,330 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerProxy: d827362c-8092-4b3a-8ed7-ce1b50249841: start RPC server
scm_1       | 2020-07-27 01:15:22,533 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
om_1        | 2020-07-27 01:16:22,939 [qtp1676857380-135] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1595812582902 in 37 milliseconds
recon_1     | 2020-07-27 01:17:10,180 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozone_datanode_1.ozone_default.
datanode_3  | 2020-07-27 01:16:22,349 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-07-27 01:16:16,431 [Datanode State Machine Task Thread - 1] INFO server.GrpcService: d827362c-8092-4b3a-8ed7-ce1b50249841: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
scm_1       | 2020-07-27 01:15:22,533 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 2020-07-27 01:16:23,001 [qtp1676857380-135] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 55 milliseconds
recon_1     | 2020-07-27 01:17:10,297 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
datanode_3  | 2020-07-27 01:16:22,351 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-07-27 01:16:20,802 [Command processor thread] INFO impl.RaftServerProxy: d827362c-8092-4b3a-8ed7-ce1b50249841: addNew group-19D4C7579CB9:[d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858] returns group-19D4C7579CB9:java.util.concurrent.CompletableFuture@75f27c93[Not completed]
scm_1       | 2020-07-27 01:15:22,540 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
s3g_1       | 2020-07-27 01:37:42,386 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 2020-07-27 01:16:23,002 [qtp1676857380-135] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1595812582902
recon_1     | 2020-07-27 01:17:23,675 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 2020-07-27 01:16:22,352 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-07-27 01:16:20,856 [pool-19-thread-1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841: new RaftServerImpl for group-19D4C7579CB9:[d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858] with ContainerStateMachine:uninitialized
scm_1       | 2020-07-27 01:15:22,641 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56b9d43f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
s3g_1       | <Error>
om_1        | 2020-07-27 01:16:42,865 [IPC Server handler 2 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:hadoop
recon_1     | 2020-07-27 01:17:23,676 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2020-07-27 01:16:22,398 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542
datanode_1  | 2020-07-27 01:16:20,874 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 2020-07-27 01:15:22,739 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.5:44782: output error
s3g_1       |   <Code>InvalidBucketName</Code>
om_1        | 2020-07-27 01:17:34,103 [IPC Server handler 92 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-57651 for user:hadoop
recon_1     | 2020-07-27 01:17:24,017 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 4
datanode_3  | 2020-07-27 01:16:22,408 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542
datanode_1  | 2020-07-27 01:16:20,874 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2020-07-27 01:15:22,739 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.4:34738: output error
s3g_1       |   <Message>The specified bucket is not valid.</Message>
om_1        | 2020-07-27 01:17:34,113 [IPC Server handler 94 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-94810 for user:hadoop
recon_1     | 2020-07-27 01:17:24,125 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
datanode_3  | 2020-07-27 01:16:22,423 [pool-19-thread-1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542: start as a follower, conf=-1: [049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null
datanode_1  | 2020-07-27 01:16:20,874 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
scm_1       | 2020-07-27 01:15:22,748 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
s3g_1       |   <Resource>bucket_1</Resource>
om_1        | 2020-07-27 01:17:34,117 [IPC Server handler 97 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-32991 for user:hadoop
recon_1     | 2020-07-27 01:17:24,178 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2020-07-27 01:16:22,423 [pool-19-thread-1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-07-27 01:16:20,875 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1       | java.nio.channels.AsynchronousCloseException
s3g_1       |   <RequestId/>
om_1        | 2020-07-27 01:17:34,121 [IPC Server handler 21 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-14724 for user:hadoop
recon_1     | 2020-07-27 01:18:24,188 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 2020-07-27 01:16:22,424 [pool-19-thread-1] INFO impl.RoleInfo: 049cb58c-d205-4f90-a803-ee8758f93325: start FollowerState
datanode_1  | 2020-07-27 01:16:20,878 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
s3g_1       | </Error>
om_1        | 2020-07-27 01:17:34,128 [IPC Server handler 90 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-10268 for user:hadoop
recon_1     | 2020-07-27 01:18:24,188 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2020-07-27 01:16:22,437 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC986645F542,id=049cb58c-d205-4f90-a803-ee8758f93325
datanode_1  | 2020-07-27 01:16:20,909 [pool-19-thread-1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9: ConfigurationManager, init=-1: [d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858], old=null, confs=<EMPTY_MAP>
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
s3g_1       | 
om_1        | 2020-07-27 01:18:51,350 [IPC Server handler 62 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:99581-source for user:hadoop
recon_1     | 2020-07-27 01:18:24,198 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 199
datanode_3  | 2020-07-27 01:16:22,439 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542
datanode_1  | 2020-07-27 01:16:20,909 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
s3g_1       | 2020-07-27 01:37:50,177 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 2020-07-27 01:18:53,665 [IPC Server handler 77 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:99581-target for user:hadoop
recon_1     | 2020-07-27 01:18:24,231 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 84 OM DB update event(s).
datanode_3  | 2020-07-27 01:16:22,478 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "70909638-f70e-424a-bc36-dc986645f542"
datanode_1  | 2020-07-27 01:16:20,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
s3g_1       | <Error>
om_1        | 2020-07-27 01:19:56,038 [IPC Server handler 5 on default port 9862] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:99581-target
recon_1     | 2020-07-27 01:18:24,327 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | uuid128 {
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_1  | 2020-07-27 01:16:20,929 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/173f92fc-7f52-4aed-8ff4-19d4c7579cb9 does not exist. Creating ...
s3g_1       |   <Code>NoSuchBucket</Code>
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
recon_1     | 2020-07-27 01:19:24,333 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  |   mostSigBits: 8111148100301505098
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
datanode_1  | 2020-07-27 01:16:20,956 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/173f92fc-7f52-4aed-8ff4-19d4c7579cb9/in_use.lock acquired by nodename 6@d9b4dd9bc409
s3g_1       |   <Message>The specified bucket does not exist</Message>
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
recon_1     | 2020-07-27 01:19:24,333 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  |   leastSigBits: -4884474198727723710
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
datanode_1  | 2020-07-27 01:16:20,967 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/173f92fc-7f52-4aed-8ff4-19d4c7579cb9 has been successfully formatted.
s3g_1       |   <Resource>nosuchbucket</Resource>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
recon_1     | 2020-07-27 01:19:24,350 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 90
datanode_3  | }
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
datanode_1  | 2020-07-27 01:16:20,981 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-19D4C7579CB9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
recon_1     | 2020-07-27 01:19:24,384 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 43 OM DB update event(s).
datanode_3  | .
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
datanode_1  | 2020-07-27 01:16:20,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
s3g_1       | </Error>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
recon_1     | 2020-07-27 01:19:24,634 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2020-07-27 01:16:22,479 [Command processor thread] INFO impl.RaftServerProxy: 049cb58c-d205-4f90-a803-ee8758f93325: addNew group-911A6C7098D3:[fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858] returns group-911A6C7098D3:java.util.concurrent.CompletableFuture@38b97fdc[Not completed]
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_1  | 2020-07-27 01:16:21,001 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | 
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
recon_1     | 2020-07-27 01:20:24,053 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
datanode_3  | 2020-07-27 01:16:22,543 [pool-19-thread-1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325: new RaftServerImpl for group-911A6C7098D3:[fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858] with ContainerStateMachine:uninitialized
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
datanode_1  | 2020-07-27 01:16:21,022 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
recon_1     | 2020-07-27 01:20:24,062 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 9 milliseconds for processing 1 containers.
s3g_1       | 2020-07-27 01:37:55,241 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
datanode_3  | 2020-07-27 01:16:22,556 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_1  | 2020-07-27 01:16:21,038 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1     | 2020-07-27 01:20:24,644 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | <Error>
datanode_3  | 2020-07-27 01:16:22,556 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 2020-07-27 01:16:21,056 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
recon_1     | 2020-07-27 01:20:24,644 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       |   <Code>NoSuchBucket</Code>
datanode_3  | 2020-07-27 01:16:22,556 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 2020-07-27 01:16:21,059 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
recon_1     | 2020-07-27 01:20:24,651 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 15
s3g_1       |   <Message>The specified bucket does not exist</Message>
datanode_3  | 2020-07-27 01:16:22,556 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1  | 2020-07-27 01:16:21,080 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
recon_1     | 2020-07-27 01:20:24,658 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
s3g_1       |   <Resource>ozonenosuchbucketqqweqwe</Resource>
datanode_3  | 2020-07-27 01:16:22,556 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_1  | 2020-07-27 01:16:21,097 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/173f92fc-7f52-4aed-8ff4-19d4c7579cb9
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1     | 2020-07-27 01:20:24,667 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       |   <RequestId/>
datanode_3  | 2020-07-27 01:16:22,556 [pool-19-thread-1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3: ConfigurationManager, init=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null, confs=<EMPTY_MAP>
scm_1       | 2020-07-27 01:15:22,749 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 2020-07-27 01:21:24,669 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | </Error>
datanode_3  | 2020-07-27 01:16:22,561 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | java.nio.channels.AsynchronousCloseException
datanode_1  | 2020-07-27 01:16:21,098 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 2020-07-27 01:21:24,669 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 
datanode_3  | 2020-07-27 01:16:22,562 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 2020-07-27 01:21:24,676 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 11
s3g_1       | 2020-07-27 01:37:55,241 [qtp1939022383-17] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
datanode_1  | 2020-07-27 01:16:21,098 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-07-27 01:16:22,562 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3 does not exist. Creating ...
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1     | 2020-07-27 01:21:24,685 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 5 OM DB update event(s).
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
datanode_1  | 2020-07-27 01:16:21,099 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-07-27 01:16:22,567 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3/in_use.lock acquired by nodename 7@3b515c2c2a2d
om_1        | 2020-07-27 01:20:00,693 [IPC Server handler 82 on default port 9862] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:99581-target
recon_1     | 2020-07-27 01:21:24,697 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:112)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_1  | 2020-07-27 01:16:21,107 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-07-27 01:16:22,579 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3 has been successfully formatted.
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
recon_1     | 2020-07-27 01:22:24,704 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:72)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
datanode_1  | 2020-07-27 01:16:21,107 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-07-27 01:16:22,580 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-911A6C7098D3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
recon_1     | 2020-07-27 01:22:24,705 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:253)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
datanode_1  | 2020-07-27 01:16:21,108 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-07-27 01:16:22,581 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
recon_1     | 2020-07-27 01:22:24,710 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 13
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
datanode_1  | 2020-07-27 01:16:21,109 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-07-27 01:16:22,582 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
recon_1     | 2020-07-27 01:22:24,720 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
datanode_1  | 2020-07-27 01:16:21,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-07-27 01:16:22,582 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
recon_1     | 2020-07-27 01:22:24,725 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_1  | 2020-07-27 01:16:21,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-07-27 01:16:22,582 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
recon_1     | 2020-07-27 01:23:24,732 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
datanode_1  | 2020-07-27 01:16:21,135 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-07-27 01:16:22,582 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
recon_1     | 2020-07-27 01:23:24,733 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_1  | 2020-07-27 01:16:21,150 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-07-27 01:16:22,584 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1     | 2020-07-27 01:23:24,757 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 13
recon_1     | 2020-07-27 01:23:24,773 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2020-07-27 01:23:24,787 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-27 01:24:24,796 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-07-27 01:24:24,796 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-07-27 01:24:24,807 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 11
recon_1     | 2020-07-27 01:24:24,813 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 6 OM DB update event(s).
recon_1     | 2020-07-27 01:24:24,817 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-27 01:25:24,026 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2020-07-27 01:25:24,027 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 6 milliseconds.
datanode_1  | 2020-07-27 01:16:21,150 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
recon_1     | 2020-07-27 01:25:24,063 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
datanode_3  | 2020-07-27 01:16:22,585 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_1  | 2020-07-27 01:16:21,162 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
recon_1     | 2020-07-27 01:25:24,066 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 1 containers.
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
datanode_3  | 2020-07-27 01:16:22,585 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
datanode_1  | 2020-07-27 01:16:21,165 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
recon_1     | 2020-07-27 01:25:24,827 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
datanode_3  | 2020-07-27 01:16:22,585 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
datanode_1  | 2020-07-27 01:16:21,165 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
recon_1     | 2020-07-27 01:25:24,827 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
datanode_3  | 2020-07-27 01:16:22,585 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_1  | 2020-07-27 01:16:21,166 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
recon_1     | 2020-07-27 01:25:24,839 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 12
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
datanode_3  | 2020-07-27 01:16:22,585 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2020-07-27 01:15:22,751 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.2:50830: output error
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 2020-07-27 01:16:21,167 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
recon_1     | 2020-07-27 01:25:24,844 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 8 OM DB update event(s).
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
datanode_3  | 2020-07-27 01:16:22,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 2020-07-27 01:15:22,751 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 2020-07-27 01:16:21,231 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9
recon_1     | 2020-07-27 01:25:24,849 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
datanode_3  | 2020-07-27 01:16:22,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
scm_1       | java.nio.channels.AsynchronousCloseException
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1  | 2020-07-27 01:16:21,241 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9
recon_1     | 2020-07-27 01:26:24,857 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
datanode_3  | 2020-07-27 01:16:22,589 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_1  | 2020-07-27 01:16:21,251 [pool-19-thread-1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9: start as a follower, conf=-1: [d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858], old=null
recon_1     | 2020-07-27 01:26:24,857 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
datanode_3  | 2020-07-27 01:16:22,589 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
om_1        | 2020-07-27 01:20:33,283 [IPC Server handler 39 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:71706-rpcwoport for user:hadoop
datanode_1  | 2020-07-27 01:16:21,265 [pool-19-thread-1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9: changes role from      null to FOLLOWER at term 0 for startAsFollower
recon_1     | 2020-07-27 01:26:24,867 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 18
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
datanode_3  | 2020-07-27 01:16:22,589 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
om_1        | 2020-07-27 01:21:49,656 [IPC Server handler 87 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:71706-rpcwoport2 for user:hadoop
datanode_1  | 2020-07-27 01:16:21,266 [pool-19-thread-1] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: start FollowerState
recon_1     | 2020-07-27 01:26:24,873 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 7 OM DB update event(s).
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
datanode_3  | 2020-07-27 01:16:22,589 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
om_1        | 2020-07-27 01:22:14,680 [IPC Server handler 85 on default port 9862] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /71706-rpcwoport2/bb1 failed, because acl already exist
datanode_1  | 2020-07-27 01:16:21,290 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-19D4C7579CB9,id=d827362c-8092-4b3a-8ed7-ce1b50249841
recon_1     | 2020-07-27 01:26:24,878 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
datanode_3  | 2020-07-27 01:16:22,590 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
om_1        | 2020-07-27 01:22:53,341 [IPC Server handler 41 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:71706-rpcwport for user:hadoop
datanode_1  | 2020-07-27 01:16:21,291 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9
recon_1     | 2020-07-27 01:27:24,887 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
datanode_3  | 2020-07-27 01:16:22,601 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
om_1        | 2020-07-27 01:24:12,081 [IPC Server handler 9 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:71706-rpcwoscheme for user:hadoop
datanode_1  | 2020-07-27 01:16:21,350 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "173f92fc-7f52-4aed-8ff4-19d4c7579cb9"
recon_1     | 2020-07-27 01:27:24,887 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
datanode_3  | 2020-07-27 01:16:22,602 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
datanode_1  | uuid128 {
recon_1     | 2020-07-27 01:27:24,892 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 16
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
datanode_3  | 2020-07-27 01:16:22,602 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
om_1        | 2020-07-27 01:25:34,085 [IPC Server handler 12 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:ufxbv for user:hadoop
datanode_1  |   mostSigBits: 1675219199570627309
recon_1     | 2020-07-27 01:27:24,906 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 7 OM DB update event(s).
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
datanode_3  | 2020-07-27 01:16:22,602 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
om_1        | 2020-07-27 01:26:38,510 [IPC Server handler 78 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest1 for user:hadoop
datanode_1  |   leastSigBits: -8073799830300287815
recon_1     | 2020-07-27 01:27:24,927 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
om_1        | 2020-07-27 01:26:40,873 [IPC Server handler 90 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest2 for user:hadoop
datanode_1  | }
recon_1     | 2020-07-27 01:28:24,931 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
datanode_3  | 2020-07-27 01:16:22,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 2020-07-27 01:26:43,247 [IPC Server handler 22 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest1-src for user:hadoop
datanode_1  | .
recon_1     | 2020-07-27 01:28:24,931 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
datanode_3  | 2020-07-27 01:16:22,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2020-07-27 01:26:45,621 [IPC Server handler 76 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest2-src for user:hadoop
datanode_1  | 2020-07-27 01:16:21,353 [Command processor thread] INFO impl.RaftServerProxy: d827362c-8092-4b3a-8ed7-ce1b50249841: addNew group-911A6C7098D3:[fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858] returns group-911A6C7098D3:java.util.concurrent.CompletableFuture@58f8cd13[Not completed]
recon_1     | 2020-07-27 01:28:24,944 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 18
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_3  | 2020-07-27 01:16:22,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 2020-07-27 01:29:19,678 [IPC Server handler 4 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:fstest1
datanode_1  | 2020-07-27 01:16:21,426 [pool-19-thread-1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841: new RaftServerImpl for group-911A6C7098D3:[fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858] with ContainerStateMachine:uninitialized
recon_1     | 2020-07-27 01:28:24,959 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 17 OM DB update event(s).
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
datanode_3  | 2020-07-27 01:16:22,608 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
datanode_1  | 2020-07-27 01:16:21,428 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
recon_1     | 2020-07-27 01:28:24,977 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
datanode_3  | 2020-07-27 01:16:22,609 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:153)
datanode_1  | 2020-07-27 01:16:21,428 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1     | 2020-07-27 01:29:24,983 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
scm_1       | 2020-07-27 01:16:17,958 [IPC Server handler 20 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/d827362c-8092-4b3a-8ed7-ce1b50249841
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_1  | 2020-07-27 01:16:21,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
recon_1     | 2020-07-27 01:29:24,983 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
datanode_3  | 2020-07-27 01:16:22,669 [pool-19-thread-1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3: start as a follower, conf=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null
scm_1       | 2020-07-27 01:16:17,969 [IPC Server handler 20 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
datanode_1  | 2020-07-27 01:16:21,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
recon_1     | 2020-07-27 01:29:24,993 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 29
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
datanode_3  | 2020-07-27 01:16:22,669 [pool-19-thread-1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2020-07-27 01:16:18,039 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
datanode_1  | 2020-07-27 01:16:21,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1     | 2020-07-27 01:29:25,011 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 24 OM DB update event(s).
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
datanode_3  | 2020-07-27 01:16:22,669 [pool-19-thread-1] INFO impl.RoleInfo: 049cb58c-d205-4f90-a803-ee8758f93325: start FollowerState
scm_1       | 2020-07-27 01:16:18,039 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
datanode_1  | 2020-07-27 01:16:21,429 [pool-19-thread-1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3: ConfigurationManager, init=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null, confs=<EMPTY_MAP>
recon_1     | 2020-07-27 01:29:25,037 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
datanode_3  | 2020-07-27 01:16:22,669 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-911A6C7098D3,id=049cb58c-d205-4f90-a803-ee8758f93325
scm_1       | 2020-07-27 01:16:18,150 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=173f92fc-7f52-4aed-8ff4-19d4c7579cb9 to datanode:d827362c-8092-4b3a-8ed7-ce1b50249841
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
recon_1     | 2020-07-27 01:30:24,068 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
datanode_1  | 2020-07-27 01:16:21,430 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
datanode_3  | 2020-07-27 01:16:22,670 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3
scm_1       | 2020-07-27 01:16:18,218 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 173f92fc-7f52-4aed-8ff4-19d4c7579cb9, Nodes: d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-27T01:16:18.134982Z]
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1     | 2020-07-27 01:30:24,073 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 1 containers.
datanode_1  | 2020-07-27 01:16:21,430 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
datanode_3  | 2020-07-27 01:16:23,923 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "69ab0f71-979b-4f32-abe3-911a6c7098d3"
scm_1       | 2020-07-27 01:16:18,226 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
recon_1     | 2020-07-27 01:30:25,048 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_1  | 2020-07-27 01:16:21,430 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3 does not exist. Creating ...
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
datanode_3  | uuid128 {
scm_1       | 2020-07-27 01:16:18,602 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/fd0af4ce-9605-4cba-bb56-a16d05501772
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
recon_1     | 2020-07-27 01:30:25,048 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_1  | 2020-07-27 01:16:21,444 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3/in_use.lock acquired by nodename 6@d9b4dd9bc409
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
datanode_3  |   mostSigBits: 7614196575549214514
scm_1       | 2020-07-27 01:16:18,603 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
recon_1     | 2020-07-27 01:30:25,068 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 15
datanode_1  | 2020-07-27 01:16:21,449 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3 has been successfully formatted.
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode_3  |   leastSigBits: -6060841130836059949
scm_1       | 2020-07-27 01:16:18,604 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1     | 2020-07-27 01:30:25,079 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 15 OM DB update event(s).
datanode_1  | 2020-07-27 01:16:21,450 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-911A6C7098D3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
datanode_3  | }
scm_1       | 2020-07-27 01:16:18,604 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 2020-07-27 01:30:25,088 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_1  | 2020-07-27 01:16:21,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
datanode_3  | .
scm_1       | 2020-07-27 01:16:18,607 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=57140d50-7eca-41c1-bb5e-021e176a3503 to datanode:fd0af4ce-9605-4cba-bb56-a16d05501772
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 2020-07-27 01:31:25,095 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_1  | 2020-07-27 01:16:21,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
datanode_3  | 2020-07-27 01:16:26,637 [grpc-default-executor-0] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:d827362c-8092-4b3a-8ed7-ce1b50249841
scm_1       | 2020-07-27 01:16:18,608 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 57140d50-7eca-41c1-bb5e-021e176a3503, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-27T01:16:18.607261Z]
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 2020-07-27 01:31:25,095 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_1  | 2020-07-27 01:16:21,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
datanode_3  | 2020-07-27 01:16:26,638 [grpc-default-executor-0] INFO impl.RoleInfo: 049cb58c-d205-4f90-a803-ee8758f93325: shutdown FollowerState
scm_1       | 2020-07-27 01:16:18,609 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1     | 2020-07-27 01:31:25,106 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 32
datanode_1  | 2020-07-27 01:16:21,450 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
datanode_3  | 2020-07-27 01:16:26,638 [grpc-default-executor-0] INFO impl.RoleInfo: 049cb58c-d205-4f90-a803-ee8758f93325: start FollowerState
scm_1       | 2020-07-27 01:16:18,886 [IPC Server handler 40 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/049cb58c-d205-4f90-a803-ee8758f93325
om_1        | 2020-07-27 01:29:21,986 [IPC Server handler 15 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:fstest2
recon_1     | 2020-07-27 01:31:25,128 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 31 OM DB update event(s).
datanode_1  | 2020-07-27 01:16:21,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
datanode_3  | 2020-07-27 01:16:26,638 [Thread-26] INFO impl.FollowerState: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1       | 2020-07-27 01:16:18,886 [IPC Server handler 40 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
recon_1     | 2020-07-27 01:31:25,144 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_1  | 2020-07-27 01:16:21,468 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
datanode_3  | 2020-07-27 01:16:26,801 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-911A6C7098D3 with new leaderId: d827362c-8092-4b3a-8ed7-ce1b50249841
scm_1       | 2020-07-27 01:16:18,886 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=70909638-f70e-424a-bc36-dc986645f542 to datanode:049cb58c-d205-4f90-a803-ee8758f93325
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:153)
recon_1     | 2020-07-27 01:32:25,148 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_1  | 2020-07-27 01:16:21,469 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
datanode_3  | 2020-07-27 01:16:26,802 [grpc-default-executor-0] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3: change Leader from null to d827362c-8092-4b3a-8ed7-ce1b50249841 at term 1 for appendEntries, leader elected after 4219ms
scm_1       | 2020-07-27 01:16:18,888 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 70909638-f70e-424a-bc36-dc986645f542, Nodes: 049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-27T01:16:18.886918Z]
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
recon_1     | 2020-07-27 01:32:25,149 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_1  | 2020-07-27 01:16:21,469 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
datanode_3  | 2020-07-27 01:16:26,852 [grpc-default-executor-0] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3: set configuration 0: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null at 0
scm_1       | 2020-07-27 01:16:18,889 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
recon_1     | 2020-07-27 01:32:25,162 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 14
datanode_1  | 2020-07-27 01:16:21,469 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm_1       | 2020-07-27 01:16:18,890 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_3  | 2020-07-27 01:16:26,856 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
recon_1     | 2020-07-27 01:32:25,177 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
datanode_1  | 2020-07-27 01:16:21,470 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm_1       | 2020-07-27 01:16:18,890 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
datanode_3  | 2020-07-27 01:16:27,072 [049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 049cb58c-d205-4f90-a803-ee8758f93325@group-911A6C7098D3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3/current/log_inprogress_0
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
recon_1     | 2020-07-27 01:32:25,193 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_1  | 2020-07-27 01:16:21,470 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2020-07-27 01:16:18,890 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
datanode_3  | 2020-07-27 01:16:27,558 [Thread-24] INFO impl.FollowerState: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-FollowerState: change to CANDIDATE, lastRpcTime:5133ms, electionTimeout:5132ms
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
recon_1     | 2020-07-27 01:33:25,205 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_1  | 2020-07-27 01:16:21,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
scm_1       | 2020-07-27 01:16:18,890 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
datanode_3  | 2020-07-27 01:16:27,558 [Thread-24] INFO impl.RoleInfo: 049cb58c-d205-4f90-a803-ee8758f93325: shutdown FollowerState
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1     | 2020-07-27 01:33:25,206 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_1  | 2020-07-27 01:16:21,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
scm_1       | 2020-07-27 01:16:18,891 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
datanode_3  | 2020-07-27 01:16:27,558 [Thread-24] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
recon_1     | 2020-07-27 01:33:25,219 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 15
datanode_1  | 2020-07-27 01:16:21,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
scm_1       | 2020-07-27 01:16:18,898 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3 to datanode:fd0af4ce-9605-4cba-bb56-a16d05501772
datanode_3  | 2020-07-27 01:16:27,560 [Thread-24] INFO impl.RoleInfo: 049cb58c-d205-4f90-a803-ee8758f93325: start LeaderElection
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
recon_1     | 2020-07-27 01:33:25,231 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 15 OM DB update event(s).
datanode_1  | 2020-07-27 01:16:21,471 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
scm_1       | 2020-07-27 01:16:18,898 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3 to datanode:d827362c-8092-4b3a-8ed7-ce1b50249841
datanode_3  | 2020-07-27 01:16:27,574 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO impl.LeaderElection: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1: begin an election at term 1 for -1: [049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
datanode_1  | 2020-07-27 01:16:21,472 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
recon_1     | 2020-07-27 01:33:25,240 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
scm_1       | 2020-07-27 01:16:18,898 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=69ab0f71-979b-4f32-abe3-911a6c7098d3 to datanode:049cb58c-d205-4f90-a803-ee8758f93325
datanode_3  | 2020-07-27 01:16:27,575 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO impl.RoleInfo: 049cb58c-d205-4f90-a803-ee8758f93325: shutdown LeaderElection
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_1  | 2020-07-27 01:16:21,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1     | 2020-07-27 01:34:25,245 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
scm_1       | 2020-07-27 01:16:18,900 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 69ab0f71-979b-4f32-abe3-911a6c7098d3, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-27T01:16:18.898062Z]
datanode_3  | 2020-07-27 01:16:27,575 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 2020-07-27 01:16:21,478 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
recon_1     | 2020-07-27 01:34:25,246 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2020-07-27 01:16:18,902 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_3  | 2020-07-27 01:16:27,576 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DC986645F542 with new leaderId: 049cb58c-d205-4f90-a803-ee8758f93325
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 2020-07-27 01:16:21,478 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
recon_1     | 2020-07-27 01:34:25,261 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 24
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
scm_1       | 2020-07-27 01:16:21,072 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 173f92fc-7f52-4aed-8ff4-19d4c7579cb9, Nodes: d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:d827362c-8092-4b3a-8ed7-ce1b50249841, CreationTimestamp2020-07-27T01:16:18.134982Z] moved to OPEN state
datanode_3  | 2020-07-27 01:16:27,576 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542: change Leader from null to 049cb58c-d205-4f90-a803-ee8758f93325 at term 1 for becomeLeader, leader elected after 5437ms
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1  | 2020-07-27 01:16:21,478 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
recon_1     | 2020-07-27 01:34:25,278 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 29 OM DB update event(s).
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
scm_1       | 2020-07-27 01:16:21,125 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_3  | 2020-07-27 01:16:27,593 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_1  | 2020-07-27 01:16:21,478 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
recon_1     | 2020-07-27 01:34:25,306 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-27 01:35:24,055 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
scm_1       | 2020-07-27 01:16:21,151 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_3  | 2020-07-27 01:16:27,595 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-07-27 01:16:27,597 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542
datanode_1  | 2020-07-27 01:16:21,479 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
recon_1     | 2020-07-27 01:35:24,055 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 25 milliseconds.
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
datanode_3  | 2020-07-27 01:16:27,602 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
om_1        | 2020-07-27 01:31:46,151 [IPC Server handler 42 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:fstest1
scm_1       | 2020-07-27 01:16:21,873 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 57140d50-7eca-41c1-bb5e-021e176a3503, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:fd0af4ce-9605-4cba-bb56-a16d05501772, CreationTimestamp2020-07-27T01:16:18.607261Z] moved to OPEN state
datanode_1  | 2020-07-27 01:16:21,479 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
recon_1     | 2020-07-27 01:35:24,079 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
datanode_3  | 2020-07-27 01:16:27,606 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
scm_1       | 2020-07-27 01:16:21,877 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_1  | 2020-07-27 01:16:21,479 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
recon_1     | 2020-07-27 01:35:24,089 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 10 milliseconds for processing 1 containers.
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
datanode_3  | 2020-07-27 01:16:27,617 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:153)
scm_1       | 2020-07-27 01:16:21,877 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_1  | 2020-07-27 01:16:21,479 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
recon_1     | 2020-07-27 01:35:25,311 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
datanode_3  | 2020-07-27 01:16:27,619 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
scm_1       | 2020-07-27 01:16:22,143 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 70909638-f70e-424a-bc36-dc986645f542, Nodes: 049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:049cb58c-d205-4f90-a803-ee8758f93325, CreationTimestamp2020-07-27T01:16:18.886918Z] moved to OPEN state
datanode_1  | 2020-07-27 01:16:21,479 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3
recon_1     | 2020-07-27 01:35:25,311 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
datanode_3  | 2020-07-27 01:16:27,619 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
scm_1       | 2020-07-27 01:16:22,157 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_1  | 2020-07-27 01:16:21,485 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3
recon_1     | 2020-07-27 01:35:25,318 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 18
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
datanode_3  | 2020-07-27 01:16:27,629 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO impl.RoleInfo: 049cb58c-d205-4f90-a803-ee8758f93325: start LeaderState
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
scm_1       | 2020-07-27 01:16:22,157 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_1  | 2020-07-27 01:16:21,486 [pool-19-thread-1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3: start as a follower, conf=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null
recon_1     | 2020-07-27 01:35:25,327 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 15 OM DB update event(s).
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
datanode_3  | 2020-07-27 01:16:27,637 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
scm_1       | 2020-07-27 01:16:26,682 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 69ab0f71-979b-4f32-abe3-911a6c7098d3, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}d827362c-8092-4b3a-8ed7-ce1b50249841{ip: 172.23.0.5, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}049cb58c-d205-4f90-a803-ee8758f93325{ip: 172.23.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:d827362c-8092-4b3a-8ed7-ce1b50249841, CreationTimestamp2020-07-27T01:16:18.898062Z] moved to OPEN state
datanode_1  | 2020-07-27 01:16:21,486 [pool-19-thread-1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3: changes role from      null to FOLLOWER at term 0 for startAsFollower
recon_1     | 2020-07-27 01:35:25,344 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-07-27 01:16:27,644 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/70909638-f70e-424a-bc36-dc986645f542/current/log_inprogress_0
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
scm_1       | 2020-07-27 01:16:26,683 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
datanode_1  | 2020-07-27 01:16:21,486 [pool-19-thread-1] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: start FollowerState
recon_1     | 2020-07-27 01:36:25,351 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 2020-07-27 01:38:15,470 [qtp1939022383-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: link, , key: multipartKey2
datanode_3  | 2020-07-27 01:16:27,650 [049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542-LeaderElection1] INFO impl.RaftServerImpl: 049cb58c-d205-4f90-a803-ee8758f93325@group-DC986645F542: set configuration 0: [049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null at 0
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm_1       | 2020-07-27 01:16:26,684 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_1  | 2020-07-27 01:16:21,487 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-911A6C7098D3,id=d827362c-8092-4b3a-8ed7-ce1b50249841
recon_1     | 2020-07-27 01:36:25,351 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey2. Entity too small.
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
scm_1       | 2020-07-27 01:16:26,687 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
datanode_1  | 2020-07-27 01:16:21,487 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3
recon_1     | 2020-07-27 01:36:25,359 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 20
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
scm_1       | 2020-07-27 01:16:26,687 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode_1  | 2020-07-27 01:16:23,884 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "69ab0f71-979b-4f32-abe3-911a6c7098d3"
recon_1     | 2020-07-27 01:36:25,378 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 24 OM DB update event(s).
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
scm_1       | 2020-07-27 01:16:26,687 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
datanode_1  | uuid128 {
recon_1     | 2020-07-27 01:36:25,440 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1       | 2020-07-27 01:17:18,804 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
datanode_1  |   mostSigBits: 7614196575549214514
recon_1     | 2020-07-27 01:37:25,448 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 2020-07-27 01:17:18,804 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_1  |   leastSigBits: -6060841130836059949
recon_1     | 2020-07-27 01:37:25,448 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
scm_1       | 2020-07-27 01:19:18,805 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | }
recon_1     | 2020-07-27 01:37:25,460 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
scm_1       | 2020-07-27 01:19:18,805 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1  | .
recon_1     | 2020-07-27 01:37:25,466 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 8 OM DB update event(s).
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
scm_1       | 2020-07-27 01:19:28,192 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_1  | 2020-07-27 01:16:26,479 [Thread-24] INFO impl.FollowerState: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-FollowerState: change to CANDIDATE, lastRpcTime:5213ms, electionTimeout:5189ms
recon_1     | 2020-07-27 01:37:25,473 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm_1       | 2020-07-27 01:19:28,197 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583184648700031 bcsId: 0
om_1        | 2020-07-27 01:31:48,515 [IPC Server handler 95 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:fstest2
datanode_1  | 2020-07-27 01:16:26,480 [Thread-24] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: shutdown FollowerState
recon_1     | 2020-07-27 01:38:25,480 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm_1       | 2020-07-27 01:21:18,807 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
datanode_1  | 2020-07-27 01:16:26,481 [Thread-24] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
recon_1     | 2020-07-27 01:38:25,481 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
scm_1       | 2020-07-27 01:21:18,807 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:153)
datanode_1  | 2020-07-27 01:16:26,482 [Thread-24] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: start LeaderElection
recon_1     | 2020-07-27 01:38:25,496 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 53
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
scm_1       | 2020-07-27 01:21:26,697 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_1  | 2020-07-27 01:16:26,490 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO impl.LeaderElection: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1: begin an election at term 1 for -1: [d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858], old=null
recon_1     | 2020-07-27 01:38:25,502 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
scm_1       | 2020-07-27 01:21:26,706 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 5 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
datanode_1  | 2020-07-27 01:16:26,491 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: shutdown LeaderElection
recon_1     | 2020-07-27 01:38:25,513 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-07-27 01:39:25,520 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2020-07-27 01:21:28,267 [IPC Server handler 44 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
recon_1     | 2020-07-27 01:39:25,521 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
datanode_1  | 2020-07-27 01:16:26,491 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1       | 2020-07-27 01:21:28,268 [IPC Server handler 44 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583192577048707 bcsId: 0
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
recon_1     | 2020-07-27 01:39:25,547 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 59
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
datanode_1  | 2020-07-27 01:16:26,491 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-19D4C7579CB9 with new leaderId: d827362c-8092-4b3a-8ed7-ce1b50249841
scm_1       | 2020-07-27 01:21:28,269 [IPC Server handler 44 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583191682220162 bcsId: 0
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
recon_1     | 2020-07-27 01:39:25,566 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 16 OM DB update event(s).
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
datanode_1  | 2020-07-27 01:16:26,492 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9: change Leader from null to d827362c-8092-4b3a-8ed7-ce1b50249841 at term 1 for becomeLeader, leader elected after 5510ms
scm_1       | 2020-07-27 01:22:28,275 [IPC Server handler 44 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1     | 2020-07-27 01:39:25,590 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
datanode_1  | 2020-07-27 01:16:26,499 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2020-07-27 01:22:28,275 [IPC Server handler 44 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583191141679233 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
recon_1     | 2020-07-27 01:40:24,090 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
datanode_1  | 2020-07-27 01:16:26,499 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1       | 2020-07-27 01:23:18,808 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
recon_1     | 2020-07-27 01:40:24,094 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 1 containers.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
datanode_1  | 2020-07-27 01:16:26,501 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9
scm_1       | 2020-07-27 01:23:18,809 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
recon_1     | 2020-07-27 01:40:25,593 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
datanode_1  | 2020-07-27 01:16:26,503 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
scm_1       | 2020-07-27 01:24:28,280 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1     | 2020-07-27 01:40:25,593 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
datanode_1  | 2020-07-27 01:16:26,504 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
scm_1       | 2020-07-27 01:24:28,280 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583201789051015 bcsId: 0
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 2020-07-27 01:40:25,602 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 50
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
datanode_1  | 2020-07-27 01:16:26,509 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
scm_1       | 2020-07-27 01:24:28,280 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583200876068998 bcsId: 0
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 2020-07-27 01:40:25,608 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 9 OM DB update event(s).
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
datanode_1  | 2020-07-27 01:16:26,509 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1       | 2020-07-27 01:24:28,282 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583200322486405 bcsId: 0
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 2020-07-27 01:40:25,616 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
datanode_1  | 2020-07-27 01:16:26,510 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 2020-07-27 01:25:18,813 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1     | 2020-07-27 01:41:25,623 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
datanode_1  | 2020-07-27 01:16:26,514 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: start LeaderState
om_1        | 2020-07-27 01:31:50,899 [IPC Server handler 51 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:fstest1-src
recon_1     | 2020-07-27 01:41:25,623 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2020-07-27 01:25:18,813 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
datanode_1  | 2020-07-27 01:16:26,537 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
recon_1     | 2020-07-27 01:41:25,633 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 95
scm_1       | 2020-07-27 01:25:28,292 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
datanode_1  | 2020-07-27 01:16:26,537 [Thread-26] INFO impl.FollowerState: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-FollowerState: change to CANDIDATE, lastRpcTime:5051ms, electionTimeout:5049ms
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:153)
recon_1     | 2020-07-27 01:41:25,644 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 23 OM DB update event(s).
scm_1       | 2020-07-27 01:25:28,292 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583206927728778 bcsId: 0
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
datanode_1  | 2020-07-27 01:16:26,540 [Thread-26] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: shutdown FollowerState
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
recon_1     | 2020-07-27 01:41:25,678 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2020-07-27 01:25:28,292 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583206039650441 bcsId: 0
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
datanode_1  | 2020-07-27 01:16:26,540 [Thread-26] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
recon_1     | 2020-07-27 01:41:42,180 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozone_datanode_1.ozone_default.
scm_1       | 2020-07-27 01:25:28,292 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583205498454152 bcsId: 0
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
datanode_1  | 2020-07-27 01:16:26,540 [Thread-26] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: start LeaderElection
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
recon_1     | 2020-07-27 01:41:42,199 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
scm_1       | 2020-07-27 01:26:26,717 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
datanode_1  | 2020-07-27 01:16:26,570 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-LeaderElection1] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9: set configuration 0: [d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858], old=null at 0
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
recon_1     | 2020-07-27 01:41:42,249 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_3.ozone_default.
scm_1       | 2020-07-27 01:26:28,299 [IPC Server handler 59 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_1  | 2020-07-27 01:16:26,588 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO impl.LeaderElection: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2: begin an election at term 1 for -1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
recon_1     | 2020-07-27 01:41:42,253 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #3 to Recon.
scm_1       | 2020-07-27 01:26:28,299 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583210026991755 bcsId: 0
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
datanode_1  | 2020-07-27 01:16:26,673 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO impl.LeaderElection: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2: Election PASSED; received 1 response(s) [d827362c-8092-4b3a-8ed7-ce1b50249841<-fd0af4ce-9605-4cba-bb56-a16d05501772#0:OK-t1] and 0 exception(s); d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3:t1, leader=null, voted=d827362c-8092-4b3a-8ed7-ce1b50249841, raftlog=d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1     | 2020-07-27 01:41:42,333 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_2.ozone_default.
recon_1     | 2020-07-27 01:41:42,340 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #4 to Recon.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
datanode_1  | 2020-07-27 01:16:26,673 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: shutdown LeaderElection
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
recon_1     | 2020-07-27 01:42:25,685 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2020-07-27 01:26:28,299 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583210938531980 bcsId: 0
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
datanode_1  | 2020-07-27 01:16:26,673 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
scm_1       | 2020-07-27 01:26:28,299 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583211845288077 bcsId: 0
recon_1     | 2020-07-27 01:42:25,686 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
datanode_1  | 2020-07-27 01:16:26,673 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-911A6C7098D3 with new leaderId: d827362c-8092-4b3a-8ed7-ce1b50249841
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
scm_1       | 2020-07-27 01:27:18,815 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
recon_1     | 2020-07-27 01:42:25,691 [pool-11-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 24
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
datanode_1  | 2020-07-27 01:16:26,673 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3: change Leader from null to d827362c-8092-4b3a-8ed7-ce1b50249841 at term 1 for becomeLeader, leader elected after 5223ms
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1       | 2020-07-27 01:27:18,816 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
recon_1     | 2020-07-27 01:42:25,724 [pool-12-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 10 OM DB update event(s).
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
datanode_1  | 2020-07-27 01:16:26,673 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 2020-07-27 01:27:28,304 [IPC Server handler 59 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
recon_1     | 2020-07-27 01:42:25,729 [pool-12-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
datanode_1  | 2020-07-27 01:16:26,673 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 2020-07-27 01:27:28,304 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583212768100494 bcsId: 0
recon_1     | 2020-07-27 01:42:45,026 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_2.ozone_default.
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 2020-07-27 01:28:28,306 [IPC Server handler 59 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
recon_1     | 2020-07-27 01:42:45,048 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Exception while adding container #5 .
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
datanode_1  | 2020-07-27 01:16:26,674 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-07-27 01:28:28,308 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583216590815375 bcsId: 0
recon_1     | java.io.IOException: Pipeline PipelineID=d64b1dbe-59ae-4f1a-8a6a-34cbf8071ad4 not found. Cannot add container #5
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
datanode_1  | 2020-07-27 01:16:26,674 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
om_1        | 2020-07-27 01:31:53,130 [IPC Server handler 55 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:fstest2-src
scm_1       | 2020-07-27 01:28:28,308 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583217237917840 bcsId: 0
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.addNewContainer(ReconContainerManager.java:117)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
datanode_1  | 2020-07-27 01:16:26,674 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
scm_1       | 2020-07-27 01:28:28,308 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583218410619025 bcsId: 0
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.checkAndAddNewContainer(ReconContainerManager.java:91)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
datanode_1  | 2020-07-27 01:16:26,674 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:153)
scm_1       | 2020-07-27 01:29:18,816 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:76)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode_1  | 2020-07-27 01:16:26,674 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
scm_1       | 2020-07-27 01:29:18,820 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:39)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
datanode_1  | 2020-07-27 01:16:26,674 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
scm_1       | 2020-07-27 01:29:28,314 [IPC Server handler 59 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
datanode_1  | 2020-07-27 01:16:26,687 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
scm_1       | 2020-07-27 01:29:28,315 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583221882912917 bcsId: 0
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
datanode_1  | 2020-07-27 01:16:26,690 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
scm_1       | 2020-07-27 01:29:28,315 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583222536634518 bcsId: 0
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
datanode_1  | 2020-07-27 01:16:26,690 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
scm_1       | 2020-07-27 01:31:18,821 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode_1  | 2020-07-27 01:16:26,697 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2020-07-27 01:31:18,822 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
recon_1     | 2020-07-27 01:42:45,049 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] ERROR scm.ReconIncrementalContainerReportHandler: Exception while checking and adding new container.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_1  | 2020-07-27 01:16:26,699 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1       | 2020-07-27 01:31:26,717 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d64b1dbe-59ae-4f1a-8a6a-34cbf8071ad4 not found
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
datanode_1  | 2020-07-27 01:16:26,699 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2020-07-27 01:31:28,319 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 5 blocks
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removeContainerFromPipeline(PipelineStateMap.java:372)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
datanode_1  | 2020-07-27 01:16:26,702 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3
scm_1       | 2020-07-27 01:31:28,319 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583226340999320 bcsId: 0
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removeContainerFromPipeline(PipelineStateManager.java:111)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_1  | 2020-07-27 01:16:26,713 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1       | 2020-07-27 01:31:28,319 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583226960380057 bcsId: 0
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removeContainerFromPipeline(SCMPipelineManager.java:403)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
datanode_1  | 2020-07-27 01:16:26,719 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2020-07-27 01:31:28,320 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583228119449754 bcsId: 0
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.addNewContainer(ReconContainerManager.java:124)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 2020-07-27 01:16:26,719 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1       | 2020-07-27 01:31:28,320 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583231521947806 bcsId: 0
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.checkAndAddNewContainer(ReconContainerManager.java:91)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 2020-07-27 01:16:26,719 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2020-07-27 01:31:28,320 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583232157712543 bcsId: 0
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:76)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1  | 2020-07-27 01:16:26,720 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1       | 2020-07-27 01:33:18,823 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:39)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
datanode_1  | 2020-07-27 01:16:26,721 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2020-07-27 01:33:18,823 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
om_1        | 2020-07-27 01:34:25,831 [IPC Server handler 52 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:fstest1
datanode_1  | 2020-07-27 01:16:26,732 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO impl.RoleInfo: d827362c-8092-4b3a-8ed7-ce1b50249841: start LeaderState
scm_1       | 2020-07-27 01:33:28,324 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 6 blocks
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:38:15,471 [qtp1939022383-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>EntityTooSmall</Code>
s3g_1       |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
datanode_1  | 2020-07-27 01:16:26,732 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-07-27 01:16:26,744 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-LeaderElection2] INFO impl.RaftServerImpl: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3: set configuration 0: [fd0af4ce-9605-4cba-bb56-a16d05501772:172.23.0.4:9858, d827362c-8092-4b3a-8ed7-ce1b50249841:172.23.0.5:9858, 049cb58c-d205-4f90-a803-ee8758f93325:172.23.0.2:9858], old=null at 0
datanode_1  | 2020-07-27 01:16:26,914 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d827362c-8092-4b3a-8ed7-ce1b50249841@group-911A6C7098D3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/69ab0f71-979b-4f32-abe3-911a6c7098d3/current/log_inprogress_0
datanode_1  | 2020-07-27 01:16:26,943 [d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d827362c-8092-4b3a-8ed7-ce1b50249841@group-19D4C7579CB9-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/173f92fc-7f52-4aed-8ff4-19d4c7579cb9/current/log_inprogress_0
scm_1       | 2020-07-27 01:33:28,327 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
scm_1       | 2020-07-27 01:33:28,327 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583236735467681 bcsId: 0
scm_1       | 2020-07-27 01:33:28,327 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583237338857634 bcsId: 0
scm_1       | 2020-07-27 01:33:28,328 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
scm_1       | 2020-07-27 01:33:28,328 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-07-27 01:33:28,328 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583238535086243 bcsId: 0
scm_1       | 2020-07-27 01:34:28,333 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 6 blocks
scm_1       | 2020-07-27 01:34:28,334 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
scm_1       | 2020-07-27 01:34:28,334 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
s3g_1       |   <Resource>multipartKey2</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:38:16,457 [qtp1939022383-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: link, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm_1       | 2020-07-27 01:34:28,334 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583241978675367 bcsId: 0
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:153)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
scm_1       | 2020-07-27 01:34:28,335 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
scm_1       | 2020-07-27 01:34:28,335 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
scm_1       | 2020-07-27 01:34:28,335 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583242641440936 bcsId: 0
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
scm_1       | 2020-07-27 01:35:18,824 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
scm_1       | 2020-07-27 01:35:18,825 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
scm_1       | 2020-07-27 01:36:26,718 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
scm_1       | 2020-07-27 01:36:28,338 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 9 blocks
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
scm_1       | 2020-07-27 01:36:28,339 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
scm_1       | 2020-07-27 01:36:28,339 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583246403010730 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
scm_1       | 2020-07-27 01:36:28,339 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583247017214123 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
scm_1       | 2020-07-27 01:36:28,339 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
scm_1       | 2020-07-27 01:36:28,339 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
scm_1       | 2020-07-27 01:36:28,340 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583248140697772 bcsId: 0
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
scm_1       | 2020-07-27 01:36:28,340 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
scm_1       | 2020-07-27 01:36:28,340 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
scm_1       | 2020-07-27 01:36:28,340 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583251602636976 bcsId: 0
om_1        | 2020-07-27 01:34:28,043 [IPC Server handler 73 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:fstest2
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-07-27 01:37:18,825 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
s3g_1       | 2020-07-27 01:38:16,458 [qtp1939022383-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
scm_1       | 2020-07-27 01:37:18,827 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:153)
s3g_1       | <Error>
scm_1       | 2020-07-27 01:37:28,349 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       |   <Code>InvalidPart</Code>
scm_1       | 2020-07-27 01:37:28,350 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
scm_1       | 2020-07-27 01:37:28,352 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks 
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       |   <Resource>multipartKey3</Resource>
scm_1       | 2020-07-27 01:37:28,352 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583252258324657 bcsId: 0
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       |   <RequestId/>
scm_1       | 2020-07-27 01:38:28,356 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | </Error>
scm_1       | 2020-07-27 01:38:28,356 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583258822607029 bcsId: 0
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 
scm_1       | 2020-07-27 01:38:28,356 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583259800535228 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 2020-07-27 01:38:16,910 [qtp1939022383-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: link, , key: multipartKey3
scm_1       | 2020-07-27 01:39:18,828 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-07-27 01:39:18,829 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-07-27 01:39:28,359 [IPC Server handler 59 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 8 blocks
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3
scm_1       | 2020-07-27 01:39:28,360 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583263013175499 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
scm_1       | 2020-07-27 01:39:28,360 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583263229903052 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
scm_1       | 2020-07-27 01:39:28,361 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583263556927693 bcsId: 0
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
scm_1       | 2020-07-27 01:39:28,361 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583260453535938 bcsId: 0,conID: 1 locID: 104583260453339329 bcsId: 0,conID: 1 locID: 104583260448948416 bcsId: 0
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
scm_1       | 2020-07-27 01:39:28,362 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583264022823118 bcsId: 0
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-07-27 01:39:28,362 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583264059982031 bcsId: 0
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
om_1        | 2020-07-27 01:37:21,812 [IPC Server handler 60 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:legacy for user:hadoop
scm_1       | 2020-07-27 01:39:28,363 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583260207579326 bcsId: 0
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2020-07-27 01:37:41,705 [IPC Server handler 60 on default port 9862] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link in volume:s3v
scm_1       | 2020-07-27 01:39:28,363 [IPC Server handler 59 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583260259549375 bcsId: 0
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2020-07-27 01:40:28,367 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
scm_1       | 2020-07-27 01:40:28,367 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583267379904725 bcsId: 0
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
scm_1       | 2020-07-27 01:41:18,830 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
scm_1       | 2020-07-27 01:41:18,830 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
scm_1       | 2020-07-27 01:41:26,718 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
scm_1       | 2020-07-27 01:41:28,369 [IPC Server handler 84 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 9 blocks
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
scm_1       | 2020-07-27 01:41:28,370 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583268919804129 bcsId: 0,conID: 1 locID: 104583268918558944 bcsId: 0,conID: 1 locID: 104583268921442530 bcsId: 0
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
scm_1       | 2020-07-27 01:41:28,370 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583268290461916 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
scm_1       | 2020-07-27 01:41:28,370 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583268685447390 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
scm_1       | 2020-07-27 01:41:28,370 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583268732043487 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
scm_1       | 2020-07-27 01:41:28,370 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583270464684267 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
scm_1       | 2020-07-27 01:41:28,371 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583270679052524 bcsId: 0
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
scm_1       | 2020-07-27 01:41:28,371 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583270844989677 bcsId: 0
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
scm_1       | 2020-07-27 01:41:28,371 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583271174045934 bcsId: 0
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
scm_1       | 2020-07-27 01:41:28,371 [IPC Server handler 84 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104583271262388463 bcsId: 0
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
scm_1       | 2020-07-27 01:42:43,915 [IPC Server handler 74 on default port 9863] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d64b1dbe-59ae-4f1a-8a6a-34cbf8071ad4, Nodes: fd0af4ce-9605-4cba-bb56-a16d05501772{ip: 172.23.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN, leaderId:, CreationTimestamp2020-07-27T01:42:43.915413Z]
om_1        | 2020-07-27 01:37:50,174 [IPC Server handler 83 on default port 9862] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:118)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-07-27 01:38:15,468 [IPC Server handler 16 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /legacy/source-bucket/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2020-07-27 01:38:15,468 [IPC Server handler 16 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket legacy/source-bucket
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey2. Entity too small.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:217)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 2020-07-27 01:38:16,454 [IPC Server handler 20 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /legacy/source-bucket/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
om_1        | partName: "etag1"
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
om_1        | , partNumber: 2
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
om_1        | partName: "etag2"
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
om_1        | ]
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
om_1        | 2020-07-27 01:38:16,455 [IPC Server handler 20 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket legacy/source-bucket
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:157)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 2020-07-27 01:38:16,911 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | <Error>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       |   <Code>InvalidPart</Code>
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       |   <Resource>multipartKey3</Resource>
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | </Error>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 2020-07-27 01:38:22,197 [qtp1939022383-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: link, , key: multipartKey3
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /legacy/source-bucket/multipartKey3104583259580793024
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
om_1        | 2020-07-27 01:38:16,908 [IPC Server handler 62 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /legacy/source-bucket/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
om_1        | partName: "etag1"
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
om_1        | , partNumber: 1
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
om_1        | partName: "etag2"
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
om_1        | ]
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2020-07-27 01:38:16,909 [IPC Server handler 62 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket legacy/source-bucket
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:157)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-07-27 01:38:22,192 [IPC Server handler 76 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket legacy/source-bucket
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /legacy/source-bucket/multipartKey3104583259580793024
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:199)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
om_1        | 2020-07-27 01:38:22,627 [IPC Server handler 60 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket legacy/source-bucket
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /legacy/source-bucket/multipartKey3104583259800338625
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:199)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 2020-07-27 01:38:23,083 [IPC Server handler 65 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /legacy/source-bucket/multipartKey3
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 2020-07-27 01:38:23,083 [IPC Server handler 65 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket legacy/source-bucket
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3 because parts are in Invalid order.
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:38:22,209 [qtp1939022383-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       |   <Resource>multipartKey3</Resource>
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | </Error>
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 2020-07-27 01:38:22,629 [qtp1939022383-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: link, , key: multipartKey3
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /legacy/source-bucket/multipartKey3104583259800338625
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 2020-07-27 01:38:25,544 [IPC Server handler 28 on default port 9862] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket legacy/source-bucket
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: linkkey: multipartKey5
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:131)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 2020-07-27 01:38:22,630 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | <Error>
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       |   <Code>InvalidPart</Code>
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
om_1        | 2020-07-27 01:38:25,973 [IPC Server handler 66 on default port 9862] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:legacy, Bucket:source-bucket, KeymultipartKey. Exception:{}
s3g_1       |   <Resource>multipartKey3</Resource>
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:383)
s3g_1       | </Error>
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:325)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:276)
s3g_1       | 
s3g_1       | 2020-07-27 01:38:23,084 [qtp1939022383-21] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: link, , key: multipartKey3
s3g_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: link key: multipartKey3 because parts are in Invalid order.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 2020-07-27 01:38:23,092 [qtp1939022383-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | <Error>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       |   <Code>InvalidPartOrder</Code>
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       |   <Resource>multipartKey3</Resource>
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | </Error>
om_1        | 2020-07-27 01:39:27,370 [IPC Server handler 19 on default port 9862] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:legacy, Bucket:source-bucket, Key:multidelete/f4.
s3g_1       | 
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
s3g_1       | 2020-07-27 01:38:25,545 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:134)
s3g_1       |   <Code>NoSuchUpload</Code>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-07-27 01:40:02,545 [IPC Server handler 52 on default port 9862] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-81997 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-07-27 01:40:06,745 [IPC Server handler 72 on default port 9862] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:118)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-07-27 01:40:27,629 [IPC Server handler 35 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-14389/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2020-07-27 01:40:27,629 [IPC Server handler 35 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket s3v/bucket-14389
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey2. Entity too small.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:217)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       |   <Resource>random</Resource>
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | </Error>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 2020-07-27 01:38:25,974 [qtp1939022383-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | <Error>
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       |   <Code>NoSuchUpload</Code>
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       |   <Resource>random</Resource>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | </Error>
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 2020-07-27 01:38:57,663 [qtp1939022383-24] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-63441, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 2020-07-27 01:38:57,665 [qtp1939022383-24] INFO endpoint.BucketEndpoint: Location is /destbucket-63441
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 2020-07-27 01:39:03,692 [qtp1939022383-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 2020-07-27 01:40:28,549 [IPC Server handler 58 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-14389/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
s3g_1       | <Error>
om_1        | partName: "etag1"
s3g_1       |   <Code>NoSuchBucket</Code>
om_1        | , partNumber: 2
s3g_1       |   <Message>The specified bucket does not exist</Message>
om_1        | partName: "etag2"
s3g_1       |   <Resource>dfdfdfdfdfnonexistent</Resource>
om_1        | ]
s3g_1       |   <RequestId/>
om_1        | 2020-07-27 01:40:28,550 [IPC Server handler 58 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-14389
s3g_1       | </Error>
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:157)
s3g_1       | 2020-07-27 01:39:04,128 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | <Error>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       |   <Code>NoSuchBucket</Code>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>dfdfdfdfdfnonexistent</Resource>
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | </Error>
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 2020-07-27 01:39:04,967 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | <Error>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       |   <Code>NoSuchKey</Code>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       |   <Message>The specified key does not exist</Message>
s3g_1       |   <Resource>nonnonexistentkey</Resource>
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       |   <RequestId/>
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | </Error>
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 
s3g_1       | 2020-07-27 01:39:20,473 [qtp1939022383-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>link-nosuchbucket</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:39:36,489 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=10000-10000</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:39:40,744 [qtp1939022383-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=0-0</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:39:41,184 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=0-1</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:39:41,606 [qtp1939022383-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=0-10000</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:39:54,507 [qtp1939022383-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-82816, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 2020-07-27 01:39:54,509 [qtp1939022383-17] INFO endpoint.BucketEndpoint: Location is /bucket-82816
om_1        | 2020-07-27 01:40:28,981 [IPC Server handler 2 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-14389/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
s3g_1       | 2020-07-27 01:39:56,752 [qtp1939022383-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-93581, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | partName: "etag1"
s3g_1       | 2020-07-27 01:39:56,754 [qtp1939022383-17] INFO endpoint.BucketEndpoint: Location is /bucket-93581
om_1        | , partNumber: 1
s3g_1       | 2020-07-27 01:40:01,538 [qtp1939022383-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-81997, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | partName: "etag2"
s3g_1       | 2020-07-27 01:40:01,541 [qtp1939022383-17] INFO endpoint.BucketEndpoint: Location is /bucket-81997
om_1        | ]
s3g_1       | 2020-07-27 01:40:02,092 [qtp1939022383-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-83034, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | 2020-07-27 01:40:28,981 [IPC Server handler 2 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-14389
s3g_1       | 2020-07-27 01:40:02,094 [qtp1939022383-17] INFO endpoint.BucketEndpoint: Location is /bucket-83034
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3
s3g_1       | 2020-07-27 01:40:02,544 [qtp1939022383-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-81997, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:157)
s3g_1       | 2020-07-27 01:40:02,546 [qtp1939022383-20] INFO endpoint.BucketEndpoint: Location is /bucket-81997
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 2020-07-27 01:40:03,058 [qtp1939022383-17] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:478)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:426)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:417)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:266)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:96)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:205)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
om_1        | 2020-07-27 01:40:31,648 [IPC Server handler 56 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-14389
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-14389/multipartKey3104583268237967597
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:199)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:40:03,059 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | <Error>
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       |   <Code>InvalidBucketName</Code>
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       |   <Message>The specified bucket is not valid.</Message>
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       |   <Resource>bucket_1</Resource>
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       |   <RequestId/>
om_1        | 2020-07-27 01:40:32,070 [IPC Server handler 8 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-14389
s3g_1       | </Error>
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-14389/multipartKey3104583268290134254
s3g_1       | 
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:199)
s3g_1       | 2020-07-27 01:40:05,191 [qtp1939022383-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-51632, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 2020-07-27 01:40:05,192 [qtp1939022383-20] INFO endpoint.BucketEndpoint: Location is /bucket-51632
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 2020-07-27 01:40:05,714 [qtp1939022383-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-43238, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 2020-07-27 01:40:05,716 [qtp1939022383-20] INFO endpoint.BucketEndpoint: Location is /bucket-43238
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 2020-07-27 01:40:06,747 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | <Error>
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       |   <Code>NoSuchBucket</Code>
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       |   <Message>The specified bucket does not exist</Message>
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       |   <Resource>nosuchbucket</Resource>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | </Error>
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 2020-07-27 01:40:08,889 [qtp1939022383-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-63013, with Versioning false and Storage Type set to DISK and Encryption set to false 
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 2020-07-27 01:40:08,894 [qtp1939022383-20] INFO endpoint.BucketEndpoint: Location is /bucket-63013
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 2020-07-27 01:40:09,916 [qtp1939022383-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om_1        | 2020-07-27 01:40:32,503 [IPC Server handler 58 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-14389/multipartKey3
s3g_1       | <Error>
om_1        | 2020-07-27 01:40:32,504 [IPC Server handler 58 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-14389
s3g_1       |   <Code>NoSuchBucket</Code>
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3 because parts are in Invalid order.
s3g_1       |   <Message>The specified bucket does not exist</Message>
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:174)
s3g_1       |   <Resource>ozonenosuchbucketqqweqwe</Resource>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       |   <RequestId/>
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | </Error>
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 2020-07-27 01:40:09,916 [qtp1939022383-20] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:112)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:72)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-07-27 01:40:34,918 [IPC Server handler 97 on default port 9862] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket s3v/bucket-14389
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-14389key: multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:131)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-07-27 01:40:35,349 [IPC Server handler 49 on default port 9862] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-14389, KeymultipartKey. Exception:{}
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:383)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:325)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:276)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:253)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
om_1        | 2020-07-27 01:41:17,126 [IPC Server handler 49 on default port 9862] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-91292, Key:multidelete/f4.
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:134)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om_1        | 2020-07-27 01:41:40,774 [IPC Server handler 88 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-13453 for user:hadoop
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
om_1        | 2020-07-27 01:42:43,862 [IPC Server handler 95 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-36431 for user:hadoop
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:40:12,212 [qtp1939022383-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-54742, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-07-27 01:40:12,213 [qtp1939022383-17] INFO endpoint.BucketEndpoint: Location is /bucket-54742
s3g_1       | 2020-07-27 01:40:14,866 [qtp1939022383-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-14389, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-07-27 01:40:14,868 [qtp1939022383-20] INFO endpoint.BucketEndpoint: Location is /bucket-14389
s3g_1       | 2020-07-27 01:40:27,630 [qtp1939022383-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-14389, , key: multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey2. Entity too small.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:40:27,631 [qtp1939022383-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>EntityTooSmall</Code>
s3g_1       |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
s3g_1       |   <Resource>multipartKey2</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:28,550 [qtp1939022383-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-14389, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:40:28,551 [qtp1939022383-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:28,982 [qtp1939022383-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-14389, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:40:28,989 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:31,649 [qtp1939022383-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-14389, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-14389/multipartKey3104583268237967597
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:40:31,650 [qtp1939022383-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:32,070 [qtp1939022383-17] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-14389, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-14389/multipartKey3104583268290134254
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:40:32,071 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:32,504 [qtp1939022383-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-14389, , key: multipartKey3
s3g_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-14389 key: multipartKey3 because parts are in Invalid order.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:593)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:911)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:936)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:531)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1645)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-07-27 01:40:32,505 [qtp1939022383-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPartOrder</Code>
s3g_1       |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
s3g_1       |   <Resource>multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:34,919 [qtp1939022383-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchUpload</Code>
s3g_1       |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1       |   <Resource>random</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:35,351 [qtp1939022383-17] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchUpload</Code>
s3g_1       |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1       |   <Resource>random</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:55,851 [qtp1939022383-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-26181, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-07-27 01:40:55,852 [qtp1939022383-21] INFO endpoint.BucketEndpoint: Location is /bucket-26181
s3g_1       | 2020-07-27 01:40:56,266 [qtp1939022383-19] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-51922, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-07-27 01:40:56,268 [qtp1939022383-19] INFO endpoint.BucketEndpoint: Location is /destbucket-51922
s3g_1       | 2020-07-27 01:40:59,506 [qtp1939022383-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:40:59,930 [qtp1939022383-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:41:00,773 [qtp1939022383-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchKey</Code>
s3g_1       |   <Message>The specified key does not exist</Message>
s3g_1       |   <Resource>nonnonexistentkey</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:41:02,959 [qtp1939022383-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-74259, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-07-27 01:41:02,961 [qtp1939022383-21] INFO endpoint.BucketEndpoint: Location is /bucket-74259
s3g_1       | 2020-07-27 01:41:11,612 [qtp1939022383-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>bucket-74259-nosuchbucket</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:41:13,770 [qtp1939022383-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-91292, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-07-27 01:41:13,771 [qtp1939022383-21] INFO endpoint.BucketEndpoint: Location is /bucket-91292
s3g_1       | 2020-07-27 01:41:19,703 [qtp1939022383-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-74887, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-07-27 01:41:19,707 [qtp1939022383-19] INFO endpoint.BucketEndpoint: Location is /bucket-74887
s3g_1       | 2020-07-27 01:41:24,233 [qtp1939022383-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=10000-10000</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:41:28,419 [qtp1939022383-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=0-0</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:41:28,843 [qtp1939022383-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=0-1</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:41:29,269 [qtp1939022383-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=0-10000</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-07-27 01:41:31,437 [qtp1939022383-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-65874, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-07-27 01:41:31,439 [qtp1939022383-21] INFO endpoint.BucketEndpoint: Location is /bucket-65874
