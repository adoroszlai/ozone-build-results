Attaching to ozone-topology_datanode_2_1, ozone-topology_datanode_4_1, ozone-topology_datanode_6_1, ozone-topology_datanode_1_1, ozone-topology_om_1, ozone-topology_scm_1, ozone-topology_datanode_3_1, ozone-topology_datanode_5_1
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-07-15 07:05:21,427 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = 819d7666626c/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:41Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-07-15 07:05:21,532 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-07-15 07:05:23,438 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-07-15 07:05:24,544 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-07-15 07:05:25,490 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-07-15 07:05:25,493 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-07-15 07:05:26,117 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:819d7666626c ip:10.5.0.4
datanode_1_1  | 2020-07-15 07:05:27,189 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-07-15 07:05:27,234 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-07-15 07:05:27,267 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-07-15 07:05:27,393 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-07-15 07:05:27,811 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-07-15 07:05:35,764 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-07-15 07:05:36,127 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-07-15 07:05:37,354 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-07-15 07:05:37,355 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-07-15 07:05:37,360 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-15 07:05:37,363 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-07-15 07:05:37,365 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-07-15 07:05:38,659 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-15 07:05:40,258 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-07-15 07:05:40,441 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-07-15 07:05:40,709 [main] INFO util.log: Logging initialized @27375ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-07-15 07:05:41,569 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-07-15 07:05:41,594 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-07-15 07:05:41,622 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-07-15 07:05:41,635 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-07-15 07:05:41,635 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-07-15 07:05:41,653 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-07-15 07:05:41,966 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-07-15 07:05:42,034 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-07-15 07:05:42,036 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-07-15 07:05:42,343 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-07-15 07:05:42,343 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-07-15 07:05:42,362 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1_1  | 2020-07-15 07:05:42,447 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4948daec{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-07-15 07:05:42,447 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5c573229{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-07-15 07:05:43,278 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4ffa7041{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-1610127163289495426.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-07-15 07:05:43,342 [main] INFO server.AbstractConnector: Started ServerConnector@285bf5ac{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-07-15 07:05:43,342 [main] INFO server.Server: Started @30024ms
datanode_1_1  | 2020-07-15 07:05:43,362 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-07-15 07:05:43,366 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-07-15 07:05:43,380 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-07-15 07:05:43,525 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b8cefe3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-07-15 07:05:44,967 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-07-15 07:05:47,101 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-15 07:05:48,102 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-15 07:05:49,103 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-15 07:05:50,104 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-15 07:05:51,105 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-07-15 07:05:52,526 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-07-15 07:05:52,550 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-07-15 07:05:52,555 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c at port 9858
datanode_1_1  | 2020-07-15 07:05:52,714 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: start RPC server
datanode_1_1  | 2020-07-15 07:05:53,226 [Datanode State Machine Thread - 0] INFO server.GrpcService: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-07-15 07:06:03,856 [grpc-default-executor-0] INFO impl.RaftServerProxy: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: addNew group-0F98F1DD7B15:[a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858] returns group-0F98F1DD7B15:java.util.concurrent.CompletableFuture@2b97d737[Not completed]
datanode_1_1  | 2020-07-15 07:06:04,041 [pool-19-thread-1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: new RaftServerImpl for group-0F98F1DD7B15:[a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-07-15 07:06:04,068 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-07-15 07:06:04,069 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-07-15 07:06:04,070 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-07-15 07:06:04,085 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-07-15 07:06:04,094 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-07-15 07:06:04,155 [pool-19-thread-1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15: ConfigurationManager, init=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-07-15 07:06:04,155 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-15 07:06:04,197 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-07-15 07:06:04,202 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15 does not exist. Creating ...
datanode_1_1  | 2020-07-15 07:06:04,274 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15/in_use.lock acquired by nodename 7@819d7666626c
datanode_1_1  | 2020-07-15 07:06:04,292 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15 has been successfully formatted.
datanode_1_1  | 2020-07-15 07:06:04,406 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0F98F1DD7B15: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-07-15 07:06:04,414 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-07-15 07:06:04,444 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-07-15 07:06:04,560 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-07-15 07:06:04,567 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-15 07:06:04,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-15 07:06:04,644 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15
datanode_1_1  | 2020-07-15 07:06:04,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-15 07:06:04,860 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15
datanode_1_1  | 2020-07-15 07:06:04,886 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-07-15 07:06:04,903 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-15 07:06:04,904 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-15 07:06:04,918 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-07-15 07:06:04,920 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-15 07:06:04,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-07-15 07:06:04,934 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-07-15 07:06:04,945 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-07-15 07:06:04,986 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-07-15 07:06:05,139 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-07-15 07:06:05,160 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-15 07:06:05,160 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-15 07:06:05,213 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-07-15 07:06:05,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-07-15 07:06:05,225 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-07-15 07:06:05,329 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-07-15 07:06:05,340 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-07-15 07:06:06,016 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15
datanode_1_1  | 2020-07-15 07:06:06,083 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15
datanode_1_1  | 2020-07-15 07:06:06,221 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: Failed requestVote 43e178db-63b6-424e-a7a3-b59ab147be00->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c#0: org.apache.ratis.protocol.ServerNotReadyException: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15 is not in [RUNNING]: current state is NEW
datanode_1_1  | 2020-07-15 07:06:06,248 [pool-19-thread-1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15: start as a follower, conf=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null
datanode_1_1  | 2020-07-15 07:06:06,252 [pool-19-thread-1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-07-15 07:06:06,265 [pool-19-thread-1] INFO impl.RoleInfo: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: start FollowerState
datanode_1_1  | 2020-07-15 07:06:06,341 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F98F1DD7B15,id=a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c
datanode_1_1  | 2020-07-15 07:06:06,343 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15
datanode_1_1  | 2020-07-15 07:06:07,441 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0F98F1DD7B15 with new leaderId: 43e178db-63b6-424e-a7a3-b59ab147be00
datanode_1_1  | 2020-07-15 07:06:07,442 [grpc-default-executor-0] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15: change Leader from null to 43e178db-63b6-424e-a7a3-b59ab147be00 at term 1 for appendEntries, leader elected after 3027ms
datanode_1_1  | 2020-07-15 07:06:07,444 [grpc-default-executor-0] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_1_1  | 2020-07-15 07:06:07,494 [grpc-default-executor-0] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15: inconsistency entries. Reply:43e178db-63b6-424e-a7a3-b59ab147be00<-a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c#2:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_1_1  | 2020-07-15 07:06:07,568 [grpc-default-executor-0] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15: set configuration 0: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null at 0
datanode_1_1  | 2020-07-15 07:06:07,587 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-07-15 07:06:07,770 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-0F98F1DD7B15-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15/current/log_inprogress_0
datanode_1_1  | 2020-07-15 07:06:26,850 [pool-19-thread-1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: new RaftServerImpl for group-6A323CDAE2AE:[a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-07-15 07:06:26,850 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-07-15 07:06:26,850 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-07-15 07:06:26,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-07-15 07:06:26,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-07-15 07:06:26,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-07-15 07:06:26,851 [pool-19-thread-1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE: ConfigurationManager, init=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-07-15 07:06:26,853 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-07-15 07:06:26,853 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-07-15 07:06:26,853 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/5ee2711e-67fc-4e31-84cc-6a323cdae2ae does not exist. Creating ...
datanode_1_1  | 2020-07-15 07:06:26,856 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5ee2711e-67fc-4e31-84cc-6a323cdae2ae/in_use.lock acquired by nodename 7@819d7666626c
datanode_1_1  | 2020-07-15 07:06:26,857 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/5ee2711e-67fc-4e31-84cc-6a323cdae2ae has been successfully formatted.
datanode_1_1  | 2020-07-15 07:06:26,858 [Command processor thread] INFO impl.RaftServerProxy: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: addNew group-6A323CDAE2AE:[a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858] returns group-6A323CDAE2AE:java.util.concurrent.CompletableFuture@76bf81ac[Not completed]
datanode_1_1  | 2020-07-15 07:06:26,859 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-6A323CDAE2AE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-07-15 07:06:26,859 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-07-15 07:06:26,859 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-07-15 07:06:26,860 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-07-15 07:06:26,867 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-07-15 07:06:26,868 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-15 07:06:26,869 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE
datanode_1_1  | 2020-07-15 07:06:26,869 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-07-15 07:06:26,869 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/5ee2711e-67fc-4e31-84cc-6a323cdae2ae
datanode_1_1  | 2020-07-15 07:06:26,869 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-07-15 07:06:26,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-15 07:06:26,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-07-15 07:06:26,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-07-15 07:06:26,879 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-07-15 07:06:26,879 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-07-15 07:05:21,584 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = 70787d4c1dab/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:41Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-07-15 07:05:21,692 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-07-15 07:05:23,995 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-07-15 07:05:25,269 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-07-15 07:05:26,681 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-07-15 07:05:26,681 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-07-15 07:05:27,325 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:70787d4c1dab ip:10.5.0.5
datanode_2_1  | 2020-07-15 07:05:28,223 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-07-15 07:05:28,234 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-07-15 07:05:28,244 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-07-15 07:05:28,354 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-07-15 07:05:28,725 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-07-15 07:05:35,901 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-07-15 07:05:36,723 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-07-15 07:05:38,102 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-07-15 07:05:38,110 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-07-15 07:05:38,111 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-15 07:05:38,121 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-07-15 07:05:38,122 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-07-15 07:05:39,604 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-15 07:05:41,581 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-07-15 07:05:41,764 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-07-15 07:05:41,955 [main] INFO util.log: Logging initialized @28452ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-07-15 07:05:42,648 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-07-15 07:05:42,683 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-07-15 07:05:42,727 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-07-15 07:05:42,736 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-07-15 07:05:42,749 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-07-15 07:05:42,755 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-07-15 07:05:42,963 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-07-15 07:05:43,012 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-07-15 07:05:43,029 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-07-15 07:05:43,456 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-07-15 07:05:43,456 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-07-15 07:05:43,481 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2_1  | 2020-07-15 07:05:43,565 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4948daec{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-07-15 07:05:43,566 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5c573229{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-07-15 07:05:44,386 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4ffa7041{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16615919069259961648.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-07-15 07:05:44,438 [main] INFO server.AbstractConnector: Started ServerConnector@285bf5ac{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-07-15 07:05:44,439 [main] INFO server.Server: Started @30935ms
datanode_2_1  | 2020-07-15 07:05:44,481 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-07-15 07:05:44,481 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-07-15 07:05:44,487 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-07-15 07:05:44,633 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e3a7339] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-07-15 07:05:45,878 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-07-15 07:05:48,196 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-15 07:05:49,197 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-15 07:05:50,198 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-07-15 07:05:51,229 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-07-15 07:05:21,793 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = 5ac886a109f0/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_5_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-07-15 07:05:23,613 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = 96831866e4b8/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:41Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-07-15 07:05:21,883 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5_1  | 2020-07-15 07:05:24,096 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-07-15 07:05:25,213 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-07-15 07:05:26,725 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-07-15 07:05:26,726 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-07-15 07:05:27,663 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:5ac886a109f0 ip:10.5.0.8
datanode_5_1  | 2020-07-15 07:05:28,818 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-07-15 07:05:28,874 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-07-15 07:05:28,926 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-07-15 07:05:29,013 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-07-15 07:05:29,417 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-07-15 07:05:37,494 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-07-15 07:05:38,170 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-07-15 07:05:39,368 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-07-15 07:05:39,394 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-07-15 07:05:39,402 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-15 07:05:39,404 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-07-15 07:05:39,422 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-07-15 07:05:40,684 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-15 07:05:42,681 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-07-15 07:05:42,847 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-07-15 07:05:43,065 [main] INFO util.log: Logging initialized @29524ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-07-15 07:05:43,781 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-07-15 07:05:43,825 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-07-15 07:05:43,889 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-07-15 07:05:43,914 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-07-15 07:05:43,923 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-07-15 07:05:43,930 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-07-15 07:05:44,502 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-07-15 07:05:44,582 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-07-15 07:05:44,598 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-07-15 07:05:44,933 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-07-15 07:05:44,937 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-07-15 07:05:44,943 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_5_1  | 2020-07-15 07:05:45,003 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4948daec{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-07-15 07:05:45,030 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5c573229{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-07-15 07:05:45,751 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4ffa7041{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-8439464399259272563.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-07-15 07:05:45,808 [main] INFO server.AbstractConnector: Started ServerConnector@285bf5ac{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-07-15 07:05:45,808 [main] INFO server.Server: Started @32267ms
datanode_5_1  | 2020-07-15 07:05:45,858 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-07-15 07:05:45,858 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-07-15 07:05:45,862 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-07-15 07:05:46,143 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6505e11d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-07-15 07:05:47,355 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-07-15 07:05:49,508 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-07-15 07:05:50,511 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-07-15 07:05:51,549 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5_1  | java.net.SocketTimeoutException: Call From 5ac886a109f0/10.5.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:54292 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1_1  | 2020-07-15 07:06:26,879 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-07-15 07:06:26,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-07-15 07:06:26,882 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-07-15 07:06:26,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-07-15 07:06:26,891 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-15 07:06:26,891 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-07-15 07:06:26,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-07-15 07:06:26,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-07-15 07:06:26,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-07-15 07:06:26,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-07-15 07:06:26,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-07-15 07:06:26,898 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE
datanode_1_1  | 2020-07-15 07:06:26,899 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE
datanode_1_1  | 2020-07-15 07:06:26,900 [pool-19-thread-1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE: start as a follower, conf=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858], old=null
datanode_1_1  | 2020-07-15 07:06:26,900 [pool-19-thread-1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-07-15 07:06:26,900 [pool-19-thread-1] INFO impl.RoleInfo: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: start FollowerState
datanode_1_1  | 2020-07-15 07:06:26,902 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A323CDAE2AE,id=a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c
datanode_1_1  | 2020-07-15 07:06:26,902 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE
datanode_1_1  | 2020-07-15 07:06:26,913 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "5ee2711e-67fc-4e31-84cc-6a323cdae2ae"
datanode_1_1  | uuid128 {
datanode_1_1  |   mostSigBits: 6837151559709380145
datanode_1_1  |   leastSigBits: -8877604001452203346
datanode_1_1  | }
datanode_1_1  | .
datanode_1_1  | 2020-07-15 07:06:31,907 [Thread-40] INFO impl.FollowerState: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-FollowerState: change to CANDIDATE, lastRpcTime:5007ms, electionTimeout:5005ms
datanode_1_1  | 2020-07-15 07:06:31,908 [Thread-40] INFO impl.RoleInfo: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: shutdown FollowerState
datanode_1_1  | 2020-07-15 07:06:31,908 [Thread-40] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-07-15 07:06:31,910 [Thread-40] INFO impl.RoleInfo: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: start LeaderElection
datanode_1_1  | 2020-07-15 07:06:31,913 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO impl.LeaderElection: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1: begin an election at term 1 for -1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858], old=null
datanode_1_1  | 2020-07-15 07:06:31,915 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO impl.RoleInfo: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: shutdown LeaderElection
datanode_1_1  | 2020-07-15 07:06:31,915 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-07-15 07:06:31,915 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6A323CDAE2AE with new leaderId: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c
datanode_1_1  | 2020-07-15 07:06:31,915 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE: change Leader from null to a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c at term 1 for becomeLeader, leader elected after 5056ms
datanode_1_1  | 2020-07-15 07:06:31,920 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-07-15 07:06:31,920 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-07-15 07:06:31,922 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE
datanode_1_1  | 2020-07-15 07:06:31,924 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-07-15 07:06:31,925 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-07-15 07:06:31,933 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-07-15 07:06:31,934 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-07-15 07:06:31,934 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-07-15 07:06:31,939 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO impl.RoleInfo: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: start LeaderState
datanode_1_1  | 2020-07-15 07:06:31,942 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-07-15 07:06:31,943 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-LeaderElection1] INFO impl.RaftServerImpl: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE: set configuration 0: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-07-15 07:06:31,946 [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c@group-6A323CDAE2AE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5ee2711e-67fc-4e31-84cc-6a323cdae2ae/current/log_inprogress_0
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_5_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:54292 remote=scm/10.5.0.71:9861]
datanode_5_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_5_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_5_1  | 2020-07-15 07:05:52,527 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-07-15 07:05:52,547 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-07-15 07:05:52,553 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 43e178db-63b6-424e-a7a3-b59ab147be00 at port 9858
datanode_5_1  | 2020-07-15 07:05:52,661 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 43e178db-63b6-424e-a7a3-b59ab147be00: start RPC server
datanode_5_1  | 2020-07-15 07:05:53,174 [Datanode State Machine Thread - 1] INFO server.GrpcService: 43e178db-63b6-424e-a7a3-b59ab147be00: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-07-15 07:05:57,424 [Command processor thread] INFO impl.RaftServerProxy: 43e178db-63b6-424e-a7a3-b59ab147be00: addNew group-F568B3C08038:[43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858] returns group-F568B3C08038:java.util.concurrent.CompletableFuture@788d87d9[Not completed]
datanode_5_1  | 2020-07-15 07:05:57,590 [pool-19-thread-1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00: new RaftServerImpl for group-F568B3C08038:[43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-07-15 07:05:57,598 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-07-15 07:05:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-15 07:05:57,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-07-15 07:05:57,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-07-15 07:05:57,612 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-15 07:05:57,651 [pool-19-thread-1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038: ConfigurationManager, init=-1: [43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-07-15 07:05:57,669 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-15 07:05:57,696 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-07-15 07:05:57,702 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fc02d72e-98dd-4822-bd77-f568b3c08038 does not exist. Creating ...
datanode_5_1  | 2020-07-15 07:05:57,738 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fc02d72e-98dd-4822-bd77-f568b3c08038/in_use.lock acquired by nodename 6@5ac886a109f0
datanode_5_1  | 2020-07-15 07:05:57,742 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fc02d72e-98dd-4822-bd77-f568b3c08038 has been successfully formatted.
datanode_5_1  | 2020-07-15 07:05:57,798 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-F568B3C08038: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-07-15 07:05:57,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-07-15 07:05:57,805 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-07-15 07:05:57,821 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-07-15 07:05:57,837 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-15 07:05:57,839 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-15 07:05:57,866 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038
datanode_5_1  | 2020-07-15 07:05:57,948 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:41Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-07-15 07:05:23,765 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-07-15 07:05:25,911 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-07-15 07:05:26,783 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-07-15 07:05:28,230 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-07-15 07:05:28,230 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-07-15 07:05:29,112 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:96831866e4b8 ip:10.5.0.7
datanode_4_1  | 2020-07-15 07:05:30,155 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-07-15 07:05:30,185 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-07-15 07:05:30,218 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-07-15 07:05:30,294 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-07-15 07:05:30,698 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-07-15 07:05:37,892 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-07-15 07:05:38,518 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-07-15 07:05:39,742 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-07-15 07:05:39,743 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-07-15 07:05:39,760 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-15 07:05:39,760 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-07-15 07:05:39,761 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-07-15 07:05:41,336 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-15 07:05:43,222 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-07-15 07:05:43,360 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-07-15 07:05:43,507 [main] INFO util.log: Logging initialized @28517ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-07-15 07:05:44,149 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-07-15 07:05:44,175 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-07-15 07:05:44,222 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-07-15 07:05:44,234 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-07-15 07:05:44,237 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-07-15 07:05:44,241 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-07-15 07:05:44,473 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-07-15 07:05:44,539 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-07-15 07:05:44,546 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-07-15 07:05:44,823 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-07-15 07:05:44,839 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-07-15 07:05:44,852 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_4_1  | 2020-07-15 07:05:45,072 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4948daec{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-07-15 07:05:45,090 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5c573229{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-07-15 07:05:45,718 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4ffa7041{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16339935078408105031.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-07-15 07:05:45,769 [main] INFO server.AbstractConnector: Started ServerConnector@285bf5ac{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-07-15 07:05:45,773 [main] INFO server.Server: Started @30783ms
datanode_4_1  | 2020-07-15 07:05:45,835 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-07-15 07:05:45,835 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-07-15 07:05:45,839 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-07-15 07:05:45,970 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6505e11d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-07-15 07:05:47,207 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-07-15 07:05:49,442 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-15 07:05:50,442 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-07-15 07:05:51,477 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From 96831866e4b8/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:35386 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_4_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:35386 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5_1  | 2020-07-15 07:05:57,974 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fc02d72e-98dd-4822-bd77-f568b3c08038
datanode_5_1  | 2020-07-15 07:05:57,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-07-15 07:05:57,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-15 07:05:57,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-15 07:05:57,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-07-15 07:05:57,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-07-15 07:05:57,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-07-15 07:05:58,008 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-07-15 07:05:58,017 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-07-15 07:05:58,018 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-07-15 07:05:58,081 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-07-15 07:05:58,109 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-15 07:05:58,122 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-15 07:05:58,173 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-07-15 07:05:58,178 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-07-15 07:05:58,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-07-15 07:05:58,203 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-07-15 07:05:58,204 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-15 07:05:58,376 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038
datanode_5_1  | 2020-07-15 07:05:58,384 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038
datanode_5_1  | 2020-07-15 07:05:58,428 [pool-19-thread-1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038: start as a follower, conf=-1: [43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-15 07:05:58,429 [pool-19-thread-1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-07-15 07:05:58,435 [pool-19-thread-1] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: start FollowerState
datanode_5_1  | 2020-07-15 07:05:58,462 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F568B3C08038,id=43e178db-63b6-424e-a7a3-b59ab147be00
datanode_5_1  | 2020-07-15 07:05:58,468 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038
datanode_5_1  | 2020-07-15 07:05:58,613 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "fc02d72e-98dd-4822-bd77-f568b3c08038"
datanode_5_1  | uuid128 {
datanode_5_1  |   mostSigBits: -287430831065184222
datanode_5_1  |   leastSigBits: -4794093448271462344
datanode_5_1  | }
datanode_5_1  | .
datanode_5_1  | 2020-07-15 07:05:58,631 [Command processor thread] INFO impl.RaftServerProxy: 43e178db-63b6-424e-a7a3-b59ab147be00: addNew group-0F98F1DD7B15:[a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858] returns group-0F98F1DD7B15:java.util.concurrent.CompletableFuture@76e8368b[Not completed]
datanode_5_1  | 2020-07-15 07:05:58,706 [pool-19-thread-1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00: new RaftServerImpl for group-0F98F1DD7B15:[a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-07-15 07:05:58,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-07-15 07:05:58,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-15 07:05:58,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-07-15 07:05:58,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-07-15 07:05:58,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-15 07:05:58,723 [pool-19-thread-1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15: ConfigurationManager, init=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-07-15 07:05:58,723 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-07-15 07:05:58,723 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-07-15 07:05:58,741 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15 does not exist. Creating ...
datanode_5_1  | 2020-07-15 07:05:58,763 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15/in_use.lock acquired by nodename 6@5ac886a109f0
datanode_5_1  | 2020-07-15 07:05:58,770 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15 has been successfully formatted.
datanode_5_1  | 2020-07-15 07:05:58,773 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0F98F1DD7B15: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-07-15 07:05:58,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-07-15 07:05:58,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-07-15 07:05:58,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-07-15 07:05:58,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | java.net.SocketTimeoutException: Call From 70787d4c1dab/10.5.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:43240 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:43240 remote=scm/10.5.0.71:9861]
datanode_2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2_1  | 2020-07-15 07:05:52,584 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-07-15 07:05:52,585 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-07-15 07:05:52,606 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 47c0b11d-1167-49f1-92df-2a0b841871d7 at port 9858
datanode_2_1  | 2020-07-15 07:05:52,720 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 47c0b11d-1167-49f1-92df-2a0b841871d7: start RPC server
datanode_2_1  | 2020-07-15 07:05:53,361 [Datanode State Machine Thread - 1] INFO server.GrpcService: 47c0b11d-1167-49f1-92df-2a0b841871d7: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-07-15 07:05:57,966 [Command processor thread] INFO impl.RaftServerProxy: 47c0b11d-1167-49f1-92df-2a0b841871d7: addNew group-A9434E973C8F:[47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858] returns group-A9434E973C8F:java.util.concurrent.CompletableFuture@7c271c15[Not completed]
datanode_2_1  | 2020-07-15 07:05:58,073 [pool-19-thread-1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7: new RaftServerImpl for group-A9434E973C8F:[47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-07-15 07:05:58,082 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-07-15 07:05:58,086 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-15 07:05:58,088 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-07-15 07:05:58,088 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-07-15 07:05:58,089 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-15 07:05:58,110 [pool-19-thread-1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F: ConfigurationManager, init=-1: [47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-07-15 07:05:58,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-15 07:05:58,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-07-15 07:05:58,135 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d6985ba7-a249-4a33-9a53-a9434e973c8f does not exist. Creating ...
datanode_2_1  | 2020-07-15 07:05:58,167 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d6985ba7-a249-4a33-9a53-a9434e973c8f/in_use.lock acquired by nodename 6@70787d4c1dab
datanode_2_1  | 2020-07-15 07:05:58,180 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d6985ba7-a249-4a33-9a53-a9434e973c8f has been successfully formatted.
datanode_2_1  | 2020-07-15 07:05:58,203 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A9434E973C8F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-07-15 07:05:58,274 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-07-15 07:05:58,276 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-07-15 07:05:58,327 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-07-15 07:05:58,336 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-15 07:05:58,359 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-15 07:05:58,386 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F
datanode_2_1  | 2020-07-15 07:05:58,493 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-15 07:05:58,518 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d6985ba7-a249-4a33-9a53-a9434e973c8f
datanode_2_1  | 2020-07-15 07:05:58,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-07-15 07:05:58,527 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-15 07:05:58,528 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-15 07:05:58,542 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-07-15 07:05:58,543 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-07-15 07:05:58,543 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-07-15 07:05:58,552 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-07-15 07:05:58,562 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-07-15 07:05:58,569 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-07-15 07:05:58,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-07-15 07:05:58,932 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-15 07:05:58,933 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-15 07:05:58,998 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-07-15 07:05:59,048 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-07-15 07:05:59,051 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-07-15 07:05:59,052 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-07-15 07:05:59,065 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-07-15 07:05:59,292 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F
datanode_2_1  | 2020-07-15 07:05:59,418 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F
datanode_2_1  | 2020-07-15 07:05:59,457 [pool-19-thread-1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F: start as a follower, conf=-1: [47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-15 07:05:59,463 [pool-19-thread-1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-07-15 07:05:59,465 [pool-19-thread-1] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: start FollowerState
datanode_2_1  | 2020-07-15 07:05:59,508 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A9434E973C8F,id=47c0b11d-1167-49f1-92df-2a0b841871d7
datanode_2_1  | 2020-07-15 07:05:59,517 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F
datanode_2_1  | 2020-07-15 07:05:59,614 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "d6985ba7-a249-4a33-9a53-a9434e973c8f"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: -2983533977592575437
datanode_2_1  |   leastSigBits: -7326326062255227761
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-07-15 07:05:59,614 [Command processor thread] INFO impl.RaftServerProxy: 47c0b11d-1167-49f1-92df-2a0b841871d7: addNew group-BD702AAE76FF:[872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858] returns group-BD702AAE76FF:java.util.concurrent.CompletableFuture@72a6021d[Not completed]
datanode_2_1  | 2020-07-15 07:05:59,645 [pool-19-thread-1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7: new RaftServerImpl for group-BD702AAE76FF:[872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-07-15 07:05:59,658 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-07-15 07:05:59,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-07-15 07:05:59,666 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-07-15 07:05:59,666 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-07-15 07:05:59,666 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-15 07:05:59,666 [pool-19-thread-1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF: ConfigurationManager, init=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-07-15 07:05:59,667 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-07-15 07:05:59,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-07-15 07:05:59,669 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff does not exist. Creating ...
datanode_2_1  | 2020-07-15 07:05:59,679 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff/in_use.lock acquired by nodename 6@70787d4c1dab
datanode_2_1  | 2020-07-15 07:05:59,689 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff has been successfully formatted.
datanode_2_1  | 2020-07-15 07:05:59,689 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-BD702AAE76FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-07-15 07:05:59,690 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-07-15 07:05:59,690 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-07-15 07:05:59,691 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-07-15 07:05:59,691 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_4_1  | 2020-07-15 07:05:52,484 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-07-15 07:05:52,489 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-07-15 07:05:52,501 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e00f9da5-82a4-43be-9dbb-d8c493d15126 at port 9858
datanode_4_1  | 2020-07-15 07:05:52,683 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: e00f9da5-82a4-43be-9dbb-d8c493d15126: start RPC server
datanode_4_1  | 2020-07-15 07:05:53,214 [Datanode State Machine Thread - 1] INFO server.GrpcService: e00f9da5-82a4-43be-9dbb-d8c493d15126: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-07-15 07:06:01,286 [grpc-default-executor-0] INFO impl.RaftServerProxy: e00f9da5-82a4-43be-9dbb-d8c493d15126: addNew group-0F98F1DD7B15:[a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858] returns group-0F98F1DD7B15:java.util.concurrent.CompletableFuture@6e7b09b9[Not completed]
datanode_4_1  | 2020-07-15 07:06:01,361 [pool-19-thread-1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126: new RaftServerImpl for group-0F98F1DD7B15:[a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-15 07:06:01,366 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-07-15 07:06:01,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-07-15 07:06:01,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-07-15 07:06:01,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-15 07:06:01,374 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-15 07:06:01,392 [pool-19-thread-1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15: ConfigurationManager, init=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-07-15 07:06:01,400 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-15 07:06:01,411 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-15 07:06:01,420 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15 does not exist. Creating ...
datanode_4_1  | 2020-07-15 07:06:01,466 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15/in_use.lock acquired by nodename 6@96831866e4b8
datanode_4_1  | 2020-07-15 07:06:01,474 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15 has been successfully formatted.
datanode_4_1  | 2020-07-15 07:06:01,509 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0F98F1DD7B15: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-07-15 07:06:01,512 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-07-15 07:06:01,525 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-07-15 07:06:01,541 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-07-15 07:06:01,545 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-15 07:06:01,548 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-15 07:06:01,589 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15
datanode_5_1  | 2020-07-15 07:05:58,789 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-15 07:05:58,790 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15
datanode_5_1  | 2020-07-15 07:05:58,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-07-15 07:05:58,813 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15
datanode_5_1  | 2020-07-15 07:05:58,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-07-15 07:05:58,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-15 07:05:58,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-07-15 07:05:58,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-07-15 07:05:58,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-07-15 07:05:58,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-07-15 07:05:58,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-07-15 07:05:58,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-07-15 07:05:58,833 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-07-15 07:05:58,850 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-07-15 07:05:58,851 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-15 07:05:58,874 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-07-15 07:05:58,879 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-07-15 07:05:58,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-07-15 07:05:58,884 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-07-15 07:05:58,884 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-07-15 07:05:58,884 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-07-15 07:05:58,884 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15
datanode_5_1  | 2020-07-15 07:05:58,885 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15
datanode_5_1  | 2020-07-15 07:05:58,895 [pool-19-thread-1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15: start as a follower, conf=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null
datanode_5_1  | 2020-07-15 07:05:58,898 [pool-19-thread-1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-07-15 07:05:58,899 [pool-19-thread-1] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: start FollowerState
datanode_5_1  | 2020-07-15 07:05:58,907 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F98F1DD7B15,id=43e178db-63b6-424e-a7a3-b59ab147be00
datanode_5_1  | 2020-07-15 07:05:58,907 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15
datanode_5_1  | 2020-07-15 07:06:03,505 [Thread-23] INFO impl.FollowerState: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-FollowerState: change to CANDIDATE, lastRpcTime:5070ms, electionTimeout:5044ms
datanode_5_1  | 2020-07-15 07:06:03,507 [Thread-23] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: shutdown FollowerState
datanode_5_1  | 2020-07-15 07:06:03,507 [Thread-23] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-07-15 07:06:03,510 [Thread-23] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: start LeaderElection
datanode_5_1  | 2020-07-15 07:06:03,515 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO impl.LeaderElection: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1: begin an election at term 1 for -1: [43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858], old=null
datanode_5_1  | 2020-07-15 07:06:03,516 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: shutdown LeaderElection
datanode_5_1  | 2020-07-15 07:06:03,516 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-07-15 07:06:03,516 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F568B3C08038 with new leaderId: 43e178db-63b6-424e-a7a3-b59ab147be00
datanode_5_1  | 2020-07-15 07:06:03,525 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038: change Leader from null to 43e178db-63b6-424e-a7a3-b59ab147be00 at term 1 for becomeLeader, leader elected after 5717ms
datanode_5_1  | 2020-07-15 07:06:03,544 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-07-15 07:06:03,544 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-07-15 07:06:03,547 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038
datanode_5_1  | 2020-07-15 07:06:03,579 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-15 07:06:03,583 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-07-15 07:06:03,621 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-07-15 07:06:03,653 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-07-15 07:06:01,649 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-07-15 07:06:01,697 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15
datanode_4_1  | 2020-07-15 07:06:01,714 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-07-15 07:06:01,734 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-15 07:06:01,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-15 07:06:01,741 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-07-15 07:06:01,742 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-07-15 07:06:01,742 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-07-15 07:06:01,744 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-07-15 07:06:01,759 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-07-15 07:06:01,762 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-07-15 07:06:01,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-07-15 07:06:01,952 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-15 07:06:01,953 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-15 07:06:02,064 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-07-15 07:06:02,065 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-07-15 07:06:02,068 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-07-15 07:06:02,089 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-07-15 07:06:02,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-07-15 07:06:02,220 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15
datanode_4_1  | 2020-07-15 07:06:02,236 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15
datanode_4_1  | 2020-07-15 07:06:02,299 [pool-19-thread-1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15: start as a follower, conf=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null
datanode_4_1  | 2020-07-15 07:06:02,303 [pool-19-thread-1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-07-15 07:06:02,312 [pool-19-thread-1] INFO impl.RoleInfo: e00f9da5-82a4-43be-9dbb-d8c493d15126: start FollowerState
datanode_4_1  | 2020-07-15 07:06:02,336 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F98F1DD7B15,id=e00f9da5-82a4-43be-9dbb-d8c493d15126
datanode_4_1  | 2020-07-15 07:06:02,339 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15
datanode_4_1  | 2020-07-15 07:06:04,314 [grpc-default-executor-0] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:43e178db-63b6-424e-a7a3-b59ab147be00
datanode_4_1  | 2020-07-15 07:06:04,321 [grpc-default-executor-0] INFO impl.RoleInfo: e00f9da5-82a4-43be-9dbb-d8c493d15126: shutdown FollowerState
datanode_4_1  | 2020-07-15 07:06:04,322 [Thread-23] INFO impl.FollowerState: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 2020-07-15 07:06:04,325 [grpc-default-executor-0] INFO impl.RoleInfo: e00f9da5-82a4-43be-9dbb-d8c493d15126: start FollowerState
datanode_4_1  | 2020-07-15 07:06:04,957 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0F98F1DD7B15 with new leaderId: 43e178db-63b6-424e-a7a3-b59ab147be00
datanode_4_1  | 2020-07-15 07:06:04,957 [grpc-default-executor-0] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15: change Leader from null to 43e178db-63b6-424e-a7a3-b59ab147be00 at term 1 for appendEntries, leader elected after 3447ms
datanode_4_1  | 2020-07-15 07:06:05,065 [grpc-default-executor-0] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15: set configuration 0: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-07-15 07:06:05,162 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-07-15 07:06:05,730 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0F98F1DD7B15-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15/current/log_inprogress_0
datanode_4_1  | 2020-07-15 07:06:27,108 [Command processor thread] INFO impl.RaftServerProxy: e00f9da5-82a4-43be-9dbb-d8c493d15126: addNew group-0AE5FF2D7A2B:[e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858] returns group-0AE5FF2D7A2B:java.util.concurrent.CompletableFuture@4d955a65[Not completed]
datanode_4_1  | 2020-07-15 07:06:27,110 [pool-19-thread-1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126: new RaftServerImpl for group-0AE5FF2D7A2B:[e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-07-15 07:06:27,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-07-15 07:06:27,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-07-15 07:06:27,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-07-15 07:06:27,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-07-15 07:06:27,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-07-15 07:06:27,111 [pool-19-thread-1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B: ConfigurationManager, init=-1: [e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-07-15 07:05:23,129 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = f99813282669/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:41Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-07-15 07:05:23,215 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-07-15 07:05:25,538 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-07-15 07:05:26,459 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-07-15 07:05:27,847 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-07-15 07:05:27,847 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-07-15 07:05:28,564 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f99813282669 ip:10.5.0.6
datanode_3_1  | 2020-07-15 07:05:29,582 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-07-15 07:05:29,603 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-07-15 07:05:29,655 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-07-15 07:05:29,695 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-07-15 07:05:30,148 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-07-15 07:05:37,331 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-07-15 07:05:37,950 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-07-15 07:05:39,082 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-07-15 07:05:39,111 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-07-15 07:05:39,112 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-15 07:05:39,112 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-07-15 07:05:39,125 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-07-15 07:05:41,363 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-15 07:05:43,066 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-07-15 07:05:43,247 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-07-15 07:05:43,439 [main] INFO util.log: Logging initialized @29232ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-07-15 07:05:44,192 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-07-15 07:05:44,224 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-07-15 07:05:44,265 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-07-15 07:05:44,279 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-07-15 07:05:44,302 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-07-15 07:05:44,302 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-07-15 07:05:44,535 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-07-15 07:05:44,589 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-07-15 07:05:44,627 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-07-15 07:05:44,889 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-07-15 07:05:44,889 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-07-15 07:05:44,902 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3_1  | 2020-07-15 07:05:45,001 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@502c2278{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-07-15 07:05:45,006 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ecdc2b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-07-15 07:05:45,706 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@632c3f55{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13596099295892690927.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-07-15 07:05:45,778 [main] INFO server.AbstractConnector: Started ServerConnector@3739f3c9{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-07-15 07:05:45,778 [main] INFO server.Server: Started @31571ms
datanode_3_1  | 2020-07-15 07:05:45,797 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-07-15 07:05:45,797 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-07-15 07:05:45,803 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-07-15 07:05:46,010 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2838996c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-07-15 07:05:47,087 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-07-15 07:05:49,344 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-15 07:05:50,345 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-07-15 07:05:51,363 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3_1  | java.net.SocketTimeoutException: Call From f99813282669/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:42066 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 2020-07-15 07:05:59,693 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-15 07:05:59,693 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF
datanode_2_1  | 2020-07-15 07:05:59,696 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-07-15 07:05:59,700 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff
datanode_2_1  | 2020-07-15 07:05:59,700 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-07-15 07:05:59,700 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-15 07:05:59,700 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-07-15 07:05:59,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-07-15 07:05:59,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-07-15 07:05:59,704 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-07-15 07:05:59,704 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-07-15 07:05:59,704 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-07-15 07:05:59,708 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-07-15 07:05:59,718 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-07-15 07:05:59,719 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-15 07:05:59,721 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-07-15 07:05:59,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-07-15 07:05:59,730 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-07-15 07:05:59,730 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-07-15 07:05:59,730 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-07-15 07:05:59,731 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-07-15 07:05:59,733 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF
datanode_2_1  | 2020-07-15 07:05:59,734 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF
datanode_2_1  | 2020-07-15 07:05:59,735 [pool-19-thread-1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF: start as a follower, conf=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-15 07:05:59,741 [pool-19-thread-1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-07-15 07:05:59,741 [pool-19-thread-1] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: start FollowerState
datanode_2_1  | 2020-07-15 07:05:59,744 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BD702AAE76FF,id=47c0b11d-1167-49f1-92df-2a0b841871d7
datanode_2_1  | 2020-07-15 07:05:59,744 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF
datanode_2_1  | 2020-07-15 07:06:03,515 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 872ac602-b542-4fd3-a544-ffbd53b46ee2{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_2_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.901691404s. [buffered_nanos=1376418050, remote_addr=/10.5.0.9:9858]
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_2_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_2_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.901691404s. [buffered_nanos=1376418050, remote_addr=/10.5.0.9:9858]
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_2_1  | 	... 18 more
datanode_2_1  | 2020-07-15 07:06:04,545 [Thread-23] INFO impl.FollowerState: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-FollowerState: change to CANDIDATE, lastRpcTime:5079ms, electionTimeout:5048ms
datanode_2_1  | 2020-07-15 07:06:04,547 [Thread-23] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: shutdown FollowerState
datanode_2_1  | 2020-07-15 07:06:04,548 [Thread-23] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-07-15 07:06:04,551 [Thread-23] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: start LeaderElection
datanode_2_1  | 2020-07-15 07:06:04,558 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO impl.LeaderElection: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1: begin an election at term 1 for -1: [47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-15 07:06:04,559 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: shutdown LeaderElection
datanode_2_1  | 2020-07-15 07:06:04,560 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-07-15 07:06:04,560 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A9434E973C8F with new leaderId: 47c0b11d-1167-49f1-92df-2a0b841871d7
datanode_2_1  | 2020-07-15 07:06:04,571 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F: change Leader from null to 47c0b11d-1167-49f1-92df-2a0b841871d7 at term 1 for becomeLeader, leader elected after 6286ms
datanode_2_1  | 2020-07-15 07:06:04,585 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-07-15 07:06:04,603 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-07-15 07:06:04,615 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F
datanode_2_1  | 2020-07-15 07:06:04,633 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-15 07:06:04,636 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-07-15 07:06:04,659 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-07-15 07:06:04,667 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-07-15 07:06:04,668 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-07-15 07:06:04,753 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: start LeaderState
datanode_2_1  | 2020-07-15 07:06:04,829 [Thread-25] INFO impl.FollowerState: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-FollowerState: change to CANDIDATE, lastRpcTime:5087ms, electionTimeout:5084ms
datanode_2_1  | 2020-07-15 07:06:04,832 [Thread-25] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: shutdown FollowerState
datanode_2_1  | 2020-07-15 07:06:04,832 [Thread-25] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-07-15 07:06:04,833 [Thread-25] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: start LeaderElection
datanode_2_1  | 2020-07-15 07:06:04,861 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO impl.LeaderElection: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2: begin an election at term 1 for -1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-15 07:06:04,900 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-07-15 07:06:05,083 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-LeaderElection1] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F: set configuration 0: [47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-07-15 07:06:05,515 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO impl.LeaderElection: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2: Election PASSED; received 1 response(s) [47c0b11d-1167-49f1-92df-2a0b841871d7<-872ac602-b542-4fd3-a544-ffbd53b46ee2#0:OK-t1] and 0 exception(s); 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF:t1, leader=null, voted=47c0b11d-1167-49f1-92df-2a0b841871d7, raftlog=47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null
datanode_2_1  | 2020-07-15 07:06:05,523 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: shutdown LeaderElection
datanode_2_1  | 2020-07-15 07:06:05,523 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-07-15 07:06:05,523 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BD702AAE76FF with new leaderId: 47c0b11d-1167-49f1-92df-2a0b841871d7
datanode_2_1  | 2020-07-15 07:06:05,524 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF: change Leader from null to 47c0b11d-1167-49f1-92df-2a0b841871d7 at term 1 for becomeLeader, leader elected after 5833ms
datanode_2_1  | 2020-07-15 07:06:05,533 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-07-15 07:06:05,537 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:42066 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-07-15 07:05:52,579 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-07-15 07:05:52,581 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-07-15 07:05:52,581 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 02f82674-a0c2-4773-90e8-73ab39d1c5f5 at port 9858
datanode_3_1  | 2020-07-15 07:05:52,686 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: start RPC server
datanode_3_1  | 2020-07-15 07:05:53,246 [Datanode State Machine Thread - 1] INFO server.GrpcService: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-07-15 07:06:05,151 [grpc-default-executor-0] INFO impl.RaftServerProxy: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: addNew group-BD702AAE76FF:[872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858] returns group-BD702AAE76FF:java.util.concurrent.CompletableFuture@2d9192db[Not completed]
datanode_3_1  | 2020-07-15 07:06:05,376 [pool-19-thread-1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: new RaftServerImpl for group-BD702AAE76FF:[872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-07-15 07:06:05,391 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-07-15 07:06:05,410 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-07-15 07:06:05,410 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-07-15 07:06:05,410 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-07-15 07:06:05,411 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-15 07:06:05,475 [pool-19-thread-1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF: ConfigurationManager, init=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-07-15 07:06:05,478 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-15 07:06:05,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-07-15 07:06:05,535 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff does not exist. Creating ...
datanode_3_1  | 2020-07-15 07:06:05,599 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff/in_use.lock acquired by nodename 6@f99813282669
datanode_3_1  | 2020-07-15 07:06:05,617 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff has been successfully formatted.
datanode_3_1  | 2020-07-15 07:06:05,682 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-BD702AAE76FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-07-15 07:06:05,686 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-07-15 07:06:05,691 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-07-15 07:06:05,709 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-07-15 07:06:05,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-15 07:06:05,737 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-15 07:06:05,766 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF
datanode_3_1  | 2020-07-15 07:06:06,096 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-07-15 07:06:06,232 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff
datanode_3_1  | 2020-07-15 07:06:06,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-07-15 07:06:06,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-15 07:06:06,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-15 07:06:06,237 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-07-15 07:06:06,241 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-07-15 07:06:06,245 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-07-15 07:06:06,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-07-15 07:06:06,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-07-15 07:06:06,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-07-15 07:06:06,368 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-07-15 07:06:06,400 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-15 07:06:06,400 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-15 07:06:06,489 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-07-15 07:06:06,490 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-07-15 07:06:06,490 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-07-15 07:06:06,491 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-07-15 07:06:06,491 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-07-15 07:06:06,770 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF
datanode_3_1  | 2020-07-15 07:06:06,784 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF
datanode_3_1  | 2020-07-15 07:06:06,871 [pool-19-thread-1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF: start as a follower, conf=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null
datanode_3_1  | 2020-07-15 07:06:06,873 [pool-19-thread-1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-07-15 07:06:06,882 [pool-19-thread-1] INFO impl.RoleInfo: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: start FollowerState
datanode_3_1  | 2020-07-15 07:06:06,893 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: Failed requestVote 47c0b11d-1167-49f1-92df-2a0b841871d7->02f82674-a0c2-4773-90e8-73ab39d1c5f5#0: org.apache.ratis.protocol.ServerNotReadyException: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF is not in [RUNNING]: current state is STARTING
datanode_3_1  | 2020-07-15 07:06:06,956 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BD702AAE76FF,id=02f82674-a0c2-4773-90e8-73ab39d1c5f5
datanode_3_1  | 2020-07-15 07:06:06,962 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF
datanode_4_1  | 2020-07-15 07:06:27,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-07-15 07:06:27,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-07-15 07:06:27,112 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b does not exist. Creating ...
datanode_4_1  | 2020-07-15 07:06:27,113 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b/in_use.lock acquired by nodename 6@96831866e4b8
datanode_4_1  | 2020-07-15 07:06:27,115 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b has been successfully formatted.
datanode_4_1  | 2020-07-15 07:06:27,118 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0AE5FF2D7A2B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-07-15 07:06:27,118 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-07-15 07:06:27,118 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-07-15 07:06:27,118 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-07-15 07:06:27,119 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-07-15 07:06:27,119 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-15 07:06:27,119 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B
datanode_4_1  | 2020-07-15 07:06:27,119 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-07-15 07:06:27,120 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b
datanode_4_1  | 2020-07-15 07:06:27,120 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-07-15 07:06:27,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-15 07:06:27,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-07-15 07:06:27,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-07-15 07:06:27,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-07-15 07:06:27,123 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-07-15 07:06:27,123 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-07-15 07:06:27,123 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-07-15 07:06:27,123 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-07-15 07:06:27,124 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-07-15 07:06:27,125 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-15 07:06:27,125 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-07-15 07:06:27,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-07-15 07:06:27,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-07-15 07:06:27,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-07-15 07:06:27,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-07-15 07:06:27,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-07-15 07:06:27,127 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B
datanode_4_1  | 2020-07-15 07:06:27,127 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B
datanode_4_1  | 2020-07-15 07:06:27,129 [pool-19-thread-1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B: start as a follower, conf=-1: [e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null
datanode_4_1  | 2020-07-15 07:06:27,130 [pool-19-thread-1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-07-15 07:06:27,130 [pool-19-thread-1] INFO impl.RoleInfo: e00f9da5-82a4-43be-9dbb-d8c493d15126: start FollowerState
datanode_4_1  | 2020-07-15 07:06:27,133 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0AE5FF2D7A2B,id=e00f9da5-82a4-43be-9dbb-d8c493d15126
datanode_4_1  | 2020-07-15 07:06:27,134 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B
datanode_4_1  | 2020-07-15 07:06:27,137 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b"
datanode_4_1  | uuid128 {
datanode_4_1  |   mostSigBits: -499510994900465755
datanode_4_1  |   leastSigBits: -7021381311102354901
datanode_4_1  | }
datanode_4_1  | .
datanode_4_1  | 2020-07-15 07:06:32,239 [Thread-42] INFO impl.FollowerState: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-FollowerState: change to CANDIDATE, lastRpcTime:5109ms, electionTimeout:5103ms
datanode_4_1  | 2020-07-15 07:06:32,240 [Thread-42] INFO impl.RoleInfo: e00f9da5-82a4-43be-9dbb-d8c493d15126: shutdown FollowerState
datanode_4_1  | 2020-07-15 07:06:32,240 [Thread-42] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-07-15 07:06:32,242 [Thread-42] INFO impl.RoleInfo: e00f9da5-82a4-43be-9dbb-d8c493d15126: start LeaderElection
datanode_4_1  | 2020-07-15 07:06:32,245 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO impl.LeaderElection: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1: begin an election at term 1 for -1: [e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null
datanode_4_1  | 2020-07-15 07:06:32,246 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO impl.RoleInfo: e00f9da5-82a4-43be-9dbb-d8c493d15126: shutdown LeaderElection
datanode_4_1  | 2020-07-15 07:06:32,247 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-07-15 07:05:21,057 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = 11847bcd10d2/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:41Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-07-15 07:05:21,122 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-07-15 07:05:23,145 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-07-15 07:05:24,157 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-07-15 07:05:25,586 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-07-15 07:05:25,592 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-07-15 07:05:26,362 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:11847bcd10d2 ip:10.5.0.9
datanode_6_1  | 2020-07-15 07:05:27,436 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-07-15 07:05:27,497 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-07-15 07:05:27,573 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-07-15 07:05:27,599 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-07-15 07:05:28,022 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-07-15 07:05:35,716 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-07-15 07:05:36,271 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-07-15 07:05:37,457 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-07-15 07:05:37,463 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-07-15 07:05:37,470 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-15 07:05:37,481 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-07-15 07:05:37,487 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-07-15 07:05:38,733 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-15 07:05:40,352 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-07-15 07:05:40,473 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 2020-07-15 07:05:40,672 [main] INFO util.log: Logging initialized @27415ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-07-15 07:05:41,586 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-07-15 07:05:41,638 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-07-15 07:05:41,693 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-07-15 07:05:41,699 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_6_1  | 2020-07-15 07:05:41,729 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 2020-07-15 07:05:41,734 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 2020-07-15 07:05:42,022 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-07-15 07:05:42,056 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-07-15 07:05:42,092 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-07-15 07:05:42,374 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-07-15 07:05:42,374 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-07-15 07:05:42,375 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_6_1  | 2020-07-15 07:05:42,498 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4948daec{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-07-15 07:05:42,499 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5c573229{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-07-15 07:05:43,338 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4ffa7041{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4842520342758459106.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-07-15 07:05:43,413 [main] INFO server.AbstractConnector: Started ServerConnector@285bf5ac{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-07-15 07:05:43,414 [main] INFO server.Server: Started @30157ms
datanode_6_1  | 2020-07-15 07:05:43,429 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-07-15 07:05:43,429 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-07-15 07:05:43,442 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-07-15 07:05:43,619 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f2cc290] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-07-15 07:05:45,015 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-07-15 07:05:47,140 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-15 07:05:48,141 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-15 07:05:49,142 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-07-15 07:05:50,143 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-07-15 07:06:03,658 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-07-15 07:06:03,690 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: start LeaderState
datanode_5_1  | 2020-07-15 07:06:03,792 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-07-15 07:06:03,935 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-LeaderElection1] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038: set configuration 0: [43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-07-15 07:06:04,013 [Thread-25] INFO impl.FollowerState: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-FollowerState: change to CANDIDATE, lastRpcTime:5113ms, electionTimeout:5097ms
datanode_5_1  | 2020-07-15 07:06:04,029 [Thread-25] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: shutdown FollowerState
datanode_5_1  | 2020-07-15 07:06:04,030 [Thread-25] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-07-15 07:06:04,030 [Thread-25] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: start LeaderElection
datanode_5_1  | 2020-07-15 07:06:04,082 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO impl.LeaderElection: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2: begin an election at term 1 for -1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null
datanode_5_1  | 2020-07-15 07:06:04,385 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO impl.LeaderElection: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2: Election PASSED; received 1 response(s) [43e178db-63b6-424e-a7a3-b59ab147be00<-e00f9da5-82a4-43be-9dbb-d8c493d15126#0:OK-t1] and 0 exception(s); 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15:t1, leader=null, voted=43e178db-63b6-424e-a7a3-b59ab147be00, raftlog=43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null
datanode_5_1  | 2020-07-15 07:06:04,389 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: shutdown LeaderElection
datanode_5_1  | 2020-07-15 07:06:04,389 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-07-15 07:06:04,389 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0F98F1DD7B15 with new leaderId: 43e178db-63b6-424e-a7a3-b59ab147be00
datanode_5_1  | 2020-07-15 07:06:04,407 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15: change Leader from null to 43e178db-63b6-424e-a7a3-b59ab147be00 at term 1 for becomeLeader, leader elected after 5604ms
datanode_5_1  | 2020-07-15 07:06:04,409 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-07-15 07:06:04,430 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-07-15 07:06:04,431 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15
datanode_5_1  | 2020-07-15 07:06:04,431 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-07-15 07:06:04,431 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-07-15 07:06:04,432 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-07-15 07:06:04,432 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-07-15 07:06:04,432 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-07-15 07:06:04,482 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-07-15 07:06:04,482 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-15 07:06:04,482 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-07-15 07:06:04,485 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-07-15 07:06:04,557 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-07-15 07:06:04,558 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-07-15 07:06:04,558 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15
datanode_5_1  | 2020-07-15 07:06:04,575 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-07-15 07:06:04,587 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-07-15 07:06:04,593 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-07-15 07:06:04,593 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-07-15 07:06:04,593 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-07-15 07:06:04,599 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-15 07:05:51,170 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_6_1  | java.net.SocketTimeoutException: Call From 11847bcd10d2/10.5.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:34028 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_6_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_6_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_6_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:34028 remote=scm/10.5.0.71:9861]
datanode_6_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_6_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_6_1  | 2020-07-15 07:05:52,605 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-07-15 07:05:52,619 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-07-15 07:05:52,634 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 872ac602-b542-4fd3-a544-ffbd53b46ee2 at port 9858
datanode_6_1  | 2020-07-15 07:05:52,758 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 872ac602-b542-4fd3-a544-ffbd53b46ee2: start RPC server
datanode_6_1  | 2020-07-15 07:05:53,358 [Datanode State Machine Thread - 1] INFO server.GrpcService: 872ac602-b542-4fd3-a544-ffbd53b46ee2: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-07-15 07:06:02,286 [grpc-default-executor-0] INFO impl.RaftServerProxy: 872ac602-b542-4fd3-a544-ffbd53b46ee2: addNew group-BD702AAE76FF:[872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858] returns group-BD702AAE76FF:java.util.concurrent.CompletableFuture@4b069ca9[Not completed]
datanode_6_1  | 2020-07-15 07:06:02,341 [pool-19-thread-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2: new RaftServerImpl for group-BD702AAE76FF:[872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-07-15 07:06:02,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-07-15 07:06:02,359 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-07-15 07:06:02,359 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-07-15 07:06:02,362 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-15 07:06:02,363 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-15 07:06:02,380 [pool-19-thread-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF: ConfigurationManager, init=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-07-15 07:06:02,387 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-15 07:06:02,401 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-07-15 07:06:02,410 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff does not exist. Creating ...
datanode_6_1  | 2020-07-15 07:06:02,439 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff/in_use.lock acquired by nodename 6@11847bcd10d2
datanode_6_1  | 2020-07-15 07:06:02,444 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff has been successfully formatted.
datanode_6_1  | 2020-07-15 07:06:02,482 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-BD702AAE76FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-07-15 07:06:02,483 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-07-15 07:06:32,247 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0AE5FF2D7A2B with new leaderId: e00f9da5-82a4-43be-9dbb-d8c493d15126
datanode_4_1  | 2020-07-15 07:06:32,247 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B: change Leader from null to e00f9da5-82a4-43be-9dbb-d8c493d15126 at term 1 for becomeLeader, leader elected after 5128ms
datanode_4_1  | 2020-07-15 07:06:32,252 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-07-15 07:06:32,252 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-07-15 07:06:32,255 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B
datanode_4_1  | 2020-07-15 07:06:32,264 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-07-15 07:06:32,265 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-07-15 07:06:32,269 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-07-15 07:06:32,269 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-07-15 07:06:32,270 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-07-15 07:06:32,274 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO impl.RoleInfo: e00f9da5-82a4-43be-9dbb-d8c493d15126: start LeaderState
datanode_4_1  | 2020-07-15 07:06:32,277 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-07-15 07:06:32,278 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b/current/log_inprogress_0
datanode_4_1  | 2020-07-15 07:06:32,279 [e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B-LeaderElection1] INFO impl.RaftServerImpl: e00f9da5-82a4-43be-9dbb-d8c493d15126@group-0AE5FF2D7A2B: set configuration 0: [e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null at 0
datanode_5_1  | 2020-07-15 07:06:04,636 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO impl.RoleInfo: 43e178db-63b6-424e-a7a3-b59ab147be00: start LeaderState
datanode_5_1  | 2020-07-15 07:06:04,649 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-07-15 07:06:04,679 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-LeaderElection2] INFO impl.RaftServerImpl: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15: set configuration 0: [a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c:10.5.0.4:9858, 43e178db-63b6-424e-a7a3-b59ab147be00:10.5.0.8:9858, e00f9da5-82a4-43be-9dbb-d8c493d15126:10.5.0.7:9858], old=null at 0
datanode_5_1  | 2020-07-15 07:06:04,940 [43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 43e178db-63b6-424e-a7a3-b59ab147be00@group-F568B3C08038-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc02d72e-98dd-4822-bd77-f568b3c08038/current/log_inprogress_0
datanode_5_1  | 2020-07-15 07:06:04,979 [43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/589f6424-c0e1-4cf6-a653-0f98f1dd7b15/current/log_inprogress_0
datanode_5_1  | 2020-07-15 07:06:05,700 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_5_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.989139857s. [buffered_nanos=509223453, remote_addr=/10.5.0.4:9858]
datanode_5_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_5_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_5_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_5_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_5_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_5_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_5_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.989139857s. [buffered_nanos=509223453, remote_addr=/10.5.0.4:9858]
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_5_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_5_1  | 	... 18 more
datanode_5_1  | 2020-07-15 07:06:05,701 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "589f6424-c0e1-4cf6-a653-0f98f1dd7b15"
datanode_5_1  | uuid128 {
datanode_5_1  |   mostSigBits: 6385932905652243702
datanode_5_1  |   leastSigBits: -6461803890779260139
datanode_5_1  | }
datanode_5_1  | .
datanode_5_1  | 2020-07-15 07:06:07,558 [grpc-default-executor-0] INFO impl.FollowerInfo: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c: nextIndex: updateUnconditionally 1 -> 0
datanode_5_1  | 2020-07-15 07:07:07,560 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode_5_1  | 2020-07-15 07:07:18,076 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=8,entriesCount=1,lastEntry=(t:1, i:1)
datanode_5_1  | 2020-07-15 07:07:18,188 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:2)
datanode_5_1  | 2020-07-15 07:07:19,231 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:3)
datanode_5_1  | 2020-07-15 07:07:19,262 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:4)
datanode_5_1  | 2020-07-15 07:07:31,839 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:5)
datanode_3_1  | 2020-07-15 07:06:08,658 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BD702AAE76FF with new leaderId: 47c0b11d-1167-49f1-92df-2a0b841871d7
datanode_3_1  | 2020-07-15 07:06:08,659 [grpc-default-executor-0] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF: change Leader from null to 47c0b11d-1167-49f1-92df-2a0b841871d7 at term 1 for appendEntries, leader elected after 2976ms
datanode_3_1  | 2020-07-15 07:06:08,661 [grpc-default-executor-0] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_3_1  | 2020-07-15 07:06:08,663 [grpc-default-executor-0] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF: inconsistency entries. Reply:47c0b11d-1167-49f1-92df-2a0b841871d7<-02f82674-a0c2-4773-90e8-73ab39d1c5f5#2:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_3_1  | 2020-07-15 07:06:08,716 [grpc-default-executor-0] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF: set configuration 0: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null at 0
datanode_3_1  | 2020-07-15 07:06:08,735 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-07-15 07:06:08,888 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-BD702AAE76FF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff/current/log_inprogress_0
datanode_3_1  | 2020-07-15 07:06:27,240 [Command processor thread] INFO impl.RaftServerProxy: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: addNew group-7BDA907D73D4:[02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858] returns group-7BDA907D73D4:java.util.concurrent.CompletableFuture@243dbe4b[Not completed]
datanode_3_1  | 2020-07-15 07:06:27,244 [pool-19-thread-1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: new RaftServerImpl for group-7BDA907D73D4:[02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-07-15 07:06:27,244 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-07-15 07:06:27,244 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-07-15 07:06:27,244 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-07-15 07:06:27,244 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-15 07:06:02,484 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-07-15 07:06:02,503 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-07-15 07:06:02,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-15 07:06:02,511 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-15 07:06:02,534 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF
datanode_6_1  | 2020-07-15 07:06:02,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-07-15 07:06:02,652 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff
datanode_6_1  | 2020-07-15 07:06:02,661 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-07-15 07:06:02,664 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-15 07:06:02,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-15 07:06:02,677 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-15 07:06:02,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-07-15 07:06:02,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-07-15 07:06:02,682 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-15 07:06:02,682 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-07-15 07:06:02,702 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-07-15 07:06:02,805 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-07-15 07:06:02,853 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-15 07:06:02,853 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-15 07:06:02,985 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-07-15 07:06:03,016 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-15 07:06:03,017 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-07-15 07:06:03,017 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-07-15 07:06:03,036 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-07-15 07:06:03,221 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF
datanode_6_1  | 2020-07-15 07:06:03,239 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF
datanode_6_1  | 2020-07-15 07:06:03,309 [pool-19-thread-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF: start as a follower, conf=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null
datanode_6_1  | 2020-07-15 07:06:03,314 [pool-19-thread-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-07-15 07:06:03,322 [pool-19-thread-1] INFO impl.RoleInfo: 872ac602-b542-4fd3-a544-ffbd53b46ee2: start FollowerState
datanode_6_1  | 2020-07-15 07:06:03,372 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BD702AAE76FF,id=872ac602-b542-4fd3-a544-ffbd53b46ee2
datanode_6_1  | 2020-07-15 07:06:03,388 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF
datanode_6_1  | 2020-07-15 07:06:05,290 [grpc-default-executor-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:47c0b11d-1167-49f1-92df-2a0b841871d7
datanode_6_1  | 2020-07-15 07:06:05,293 [grpc-default-executor-1] INFO impl.RoleInfo: 872ac602-b542-4fd3-a544-ffbd53b46ee2: shutdown FollowerState
datanode_6_1  | 2020-07-15 07:06:05,295 [Thread-23] INFO impl.FollowerState: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 2020-07-15 07:06:05,295 [grpc-default-executor-1] INFO impl.RoleInfo: 872ac602-b542-4fd3-a544-ffbd53b46ee2: start FollowerState
datanode_6_1  | 2020-07-15 07:06:06,115 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BD702AAE76FF with new leaderId: 47c0b11d-1167-49f1-92df-2a0b841871d7
datanode_6_1  | 2020-07-15 07:06:06,156 [grpc-default-executor-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF: change Leader from null to 47c0b11d-1167-49f1-92df-2a0b841871d7 at term 1 for appendEntries, leader elected after 3633ms
datanode_6_1  | 2020-07-15 07:06:06,302 [grpc-default-executor-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF: set configuration 0: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null at 0
datanode_6_1  | 2020-07-15 07:06:06,480 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-15 07:06:06,945 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-BD702AAE76FF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff/current/log_inprogress_0
datanode_6_1  | 2020-07-15 07:06:26,883 [Command processor thread] INFO impl.RaftServerProxy: 872ac602-b542-4fd3-a544-ffbd53b46ee2: addNew group-0965BA38CC31:[872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858] returns group-0965BA38CC31:java.util.concurrent.CompletableFuture@330efe61[Not completed]
datanode_6_1  | 2020-07-15 07:06:26,886 [pool-19-thread-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2: new RaftServerImpl for group-0965BA38CC31:[872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-07-15 07:06:26,886 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-07-15 07:06:26,886 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-07-15 07:07:31,843 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=18,entriesCount=1,lastEntry=(t:1, i:6)
datanode_5_1  | 2020-07-15 07:07:31,859 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:7)
datanode_5_1  | 2020-07-15 07:07:31,872 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:8)
datanode_5_1  | 2020-07-15 07:07:39,547 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:9)
datanode_5_1  | 2020-07-15 07:07:39,556 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:10)
datanode_5_1  | 2020-07-15 07:07:39,572 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:11)
datanode_5_1  | 2020-07-15 07:07:39,585 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:12)
datanode_5_1  | 2020-07-15 07:07:52,485 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=33,entriesCount=1,lastEntry=(t:1, i:13)
datanode_5_1  | 2020-07-15 07:07:52,496 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=34,entriesCount=1,lastEntry=(t:1, i:14)
datanode_5_1  | 2020-07-15 07:07:52,502 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:15)
datanode_5_1  | 2020-07-15 07:07:52,514 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:16)
datanode_5_1  | 2020-07-15 07:07:55,065 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:17)
datanode_5_1  | 2020-07-15 07:07:55,073 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=39,entriesCount=1,lastEntry=(t:1, i:18)
datanode_5_1  | 2020-07-15 07:07:55,090 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:19)
datanode_5_1  | 2020-07-15 07:07:55,105 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:20)
datanode_5_1  | 2020-07-15 07:08:05,403 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:21)
datanode_5_1  | 2020-07-15 07:08:05,412 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:22)
datanode_5_1  | 2020-07-15 07:08:05,447 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=48,entriesCount=1,lastEntry=(t:1, i:23)
datanode_5_1  | 2020-07-15 07:08:05,448 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=49,entriesCount=1,lastEntry=(t:1, i:24)
datanode_5_1  | 2020-07-15 07:08:07,989 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:25)
datanode_5_1  | 2020-07-15 07:08:07,998 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:26)
datanode_5_1  | 2020-07-15 07:08:08,011 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=53,entriesCount=1,lastEntry=(t:1, i:27)
datanode_5_1  | 2020-07-15 07:08:08,019 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=54,entriesCount=1,lastEntry=(t:1, i:28)
datanode_5_1  | 2020-07-15 07:08:23,431 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:29)
datanode_5_1  | 2020-07-15 07:08:23,447 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:30)
datanode_5_1  | 2020-07-15 07:08:23,453 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=63,entriesCount=1,lastEntry=(t:1, i:31)
datanode_5_1  | 2020-07-15 07:08:23,472 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=64,entriesCount=1,lastEntry=(t:1, i:32)
datanode_5_1  | 2020-07-15 07:08:31,181 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=68,entriesCount=1,lastEntry=(t:1, i:33)
datanode_5_1  | 2020-07-15 07:08:31,189 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=69,entriesCount=1,lastEntry=(t:1, i:34)
datanode_5_1  | 2020-07-15 07:08:31,194 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:35)
datanode_5_1  | 2020-07-15 07:08:31,213 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:36)
datanode_5_1  | 2020-07-15 07:08:44,076 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:37)
datanode_5_1  | 2020-07-15 07:08:44,090 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=78,entriesCount=1,lastEntry=(t:1, i:38)
datanode_5_1  | 2020-07-15 07:08:44,128 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:39)
datanode_5_1  | 2020-07-15 07:08:44,130 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:40)
datanode_5_1  | 2020-07-15 07:08:46,677 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=82,entriesCount=1,lastEntry=(t:1, i:41)
datanode_5_1  | 2020-07-15 07:08:46,689 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:42)
datanode_5_1  | 2020-07-15 07:08:46,699 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:43)
datanode_5_1  | 2020-07-15 07:08:46,717 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:44)
datanode_5_1  | 2020-07-15 07:08:49,252 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=87,entriesCount=1,lastEntry=(t:1, i:45)
datanode_5_1  | 2020-07-15 07:08:49,263 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=88,entriesCount=1,lastEntry=(t:1, i:46)
datanode_5_1  | 2020-07-15 07:08:49,282 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:47)
datanode_5_1  | 2020-07-15 07:08:49,292 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:48)
datanode_5_1  | 2020-07-15 07:08:51,826 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=92,entriesCount=1,lastEntry=(t:1, i:49)
datanode_5_1  | 2020-07-15 07:08:51,830 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=93,entriesCount=1,lastEntry=(t:1, i:50)
datanode_5_1  | 2020-07-15 07:08:51,840 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:51)
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-07-15 07:05:24,798 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 5c57ce288875/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | 2020-07-15 07:08:51,850 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:52)
datanode_5_1  | 2020-07-15 07:08:54,388 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=97,entriesCount=1,lastEntry=(t:1, i:53)
datanode_5_1  | 2020-07-15 07:08:54,404 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:54)
datanode_5_1  | 2020-07-15 07:08:54,404 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:55)
datanode_5_1  | 2020-07-15 07:08:54,424 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:56)
datanode_5_1  | 2020-07-15 07:08:56,961 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:57)
datanode_5_1  | 2020-07-15 07:08:56,969 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:58)
datanode_5_1  | 2020-07-15 07:08:56,985 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:59)
datanode_5_1  | 2020-07-15 07:08:56,987 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:60)
datanode_5_1  | 2020-07-15 07:09:07,273 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:61)
datanode_5_1  | 2020-07-15 07:09:07,279 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:62)
datanode_5_1  | 2020-07-15 07:09:07,288 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:63)
datanode_5_1  | 2020-07-15 07:09:07,305 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:64)
datanode_5_1  | 2020-07-15 07:09:14,973 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:65)
datanode_5_1  | 2020-07-15 07:09:14,980 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=118,entriesCount=1,lastEntry=(t:1, i:66)
datanode_5_1  | 2020-07-15 07:09:14,993 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:67)
datanode_5_1  | 2020-07-15 07:09:15,011 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:68)
datanode_5_1  | 2020-07-15 07:09:17,548 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:69)
datanode_5_1  | 2020-07-15 07:09:17,550 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=123,entriesCount=1,lastEntry=(t:1, i:70)
datanode_5_1  | 2020-07-15 07:09:17,567 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:71)
datanode_5_1  | 2020-07-15 07:09:17,569 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:72)
datanode_5_1  | 2020-07-15 07:09:33,027 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:73)
datanode_5_1  | 2020-07-15 07:09:33,033 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:74)
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-07-15 07:05:31,328 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = e5c0d8b39520/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | 2020-07-15 07:06:05,564 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF
datanode_2_1  | 2020-07-15 07:06:05,565 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-07-15 07:06:05,565 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-07-15 07:06:05,566 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-07-15 07:06:05,567 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-07-15 07:06:05,567 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-07-15 07:06:05,760 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2_1  | 2020-07-15 07:06:05,765 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-15 07:06:05,770 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2_1  | 2020-07-15 07:06:05,782 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2_1  | 2020-07-15 07:06:05,806 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-07-15 07:06:05,814 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-15 07:06:05,815 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF
datanode_2_1  | 2020-07-15 07:06:05,835 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2_1  | 2020-07-15 07:06:05,861 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-07-15 07:06:05,889 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2_1  | 2020-07-15 07:06:05,890 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2_1  | 2020-07-15 07:06:05,890 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-07-15 07:06:05,890 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-07-15 07:06:05,895 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO impl.RoleInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7: start LeaderState
datanode_2_1  | 2020-07-15 07:06:05,895 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-07-15 07:06:05,965 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-LeaderElection2] INFO impl.RaftServerImpl: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF: set configuration 0: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858, 02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858, 47c0b11d-1167-49f1-92df-2a0b841871d7:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-07-15 07:06:05,966 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b74f0bc3-f7e6-49f6-891c-bd702aae76ff/current/log_inprogress_0
datanode_2_1  | 2020-07-15 07:06:05,986 [47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-A9434E973C8F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d6985ba7-a249-4a33-9a53-a9434e973c8f/current/log_inprogress_0
datanode_2_1  | 2020-07-15 07:06:06,539 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 02f82674-a0c2-4773-90e8-73ab39d1c5f5{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_2_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.940698161s. [buffered_nanos=736045866, remote_addr=/10.5.0.6:9858]
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_2_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_2_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_2_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_2_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_2_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_2_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_2_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-07-15 07:09:33,034 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:75)
datanode_5_1  | 2020-07-15 07:09:33,044 [java.util.concurrent.ThreadPoolExecutor$Worker@dff73fe[State = -1, empty queue]] WARN server.GrpcLogAppender: 43e178db-63b6-424e-a7a3-b59ab147be00@group-0F98F1DD7B15->a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:76)
datanode_6_1  | 2020-07-15 07:06:26,886 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-07-15 07:06:26,886 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-07-15 07:06:26,886 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-07-15 07:06:26,887 [pool-19-thread-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31: ConfigurationManager, init=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-07-15 07:06:26,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-07-15 07:06:26,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-07-15 07:06:26,891 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/dfb14656-679c-43e1-a346-0965ba38cc31 does not exist. Creating ...
datanode_6_1  | 2020-07-15 07:06:26,895 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/dfb14656-679c-43e1-a346-0965ba38cc31/in_use.lock acquired by nodename 6@11847bcd10d2
datanode_6_1  | 2020-07-15 07:06:26,901 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/dfb14656-679c-43e1-a346-0965ba38cc31 has been successfully formatted.
datanode_6_1  | 2020-07-15 07:06:26,903 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0965BA38CC31: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-07-15 07:06:26,903 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-07-15 07:06:26,907 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-07-15 07:06:26,907 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-07-15 07:06:26,908 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-07-15 07:06:26,909 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-15 07:06:26,909 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31
datanode_6_1  | 2020-07-15 07:06:26,909 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-07-15 07:06:26,909 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/dfb14656-679c-43e1-a346-0965ba38cc31
datanode_6_1  | 2020-07-15 07:06:26,910 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-07-15 07:06:26,910 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-15 07:06:26,910 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-07-15 07:06:26,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-07-15 07:06:26,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-07-15 07:06:26,912 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-07-15 07:06:26,912 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-07-15 07:06:26,912 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-07-15 07:06:26,912 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-07-15 07:06:26,914 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-07-15 07:06:26,915 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-15 07:06:26,915 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-07-15 07:06:26,916 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-07-15 07:06:26,916 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-07-15 07:06:26,916 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-07-15 07:06:26,917 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-07-15 07:06:26,922 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-07-15 07:06:26,922 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31
datanode_6_1  | 2020-07-15 07:06:26,923 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31
datanode_6_1  | 2020-07-15 07:06:26,925 [pool-19-thread-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31: start as a follower, conf=-1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858], old=null
datanode_6_1  | 2020-07-15 07:06:26,925 [pool-19-thread-1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-07-15 07:06:26,926 [pool-19-thread-1] INFO impl.RoleInfo: 872ac602-b542-4fd3-a544-ffbd53b46ee2: start FollowerState
datanode_6_1  | 2020-07-15 07:06:26,927 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0965BA38CC31,id=872ac602-b542-4fd3-a544-ffbd53b46ee2
datanode_6_1  | 2020-07-15 07:06:26,927 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31
datanode_6_1  | 2020-07-15 07:06:26,931 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "dfb14656-679c-43e1-a346-0965ba38cc31"
datanode_6_1  | uuid128 {
datanode_6_1  |   mostSigBits: -2328002195454409759
datanode_6_1  |   leastSigBits: -6681642664636920783
datanode_6_1  | }
datanode_6_1  | .
datanode_6_1  | 2020-07-15 07:06:32,049 [Thread-45] INFO impl.FollowerState: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-FollowerState: change to CANDIDATE, lastRpcTime:5123ms, electionTimeout:5121ms
datanode_6_1  | 2020-07-15 07:06:32,050 [Thread-45] INFO impl.RoleInfo: 872ac602-b542-4fd3-a544-ffbd53b46ee2: shutdown FollowerState
datanode_6_1  | 2020-07-15 07:06:32,050 [Thread-45] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-07-15 07:06:32,052 [Thread-45] INFO impl.RoleInfo: 872ac602-b542-4fd3-a544-ffbd53b46ee2: start LeaderElection
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:42Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-07-15 07:05:24,877 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-07-15 07:05:32,262 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-07-15 07:05:32,843 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-07-15 07:05:32,843 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-07-15 07:05:33,286 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-15 07:05:36,570 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:37,573 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:38,575 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:39,576 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:40,576 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:41,582 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:42,583 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:43,584 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:44,584 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:45,585 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-07-15 07:05:45,587 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-d450cccd-8699-4837-9d63-62438c318b37;layoutVersion=0
om_1          | 2020-07-15 07:05:52,575 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 5c57ce288875/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-07-15 07:05:59,869 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 5c57ce288875/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:41Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-07-15 07:05:31,472 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-07-15 07:05:32,768 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-15 07:05:33,294 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-d450cccd-8699-4837-9d63-62438c318b37;layoutVersion=0
scm_1         | 2020-07-15 07:05:33,355 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at e5c0d8b39520/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-07-15 07:05:48,479 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = e5c0d8b39520/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | 2020-07-15 07:06:32,055 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO impl.LeaderElection: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1: begin an election at term 1 for -1: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858], old=null
datanode_6_1  | 2020-07-15 07:06:32,057 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO impl.RoleInfo: 872ac602-b542-4fd3-a544-ffbd53b46ee2: shutdown LeaderElection
datanode_6_1  | 2020-07-15 07:06:32,057 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-07-15 07:06:32,057 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0965BA38CC31 with new leaderId: 872ac602-b542-4fd3-a544-ffbd53b46ee2
datanode_6_1  | 2020-07-15 07:06:32,058 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31: change Leader from null to 872ac602-b542-4fd3-a544-ffbd53b46ee2 at term 1 for becomeLeader, leader elected after 5153ms
datanode_6_1  | 2020-07-15 07:06:32,059 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-07-15 07:06:32,059 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-07-15 07:06:32,061 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31
datanode_6_1  | 2020-07-15 07:06:32,067 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-07-15 07:06:32,068 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-07-15 07:06:32,073 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-07-15 07:06:32,073 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-07-15 07:06:32,073 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-07-15 07:06:32,078 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO impl.RoleInfo: 872ac602-b542-4fd3-a544-ffbd53b46ee2: start LeaderState
datanode_6_1  | 2020-07-15 07:06:32,085 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-07-15 07:06:32,087 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/dfb14656-679c-43e1-a346-0965ba38cc31/current/log_inprogress_0
datanode_6_1  | 2020-07-15 07:06:32,088 [872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31-LeaderElection1] INFO impl.RaftServerImpl: 872ac602-b542-4fd3-a544-ffbd53b46ee2@group-0965BA38CC31: set configuration 0: [872ac602-b542-4fd3-a544-ffbd53b46ee2:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-07-15 07:11:07,963 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 153.
datanode_6_1  | 2020-07-15 07:11:07,963 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 153.
datanode_6_1  | 2020-07-15 07:11:07,969 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is closed with bcsId 153.
datanode_6_1  | 2020-07-15 07:11:08,006 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 161.
datanode_6_1  | 2020-07-15 07:11:08,007 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 161.
datanode_6_1  | 2020-07-15 07:11:08,013 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is closed with bcsId 161.
datanode_2_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.940698161s. [buffered_nanos=736045866, remote_addr=/10.5.0.6:9858]
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_2_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_2_1  | 	... 18 more
datanode_2_1  | 2020-07-15 07:06:06,540 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "b74f0bc3-f7e6-49f6-891c-bd702aae76ff"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: -5237954905303004682
datanode_2_1  |   leastSigBits: -8566764101715462401
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-07-15 07:06:08,702 [grpc-default-executor-0] INFO impl.FollowerInfo: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5: nextIndex: updateUnconditionally 1 -> 0
datanode_2_1  | 2020-07-15 07:07:08,704 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode_2_1  | 2020-07-15 07:07:22,410 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2_1  | 2020-07-15 07:07:22,485 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:2)
datanode_2_1  | 2020-07-15 07:07:24,052 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:3)
datanode_2_1  | 2020-07-15 07:07:24,053 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:4)
datanode_2_1  | 2020-07-15 07:07:26,591 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:5)
datanode_2_1  | 2020-07-15 07:07:26,603 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:6)
datanode_2_1  | 2020-07-15 07:07:26,629 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:7)
datanode_2_1  | 2020-07-15 07:07:26,639 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:8)
datanode_2_1  | 2020-07-15 07:07:29,193 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:9)
datanode_2_1  | 2020-07-15 07:07:29,193 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:10)
datanode_2_1  | 2020-07-15 07:07:29,210 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:11)
datanode_2_1  | 2020-07-15 07:07:29,227 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:12)
datanode_2_1  | 2020-07-15 07:07:34,416 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:13)
datanode_2_1  | 2020-07-15 07:07:34,425 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:14)
datanode_2_1  | 2020-07-15 07:07:34,436 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:15)
datanode_2_1  | 2020-07-15 07:07:34,447 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=28,entriesCount=1,lastEntry=(t:1, i:16)
datanode_2_1  | 2020-07-15 07:07:36,986 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:17)
datanode_2_1  | 2020-07-15 07:07:36,997 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:18)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:42Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-07-15 07:05:59,933 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-07-15 07:06:03,206 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-07-15 07:06:03,497 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-07-15 07:06:03,497 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-07-15 07:06:03,641 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-15 07:06:03,738 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-15 07:06:08,829 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-07-15 07:06:09,785 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-07-15 07:06:09,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-07-15 07:06:10,145 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-07-15 07:06:10,236 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-07-15 07:06:10,236 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1          | 2020-07-15 07:06:10,310 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
om_1          | 2020-07-15 07:06:10,422 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-07-15 07:06:10,443 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-07-15 07:06:10,607 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-07-15 07:06:10,607 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1          | 2020-07-15 07:06:10,666 [Listener at om/9862] INFO util.log: Logging initialized @17293ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-07-15 07:06:10,827 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-07-15 07:06:10,831 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_2_1  | 2020-07-15 07:07:36,997 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:19)
datanode_2_1  | 2020-07-15 07:07:42,123 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:20)
datanode_2_1  | 2020-07-15 07:07:42,135 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:21)
datanode_2_1  | 2020-07-15 07:07:42,139 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:22)
datanode_2_1  | 2020-07-15 07:07:42,165 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:23)
datanode_2_1  | 2020-07-15 07:07:44,716 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:24)
datanode_2_1  | 2020-07-15 07:07:44,725 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:25)
datanode_2_1  | 2020-07-15 07:07:44,738 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:26)
datanode_2_1  | 2020-07-15 07:07:44,762 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=43,entriesCount=1,lastEntry=(t:1, i:27)
datanode_2_1  | 2020-07-15 07:07:47,301 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:28)
datanode_2_1  | 2020-07-15 07:07:47,309 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:29)
datanode_2_1  | 2020-07-15 07:07:47,339 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:30)
datanode_2_1  | 2020-07-15 07:07:47,349 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=48,entriesCount=1,lastEntry=(t:1, i:31)
datanode_2_1  | 2020-07-15 07:07:49,893 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:32)
datanode_2_1  | 2020-07-15 07:07:49,903 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:33)
datanode_2_1  | 2020-07-15 07:07:49,907 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:34)
datanode_2_1  | 2020-07-15 07:07:57,652 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:35)
datanode_2_1  | 2020-07-15 07:07:57,662 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:36)
datanode_2_1  | 2020-07-15 07:07:57,663 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=58,entriesCount=1,lastEntry=(t:1, i:37)
datanode_2_1  | 2020-07-15 07:07:57,683 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=59,entriesCount=1,lastEntry=(t:1, i:38)
datanode_2_1  | 2020-07-15 07:08:00,218 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:39)
datanode_2_1  | 2020-07-15 07:08:00,242 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:40)
datanode_2_1  | 2020-07-15 07:08:00,242 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=63,entriesCount=1,lastEntry=(t:1, i:41)
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/10686014b98a01c30f54614e172f57ab99c48c5b ; compiled by 'runner' on 2020-07-15T06:41Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-07-15 07:05:48,512 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-07-15 07:05:48,779 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-15 07:05:49,028 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-07-15 07:05:49,217 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@70925b45
scm_1         | 2020-07-15 07:05:49,218 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-07-15 07:05:49,344 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-07-15 07:05:49,473 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-07-15 07:05:49,505 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-07-15 07:05:49,573 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-07-15 07:05:49,575 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-07-15 07:05:49,621 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1         | 2020-07-15 07:05:50,117 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-15 07:05:50,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-07-15 07:05:50,195 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-15 07:05:50,208 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-07-15 07:05:50,244 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-07-15 07:05:50,249 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-07-15 07:05:50,313 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-07-15 07:05:50,313 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1         | 2020-07-15 07:05:50,341 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @14269ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-07-15 07:05:50,463 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-07-15 07:05:50,487 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-07-15 07:05:50,492 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-07-15 07:05:50,494 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1         | 2020-07-15 07:05:50,494 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2020-07-15 07:05:50,495 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2020-07-15 07:05:50,548 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-07-15 07:05:50,562 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-07-15 07:05:50,749 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-07-15 07:05:50,802 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-07-15 07:05:50,802 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-07-15 07:05:51,086 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-07-15 07:05:51,093 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-07-15 07:05:51,132 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-07-15 07:05:51,181 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-07-15 07:05:51,202 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-07-15 07:05:51,205 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_2_1  | 2020-07-15 07:08:02,798 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:42)
datanode_2_1  | 2020-07-15 07:08:02,806 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:43)
datanode_2_1  | 2020-07-15 07:08:02,817 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:44)
datanode_2_1  | 2020-07-15 07:08:02,831 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=68,entriesCount=1,lastEntry=(t:1, i:45)
datanode_2_1  | 2020-07-15 07:08:10,550 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:46)
datanode_2_1  | 2020-07-15 07:08:10,557 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=73,entriesCount=1,lastEntry=(t:1, i:47)
datanode_2_1  | 2020-07-15 07:08:10,573 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=74,entriesCount=1,lastEntry=(t:1, i:48)
datanode_2_1  | 2020-07-15 07:08:13,126 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:49)
datanode_2_1  | 2020-07-15 07:08:13,126 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:50)
datanode_2_1  | 2020-07-15 07:08:13,136 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=78,entriesCount=1,lastEntry=(t:1, i:51)
datanode_2_1  | 2020-07-15 07:08:13,148 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:52)
datanode_2_1  | 2020-07-15 07:08:15,690 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:53)
datanode_2_1  | 2020-07-15 07:08:15,700 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=82,entriesCount=1,lastEntry=(t:1, i:54)
datanode_2_1  | 2020-07-15 07:08:15,710 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:55)
datanode_2_1  | 2020-07-15 07:08:15,720 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:56)
datanode_2_1  | 2020-07-15 07:08:18,257 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:57)
datanode_2_1  | 2020-07-15 07:08:18,269 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=87,entriesCount=1,lastEntry=(t:1, i:58)
datanode_2_1  | 2020-07-15 07:08:18,278 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=88,entriesCount=1,lastEntry=(t:1, i:59)
datanode_2_1  | 2020-07-15 07:08:18,283 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:60)
datanode_2_1  | 2020-07-15 07:08:20,812 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:61)
datanode_2_1  | 2020-07-15 07:08:20,823 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=92,entriesCount=1,lastEntry=(t:1, i:62)
datanode_2_1  | 2020-07-15 07:08:20,830 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=93,entriesCount=1,lastEntry=(t:1, i:63)
datanode_3_1  | 2020-07-15 07:06:27,244 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-07-15 07:06:27,245 [pool-19-thread-1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4: ConfigurationManager, init=-1: [02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-07-15 07:06:27,245 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-07-15 07:06:27,245 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-07-15 07:06:27,245 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3152cb4e-5034-4049-acaf-7bda907d73d4 does not exist. Creating ...
datanode_3_1  | 2020-07-15 07:06:27,247 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3152cb4e-5034-4049-acaf-7bda907d73d4/in_use.lock acquired by nodename 6@f99813282669
datanode_3_1  | 2020-07-15 07:06:27,248 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3152cb4e-5034-4049-acaf-7bda907d73d4 has been successfully formatted.
datanode_3_1  | 2020-07-15 07:06:27,249 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-7BDA907D73D4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-07-15 07:06:27,254 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-07-15 07:06:27,255 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-07-15 07:06:27,257 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-07-15 07:06:27,258 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-07-15 07:06:27,260 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-15 07:06:27,260 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4
datanode_3_1  | 2020-07-15 07:06:27,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-07-15 07:06:27,261 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3152cb4e-5034-4049-acaf-7bda907d73d4
datanode_3_1  | 2020-07-15 07:06:27,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-07-15 07:06:27,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-15 07:06:27,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-07-15 07:06:27,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-07-15 07:06:27,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-07-15 07:06:27,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-07-15 07:06:27,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-07-15 07:06:27,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-07-15 07:06:27,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-07-15 07:06:27,263 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-07-15 07:06:27,264 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-15 07:06:27,264 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-07-15 07:06:27,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-07-15 07:06:27,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-07-15 07:06:27,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-07-15 07:06:27,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-07-15 07:06:27,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-07-15 07:06:27,266 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4
datanode_3_1  | 2020-07-15 07:06:27,266 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4
datanode_3_1  | 2020-07-15 07:06:27,267 [pool-19-thread-1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4: start as a follower, conf=-1: [02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858], old=null
datanode_3_1  | 2020-07-15 07:06:27,269 [pool-19-thread-1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-07-15 07:06:27,269 [pool-19-thread-1] INFO impl.RoleInfo: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: start FollowerState
datanode_3_1  | 2020-07-15 07:06:27,271 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7BDA907D73D4,id=02f82674-a0c2-4773-90e8-73ab39d1c5f5
datanode_3_1  | 2020-07-15 07:06:27,271 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4
datanode_3_1  | 2020-07-15 07:06:27,275 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "3152cb4e-5034-4049-acaf-7bda907d73d4"
datanode_3_1  | uuid128 {
datanode_3_1  |   mostSigBits: 3554126593162231881
datanode_3_1  |   leastSigBits: -6003443599604354092
datanode_3_1  | }
datanode_3_1  | .
datanode_3_1  | 2020-07-15 07:06:32,291 [Thread-44] INFO impl.FollowerState: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-FollowerState: change to CANDIDATE, lastRpcTime:5021ms, electionTimeout:5019ms
datanode_3_1  | 2020-07-15 07:06:32,292 [Thread-44] INFO impl.RoleInfo: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: shutdown FollowerState
datanode_3_1  | 2020-07-15 07:06:32,292 [Thread-44] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-07-15 07:06:32,297 [Thread-44] INFO impl.RoleInfo: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: start LeaderElection
datanode_3_1  | 2020-07-15 07:06:32,301 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO impl.LeaderElection: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1: begin an election at term 1 for -1: [02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858], old=null
datanode_3_1  | 2020-07-15 07:06:32,302 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO impl.RoleInfo: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: shutdown LeaderElection
datanode_3_1  | 2020-07-15 07:06:32,302 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-07-15 07:06:32,302 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7BDA907D73D4 with new leaderId: 02f82674-a0c2-4773-90e8-73ab39d1c5f5
datanode_3_1  | 2020-07-15 07:06:32,302 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4: change Leader from null to 02f82674-a0c2-4773-90e8-73ab39d1c5f5 at term 1 for becomeLeader, leader elected after 5053ms
datanode_3_1  | 2020-07-15 07:06:32,307 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-07-15 07:06:32,307 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-07-15 07:06:32,309 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4
datanode_3_1  | 2020-07-15 07:06:32,311 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-07-15 07:06:32,312 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-07-15 07:06:32,316 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-07-15 07:06:32,316 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-07-15 07:06:32,317 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-07-15 07:06:32,322 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO impl.RoleInfo: 02f82674-a0c2-4773-90e8-73ab39d1c5f5: start LeaderState
datanode_3_1  | 2020-07-15 07:06:32,324 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-07-15 07:06:32,326 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3152cb4e-5034-4049-acaf-7bda907d73d4/current/log_inprogress_0
datanode_3_1  | 2020-07-15 07:06:32,328 [02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4-LeaderElection1] INFO impl.RaftServerImpl: 02f82674-a0c2-4773-90e8-73ab39d1c5f5@group-7BDA907D73D4: set configuration 0: [02f82674-a0c2-4773-90e8-73ab39d1c5f5:10.5.0.6:9858], old=null at 0
datanode_2_1  | 2020-07-15 07:08:20,838 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:64)
datanode_2_1  | 2020-07-15 07:08:26,016 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=97,entriesCount=1,lastEntry=(t:1, i:65)
datanode_2_1  | 2020-07-15 07:08:26,035 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:66)
datanode_2_1  | 2020-07-15 07:08:26,080 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:67)
datanode_2_1  | 2020-07-15 07:08:28,619 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:68)
datanode_2_1  | 2020-07-15 07:08:28,629 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:69)
datanode_2_1  | 2020-07-15 07:08:28,644 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:70)
datanode_2_1  | 2020-07-15 07:08:33,758 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=106,entriesCount=1,lastEntry=(t:1, i:71)
datanode_2_1  | 2020-07-15 07:08:33,764 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=107,entriesCount=1,lastEntry=(t:1, i:72)
datanode_2_1  | 2020-07-15 07:08:33,765 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=108,entriesCount=1,lastEntry=(t:1, i:73)
datanode_2_1  | 2020-07-15 07:08:33,783 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:74)
datanode_2_1  | 2020-07-15 07:08:36,340 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:75)
datanode_2_1  | 2020-07-15 07:08:36,347 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:76)
datanode_2_1  | 2020-07-15 07:08:36,353 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:77)
datanode_2_1  | 2020-07-15 07:08:36,377 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:78)
datanode_2_1  | 2020-07-15 07:08:38,926 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=116,entriesCount=1,lastEntry=(t:1, i:79)
datanode_2_1  | 2020-07-15 07:08:38,933 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:80)
datanode_2_1  | 2020-07-15 07:08:38,940 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=118,entriesCount=1,lastEntry=(t:1, i:81)
datanode_2_1  | 2020-07-15 07:08:38,948 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:82)
datanode_2_1  | 2020-07-15 07:08:41,479 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=121,entriesCount=1,lastEntry=(t:1, i:83)
datanode_2_1  | 2020-07-15 07:08:41,482 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:84)
datanode_2_1  | 2020-07-15 07:08:41,499 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=123,entriesCount=1,lastEntry=(t:1, i:85)
datanode_2_1  | 2020-07-15 07:08:41,513 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:86)
scm_1         | 2020-07-15 07:05:51,211 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-07-15 07:05:51,277 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-07-15 07:05:51,278 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1         | 2020-07-15 07:05:51,281 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-07-15 07:05:51,282 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1         | 2020-07-15 07:05:51,360 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-07-15 07:05:51,366 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1         | 2020-07-15 07:05:51,620 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-07-15 07:05:51,621 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-07-15 07:05:51,624 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1         | 2020-07-15 07:05:51,640 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@578c3fd9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2020-07-15 07:05:51,640 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@c9b5a99{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2020-07-15 07:05:51,875 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5aa6da2{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-6727896765107885967.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1         | 2020-07-15 07:05:51,901 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@23121d14{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1         | 2020-07-15 07:05:51,902 [Listener at 0.0.0.0/9860] INFO server.Server: Started @15830ms
scm_1         | 2020-07-15 07:05:51,912 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2020-07-15 07:05:51,912 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2020-07-15 07:05:51,916 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1         | 2020-07-15 07:05:51,938 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5fde1d64] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2020-07-15 07:05:52,047 [IPC Server handler 6 on default port 9861] WARN ipc.Server: IPC Server handler 6 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.8:54292: output error
scm_1         | 2020-07-15 07:05:52,049 [IPC Server handler 6 on default port 9861] INFO ipc.Server: IPC Server handler 6 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-15 07:05:52,075 [IPC Server handler 3 on default port 9861] WARN ipc.Server: IPC Server handler 3 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.5:43240: output error
scm_1         | 2020-07-15 07:05:52,110 [IPC Server handler 3 on default port 9861] INFO ipc.Server: IPC Server handler 3 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-15 07:05:52,073 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:35386: output error
scm_1         | 2020-07-15 07:05:52,110 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1          | 2020-07-15 07:06:10,843 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-07-15 07:06:10,861 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1          | 2020-07-15 07:06:10,861 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-07-15 07:06:10,861 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-07-15 07:06:10,950 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-07-15 07:06:10,963 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-07-15 07:06:10,964 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-07-15 07:06:11,058 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-07-15 07:06:11,059 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-07-15 07:06:11,062 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1          | 2020-07-15 07:06:11,090 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2d2f09a4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-07-15 07:06:11,092 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@39f68aec{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-07-15 07:06:11,370 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@666b91db{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-8184203659419517358.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-07-15 07:06:11,380 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@73e399cc{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-07-15 07:06:11,380 [Listener at om/9862] INFO server.Server: Started @18007ms
om_1          | 2020-07-15 07:06:11,383 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-07-15 07:06:11,384 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-07-15 07:06:11,389 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-07-15 07:06:11,399 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40cb95c1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2020-07-15 07:06:15,585 [IPC Server handler 16 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-97215 for user:hadoop
om_1          | 2020-07-15 07:06:15,617 [IPC Server handler 16 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-20528 for user:hadoop
om_1          | 2020-07-15 07:06:15,638 [IPC Server handler 13 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-20647 for user:hadoop
om_1          | 2020-07-15 07:06:15,655 [IPC Server handler 18 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-40250 for user:hadoop
om_1          | 2020-07-15 07:06:15,665 [IPC Server handler 17 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-29512 for user:hadoop
datanode_2_1  | 2020-07-15 07:08:59,552 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:87)
datanode_2_1  | 2020-07-15 07:08:59,557 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:88)
datanode_2_1  | 2020-07-15 07:08:59,560 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:89)
datanode_2_1  | 2020-07-15 07:08:59,574 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:90)
datanode_2_1  | 2020-07-15 07:09:02,104 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:91)
datanode_2_1  | 2020-07-15 07:09:02,111 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=138,entriesCount=1,lastEntry=(t:1, i:92)
datanode_2_1  | 2020-07-15 07:09:02,124 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:93)
datanode_2_1  | 2020-07-15 07:09:02,124 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:94)
datanode_2_1  | 2020-07-15 07:09:04,651 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=142,entriesCount=1,lastEntry=(t:1, i:95)
datanode_2_1  | 2020-07-15 07:09:04,682 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=143,entriesCount=1,lastEntry=(t:1, i:96)
datanode_2_1  | 2020-07-15 07:09:04,689 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:97)
datanode_2_1  | 2020-07-15 07:09:09,841 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:98)
datanode_2_1  | 2020-07-15 07:09:09,852 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=148,entriesCount=1,lastEntry=(t:1, i:99)
datanode_2_1  | 2020-07-15 07:09:09,868 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:100)
datanode_2_1  | 2020-07-15 07:09:09,882 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:101)
datanode_2_1  | 2020-07-15 07:09:12,429 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=152,entriesCount=1,lastEntry=(t:1, i:102)
datanode_2_1  | 2020-07-15 07:09:12,434 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=153,entriesCount=1,lastEntry=(t:1, i:103)
datanode_2_1  | 2020-07-15 07:09:12,442 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:104)
datanode_2_1  | 2020-07-15 07:09:20,093 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:105)
datanode_2_1  | 2020-07-15 07:09:20,101 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=159,entriesCount=1,lastEntry=(t:1, i:106)
datanode_2_1  | 2020-07-15 07:09:20,113 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:107)
datanode_2_1  | 2020-07-15 07:09:20,130 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=161,entriesCount=1,lastEntry=(t:1, i:108)
datanode_2_1  | 2020-07-15 07:09:22,662 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:109)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-15 07:05:52,073 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:34028: output error
scm_1         | 2020-07-15 07:05:52,111 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-15 07:05:52,053 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:42066: output error
scm_1         | 2020-07-15 07:05:52,111 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-07-15 07:05:54,271 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/872ac602-b542-4fd3-a544-ffbd53b46ee2
scm_1         | 2020-07-15 07:05:54,306 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c
scm_1         | 2020-07-15 07:05:54,359 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-15 07:05:54,321 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 872ac602-b542-4fd3-a544-ffbd53b46ee2{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-15 07:05:54,327 [IPC Server handler 20 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/e00f9da5-82a4-43be-9dbb-d8c493d15126
scm_1         | 2020-07-15 07:05:54,361 [IPC Server handler 20 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e00f9da5-82a4-43be-9dbb-d8c493d15126{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-15 07:05:54,405 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
scm_1         | 2020-07-15 07:05:54,490 [IPC Server handler 16 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/02f82674-a0c2-4773-90e8-73ab39d1c5f5
scm_1         | 2020-07-15 07:05:54,491 [IPC Server handler 16 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 02f82674-a0c2-4773-90e8-73ab39d1c5f5{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-15 07:05:54,491 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
scm_1         | 2020-07-15 07:05:54,492 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
scm_1         | 2020-07-15 07:05:54,569 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
scm_1         | 2020-07-15 07:05:54,570 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:54,570 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1         | 2020-07-15 07:05:54,600 [IPC Server handler 17 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/43e178db-63b6-424e-a7a3-b59ab147be00
scm_1         | 2020-07-15 07:05:54,600 [IPC Server handler 17 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 43e178db-63b6-424e-a7a3-b59ab147be00{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-07-15 07:05:54,601 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:54,648 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:54,670 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:54,670 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:54,670 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:54,674 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:54,806 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=dfb14656-679c-43e1-a346-0965ba38cc31 to datanode:872ac602-b542-4fd3-a544-ffbd53b46ee2
scm_1         | 2020-07-15 07:05:55,136 [IPC Server handler 18 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/47c0b11d-1167-49f1-92df-2a0b841871d7
scm_1         | 2020-07-15 07:05:55,141 [IPC Server handler 18 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 47c0b11d-1167-49f1-92df-2a0b841871d7{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-07-15 07:05:55,166 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:55,168 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:05:55,202 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: dfb14656-679c-43e1-a346-0965ba38cc31, Nodes: 872ac602-b542-4fd3-a544-ffbd53b46ee2{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-15T07:05:54.739902Z]
scm_1         | 2020-07-15 07:05:55,264 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d6985ba7-a249-4a33-9a53-a9434e973c8f to datanode:47c0b11d-1167-49f1-92df-2a0b841871d7
scm_1         | 2020-07-15 07:05:55,270 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d6985ba7-a249-4a33-9a53-a9434e973c8f, Nodes: 47c0b11d-1167-49f1-92df-2a0b841871d7{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-15T07:05:55.264541Z]
scm_1         | 2020-07-15 07:05:55,310 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b to datanode:e00f9da5-82a4-43be-9dbb-d8c493d15126
scm_1         | 2020-07-15 07:05:55,311 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b, Nodes: e00f9da5-82a4-43be-9dbb-d8c493d15126{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-15T07:05:55.310386Z]
scm_1         | 2020-07-15 07:05:55,322 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3152cb4e-5034-4049-acaf-7bda907d73d4 to datanode:02f82674-a0c2-4773-90e8-73ab39d1c5f5
scm_1         | 2020-07-15 07:05:55,330 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3152cb4e-5034-4049-acaf-7bda907d73d4, Nodes: 02f82674-a0c2-4773-90e8-73ab39d1c5f5{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-15T07:05:55.321957Z]
scm_1         | 2020-07-15 07:05:55,338 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fc02d72e-98dd-4822-bd77-f568b3c08038 to datanode:43e178db-63b6-424e-a7a3-b59ab147be00
scm_1         | 2020-07-15 07:05:55,346 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fc02d72e-98dd-4822-bd77-f568b3c08038, Nodes: 43e178db-63b6-424e-a7a3-b59ab147be00{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-15T07:05:55.338210Z]
scm_1         | 2020-07-15 07:05:55,366 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=5ee2711e-67fc-4e31-84cc-6a323cdae2ae to datanode:a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c
scm_1         | 2020-07-15 07:05:55,378 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 5ee2711e-67fc-4e31-84cc-6a323cdae2ae, Nodes: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-15T07:05:55.366361Z]
scm_1         | 2020-07-15 07:05:55,426 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-15 07:05:55,474 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b74f0bc3-f7e6-49f6-891c-bd702aae76ff to datanode:47c0b11d-1167-49f1-92df-2a0b841871d7
scm_1         | 2020-07-15 07:05:55,480 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b74f0bc3-f7e6-49f6-891c-bd702aae76ff to datanode:872ac602-b542-4fd3-a544-ffbd53b46ee2
scm_1         | 2020-07-15 07:05:55,480 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b74f0bc3-f7e6-49f6-891c-bd702aae76ff to datanode:02f82674-a0c2-4773-90e8-73ab39d1c5f5
scm_1         | 2020-07-15 07:05:55,497 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b74f0bc3-f7e6-49f6-891c-bd702aae76ff, Nodes: 47c0b11d-1167-49f1-92df-2a0b841871d7{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}872ac602-b542-4fd3-a544-ffbd53b46ee2{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}02f82674-a0c2-4773-90e8-73ab39d1c5f5{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-15T07:05:55.474288Z]
scm_1         | 2020-07-15 07:05:55,514 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=589f6424-c0e1-4cf6-a653-0f98f1dd7b15 to datanode:e00f9da5-82a4-43be-9dbb-d8c493d15126
scm_1         | 2020-07-15 07:05:55,515 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=589f6424-c0e1-4cf6-a653-0f98f1dd7b15 to datanode:a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c
scm_1         | 2020-07-15 07:05:55,515 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=589f6424-c0e1-4cf6-a653-0f98f1dd7b15 to datanode:43e178db-63b6-424e-a7a3-b59ab147be00
scm_1         | 2020-07-15 07:05:55,516 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 589f6424-c0e1-4cf6-a653-0f98f1dd7b15, Nodes: e00f9da5-82a4-43be-9dbb-d8c493d15126{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}43e178db-63b6-424e-a7a3-b59ab147be00{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-07-15T07:05:55.514789Z]
scm_1         | 2020-07-15 07:05:55,519 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-15 07:05:58,430 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: fc02d72e-98dd-4822-bd77-f568b3c08038, Nodes: 43e178db-63b6-424e-a7a3-b59ab147be00{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:43e178db-63b6-424e-a7a3-b59ab147be00, CreationTimestamp2020-07-15T07:05:55.338210Z] moved to OPEN state
scm_1         | 2020-07-15 07:05:58,463 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-15 07:05:58,465 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-15 07:05:59,290 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d6985ba7-a249-4a33-9a53-a9434e973c8f, Nodes: 47c0b11d-1167-49f1-92df-2a0b841871d7{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:47c0b11d-1167-49f1-92df-2a0b841871d7, CreationTimestamp2020-07-15T07:05:55.264541Z] moved to OPEN state
scm_1         | 2020-07-15 07:05:59,290 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-15 07:05:59,290 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-07-15 07:06:06,250 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 589f6424-c0e1-4cf6-a653-0f98f1dd7b15, Nodes: e00f9da5-82a4-43be-9dbb-d8c493d15126{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}43e178db-63b6-424e-a7a3-b59ab147be00{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:43e178db-63b6-424e-a7a3-b59ab147be00, CreationTimestamp2020-07-15T07:05:55.514789Z] moved to OPEN state
scm_1         | 2020-07-15 07:06:06,260 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-07-15 07:06:06,261 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1         | 2020-07-15 07:06:06,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-07-15 07:06:06,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1         | 2020-07-15 07:06:06,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1         | 2020-07-15 07:06:06,810 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b74f0bc3-f7e6-49f6-891c-bd702aae76ff, Nodes: 47c0b11d-1167-49f1-92df-2a0b841871d7{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}872ac602-b542-4fd3-a544-ffbd53b46ee2{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}02f82674-a0c2-4773-90e8-73ab39d1c5f5{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:47c0b11d-1167-49f1-92df-2a0b841871d7, CreationTimestamp2020-07-15T07:05:55.474288Z] moved to OPEN state
scm_1         | 2020-07-15 07:06:22,224 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:26,583 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:26,861 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 5ee2711e-67fc-4e31-84cc-6a323cdae2ae, Nodes: a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:a9cc35b6-8fcd-4742-851b-c7ef7ff0db4c, CreationTimestamp2020-07-15T07:05:55.366361Z] moved to OPEN state
scm_1         | 2020-07-15 07:06:26,910 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: dfb14656-679c-43e1-a346-0965ba38cc31, Nodes: 872ac602-b542-4fd3-a544-ffbd53b46ee2{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:872ac602-b542-4fd3-a544-ffbd53b46ee2, CreationTimestamp2020-07-15T07:05:54.739902Z] moved to OPEN state
scm_1         | 2020-07-15 07:06:27,119 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f9116165-8b8e-47a5-9e8f-0ae5ff2d7a2b, Nodes: e00f9da5-82a4-43be-9dbb-d8c493d15126{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:e00f9da5-82a4-43be-9dbb-d8c493d15126, CreationTimestamp2020-07-15T07:05:55.310386Z] moved to OPEN state
scm_1         | 2020-07-15 07:06:27,253 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 3152cb4e-5034-4049-acaf-7bda907d73d4, Nodes: 02f82674-a0c2-4773-90e8-73ab39d1c5f5{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:02f82674-a0c2-4773-90e8-73ab39d1c5f5, CreationTimestamp2020-07-15T07:05:55.321957Z] moved to OPEN state
scm_1         | 2020-07-15 07:06:29,182 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:31,762 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:34,404 [IPC Server handler 95 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:36,976 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:39,536 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:42,130 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:44,704 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_2_1  | 2020-07-15 07:09:22,669 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=164,entriesCount=1,lastEntry=(t:1, i:110)
datanode_2_1  | 2020-07-15 07:09:22,681 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=165,entriesCount=1,lastEntry=(t:1, i:111)
datanode_2_1  | 2020-07-15 07:09:22,688 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=166,entriesCount=1,lastEntry=(t:1, i:112)
datanode_2_1  | 2020-07-15 07:09:25,249 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:113)
datanode_2_1  | 2020-07-15 07:09:25,280 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=169,entriesCount=1,lastEntry=(t:1, i:114)
datanode_2_1  | 2020-07-15 07:09:25,283 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=170,entriesCount=1,lastEntry=(t:1, i:115)
datanode_2_1  | 2020-07-15 07:09:25,333 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=171,entriesCount=1,lastEntry=(t:1, i:116)
datanode_2_1  | 2020-07-15 07:09:27,862 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=173,entriesCount=1,lastEntry=(t:1, i:117)
datanode_2_1  | 2020-07-15 07:09:27,863 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=174,entriesCount=1,lastEntry=(t:1, i:118)
datanode_2_1  | 2020-07-15 07:09:27,913 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=175,entriesCount=1,lastEntry=(t:1, i:119)
datanode_2_1  | 2020-07-15 07:09:27,917 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=176,entriesCount=1,lastEntry=(t:1, i:120)
datanode_2_1  | 2020-07-15 07:09:30,450 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=178,entriesCount=1,lastEntry=(t:1, i:121)
datanode_2_1  | 2020-07-15 07:09:30,460 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=179,entriesCount=1,lastEntry=(t:1, i:122)
datanode_2_1  | 2020-07-15 07:09:30,473 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=180,entriesCount=1,lastEntry=(t:1, i:123)
datanode_2_1  | 2020-07-15 07:09:30,481 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=181,entriesCount=1,lastEntry=(t:1, i:124)
datanode_2_1  | 2020-07-15 07:09:35,591 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=184,entriesCount=1,lastEntry=(t:1, i:125)
datanode_2_1  | 2020-07-15 07:09:35,597 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=185,entriesCount=1,lastEntry=(t:1, i:126)
datanode_2_1  | 2020-07-15 07:09:35,606 [java.util.concurrent.ThreadPoolExecutor$Worker@b4de00b[State = -1, empty queue]] WARN server.GrpcLogAppender: 47c0b11d-1167-49f1-92df-2a0b841871d7@group-BD702AAE76FF->02f82674-a0c2-4773-90e8-73ab39d1c5f5-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=186,entriesCount=1,lastEntry=(t:1, i:127)
datanode_2_1  | 2020-07-15 07:11:07,949 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 153.
datanode_2_1  | 2020-07-15 07:11:07,949 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 153.
datanode_2_1  | 2020-07-15 07:11:07,953 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is closed with bcsId 153.
datanode_2_1  | 2020-07-15 07:11:08,003 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 161.
datanode_2_1  | 2020-07-15 07:11:08,003 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 161.
datanode_2_1  | 2020-07-15 07:11:08,008 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is closed with bcsId 161.
scm_1         | 2020-07-15 07:06:47,292 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:49,877 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:52,437 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:55,039 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:06:57,626 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:00,208 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:02,787 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:05,362 [IPC Server handler 96 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:07,981 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:10,565 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:13,111 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:15,665 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:18,250 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:20,802 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:23,362 [IPC Server handler 96 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:25,995 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:28,605 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:31,167 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:33,738 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:36,309 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:38,906 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:41,476 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:44,027 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:46,659 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:49,243 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:49,627 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-15 07:07:49,627 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-15 07:07:51,810 [IPC Server handler 36 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:54,372 [IPC Server handler 96 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:56,948 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:07:59,516 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:02,098 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:04,645 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:07,229 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:09,834 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:12,410 [IPC Server handler 98 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:14,965 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:17,532 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:20,086 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:22,647 [IPC Server handler 36 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:25,216 [IPC Server handler 34 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:27,852 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:30,441 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:33,001 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:35,572 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:38,164 [IPC Server handler 34 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:08:48,253 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:09:03,368 [IPC Server handler 50 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:09:18,541 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:09:33,712 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:09:48,808 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:09:49,628 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-07-15 07:09:49,628 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-07-15 07:10:03,897 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:10:18,989 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:10:26,602 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:10:29,147 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:10:31,708 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:10:34,270 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:10:36,841 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:10:46,978 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:10:54,561 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:11:04,651 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:11:06,276 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1         | 2020-07-15 07:11:06,294 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7
scm_1         | 2020-07-15 07:11:06,295 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 16 milliseconds for processing 10 containers.
scm_1         | 2020-07-15 07:11:06,298 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9
scm_1         | 2020-07-15 07:11:06,299 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #10
scm_1         | 2020-07-15 07:11:07,955 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #7 to CLOSED state, datanode 47c0b11d-1167-49f1-92df-2a0b841871d7{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-07-15 07:11:08,013 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #9 to CLOSED state, datanode 47c0b11d-1167-49f1-92df-2a0b841871d7{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-07-15 07:11:12,255 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-07-15 07:11:14,855 [IPC Server handler 80 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
